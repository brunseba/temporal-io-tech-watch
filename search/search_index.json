{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Temporal.io Enterprise Deployment Guide","text":"<p>Welcome to the comprehensive documentation for deploying Temporal.io in enterprise Kubernetes environments. This guide provides everything you need to design, implement, and operate a production-ready Temporal deployment.</p>"},{"location":"#what-is-temporal","title":"What is Temporal?","text":"<p>Temporal is a distributed, scalable, durable, and highly available orchestration engine that executes asynchronous long-running business logic in a scalable and resilient way. It enables developers to build reliable applications by abstracting away the complexity of distributed systems.</p>"},{"location":"#what-youll-learn","title":"What You'll Learn","text":"<p>This documentation covers:</p> <ul> <li>Architecture Design: Complete system architecture with security, monitoring, and scalability considerations</li> <li>Implementation: Step-by-step deployment guides for production environments</li> <li>Operations: Monitoring, troubleshooting, backup, and disaster recovery procedures</li> <li>Development: Best practices for building workflows and integrating applications</li> <li>Security: Enterprise-grade security implementation with SSO, TLS, and secrets management</li> <li>GitOps: Automated deployment strategies using ArgoCD and modern DevOps practices</li> </ul>"},{"location":"#target-audience","title":"Target Audience","text":"<p>This guide is designed for:</p> <ul> <li>Developers building workflows and activities</li> <li>Product Owners defining business requirements</li> <li>Architects designing system integration</li> <li>SRE/DevOps Engineers operating and maintaining infrastructure</li> </ul>"},{"location":"#architecture-overview","title":"Architecture Overview","text":"<p>Our target architecture includes:</p> <ul> <li>Temporal Backend: Deployed in <code>temporal-backend</code> namespace</li> <li>Business Applications: Deployed in <code>temporal-product</code> namespace</li> <li>Database: PostgreSQL for persistence and visibility</li> <li>Search: Elasticsearch for advanced visibility</li> <li>Monitoring: Prometheus + Grafana + OpenTelemetry</li> <li>Security: Authentik SSO + HashiCorp Vault + cert-manager</li> <li>GitOps: ArgoCD for deployment automation</li> </ul>"},{"location":"#quick-navigation","title":"Quick Navigation","text":""},{"location":"#getting-started","title":"\ud83d\ude80 Getting Started","text":"<p>New to this deployment? Start with our Getting Started section.</p>"},{"location":"#architecture-design","title":"\ud83c\udfd7\ufe0f Architecture &amp; Design","text":"<p>Understand the system architecture and design decisions in our Architecture section.</p>"},{"location":"#implementation","title":"\ud83d\udccb Implementation","text":"<p>Follow our comprehensive Implementation Guide for complete deployment instructions.</p>"},{"location":"#operations","title":"\u2699\ufe0f Operations","text":"<p>Learn about monitoring, troubleshooting, and maintenance in the Operations section.</p>"},{"location":"#security","title":"\ud83d\udd12 Security","text":"<p>Implement enterprise-grade security with our Security guides.</p>"},{"location":"#gitops","title":"\ud83d\udd04 GitOps","text":"<p>Set up automated deployments with GitOps &amp; Deployment practices.</p>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#enterprise-grade-security","title":"Enterprise-Grade Security","text":"<ul> <li>SSO integration with Authentik</li> <li>HashiCorp Vault for secrets management</li> <li>End-to-end TLS encryption</li> <li>Network policies and RBAC</li> </ul>"},{"location":"#production-ready-monitoring","title":"Production-Ready Monitoring","text":"<ul> <li>Prometheus metrics collection</li> <li>Grafana dashboards</li> <li>OpenTelemetry tracing</li> <li>Custom business metrics</li> </ul>"},{"location":"#high-availability","title":"High Availability","text":"<ul> <li>Multi-node Kubernetes deployment</li> <li>Database replication</li> <li>Auto-scaling capabilities</li> <li>Disaster recovery procedures</li> </ul>"},{"location":"#developer-experience","title":"Developer Experience","text":"<ul> <li>Python SDK integration</li> <li>FastAPI service templates</li> <li>Testing frameworks</li> <li>CI/CD pipeline templates</li> </ul>"},{"location":"#technology-stack","title":"Technology Stack","text":"Component Technology Purpose Orchestration Platform Kubernetes Container orchestration Workflow Engine Temporal.io Workflow orchestration Database PostgreSQL Persistence and visibility Search Elasticsearch Advanced search capabilities Monitoring Prometheus + Grafana Metrics and dashboards Security Authentik + Vault Authentication and secrets GitOps ArgoCD Automated deployment Service Mesh Istio (Optional) Service communication Package Manager Helm Kubernetes application management"},{"location":"#prerequisites","title":"Prerequisites","text":"<p>Before starting, ensure you have:</p> <ul> <li>Kubernetes cluster (v1.25+)</li> <li>Helm 3.x installed</li> <li>GitLab or similar Git repository</li> <li>JFrog Artifactory or container registry</li> <li>Basic understanding of Kubernetes concepts</li> </ul>"},{"location":"#whats-new","title":"What's New","text":"<ul> <li>Temporal 1.29.1 (October 2025): Eager Workflow Start (GA), Task Queue Fairness, Slimmed Docker Images</li> <li>Temporal 1.28.x (June 2025): Update-With-Start (GA), Worker Versioning (Preview), Priority Task Queues</li> <li>Temporal 1.27.x (February 2025): Nexus (GA), Enhanced Safe Deploys</li> <li>Temporal 1.26.x (December 2024): Workflow Update API (GA)</li> </ul> <p>For detailed information, see What's New in Temporal.io.</p>"},{"location":"#temporal-cloud","title":"Temporal Cloud","text":"<p>Temporal Cloud is a fully managed, hosted version of Temporal that eliminates operational overhead:</p> <ul> <li>No Infrastructure Management: Temporal handles servers, databases, and scaling</li> <li>Global Availability: Multi-region deployments with automatic failover</li> <li>Enterprise Security: SOC 2 Type 2 certified, HIPAA compliant</li> <li>Built-in Observability: Metrics, logging, and distributed tracing included</li> <li>Free Trial: $1,000 in credits for new users</li> </ul> <p>Learn more at temporal.io or review our self-hosted deployment guide.</p>"},{"location":"#support-and-contributing","title":"Support and Contributing","text":"<ul> <li>Documentation Issues: Open an issue in the GitLab repository</li> <li>Feature Requests: Submit through GitLab issues</li> <li>Security Issues: Contact the security team directly</li> <li>Temporal Community: community.temporal.io</li> <li>Official Documentation: docs.temporal.io</li> </ul>"},{"location":"#next-steps","title":"Next Steps","text":"<ol> <li>Start with Prerequisites: Review Prerequisites</li> <li>Understand the Architecture: Read System Architecture</li> <li>Follow the Implementation: Use the Complete Implementation Guide</li> <li>Set up Monitoring: Configure Monitoring &amp; Observability</li> </ol> <p>Ready to deploy Temporal.io in your enterprise environment? </p> <p>Get Started View Architecture</p>"},{"location":"temporal-design-implementation-guide/","title":"Temporal.io Design and Implementation Guide","text":""},{"location":"temporal-design-implementation-guide/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>Architecture Design</li> <li>Infrastructure Requirements</li> <li>Security Architecture</li> <li>Deployment Strategy</li> <li>Implementation Guide</li> <li>Monitoring and Observability</li> <li>Development Workflow</li> <li>Operational Procedures</li> <li>Troubleshooting</li> </ol>"},{"location":"temporal-design-implementation-guide/#overview","title":"Overview","text":"<p>This guide provides a comprehensive design and implementation strategy for deploying Temporal.io in a production-ready Kubernetes environment with enterprise-grade security, monitoring, and DevOps practices.</p>"},{"location":"temporal-design-implementation-guide/#target-architecture","title":"Target Architecture","text":"<ul> <li>Temporal Backend: Deployed in <code>temporal-backend</code> namespace</li> <li>Business Applications: Deployed in <code>temporal-product</code> namespace</li> <li>Database: PostgreSQL for persistence and visibility</li> <li>Search: Elasticsearch for advanced visibility</li> <li>Monitoring: Prometheus + Grafana + OpenTelemetry</li> <li>Security: Authentik SSO + HashiCorp Vault + cert-manager</li> <li>GitOps: ArgoCD for deployment automation</li> </ul>"},{"location":"temporal-design-implementation-guide/#personas","title":"Personas","text":"<ul> <li>Developers: Build workflows and activities</li> <li>Product Owners: Define business requirements</li> <li>Architects: Design system integration</li> <li>SRE/DevOps: Operate and maintain infrastructure</li> </ul>"},{"location":"temporal-design-implementation-guide/#architecture-design","title":"Architecture Design","text":""},{"location":"temporal-design-implementation-guide/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>graph TB\n    subgraph \"External Systems\"\n        A[API Manager&lt;br/&gt;Gravitee.io]\n        B[SSO&lt;br/&gt;Authentik]\n        C[Secrets&lt;br/&gt;HashiCorp Vault]\n        D[GitLab CI/CD]\n        E[JFrog Artifactory]\n    end\n\n    subgraph \"Kubernetes Cluster\"\n        subgraph \"temporal-backend namespace\"\n            F[Temporal Server]\n            G[Temporal Web UI]\n            H[Admin Tools]\n            I[PostgreSQL]\n            J[Elasticsearch]\n        end\n\n        subgraph \"temporal-product namespace\"\n            K[Temporal Worker]\n            L[FastAPI Service]\n        end\n\n        subgraph \"monitoring namespace\"\n            M[Prometheus]\n            N[Grafana]\n            O[OpenTelemetry]\n        end\n\n        subgraph \"security namespace\"\n            P[cert-manager]\n            Q[external-secrets]\n        end\n    end\n\n    A --&gt; G\n    A --&gt; L\n    B --&gt; A\n    C --&gt; Q\n    D --&gt; E\n    E --&gt; K\n    E --&gt; L\n    F --&gt; I\n    F --&gt; J\n    K --&gt; F\n    L --&gt; F\n    M --&gt; F\n    M --&gt; K\n    M --&gt; L\n    N --&gt; M\n    O --&gt; M</code></pre>"},{"location":"temporal-design-implementation-guide/#component-architecture","title":"Component Architecture","text":""},{"location":"temporal-design-implementation-guide/#temporal-server-components","title":"Temporal Server Components","text":"<ol> <li>Frontend Service: gRPC API endpoint for clients</li> <li>History Service: Manages workflow execution history</li> <li>Matching Service: Task queue management</li> <li>Worker Service: Internal background operations</li> </ol>"},{"location":"temporal-design-implementation-guide/#database-schema","title":"Database Schema","text":"<ul> <li>Default Store: Main temporal database (PostgreSQL)</li> <li>Visibility Store: Search and filtering (PostgreSQL + Elasticsearch)</li> </ul>"},{"location":"temporal-design-implementation-guide/#security-layers","title":"Security Layers","text":"<ol> <li>Network: Kubernetes NetworkPolicies</li> <li>Authentication: SSO integration with Authentik</li> <li>Authorization: RBAC + Temporal authorization</li> <li>Encryption: TLS everywhere with cert-manager</li> <li>Secrets: External Secrets with Vault integration</li> </ol>"},{"location":"temporal-design-implementation-guide/#infrastructure-requirements","title":"Infrastructure Requirements","text":""},{"location":"temporal-design-implementation-guide/#kubernetes-cluster-specifications","title":"Kubernetes Cluster Specifications","text":""},{"location":"temporal-design-implementation-guide/#minimum-requirements","title":"Minimum Requirements","text":"<ul> <li>Nodes: 3+ worker nodes</li> <li>CPU: 8+ cores total</li> <li>Memory: 16GB+ total</li> <li>Storage: 100GB+ persistent storage</li> <li>Kubernetes Version: 1.25+</li> </ul>"},{"location":"temporal-design-implementation-guide/#production-requirements","title":"Production Requirements","text":"<ul> <li>Nodes: 6+ worker nodes (multi-AZ)</li> <li>CPU: 32+ cores total</li> <li>Memory: 64GB+ total</li> <li>Storage: 500GB+ high-performance SSD</li> <li>Network: 10Gbps between nodes</li> </ul>"},{"location":"temporal-design-implementation-guide/#resource-allocation","title":"Resource Allocation","text":""},{"location":"temporal-design-implementation-guide/#temporal-backend-namespace","title":"temporal-backend namespace","text":"<pre><code>resources:\n  temporal-server:\n    limits:\n      cpu: 2000m\n      memory: 4Gi\n    requests:\n      cpu: 1000m\n      memory: 2Gi\n  temporal-web:\n    limits:\n      cpu: 500m\n      memory: 1Gi\n    requests:\n      cpu: 250m\n      memory: 512Mi\n  postgresql:\n    limits:\n      cpu: 2000m\n      memory: 8Gi\n    requests:\n      cpu: 1000m\n      memory: 4Gi\n  elasticsearch:\n    limits:\n      cpu: 1000m\n      memory: 4Gi\n    requests:\n      cpu: 500m\n      memory: 2Gi\n</code></pre>"},{"location":"temporal-design-implementation-guide/#temporal-product-namespace","title":"temporal-product namespace","text":"<pre><code>resources:\n  temporal-worker:\n    limits:\n      cpu: 1000m\n      memory: 2Gi\n    requests:\n      cpu: 500m\n      memory: 1Gi\n  fastapi-service:\n    limits:\n      cpu: 500m\n      memory: 1Gi\n    requests:\n      cpu: 250m\n      memory: 512Mi\n</code></pre>"},{"location":"temporal-design-implementation-guide/#security-architecture","title":"Security Architecture","text":""},{"location":"temporal-design-implementation-guide/#authentication-authorization","title":"Authentication &amp; Authorization","text":""},{"location":"temporal-design-implementation-guide/#sso-integration-with-authentik","title":"SSO Integration with Authentik","text":"<pre><code># authentik-config.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: temporal-auth-config\n  namespace: temporal-backend\ndata:\n  auth.yaml: |\n    authorization:\n      jwtKeyProvider:\n        keySourceURIs:\n          - \"https://authentik.example.com/application/o/temporal/.well-known/jwks.json\"\n        refreshInterval: \"1m\"\n      permissionsClaimName: \"permissions\"\n      authorizer: \"default\"\n      claimMapper: \"default\"\n</code></pre>"},{"location":"temporal-design-implementation-guide/#rbac-configuration","title":"RBAC Configuration","text":"<pre><code># temporal-rbac.yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  namespace: temporal-backend\n  name: temporal-operator\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"services\", \"configmaps\", \"secrets\"]\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n- apiGroups: [\"apps\"]\n  resources: [\"deployments\", \"statefulsets\"]\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n</code></pre>"},{"location":"temporal-design-implementation-guide/#tls-configuration","title":"TLS Configuration","text":""},{"location":"temporal-design-implementation-guide/#cert-manager-integration","title":"cert-manager Integration","text":"<pre><code># temporal-certificates.yaml\napiVersion: cert-manager.io/v1\nkind: Certificate\nmetadata:\n  name: temporal-server-tls\n  namespace: temporal-backend\nspec:\n  secretName: temporal-server-tls-secret\n  issuerRef:\n    name: letsencrypt-prod\n    kind: ClusterIssuer\n  dnsNames:\n    - temporal.example.com\n    - temporal-frontend.temporal-backend.svc.cluster.local\n</code></pre>"},{"location":"temporal-design-implementation-guide/#secrets-management","title":"Secrets Management","text":""},{"location":"temporal-design-implementation-guide/#external-secrets-with-vault","title":"External Secrets with Vault","text":"<pre><code># vault-secret-store.yaml\napiVersion: external-secrets.io/v1beta1\nkind: SecretStore\nmetadata:\n  name: vault-backend\n  namespace: temporal-backend\nspec:\n  provider:\n    vault:\n      server: \"https://vault.example.com\"\n      path: \"kv\"\n      version: \"v2\"\n      auth:\n        kubernetes:\n          mountPath: \"kubernetes\"\n          role: \"temporal-backend\"\n</code></pre> <pre><code># temporal-db-secret.yaml\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: temporal-db-credentials\n  namespace: temporal-backend\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: temporal-db-secret\n    creationPolicy: Owner\n  data:\n    - secretKey: username\n      remoteRef:\n        key: temporal/database\n        property: username\n    - secretKey: password\n      remoteRef:\n        key: temporal/database\n        property: password\n</code></pre>"},{"location":"temporal-design-implementation-guide/#deployment-strategy","title":"Deployment Strategy","text":""},{"location":"temporal-design-implementation-guide/#gitops-with-argocd","title":"GitOps with ArgoCD","text":""},{"location":"temporal-design-implementation-guide/#application-structure","title":"Application Structure","text":"<pre><code>temporal-infrastructure/\n\u251c\u2500\u2500 applications/\n\u2502   \u251c\u2500\u2500 temporal-backend.yaml\n\u2502   \u251c\u2500\u2500 temporal-product.yaml\n\u2502   \u2514\u2500\u2500 monitoring.yaml\n\u251c\u2500\u2500 base/\n\u2502   \u251c\u2500\u2500 temporal-server/\n\u2502   \u251c\u2500\u2500 postgresql/\n\u2502   \u251c\u2500\u2500 elasticsearch/\n\u2502   \u2514\u2500\u2500 monitoring/\n\u251c\u2500\u2500 overlays/\n\u2502   \u251c\u2500\u2500 development/\n\u2502   \u251c\u2500\u2500 staging/\n\u2502   \u2514\u2500\u2500 production/\n\u2514\u2500\u2500 scripts/\n    \u251c\u2500\u2500 deploy.sh\n    \u2514\u2500\u2500 validate.sh\n</code></pre>"},{"location":"temporal-design-implementation-guide/#argocd-application","title":"ArgoCD Application","text":"<pre><code># argocd-temporal-app.yaml\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: temporal-backend\n  namespace: argocd\nspec:\n  project: default\n  source:\n    repoURL: https://gitlab.example.com/infrastructure/temporal-deploy.git\n    targetRevision: HEAD\n    path: overlays/production\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: temporal-backend\n  syncPolicy:\n    automated:\n      prune: true\n      selfHeal: true\n    syncOptions:\n      - CreateNamespace=true\n</code></pre>"},{"location":"temporal-design-implementation-guide/#namespace-configuration","title":"Namespace Configuration","text":""},{"location":"temporal-design-implementation-guide/#temporal-backend-namespace_1","title":"temporal-backend namespace","text":"<pre><code># temporal-backend-namespace.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: temporal-backend\n  labels:\n    name: temporal-backend\n    tier: backend\n    monitoring: enabled\n---\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: temporal-backend-policy\n  namespace: temporal-backend\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-product\n    - namespaceSelector:\n        matchLabels:\n          name: monitoring\n  egress:\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 53\n    - protocol: UDP\n      port: 53\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-backend\n</code></pre>"},{"location":"temporal-design-implementation-guide/#temporal-product-namespace_1","title":"temporal-product namespace","text":"<pre><code># temporal-product-namespace.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: temporal-product\n  labels:\n    name: temporal-product\n    tier: application\n    monitoring: enabled\n---\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: temporal-product-policy\n  namespace: temporal-product\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: monitoring\n  egress:\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-backend\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 53\n    - protocol: UDP\n      port: 53\n</code></pre>"},{"location":"temporal-design-implementation-guide/#implementation-guide","title":"Implementation Guide","text":""},{"location":"temporal-design-implementation-guide/#step-1-prerequisites-setup","title":"Step 1: Prerequisites Setup","text":""},{"location":"temporal-design-implementation-guide/#11-install-required-tools","title":"1.1 Install Required Tools","text":"<pre><code># Helm\ncurl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash\n\n# ArgoCD CLI\ncurl -sSL -o argocd-linux-amd64 https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-amd64\nsudo install -m 555 argocd-linux-amd64 /usr/local/bin/argocd\n\n# External Secrets Operator\nhelm repo add external-secrets https://charts.external-secrets.io\n</code></pre>"},{"location":"temporal-design-implementation-guide/#12-cluster-preparation","title":"1.2 Cluster Preparation","text":"<pre><code># Create namespaces\nkubectl create namespace temporal-backend\nkubectl create namespace temporal-product\nkubectl create namespace monitoring\nkubectl create namespace security\n\n# Label namespaces\nkubectl label namespace temporal-backend tier=backend monitoring=enabled\nkubectl label namespace temporal-product tier=application monitoring=enabled\nkubectl label namespace monitoring tier=monitoring\nkubectl label namespace security tier=security\n</code></pre>"},{"location":"temporal-design-implementation-guide/#step-2-security-infrastructure","title":"Step 2: Security Infrastructure","text":""},{"location":"temporal-design-implementation-guide/#21-cert-manager-installation","title":"2.1 cert-manager Installation","text":"<pre><code># Install cert-manager\nhelm repo add jetstack https://charts.jetstack.io\nhelm repo update\nhelm install cert-manager jetstack/cert-manager \\\n  --namespace cert-manager \\\n  --create-namespace \\\n  --version v1.13.0 \\\n  --set installCRDs=true\n</code></pre>"},{"location":"temporal-design-implementation-guide/#22-external-secrets-operator","title":"2.2 External Secrets Operator","text":"<pre><code># Install external-secrets\nhelm install external-secrets external-secrets/external-secrets \\\n  --namespace external-secrets-system \\\n  --create-namespace \\\n  --set installCRDs=true\n</code></pre>"},{"location":"temporal-design-implementation-guide/#23-setup-vault-integration","title":"2.3 Setup Vault Integration","text":"<pre><code># Apply Vault SecretStore\nkubectl apply -f vault-secret-store.yaml\n\n# Apply External Secrets\nkubectl apply -f temporal-db-secret.yaml\n</code></pre>"},{"location":"temporal-design-implementation-guide/#step-3-database-setup","title":"Step 3: Database Setup","text":""},{"location":"temporal-design-implementation-guide/#31-postgresql-installation","title":"3.1 PostgreSQL Installation","text":"<pre><code># postgresql-values.yaml\npostgresql:\n  auth:\n    existingSecret: \"temporal-db-secret\"\n    secretKeys:\n      adminPasswordKey: \"password\"\n      userPasswordKey: \"password\"\n    username: \"temporal\"\n    database: \"temporal\"\n  primary:\n    persistence:\n      enabled: true\n      size: 100Gi\n      storageClass: \"fast-ssd\"\n    resources:\n      limits:\n        cpu: 2000m\n        memory: 8Gi\n      requests:\n        cpu: 1000m\n        memory: 4Gi\n  metrics:\n    enabled: true\n    serviceMonitor:\n      enabled: true\n</code></pre> <pre><code># Install PostgreSQL\nhelm repo add bitnami https://charts.bitnami.com/bitnami\nhelm install postgresql bitnami/postgresql \\\n  --namespace temporal-backend \\\n  --values postgresql-values.yaml\n</code></pre>"},{"location":"temporal-design-implementation-guide/#32-elasticsearch-installation","title":"3.2 Elasticsearch Installation","text":"<pre><code># elasticsearch-values.yaml\nreplicas: 3\nminimumMasterNodes: 2\nesConfig:\n  elasticsearch.yml: |\n    cluster.name: \"temporal-es\"\n    network.host: 0.0.0.0\n    discovery.seed_hosts: \"elasticsearch-master-headless\"\n    cluster.initial_master_nodes: \"elasticsearch-master-0,elasticsearch-master-1,elasticsearch-master-2\"\npersistence:\n  enabled: true\n  size: 50Gi\n  storageClass: \"fast-ssd\"\nresources:\n  limits:\n    cpu: 1000m\n    memory: 4Gi\n  requests:\n    cpu: 500m\n    memory: 2Gi\n</code></pre> <pre><code># Install Elasticsearch\nhelm repo add elastic https://helm.elastic.co\nhelm install elasticsearch elastic/elasticsearch \\\n  --namespace temporal-backend \\\n  --values elasticsearch-values.yaml\n</code></pre>"},{"location":"temporal-design-implementation-guide/#step-4-temporal-server-deployment","title":"Step 4: Temporal Server Deployment","text":""},{"location":"temporal-design-implementation-guide/#41-temporal-configuration","title":"4.1 Temporal Configuration","text":"<pre><code># temporal-values.yaml\nserver:\n  enabled: true\n  replicaCount: 3\n    image:\n      repository: temporalio/server\n      tag: \"1.29.1\"\n\n  resources:\n    limits:\n      cpu: 2000m\n      memory: 4Gi\n    requests:\n      cpu: 1000m\n      memory: 2Gi\n\n  config:\n    logLevel: \"info\"\n    numHistoryShards: 512\n\n    persistence:\n      default:\n        driver: \"sql\"\n        sql:\n          driver: \"postgres12\"\n          host: \"postgresql\"\n          port: 5432\n          database: \"temporal\"\n          existingSecret: \"temporal-db-secret\"\n          maxConns: 20\n          maxIdleConns: 20\n          maxConnLifetime: \"1h\"\n\n      visibility:\n        driver: \"sql\"\n        sql:\n          driver: \"postgres12\"\n          host: \"postgresql\"\n          port: 5432\n          database: \"temporal_visibility\"\n          existingSecret: \"temporal-db-secret\"\n          maxConns: 20\n          maxIdleConns: 20\n          maxConnLifetime: \"1h\"\n\n    # TLS Configuration\n    tls:\n      frontend:\n        server:\n          certFile: /etc/temporal/certs/tls.crt\n          keyFile: /etc/temporal/certs/tls.key\n          requireClientAuth: false\n        client:\n          serverName: temporal-frontend\n          rootCaFiles:\n            - /etc/temporal/certs/ca.crt\n\n  additionalVolumes:\n    - name: temporal-certs\n      secret:\n        secretName: temporal-server-tls-secret\n\n  additionalVolumeMounts:\n    - name: temporal-certs\n      mountPath: /etc/temporal/certs\n      readOnly: true\n\n  frontend:\n    service:\n      type: ClusterIP\n      port: 7233\n    ingress:\n      enabled: true\n      className: \"nginx\"\n      annotations:\n        nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n        nginx.ingress.kubernetes.io/backend-protocol: \"GRPC\"\n      hosts:\n        - host: temporal-api.example.com\n          paths:\n            - path: /\n              pathType: Prefix\n      tls:\n        - secretName: temporal-api-tls\n          hosts:\n            - temporal-api.example.com\n\nweb:\n  enabled: true\n  replicaCount: 2\n  image:\n    repository: temporalio/ui\n    tag: 2.37.1\n\n  resources:\n    limits:\n      cpu: 500m\n      memory: 1Gi\n    requests:\n      cpu: 250m\n      memory: 512Mi\n\n  service:\n    type: ClusterIP\n    port: 8080\n\n  ingress:\n    enabled: true\n    className: \"nginx\"\n    annotations:\n      nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    hosts:\n      - host: temporal-ui.example.com\n        paths:\n          - path: /\n            pathType: Prefix\n    tls:\n      - secretName: temporal-ui-tls\n        hosts:\n          - temporal-ui.example.com\n\n# Disable embedded databases\ncassandra:\n  enabled: false\n\nmysql:\n  enabled: false\n\n# Enable monitoring\nprometheus:\n  enabled: false  # Using external Prometheus\n\ngrafana:\n  enabled: false  # Using external Grafana\n\nelasticsearch:\n  enabled: false  # Using external Elasticsearch\n  external: true\n  host: \"elasticsearch-master-headless\"\n  port: \"9200\"\n  version: \"v7\"\n  scheme: \"http\"\n  logLevel: \"error\"\n  visibilityIndex: \"temporal_visibility_v1_prod\"\n</code></pre>"},{"location":"temporal-design-implementation-guide/#42-deploy-temporal-server","title":"4.2 Deploy Temporal Server","text":"<pre><code># Add Temporal Helm repository\nhelm repo add temporalio https://go.temporal.io/helm-charts\nhelm repo update\n\n# Install Temporal\nhelm install temporal temporalio/temporal \\\n  --namespace temporal-backend \\\n  --values temporal-values.yaml \\\n  --wait --timeout=10m\n</code></pre>"},{"location":"temporal-design-implementation-guide/#step-5-monitoring-setup","title":"Step 5: Monitoring Setup","text":""},{"location":"temporal-design-implementation-guide/#51-prometheus-configuration","title":"5.1 Prometheus Configuration","text":"<pre><code># prometheus-values.yaml\nprometheus:\n  prometheusSpec:\n    serviceMonitorSelectorNilUsesHelmValues: false\n    serviceMonitorSelector: {}\n    retention: 30d\n    storageSpec:\n      volumeClaimTemplate:\n        spec:\n          storageClassName: fast-ssd\n          accessModes: [\"ReadWriteOnce\"]\n          resources:\n            requests:\n              storage: 100Gi\n\n    additionalScrapeConfigs:\n      - job_name: 'temporal-server'\n        kubernetes_sd_configs:\n          - role: pod\n            namespaces:\n              names:\n                - temporal-backend\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\n            action: keep\n            regex: true\n          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]\n            action: replace\n            target_label: __metrics_path__\n            regex: (.+)\n\ngrafana:\n  adminPassword: \"admin123\"  # Change in production\n  persistence:\n    enabled: true\n    size: 10Gi\n    storageClassName: fast-ssd\n\n  datasources:\n    datasources.yaml:\n      apiVersion: 1\n      datasources:\n        - name: Prometheus\n          type: prometheus\n          url: http://prometheus-server:80\n          access: proxy\n          isDefault: true\n\n  dashboardProviders:\n    dashboardproviders.yaml:\n      apiVersion: 1\n      providers:\n        - name: 'temporal'\n          orgId: 1\n          folder: 'Temporal'\n          type: file\n          disableDeletion: false\n          editable: true\n          options:\n            path: /var/lib/grafana/dashboards/temporal\n\n  dashboards:\n    temporal:\n      temporal-general:\n        url: https://raw.githubusercontent.com/temporalio/dashboards/helm/server/server-general.json\n        datasource: Prometheus\n</code></pre>"},{"location":"temporal-design-implementation-guide/#52-install-monitoring-stack","title":"5.2 Install Monitoring Stack","text":"<pre><code># Install Prometheus Operator\nhelm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm install monitoring prometheus-community/kube-prometheus-stack \\\n  --namespace monitoring \\\n  --values prometheus-values.yaml \\\n  --wait --timeout=10m\n</code></pre>"},{"location":"temporal-design-implementation-guide/#step-6-application-deployment","title":"Step 6: Application Deployment","text":""},{"location":"temporal-design-implementation-guide/#61-temporal-worker-application","title":"6.1 Temporal Worker Application","text":"<pre><code># temporal-worker-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: temporal-worker\n  namespace: temporal-product\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: temporal-worker\n  template:\n    metadata:\n      labels:\n        app: temporal-worker\n      annotations:\n        prometheus.io/scrape: \"true\"\n        prometheus.io/port: \"8080\"\n        prometheus.io/path: \"/metrics\"\n    spec:\n      containers:\n      - name: temporal-worker\n        image: your-registry.com/temporal-worker:latest\n        ports:\n        - containerPort: 8080\n          name: metrics\n        env:\n        - name: TEMPORAL_HOST\n          value: \"temporal-frontend:7233\"\n        - name: TEMPORAL_NAMESPACE\n          value: \"default\"\n        resources:\n          limits:\n            cpu: 1000m\n            memory: 2Gi\n          requests:\n            cpu: 500m\n            memory: 1Gi\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8080\n          initialDelaySeconds: 5\n          periodSeconds: 5\n</code></pre>"},{"location":"temporal-design-implementation-guide/#62-fastapi-service","title":"6.2 FastAPI Service","text":"<pre><code># fastapi-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: fastapi-service\n  namespace: temporal-product\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: fastapi-service\n  template:\n    metadata:\n      labels:\n        app: fastapi-service\n      annotations:\n        prometheus.io/scrape: \"true\"\n        prometheus.io/port: \"8000\"\n        prometheus.io/path: \"/metrics\"\n    spec:\n      containers:\n      - name: fastapi\n        image: your-registry.com/fastapi-service:latest\n        ports:\n        - containerPort: 8000\n          name: http\n        - containerPort: 8080\n          name: metrics\n        env:\n        - name: TEMPORAL_HOST\n          value: \"temporal-frontend.temporal-backend:7233\"\n        - name: DATABASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: app-database-secret\n              key: url\n        resources:\n          limits:\n            cpu: 500m\n            memory: 1Gi\n          requests:\n            cpu: 250m\n            memory: 512Mi\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8000\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8000\n          initialDelaySeconds: 5\n          periodSeconds: 5\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: fastapi-service\n  namespace: temporal-product\nspec:\n  selector:\n    app: fastapi-service\n  ports:\n  - name: http\n    port: 80\n    targetPort: 8000\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: fastapi-ingress\n  namespace: temporal-product\n  annotations:\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - api.example.com\n    secretName: fastapi-tls\n  rules:\n  - host: api.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: fastapi-service\n            port:\n              number: 80\n</code></pre>"},{"location":"temporal-design-implementation-guide/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"temporal-design-implementation-guide/#opentelemetry-integration","title":"OpenTelemetry Integration","text":""},{"location":"temporal-design-implementation-guide/#61-opentelemetry-collector","title":"6.1 OpenTelemetry Collector","text":"<pre><code># otel-collector.yaml\napiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\n  name: temporal-otel\n  namespace: monitoring\nspec:\n  config: |\n    receivers:\n      prometheus:\n        config:\n          scrape_configs:\n          - job_name: 'temporal-metrics'\n            kubernetes_sd_configs:\n            - role: pod\n              namespaces:\n                names:\n                - temporal-backend\n                - temporal-product\n\n    processors:\n      batch:\n      resource:\n        attributes:\n        - key: service.name\n          from_attribute: __meta_kubernetes_pod_label_app\n          action: insert\n\n    exporters:\n      prometheus:\n        endpoint: \"0.0.0.0:8889\"\n      jaeger:\n        endpoint: \"jaeger-collector:14250\"\n        tls:\n          insecure: true\n\n    service:\n      pipelines:\n        metrics:\n          receivers: [prometheus]\n          processors: [batch, resource]\n          exporters: [prometheus]\n        traces:\n          receivers: [otlp]\n          processors: [batch, resource]\n          exporters: [jaeger]\n</code></pre>"},{"location":"temporal-design-implementation-guide/#custom-dashboards","title":"Custom Dashboards","text":""},{"location":"temporal-design-implementation-guide/#62-temporal-business-metrics-dashboard","title":"6.2 Temporal Business Metrics Dashboard","text":"<pre><code>{\n  \"dashboard\": {\n    \"title\": \"Temporal Business Metrics\",\n    \"panels\": [\n      {\n        \"title\": \"Workflow Executions\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(temporal_workflow_started_total[5m])\",\n            \"legendFormat\": \"Started\"\n          },\n          {\n            \"expr\": \"rate(temporal_workflow_completed_total[5m])\",\n            \"legendFormat\": \"Completed\"\n          },\n          {\n            \"expr\": \"rate(temporal_workflow_failed_total[5m])\",\n            \"legendFormat\": \"Failed\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Task Queue Lag\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"temporal_task_queue_lag\",\n            \"legendFormat\": \"{{task_queue}}\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Worker Health\",\n        \"type\": \"stat\",\n        \"targets\": [\n          {\n            \"expr\": \"up{job=\\\"temporal-worker\\\"}\",\n            \"legendFormat\": \"Worker Instances\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"temporal-design-implementation-guide/#development-workflow","title":"Development Workflow","text":""},{"location":"temporal-design-implementation-guide/#git-workflow-with-conventional-commits","title":"Git Workflow with Conventional Commits","text":""},{"location":"temporal-design-implementation-guide/#71-branch-strategy","title":"7.1 Branch Strategy","text":"<pre><code>main (production)\n\u251c\u2500\u2500 develop (integration)\n\u251c\u2500\u2500 feature/temporal-worker-enhancement\n\u251c\u2500\u2500 hotfix/critical-bug-fix\n\u2514\u2500\u2500 release/v1.2.0\n</code></pre>"},{"location":"temporal-design-implementation-guide/#72-conventional-commit-format","title":"7.2 Conventional Commit Format","text":"<pre><code>type(scope): description\n\n[optional body]\n\n[optional footer(s)]\n</code></pre> <p>Types: - <code>feat</code>: New feature - <code>fix</code>: Bug fix - <code>docs</code>: Documentation changes - <code>style</code>: Code style changes - <code>refactor</code>: Code refactoring - <code>test</code>: Test additions/modifications - <code>chore</code>: Maintenance tasks</p> <p>Examples: <pre><code>git commit -m \"feat(worker): add retry mechanism for failed activities\"\ngit commit -m \"fix(api): resolve connection timeout issue\"\ngit commit -m \"docs(deployment): update helm values documentation\"\n</code></pre></p>"},{"location":"temporal-design-implementation-guide/#73-semantic-versioning","title":"7.3 Semantic Versioning","text":"<ul> <li>MAJOR: Breaking changes (v2.0.0)</li> <li>MINOR: New features (v1.1.0)</li> <li>PATCH: Bug fixes (v1.0.1)</li> </ul>"},{"location":"temporal-design-implementation-guide/#74-cicd-pipeline","title":"7.4 CI/CD Pipeline","text":"<pre><code># .gitlab-ci.yml\nstages:\n  - validate\n  - test\n  - build\n  - security\n  - deploy\n\nvariables:\n  DOCKER_REGISTRY: \"jfrog.example.com\"\n  HELM_REPO: \"jfrog.example.com/helm\"\n\nvalidate:\n  stage: validate\n  script:\n    - conventional-commit-lint\n    - helm lint charts/temporal-worker\n    - yaml-lint kubernetes/\n\ntest:\n  stage: test\n  script:\n    - uv run pytest tests/\n    - uv run coverage report --fail-under=80\n\nbuild:\n  stage: build\n  script:\n    - docker build -t $DOCKER_REGISTRY/temporal-worker:$CI_COMMIT_SHA .\n    - docker push $DOCKER_REGISTRY/temporal-worker:$CI_COMMIT_SHA\n    - helm package charts/temporal-worker\n    - helm push temporal-worker-*.tgz oci://$HELM_REPO\n\nsecurity-scan:\n  stage: security\n  script:\n    - trivy image $DOCKER_REGISTRY/temporal-worker:$CI_COMMIT_SHA\n    - helm scan charts/temporal-worker\n\ndeploy-dev:\n  stage: deploy\n  environment: development\n  script:\n    - argocd app sync temporal-worker-dev\n  only:\n    - develop\n\ndeploy-prod:\n  stage: deploy\n  environment: production\n  script:\n    - argocd app sync temporal-worker-prod\n  only:\n    - main\n  when: manual\n</code></pre>"},{"location":"temporal-design-implementation-guide/#python-development-setup","title":"Python Development Setup","text":""},{"location":"temporal-design-implementation-guide/#75-project-structure","title":"7.5 Project Structure","text":"<pre><code>temporal-worker/\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 uv.lock\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 worker/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 activities.py\n\u2502   \u2502   \u251c\u2500\u2500 workflows.py\n\u2502   \u2502   \u2514\u2500\u2500 main.py\n\u2502   \u2514\u2500\u2500 shared/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 models.py\n\u2502       \u2514\u2500\u2500 utils.py\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 test_activities.py\n\u2502   \u251c\u2500\u2500 test_workflows.py\n\u2502   \u2514\u2500\u2500 conftest.py\n\u251c\u2500\u2500 docker/\n\u2502   \u2514\u2500\u2500 Dockerfile\n\u2514\u2500\u2500 k8s/\n    \u251c\u2500\u2500 deployment.yaml\n    \u2514\u2500\u2500 service.yaml\n</code></pre>"},{"location":"temporal-design-implementation-guide/#76-pyprojecttoml-configuration","title":"7.6 pyproject.toml Configuration","text":"<pre><code>[project]\nname = \"temporal-worker\"\nversion = \"1.0.0\"\ndescription = \"Temporal worker for business processes\"\nrequires-python = \"&gt;=3.11\"\ndependencies = [\n    \"temporalio&gt;=1.7.0\",\n    \"fastapi&gt;=0.104.0\",\n    \"pydantic&gt;=2.0.0\",\n    \"prometheus-client&gt;=0.19.0\",\n    \"structlog&gt;=23.0.0\",\n]\n\n[project.optional-dependencies]\ndev = [\n    \"pytest&gt;=7.0.0\",\n    \"pytest-asyncio&gt;=0.21.0\",\n    \"pytest-cov&gt;=4.0.0\",\n    \"black&gt;=23.0.0\",\n    \"ruff&gt;=0.1.0\",\n    \"mypy&gt;=1.7.0\",\n]\n\n[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n\n[tool.black]\nline-length = 88\ntarget-version = ['py311']\n\n[tool.ruff]\ntarget-version = \"py311\"\nline-length = 88\nselect = [\"E\", \"F\", \"UP\", \"B\", \"SIM\", \"I\"]\n\n[tool.mypy]\npython_version = \"3.11\"\nstrict = true\n</code></pre>"},{"location":"temporal-design-implementation-guide/#operational-procedures","title":"Operational Procedures","text":""},{"location":"temporal-design-implementation-guide/#deployment-procedures","title":"Deployment Procedures","text":""},{"location":"temporal-design-implementation-guide/#81-rolling-updates","title":"8.1 Rolling Updates","text":"<pre><code># Update worker image\nkubectl set image deployment/temporal-worker \\\n  temporal-worker=your-registry.com/temporal-worker:v1.2.0 \\\n  -n temporal-product\n\n# Monitor rollout\nkubectl rollout status deployment/temporal-worker -n temporal-product\n\n# Rollback if needed\nkubectl rollout undo deployment/temporal-worker -n temporal-product\n</code></pre>"},{"location":"temporal-design-implementation-guide/#82-database-migrations","title":"8.2 Database Migrations","text":"<pre><code># Create migration job\nkubectl apply -f - &lt;&lt;EOF\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: temporal-schema-update\n  namespace: temporal-backend\nspec:\n  template:\n    spec:\n      containers:\n      - name: schema-update\n        image: temporalio/admin-tools:1.27.2\n        command:\n        - /bin/sh\n        - -c\n        - |\n          temporal-sql-tool \\\n            --plugin postgres12 \\\n            --ep postgresql:5432 \\\n            --u temporal \\\n            --pw \\$DB_PASSWORD \\\n            --db temporal \\\n            update-schema \\\n            --schema-dir /etc/temporal/schema/postgresql/v12\n        env:\n        - name: DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: temporal-db-secret\n              key: password\n      restartPolicy: OnFailure\nEOF\n</code></pre>"},{"location":"temporal-design-implementation-guide/#83-backup-procedures","title":"8.3 Backup Procedures","text":"<pre><code># Database backup\nkubectl exec -n temporal-backend postgresql-0 -- \\\n  pg_dump -U temporal -h localhost temporal &gt; temporal-backup-$(date +%Y%m%d).sql\n\n# Elasticsearch backup\nkubectl exec -n temporal-backend elasticsearch-master-0 -- \\\n  curl -X PUT \"localhost:9200/_snapshot/temporal_backup/snapshot_$(date +%Y%m%d)\"\n</code></pre>"},{"location":"temporal-design-implementation-guide/#monitoring-and-alerting","title":"Monitoring and Alerting","text":""},{"location":"temporal-design-implementation-guide/#84-alerting-rules","title":"8.4 Alerting Rules","text":"<pre><code># temporal-alerts.yaml\ngroups:\n- name: temporal.rules\n  rules:\n  - alert: TemporalServerDown\n    expr: up{job=\"temporal-server\"} == 0\n    for: 1m\n    labels:\n      severity: critical\n    annotations:\n      summary: \"Temporal server is down\"\n      description: \"Temporal server {{ $labels.instance }} is down for more than 1 minute\"\n\n  - alert: HighWorkflowFailureRate\n    expr: rate(temporal_workflow_failed_total[5m]) &gt; 0.1\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"High workflow failure rate\"\n      description: \"Workflow failure rate is {{ $value }} per second\"\n\n  - alert: DatabaseConnectionIssue\n    expr: temporal_persistence_errors_total &gt; 10\n    for: 2m\n    labels:\n      severity: critical\n    annotations:\n      summary: \"Database connection issues\"\n      description: \"Temporal is experiencing database connection issues\"\n</code></pre>"},{"location":"temporal-design-implementation-guide/#85-log-aggregation","title":"8.5 Log Aggregation","text":"<pre><code># fluent-bit-config.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: fluent-bit-config\n  namespace: logging\ndata:\n  fluent-bit.conf: |\n    [SERVICE]\n        Flush         1\n        Log_Level     info\n        Daemon        off\n        Parsers_File  parsers.conf\n\n    [INPUT]\n        Name              tail\n        Path              /var/log/containers/*temporal*.log\n        Parser            json\n        Tag               temporal.*\n        Refresh_Interval  5\n\n    [FILTER]\n        Name                kubernetes\n        Match               temporal.*\n        Kube_URL            https://kubernetes.default.svc:443\n        Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token\n\n    [OUTPUT]\n        Name  forward\n        Match temporal.*\n        Host  fluentd.logging.svc.cluster.local\n        Port  24224\n</code></pre>"},{"location":"temporal-design-implementation-guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"temporal-design-implementation-guide/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"temporal-design-implementation-guide/#91-temporal-server-issues","title":"9.1 Temporal Server Issues","text":"<p>Issue: Temporal server fails to start <pre><code># Check server logs\nkubectl logs -n temporal-backend deployment/temporal-server\n\n# Common solutions:\n# 1. Database connectivity\nkubectl exec -n temporal-backend temporal-server-xxx -- \\\n  nc -zv postgresql 5432\n\n# 2. Check configuration\nkubectl get configmap -n temporal-backend temporal-config -o yaml\n\n# 3. Verify secrets\nkubectl get secret -n temporal-backend temporal-db-secret -o yaml\n</code></pre></p> <p>Issue: High memory usage <pre><code># Check memory metrics\nkubectl top pods -n temporal-backend\n\n# Adjust resources\nkubectl patch deployment temporal-server -n temporal-backend -p '\n{\n  \"spec\": {\n    \"template\": {\n      \"spec\": {\n        \"containers\": [{\n          \"name\": \"temporal-server\",\n          \"resources\": {\n            \"limits\": {\"memory\": \"8Gi\"},\n            \"requests\": {\"memory\": \"4Gi\"}\n          }\n        }]\n      }\n    }\n  }\n}'\n</code></pre></p>"},{"location":"temporal-design-implementation-guide/#92-database-issues","title":"9.2 Database Issues","text":"<p>Issue: Database connection pool exhaustion <pre><code># Check connection metrics\nkubectl exec -n temporal-backend postgresql-0 -- \\\n  psql -U temporal -c \"SELECT count(*) FROM pg_stat_activity;\"\n\n# Increase connection pool\nkubectl patch configmap temporal-config -n temporal-backend --patch '\n{\n  \"data\": {\n    \"config.yaml\": \"...\\npersistence:\\n  default:\\n    sql:\\n      maxConns: 50\\n      maxIdleConns: 25\\n...\"\n  }\n}'\n</code></pre></p>"},{"location":"temporal-design-implementation-guide/#93-worker-issues","title":"9.3 Worker Issues","text":"<p>Issue: Workers not receiving tasks <pre><code># Check worker logs\nkubectl logs -n temporal-product deployment/temporal-worker\n\n# Verify task queue configuration\ntemporal workflow list --namespace default\n\n# Check network connectivity\nkubectl exec -n temporal-product temporal-worker-xxx -- \\\n  nc -zv temporal-frontend.temporal-backend 7233\n</code></pre></p>"},{"location":"temporal-design-implementation-guide/#94-performance-troubleshooting","title":"9.4 Performance Troubleshooting","text":"<p>Performance Checklist: 1. Database Performance <pre><code>-- Check slow queries\nSELECT query, mean_time, calls \nFROM pg_stat_statements \nORDER BY mean_time DESC \nLIMIT 10;\n</code></pre></p> <ol> <li> <p>Elasticsearch Performance <pre><code># Check cluster health\nkubectl exec -n temporal-backend elasticsearch-master-0 -- \\\n  curl -s localhost:9200/_cluster/health?pretty\n</code></pre></p> </li> <li> <p>Kubernetes Resources <pre><code># Check resource usage\nkubectl top nodes\nkubectl top pods --all-namespaces --sort-by=memory\n</code></pre></p> </li> </ol>"},{"location":"temporal-design-implementation-guide/#emergency-procedures","title":"Emergency Procedures","text":""},{"location":"temporal-design-implementation-guide/#95-disaster-recovery","title":"9.5 Disaster Recovery","text":"<p>Complete System Recovery: <pre><code># 1. Restore database from backup\nkubectl exec -n temporal-backend postgresql-0 -- \\\n  psql -U temporal -h localhost &lt; temporal-backup-20231215.sql\n\n# 2. Restore Elasticsearch snapshots\nkubectl exec -n temporal-backend elasticsearch-master-0 -- \\\n  curl -X POST \"localhost:9200/_snapshot/temporal_backup/snapshot_20231215/_restore\"\n\n# 3. Restart Temporal services\nkubectl rollout restart deployment/temporal-server -n temporal-backend\nkubectl rollout restart deployment/temporal-web -n temporal-backend\n\n# 4. Verify system health\nkubectl get pods -n temporal-backend\nkubectl get pods -n temporal-product\n</code></pre></p> <p>Partial Service Recovery: <pre><code># Scale down affected services\nkubectl scale deployment temporal-worker -n temporal-product --replicas=0\n\n# Clear problematic workflows (if needed)\ntemporal workflow terminate --workflow-id problematic-workflow-id\n\n# Scale back up\nkubectl scale deployment temporal-worker -n temporal-product --replicas=3\n</code></pre></p>"},{"location":"temporal-design-implementation-guide/#health-checks-and-validation","title":"Health Checks and Validation","text":""},{"location":"temporal-design-implementation-guide/#96-system-validation-scripts","title":"9.6 System Validation Scripts","text":"<pre><code>#!/bin/bash\n# validate-temporal-deployment.sh\n\necho \"Validating Temporal deployment...\"\n\n# Check namespace existence\nfor ns in temporal-backend temporal-product monitoring; do\n  if kubectl get namespace $ns &gt;/dev/null 2&gt;&amp;1; then\n    echo \"\u2713 Namespace $ns exists\"\n  else\n    echo \"\u2717 Namespace $ns missing\"\n    exit 1\n  fi\ndone\n\n# Check pod status\necho \"Checking pod status...\"\nkubectl get pods -n temporal-backend -o wide\nkubectl get pods -n temporal-product -o wide\n\n# Verify services\necho \"Checking services...\"\nkubectl get svc -n temporal-backend\nkubectl get svc -n temporal-product\n\n# Test connectivity\necho \"Testing Temporal server connectivity...\"\nkubectl exec -n temporal-product deploy/temporal-worker -- \\\n  temporal workflow list --namespace default &gt;/dev/null 2&gt;&amp;1 &amp;&amp; \\\n  echo \"\u2713 Temporal server accessible\" || \\\n  echo \"\u2717 Temporal server not accessible\"\n\n# Check metrics endpoint\necho \"Testing metrics endpoints...\"\nkubectl port-forward -n temporal-backend svc/temporal-server 9090:9090 &amp;\nPF_PID=$!\nsleep 5\ncurl -s http://localhost:9090/metrics | grep -q temporal &amp;&amp; \\\n  echo \"\u2713 Metrics endpoint responding\" || \\\n  echo \"\u2717 Metrics endpoint not responding\"\nkill $PF_PID\n\necho \"Validation complete!\"\n</code></pre>"},{"location":"temporal-design-implementation-guide/#conclusion","title":"Conclusion","text":"<p>This comprehensive guide provides a production-ready implementation of Temporal.io with enterprise-grade security, monitoring, and operational procedures. The architecture supports scalability, high availability, and maintainability while following DevOps best practices.</p>"},{"location":"temporal-design-implementation-guide/#key-benefits","title":"Key Benefits","text":"<ul> <li>Scalable Architecture: Kubernetes-native deployment with horizontal scaling</li> <li>Security First: End-to-end encryption, SSO integration, and secrets management</li> <li>Observability: Comprehensive monitoring with Prometheus, Grafana, and OpenTelemetry</li> <li>GitOps Ready: Automated deployment with ArgoCD and conventional commits</li> <li>Production Ready: High availability, backup procedures, and disaster recovery</li> </ul>"},{"location":"temporal-design-implementation-guide/#next-steps","title":"Next Steps","text":"<ol> <li>Environment Setup: Follow the implementation guide step by step</li> <li>Security Hardening: Implement additional security measures as needed</li> <li>Performance Testing: Conduct load testing to validate performance</li> <li>Team Training: Train development and operations teams on the new platform</li> <li>Documentation: Maintain up-to-date documentation for ongoing operations</li> </ol> <p>For additional support and advanced configurations, refer to the official Temporal.io documentation and consider engaging with the Temporal community for best practices and optimization strategies.</p>"},{"location":"architecture/database-design/","title":"Database Design","text":"<p>This document provides comprehensive coverage of the database architecture for the Temporal.io enterprise deployment, including data models, storage strategies, performance optimization, and operational procedures.</p>"},{"location":"architecture/database-design/#database-architecture-overview","title":"Database Architecture Overview","text":"<p>The database design implements a multi-store approach with PostgreSQL as the primary database for persistence and visibility, complemented by Elasticsearch for advanced search capabilities and Redis for caching layers.</p> <pre><code>graph TB\n    subgraph \"Application Layer\"\n        APP1[Temporal Frontend]\n        APP2[Temporal History]\n        APP3[Temporal Matching]\n        APP4[Temporal Worker]\n        APP5[Temporal Web UI]\n    end\n\n    subgraph \"Database Layer\"\n        subgraph \"Primary Storage\"\n            DB1[PostgreSQL Primary&lt;br/&gt;Read/Write Operations]\n            DB2[PostgreSQL Replica 1&lt;br/&gt;Read Operations]\n            DB3[PostgreSQL Replica 2&lt;br/&gt;Read Operations]\n        end\n\n        subgraph \"Search Layer\"\n            ES1[Elasticsearch Master 1]\n            ES2[Elasticsearch Master 2]\n            ES3[Elasticsearch Master 3]\n            ES4[Elasticsearch Data 1]\n            ES5[Elasticsearch Data 2]\n            ES6[Elasticsearch Data 3]\n        end\n\n        subgraph \"Cache Layer\"\n            CACHE1[Redis Primary&lt;br/&gt;Session Cache]\n            CACHE2[Redis Replica&lt;br/&gt;Read Cache]\n            CACHE3[Redis Sentinel&lt;br/&gt;Failover]\n        end\n\n        subgraph \"Backup Storage\"\n            BACKUP1[WAL Streaming&lt;br/&gt;Continuous Backup]\n            BACKUP2[Point-in-Time Recovery&lt;br/&gt;PITR]\n            BACKUP3[Object Storage&lt;br/&gt;S3/GCS/Azure]\n        end\n    end\n\n    subgraph \"Monitoring &amp; Management\"\n        MON1[PostgreSQL Exporter&lt;br/&gt;Metrics]\n        MON2[Elasticsearch Exporter&lt;br/&gt;Metrics]\n        MON3[Redis Exporter&lt;br/&gt;Metrics]\n        MON4[Backup Monitoring&lt;br/&gt;Health Checks]\n    end\n\n    APP1 --&gt; DB1\n    APP2 --&gt; DB1\n    APP3 --&gt; DB1\n    APP4 --&gt; DB1\n    APP5 --&gt; DB2\n\n    APP1 --&gt; ES1\n    APP5 --&gt; ES1\n\n    APP1 --&gt; CACHE1\n    APP5 --&gt; CACHE1\n\n    DB1 --&gt; DB2\n    DB1 --&gt; DB3\n    DB1 --&gt; BACKUP1\n\n    MON1 --&gt; DB1\n    MON2 --&gt; ES1\n    MON3 --&gt; CACHE1</code></pre>"},{"location":"architecture/database-design/#postgresql-database-design","title":"PostgreSQL Database Design","text":""},{"location":"architecture/database-design/#primary-database-configuration","title":"Primary Database Configuration","text":""},{"location":"architecture/database-design/#high-availability-setup","title":"High Availability Setup","text":"<pre><code># PostgreSQL High Availability Configuration\npostgresql_ha:\n  deployment_type: \"primary_replica\"\n  replication_mode: \"streaming\"\n\n  primary:\n    name: \"postgresql-primary\"\n    resources:\n      cpu: \"4000m\"\n      memory: \"16Gi\"\n      storage: \"500Gi\"\n      storage_class: \"fast-ssd\"\n\n  replicas:\n    count: 2\n    resources:\n      cpu: \"2000m\"\n      memory: \"8Gi\"\n      storage: \"500Gi\"\n      storage_class: \"fast-ssd\"\n    lag_threshold: \"1MB\"\n\n  connection_pooling:\n    enabled: true\n    tool: \"pgbouncer\"\n    max_connections: 1000\n    default_pool_size: 50\n    min_pool_size: 10\n\n  backup:\n    type: \"continuous\"\n    tool: \"pgbackrest\"\n    retention: \"30_days\"\n    compression: \"lz4\"\n</code></pre>"},{"location":"architecture/database-design/#postgresql-configuration","title":"PostgreSQL Configuration","text":"<pre><code>-- postgresql.conf optimizations for Temporal\n-- Memory Settings\nshared_buffers = '4GB'                    -- 25% of available RAM\neffective_cache_size = '12GB'             -- 75% of available RAM\nwork_mem = '64MB'                         -- For complex queries\nmaintenance_work_mem = '1GB'              -- For VACUUM, INDEX operations\n\n-- Write-Ahead Logging (WAL)\nwal_level = 'replica'                     -- Enable streaming replication\nmax_wal_size = '2GB'                      -- Maximum WAL size\nmin_wal_size = '1GB'                      -- Minimum WAL size\nwal_compression = on                      -- Compress WAL records\nwal_log_hints = on                        -- Enable WAL hints for pg_rewind\n\n-- Checkpoints\ncheckpoint_completion_target = 0.9        -- Spread checkpoint I/O\ncheckpoint_timeout = '15min'              -- Checkpoint frequency\n\n-- Connection Settings\nmax_connections = 1000                    -- Maximum concurrent connections\nshared_preload_libraries = 'pg_stat_statements,auto_explain,pg_cron'\n\n-- Query Optimization\nrandom_page_cost = 1.1                    -- SSD optimization\neffective_io_concurrency = 200            -- Concurrent I/O operations\ndefault_statistics_target = 500           -- Query planner statistics\n\n-- Logging\nlog_statement = 'mod'                     -- Log modifications\nlog_min_duration_statement = 1000         -- Log slow queries (&gt;1s)\nlog_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '\nlog_lock_waits = on                       -- Log lock waits\nlog_temp_files = 10MB                     -- Log temp files &gt; 10MB\n\n-- Auto-vacuum\nautovacuum = on\nautovacuum_max_workers = 6\nautovacuum_naptime = 15s\nautovacuum_vacuum_threshold = 100\nautovacuum_analyze_threshold = 50\nautovacuum_vacuum_scale_factor = 0.05\nautovacuum_analyze_scale_factor = 0.02\n</code></pre>"},{"location":"architecture/database-design/#database-schema-design","title":"Database Schema Design","text":""},{"location":"architecture/database-design/#temporal-default-store-schema","title":"Temporal Default Store Schema","text":"<pre><code>-- Core Temporal tables for workflow execution\nCREATE SCHEMA temporal;\n\n-- Executions table - stores workflow execution state\nCREATE TABLE temporal.executions (\n    shard_id INTEGER NOT NULL,\n    namespace_id CHAR(64) NOT NULL,\n    workflow_id VARCHAR(255) NOT NULL,\n    run_id CHAR(64) NOT NULL,\n    next_event_id BIGINT NOT NULL,\n    last_write_version BIGINT NOT NULL,\n    data BYTEA NOT NULL,\n    data_encoding VARCHAR(16) NOT NULL,\n    state BYTEA NOT NULL,\n    state_encoding VARCHAR(16) NOT NULL,\n    db_record_version BIGINT NOT NULL DEFAULT 0,\n    PRIMARY KEY (shard_id, namespace_id, workflow_id, run_id)\n);\n\n-- History tree table - stores workflow history events\nCREATE TABLE temporal.history_tree (\n    shard_id INTEGER NOT NULL,\n    tree_id CHAR(64) NOT NULL,\n    branch_id CHAR(64) NOT NULL,\n    data BYTEA NOT NULL,\n    data_encoding VARCHAR(16) NOT NULL,\n    PRIMARY KEY (shard_id, tree_id, branch_id)\n);\n\n-- Current executions table - fast lookup for current workflow state\nCREATE TABLE temporal.current_executions (\n    shard_id INTEGER NOT NULL,\n    namespace_id CHAR(64) NOT NULL,\n    workflow_id VARCHAR(255) NOT NULL,\n    run_id CHAR(64) NOT NULL,\n    create_request_id VARCHAR(64) NOT NULL,\n    state INTEGER NOT NULL,\n    status INTEGER NOT NULL,\n    start_version BIGINT NOT NULL,\n    last_write_version BIGINT NOT NULL,\n    PRIMARY KEY (shard_id, namespace_id, workflow_id)\n);\n\n-- Tasks table - stores task queue items\nCREATE TABLE temporal.tasks (\n    range_hash BIGINT NOT NULL,\n    task_queue_id BYTEA NOT NULL,\n    task_id BIGINT NOT NULL,\n    data BYTEA NOT NULL,\n    data_encoding VARCHAR(16) NOT NULL,\n    PRIMARY KEY (range_hash, task_queue_id, task_id)\n);\n\n-- Activity info table - tracks activity execution state\nCREATE TABLE temporal.activity_info_maps (\n    shard_id INTEGER NOT NULL,\n    namespace_id CHAR(64) NOT NULL,\n    workflow_id VARCHAR(255) NOT NULL,\n    run_id CHAR(64) NOT NULL,\n    schedule_id BIGINT NOT NULL,\n    data BYTEA NOT NULL,\n    data_encoding VARCHAR(16) NOT NULL,\n    last_heartbeat_updated_time TIMESTAMP NOT NULL,\n    PRIMARY KEY (shard_id, namespace_id, workflow_id, run_id, schedule_id)\n);\n\n-- Timer info table - manages workflow timers\nCREATE TABLE temporal.timer_info_maps (\n    shard_id INTEGER NOT NULL,\n    namespace_id CHAR(64) NOT NULL,\n    workflow_id VARCHAR(255) NOT NULL,\n    run_id CHAR(64) NOT NULL,\n    timer_id VARCHAR(255) NOT NULL,\n    data BYTEA NOT NULL,\n    data_encoding VARCHAR(16) NOT NULL,\n    PRIMARY KEY (shard_id, namespace_id, workflow_id, run_id, timer_id)\n);\n</code></pre>"},{"location":"architecture/database-design/#temporal-visibility-store-schema","title":"Temporal Visibility Store Schema","text":"<pre><code>-- Visibility schema for search and filtering\nCREATE SCHEMA temporal_visibility;\n\n-- Executions visibility table - searchable execution data\nCREATE TABLE temporal_visibility.executions (\n    namespace_id CHAR(64) NOT NULL,\n    run_id CHAR(64) NOT NULL,\n    start_time TIMESTAMP NOT NULL,\n    execution_time TIMESTAMP NOT NULL,\n    workflow_id VARCHAR(255) NOT NULL,\n    workflow_type_name VARCHAR(255) NOT NULL,\n    status INTEGER NOT NULL,\n    close_time TIMESTAMP,\n    history_length BIGINT,\n    memo BYTEA,\n    encoding VARCHAR(16),\n    task_queue VARCHAR(255),\n    search_attributes JSON,\n    PRIMARY KEY (namespace_id, run_id)\n);\n\n-- Indexes for efficient querying\nCREATE INDEX idx_executions_start_time ON temporal_visibility.executions(namespace_id, start_time DESC);\nCREATE INDEX idx_executions_close_time ON temporal_visibility.executions(namespace_id, close_time DESC);\nCREATE INDEX idx_executions_workflow_id ON temporal_visibility.executions(namespace_id, workflow_id);\nCREATE INDEX idx_executions_workflow_type ON temporal_visibility.executions(namespace_id, workflow_type_name);\nCREATE INDEX idx_executions_status ON temporal_visibility.executions(namespace_id, status);\nCREATE INDEX idx_executions_task_queue ON temporal_visibility.executions(namespace_id, task_queue);\n\n-- GIN index for JSON search attributes\nCREATE INDEX idx_executions_search_attributes ON temporal_visibility.executions USING GIN(search_attributes);\n\n-- Workflow search attributes table\nCREATE TABLE temporal_visibility.custom_search_attributes (\n    namespace_id CHAR(64) NOT NULL,\n    run_id CHAR(64) NOT NULL,\n    search_attributes JSON NOT NULL,\n    PRIMARY KEY (namespace_id, run_id)\n);\n</code></pre>"},{"location":"architecture/database-design/#partitioning-strategy","title":"Partitioning Strategy","text":""},{"location":"architecture/database-design/#time-based-partitioning","title":"Time-based Partitioning","text":"<pre><code>-- Partition executions table by month\nCREATE TABLE temporal_visibility.executions_template (\n    LIKE temporal_visibility.executions INCLUDING ALL\n) PARTITION BY RANGE (start_time);\n\n-- Create monthly partitions\nCREATE TABLE temporal_visibility.executions_2024_01 \n    PARTITION OF temporal_visibility.executions_template\n    FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');\n\nCREATE TABLE temporal_visibility.executions_2024_02 \n    PARTITION OF temporal_visibility.executions_template\n    FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');\n\n-- Automated partition management\nCREATE OR REPLACE FUNCTION create_monthly_partition() RETURNS void AS $$\nDECLARE\n    partition_date date;\n    partition_name text;\n    start_date text;\n    end_date text;\nBEGIN\n    partition_date := date_trunc('month', CURRENT_DATE + interval '1 month');\n    partition_name := 'executions_' || to_char(partition_date, 'YYYY_MM');\n    start_date := partition_date::text;\n    end_date := (partition_date + interval '1 month')::text;\n\n    EXECUTE format('CREATE TABLE IF NOT EXISTS temporal_visibility.%I \n                    PARTITION OF temporal_visibility.executions_template\n                    FOR VALUES FROM (%L) TO (%L)',\n                   partition_name, start_date, end_date);\nEND;\n$$ LANGUAGE plpgsql;\n\n-- Schedule partition creation\nSELECT cron.schedule('create-partition', '0 0 1 * *', 'SELECT create_monthly_partition()');\n</code></pre>"},{"location":"architecture/database-design/#performance-optimization","title":"Performance Optimization","text":""},{"location":"architecture/database-design/#index-strategy","title":"Index Strategy","text":"<pre><code>-- Composite indexes for common query patterns\nCREATE INDEX CONCURRENTLY idx_executions_composite_status \n    ON temporal_visibility.executions(namespace_id, status, start_time DESC);\n\nCREATE INDEX CONCURRENTLY idx_executions_composite_type \n    ON temporal_visibility.executions(namespace_id, workflow_type_name, start_time DESC);\n\nCREATE INDEX CONCURRENTLY idx_executions_composite_queue \n    ON temporal_visibility.executions(namespace_id, task_queue, start_time DESC);\n\n-- Partial indexes for active workflows\nCREATE INDEX CONCURRENTLY idx_executions_active \n    ON temporal_visibility.executions(namespace_id, start_time DESC)\n    WHERE status IN (1, 2); -- Running, ContinuedAsNew\n\n-- Functional indexes for complex queries\nCREATE INDEX CONCURRENTLY idx_executions_duration \n    ON temporal_visibility.executions(namespace_id, (close_time - start_time))\n    WHERE close_time IS NOT NULL;\n</code></pre>"},{"location":"architecture/database-design/#query-optimization","title":"Query Optimization","text":"<pre><code>-- Materialized view for dashboard metrics\nCREATE MATERIALIZED VIEW temporal_visibility.workflow_metrics AS\nSELECT \n    namespace_id,\n    workflow_type_name,\n    DATE(start_time) as execution_date,\n    COUNT(*) as total_executions,\n    COUNT(*) FILTER (WHERE status = 3) as completed_executions,\n    COUNT(*) FILTER (WHERE status = 4) as failed_executions,\n    COUNT(*) FILTER (WHERE status = 5) as canceled_executions,\n    AVG(EXTRACT(EPOCH FROM (close_time - start_time))) as avg_duration_seconds,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY EXTRACT(EPOCH FROM (close_time - start_time))) as median_duration_seconds,\n    PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY EXTRACT(EPOCH FROM (close_time - start_time))) as p95_duration_seconds\nFROM temporal_visibility.executions\nWHERE start_time &gt;= CURRENT_DATE - INTERVAL '30 days'\nGROUP BY namespace_id, workflow_type_name, DATE(start_time);\n\n-- Refresh materialized view hourly\nCREATE UNIQUE INDEX ON temporal_visibility.workflow_metrics(namespace_id, workflow_type_name, execution_date);\nSELECT cron.schedule('refresh-metrics', '0 * * * *', 'REFRESH MATERIALIZED VIEW CONCURRENTLY temporal_visibility.workflow_metrics');\n</code></pre>"},{"location":"architecture/database-design/#elasticsearch-configuration","title":"Elasticsearch Configuration","text":""},{"location":"architecture/database-design/#cluster-setup","title":"Cluster Setup","text":""},{"location":"architecture/database-design/#elasticsearch-cluster-configuration","title":"Elasticsearch Cluster Configuration","text":"<pre><code># Elasticsearch cluster for advanced visibility\nelasticsearch:\n  cluster_name: \"temporal-es-cluster\"\n\n  master_nodes:\n    count: 3\n    resources:\n      cpu: \"1000m\"\n      memory: \"2Gi\"\n      storage: \"50Gi\"\n    jvm_heap: \"1g\"\n\n  data_nodes:\n    count: 3\n    resources:\n      cpu: \"2000m\"\n      memory: \"8Gi\"\n      storage: \"500Gi\"\n    jvm_heap: \"4g\"\n\n  client_nodes:\n    count: 2\n    resources:\n      cpu: \"500m\"\n      memory: \"2Gi\"\n    jvm_heap: \"1g\"\n\n  settings:\n    indices.memory.index_buffer_size: \"20%\"\n    indices.memory.min_index_buffer_size: \"48mb\"\n    indices.fielddata.cache.size: \"30%\"\n    indices.breaker.fielddata.limit: \"40%\"\n    indices.breaker.request.limit: \"30%\"\n    cluster.routing.allocation.disk.watermark.low: \"85%\"\n    cluster.routing.allocation.disk.watermark.high: \"90%\"\n    cluster.routing.allocation.disk.watermark.flood_stage: \"95%\"\n</code></pre>"},{"location":"architecture/database-design/#index-templates-and-mappings","title":"Index Templates and Mappings","text":""},{"location":"architecture/database-design/#temporal-visibility-index-template","title":"Temporal Visibility Index Template","text":"<pre><code>{\n  \"index_patterns\": [\"temporal_visibility_v1_*\"],\n  \"template\": {\n    \"settings\": {\n      \"number_of_shards\": 3,\n      \"number_of_replicas\": 1,\n      \"refresh_interval\": \"5s\",\n      \"index.codec\": \"best_compression\",\n      \"index.mapping.total_fields.limit\": 2000,\n      \"index.max_result_window\": 10000,\n      \"index.lifecycle.name\": \"temporal_visibility_policy\",\n      \"index.lifecycle.rollover_alias\": \"temporal_visibility_v1\"\n    },\n    \"mappings\": {\n      \"dynamic\": \"strict\",\n      \"properties\": {\n        \"NamespaceId\": {\n          \"type\": \"keyword\"\n        },\n        \"WorkflowId\": {\n          \"type\": \"keyword\"\n        },\n        \"RunId\": {\n          \"type\": \"keyword\"\n        },\n        \"WorkflowType\": {\n          \"type\": \"keyword\"\n        },\n        \"StartTime\": {\n          \"type\": \"date\",\n          \"format\": \"strict_date_optional_time_nanos\"\n        },\n        \"ExecutionTime\": {\n          \"type\": \"date\",\n          \"format\": \"strict_date_optional_time_nanos\"\n        },\n        \"CloseTime\": {\n          \"type\": \"date\",\n          \"format\": \"strict_date_optional_time_nanos\"\n        },\n        \"ExecutionStatus\": {\n          \"type\": \"integer\"\n        },\n        \"ExecutionDuration\": {\n          \"type\": \"long\"\n        },\n        \"HistoryLength\": {\n          \"type\": \"long\"\n        },\n        \"TaskQueue\": {\n          \"type\": \"keyword\"\n        },\n        \"Memo\": {\n          \"type\": \"object\",\n          \"enabled\": false\n        },\n        \"SearchAttributes\": {\n          \"type\": \"object\",\n          \"properties\": {\n            \"CustomKeywordField\": {\n              \"type\": \"keyword\"\n            },\n            \"CustomIntField\": {\n              \"type\": \"integer\"\n            },\n            \"CustomDoubleField\": {\n              \"type\": \"double\"\n            },\n            \"CustomBoolField\": {\n              \"type\": \"boolean\"\n            },\n            \"CustomDatetimeField\": {\n              \"type\": \"date\",\n              \"format\": \"strict_date_optional_time_nanos\"\n            },\n            \"CustomStringField\": {\n              \"type\": \"text\",\n              \"analyzer\": \"standard\"\n            }\n          }\n        }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"architecture/database-design/#index-lifecycle-management","title":"Index Lifecycle Management","text":"<pre><code>{\n  \"policy\": {\n    \"phases\": {\n      \"hot\": {\n        \"actions\": {\n          \"rollover\": {\n            \"max_primary_shard_size\": \"5GB\",\n            \"max_age\": \"7d\"\n          },\n          \"set_priority\": {\n            \"priority\": 100\n          }\n        }\n      },\n      \"warm\": {\n        \"min_age\": \"7d\",\n        \"actions\": {\n          \"set_priority\": {\n            \"priority\": 50\n          },\n          \"allocate\": {\n            \"number_of_replicas\": 0\n          },\n          \"forcemerge\": {\n            \"max_num_segments\": 1\n          },\n          \"shrink\": {\n            \"number_of_shards\": 1\n          }\n        }\n      },\n      \"cold\": {\n        \"min_age\": \"30d\",\n        \"actions\": {\n          \"set_priority\": {\n            \"priority\": 0\n          },\n          \"allocate\": {\n            \"number_of_replicas\": 0\n          }\n        }\n      },\n      \"delete\": {\n        \"min_age\": \"90d\",\n        \"actions\": {\n          \"delete\": {}\n        }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"architecture/database-design/#redis-configuration","title":"Redis Configuration","text":""},{"location":"architecture/database-design/#caching-strategy","title":"Caching Strategy","text":""},{"location":"architecture/database-design/#redis-cluster-setup","title":"Redis Cluster Setup","text":"<pre><code># Redis configuration for caching\nredis:\n  deployment_mode: \"sentinel\"\n\n  sentinel:\n    count: 3\n    resources:\n      cpu: \"100m\"\n      memory: \"128Mi\"\n\n  master:\n    resources:\n      cpu: \"500m\"\n      memory: \"2Gi\"\n    persistence:\n      enabled: true\n      size: \"10Gi\"\n\n  replica:\n    count: 2\n    resources:\n      cpu: \"250m\"\n      memory: \"1Gi\"\n\n  configuration:\n    maxmemory: \"1536mb\"\n    maxmemory-policy: \"allkeys-lru\"\n    timeout: 300\n    tcp-keepalive: 60\n    save: \"900 1 300 10 60 10000\"\n    stop-writes-on-bgsave-error: \"yes\"\n    rdbcompression: \"yes\"\n    rdbchecksum: \"yes\"\n\n  cache_patterns:\n    user_sessions:\n      ttl: 3600  # 1 hour\n      namespace: \"session:\"\n\n    workflow_metadata:\n      ttl: 600   # 10 minutes\n      namespace: \"wf_meta:\"\n\n    task_queue_info:\n      ttl: 300   # 5 minutes\n      namespace: \"tq_info:\"\n</code></pre>"},{"location":"architecture/database-design/#data-management-strategies","title":"Data Management Strategies","text":""},{"location":"architecture/database-design/#backup-and-recovery","title":"Backup and Recovery","text":""},{"location":"architecture/database-design/#continuous-backup-with-pgbackrest","title":"Continuous Backup with pgBackRest","text":"<pre><code># pgBackRest configuration\npgbackrest:\n  global:\n    repo1-type: \"s3\"\n    repo1-s3-bucket: \"temporal-backups\"\n    repo1-s3-region: \"us-east-1\"\n    repo1-s3-endpoint: \"s3.amazonaws.com\"\n    repo1-retention-full: 30\n    repo1-retention-diff: 7\n    repo1-retention-incr: 3\n\n  stanza:\n    temporal:\n      pg1-path: \"/var/lib/postgresql/data\"\n      pg1-host: \"postgresql-primary\"\n      pg1-host-user: \"postgres\"\n      recovery-option: \"recovery_target_action=promote\"\n\n  backup_schedules:\n    full_backup: \"0 2 * * 0\"  # Weekly full backup\n    differential_backup: \"0 2 * * 1-6\"  # Daily differential backup\n    incremental_backup: \"0 */6 * * *\"  # Every 6 hours incremental backup\n</code></pre>"},{"location":"architecture/database-design/#point-in-time-recovery","title":"Point-in-Time Recovery","text":"<pre><code>#!/bin/bash\n# Point-in-time recovery script\nrecover_to_timestamp() {\n    local target_timestamp=$1\n    local recovery_dir=\"/var/lib/postgresql/recovery\"\n\n    # Stop PostgreSQL\n    kubectl scale statefulset postgresql-primary --replicas=0\n\n    # Restore from backup\n    pgbackrest --stanza=temporal --type=time \\\n               --target=\"$target_timestamp\" \\\n               --target-action=promote \\\n               restore\n\n    # Start PostgreSQL\n    kubectl scale statefulset postgresql-primary --replicas=1\n\n    echo \"Recovery to $target_timestamp completed\"\n}\n</code></pre>"},{"location":"architecture/database-design/#data-retention-policies","title":"Data Retention Policies","text":""},{"location":"architecture/database-design/#automated-data-cleanup","title":"Automated Data Cleanup","text":"<pre><code>-- Data retention stored procedures\nCREATE OR REPLACE FUNCTION cleanup_old_executions(retention_days INTEGER DEFAULT 90)\nRETURNS INTEGER AS $$\nDECLARE\n    deleted_count INTEGER;\n    cutoff_date TIMESTAMP;\nBEGIN\n    cutoff_date := CURRENT_TIMESTAMP - (retention_days || ' days')::INTERVAL;\n\n    -- Delete old completed executions\n    DELETE FROM temporal_visibility.executions \n    WHERE close_time &lt; cutoff_date \n    AND status IN (3, 4, 5, 6, 7, 8); -- Completed, Failed, Canceled, etc.\n\n    GET DIAGNOSTICS deleted_count = ROW_COUNT;\n\n    -- Log cleanup operation\n    INSERT INTO temporal.cleanup_log (cleanup_date, table_name, deleted_rows, retention_days)\n    VALUES (CURRENT_TIMESTAMP, 'executions', deleted_count, retention_days);\n\n    RETURN deleted_count;\nEND;\n$$ LANGUAGE plpgsql;\n\n-- Schedule automated cleanup\nSELECT cron.schedule('cleanup-executions', '0 3 * * *', 'SELECT cleanup_old_executions(90)');\n</code></pre>"},{"location":"architecture/database-design/#data-migration-and-upgrades","title":"Data Migration and Upgrades","text":""},{"location":"architecture/database-design/#schema-migration-framework","title":"Schema Migration Framework","text":"<pre><code>-- Migration tracking table\nCREATE TABLE temporal.schema_migrations (\n    version VARCHAR(255) PRIMARY KEY,\n    applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    checksum VARCHAR(64) NOT NULL,\n    description TEXT\n);\n\n-- Example migration: Add new search attribute\nCREATE OR REPLACE FUNCTION migrate_add_search_attribute()\nRETURNS VOID AS $$\nBEGIN\n    -- Check if migration already applied\n    IF EXISTS (SELECT 1 FROM temporal.schema_migrations WHERE version = '1.20.0_add_customer_id') THEN\n        RAISE NOTICE 'Migration 1.20.0_add_customer_id already applied';\n        RETURN;\n    END IF;\n\n    -- Add new column\n    ALTER TABLE temporal_visibility.executions \n    ADD COLUMN IF NOT EXISTS customer_id VARCHAR(255);\n\n    -- Add index\n    CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_executions_customer_id \n        ON temporal_visibility.executions(namespace_id, customer_id);\n\n    -- Record migration\n    INSERT INTO temporal.schema_migrations (version, description, checksum)\n    VALUES ('1.20.0_add_customer_id', 'Add customer_id search attribute', 'abc123def456');\n\n    RAISE NOTICE 'Migration 1.20.0_add_customer_id completed successfully';\nEND;\n$$ LANGUAGE plpgsql;\n</code></pre>"},{"location":"architecture/database-design/#performance-monitoring-and-optimization","title":"Performance Monitoring and Optimization","text":""},{"location":"architecture/database-design/#database-metrics-collection","title":"Database Metrics Collection","text":""},{"location":"architecture/database-design/#postgresql-monitoring","title":"PostgreSQL Monitoring","text":"<pre><code># PostgreSQL Exporter configuration\npostgresql_exporter:\n  enabled: true\n  datasource:\n    host: \"postgresql-primary\"\n    port: 5432\n    database: \"temporal\"\n    user: \"postgres_exporter\"\n\n  custom_queries:\n    temporal_metrics:\n      query: |\n        SELECT \n          schemaname,\n          tablename,\n          n_tup_ins as inserts,\n          n_tup_upd as updates,\n          n_tup_del as deletes,\n          n_live_tup as live_tuples,\n          n_dead_tup as dead_tuples,\n          last_vacuum,\n          last_autovacuum,\n          last_analyze,\n          last_autoanalyze\n        FROM pg_stat_user_tables \n        WHERE schemaname IN ('temporal', 'temporal_visibility')\n      metrics:\n        - schemaname:\n            usage: \"LABEL\"\n            description: \"Schema name\"\n        - tablename:\n            usage: \"LABEL\"\n            description: \"Table name\"\n        - inserts:\n            usage: \"COUNTER\"\n            description: \"Number of rows inserted\"\n        - updates:\n            usage: \"COUNTER\"\n            description: \"Number of rows updated\"\n        - deletes:\n            usage: \"COUNTER\"\n            description: \"Number of rows deleted\"\n        - live_tuples:\n            usage: \"GAUGE\"\n            description: \"Estimated number of live rows\"\n        - dead_tuples:\n            usage: \"GAUGE\"\n            description: \"Estimated number of dead rows\"\n</code></pre>"},{"location":"architecture/database-design/#performance-tuning","title":"Performance Tuning","text":""},{"location":"architecture/database-design/#slow-query-analysis","title":"Slow Query Analysis","text":"<pre><code>-- Enable pg_stat_statements for query analysis\nCREATE EXTENSION IF NOT EXISTS pg_stat_statements;\n\n-- Query to find slow operations\nSELECT \n    query,\n    calls,\n    total_time,\n    mean_time,\n    stddev_time,\n    rows,\n    100.0 * shared_blks_hit / nullif(shared_blks_hit + shared_blks_read, 0) AS hit_percent\nFROM pg_stat_statements\nWHERE mean_time &gt; 1000  -- Queries taking more than 1 second on average\nORDER BY mean_time DESC\nLIMIT 20;\n\n-- Query to find table bloat\nSELECT \n    schemaname,\n    tablename,\n    attname,\n    n_distinct,\n    correlation,\n    most_common_vals,\n    histogram_bounds\nFROM pg_stats\nWHERE schemaname IN ('temporal', 'temporal_visibility')\nAND n_distinct &lt; 100  -- Low cardinality columns that might benefit from partial indexes\nORDER BY schemaname, tablename, attname;\n</code></pre>"},{"location":"architecture/database-design/#index-usage-analysis","title":"Index Usage Analysis","text":"<pre><code>-- Analyze index usage patterns\nSELECT \n    schemaname,\n    tablename,\n    indexname,\n    idx_scan,\n    idx_tup_read,\n    idx_tup_fetch,\n    pg_size_pretty(pg_relation_size(indexrelid)) as index_size\nFROM pg_stat_user_indexes\nWHERE schemaname IN ('temporal', 'temporal_visibility')\nORDER BY idx_scan DESC;\n\n-- Find unused indexes\nSELECT \n    schemaname,\n    tablename,\n    indexname,\n    pg_size_pretty(pg_relation_size(indexrelid)) as index_size\nFROM pg_stat_user_indexes\nWHERE schemaname IN ('temporal', 'temporal_visibility')\nAND idx_scan = 0\nORDER BY pg_relation_size(indexrelid) DESC;\n</code></pre>"},{"location":"architecture/database-design/#disaster-recovery-and-high-availability","title":"Disaster Recovery and High Availability","text":""},{"location":"architecture/database-design/#database-failover-procedures","title":"Database Failover Procedures","text":""},{"location":"architecture/database-design/#automated-failover-with-patroni","title":"Automated Failover with Patroni","text":"<pre><code># Patroni configuration for PostgreSQL HA\npatroni:\n  scope: temporal-cluster\n  namespace: temporal-backend\n\n  bootstrap:\n    dcs:\n      ttl: 30\n      loop_wait: 10\n      retry_timeout: 30\n      maximum_lag_on_failover: 1048576  # 1MB\n      master_start_timeout: 300\n      synchronous_mode: true\n      synchronous_mode_strict: false\n\n    initdb:\n      - encoding: UTF8\n      - data-checksums\n\n  postgresql:\n    use_pg_rewind: true\n    use_slots: true\n    parameters:\n      wal_level: replica\n      hot_standby: \"on\"\n      max_connections: 1000\n      max_wal_senders: 10\n      max_replication_slots: 10\n      wal_keep_segments: 8\n\n  watchdog:\n    mode: required\n    device: /dev/watchdog\n    safety_margin: 5\n</code></pre>"},{"location":"architecture/database-design/#cross-region-data-replication","title":"Cross-Region Data Replication","text":""},{"location":"architecture/database-design/#logical-replication-setup","title":"Logical Replication Setup","text":"<pre><code>-- Set up logical replication for disaster recovery\n-- On primary cluster\nCREATE PUBLICATION temporal_pub FOR ALL TABLES IN SCHEMA temporal, temporal_visibility;\n\n-- On secondary cluster (different region)\nCREATE SUBSCRIPTION temporal_sub \nCONNECTION 'host=primary-cluster.example.com port=5432 user=replicator dbname=temporal'\nPUBLICATION temporal_pub\nWITH (copy_data = true, create_slot = true, enabled = true);\n\n-- Monitor replication lag\nSELECT \n    application_name,\n    client_addr,\n    state,\n    sent_lsn,\n    write_lsn,\n    flush_lsn,\n    replay_lsn,\n    write_lag,\n    flush_lag,\n    replay_lag\nFROM pg_stat_replication;\n</code></pre>"},{"location":"architecture/database-design/#recovery-testing","title":"Recovery Testing","text":""},{"location":"architecture/database-design/#automated-recovery-testing","title":"Automated Recovery Testing","text":"<pre><code>#!/bin/bash\n# Disaster recovery testing script\ntest_recovery() {\n    local test_type=$1\n    local test_timestamp=$(date +%Y%m%d_%H%M%S)\n    local test_namespace=\"temporal-dr-test-$test_timestamp\"\n\n    echo \"Starting DR test: $test_type at $test_timestamp\"\n\n    case $test_type in\n        \"point_in_time\")\n            # Test point-in-time recovery\n            test_pitr_recovery \"$test_namespace\"\n            ;;\n        \"full_restore\")\n            # Test full backup restore\n            test_full_restore \"$test_namespace\"\n            ;;\n        \"failover\")\n            # Test automatic failover\n            test_automatic_failover \"$test_namespace\"\n            ;;\n        *)\n            echo \"Unknown test type: $test_type\"\n            exit 1\n            ;;\n    esac\n\n    # Cleanup test resources\n    cleanup_test_environment \"$test_namespace\"\n\n    echo \"DR test completed: $test_type\"\n}\n\n# Schedule monthly DR tests\necho \"0 3 1 * * /path/to/test_recovery.sh point_in_time\" | crontab -\n</code></pre> <p>This comprehensive database design ensures that the Temporal.io enterprise deployment has a robust, scalable, and highly available data layer that can handle enterprise workloads while maintaining data integrity, performance, and recoverability.</p>"},{"location":"architecture/network-architecture/","title":"Network Architecture","text":"<p>This document details the comprehensive network architecture for the Temporal.io enterprise deployment, covering network topology, traffic flows, security policies, and connectivity patterns within the Kubernetes environment.</p>"},{"location":"architecture/network-architecture/#network-architecture-overview","title":"Network Architecture Overview","text":"<p>The network design implements a defense-in-depth strategy with multiple layers of network controls, micro-segmentation, and zero-trust networking principles to ensure secure and efficient communication between all system components.</p> <pre><code>graph TB\n    subgraph \"External Network\"\n        EXT1[Internet Traffic]\n        EXT2[Corporate Network&lt;br/&gt;Private Connectivity]\n        EXT3[Cloud Provider Network&lt;br/&gt;AWS/GCP/Azure]\n        EXT4[External APIs&lt;br/&gt;Third-party Services]\n    end\n\n    subgraph \"Edge Security Layer\"\n        EDGE1[WAF&lt;br/&gt;Web Application Firewall]\n        EDGE2[DDoS Protection&lt;br/&gt;Rate Limiting]\n        EDGE3[Load Balancer&lt;br/&gt;Application Gateway]\n        EDGE4[CDN&lt;br/&gt;Content Delivery Network]\n    end\n\n    subgraph \"Kubernetes Network\"\n        subgraph \"Ingress Layer\"\n            ING1[Ingress Controller&lt;br/&gt;NGINX/Traefik]\n            ING2[Certificate Termination&lt;br/&gt;TLS 1.3]\n            ING3[Service Mesh Gateway&lt;br/&gt;Istio/Linkerd]\n        end\n\n        subgraph \"Service Mesh\"\n            MESH1[Sidecar Proxies&lt;br/&gt;Envoy/Linkerd2]\n            MESH2[mTLS Encryption&lt;br/&gt;Automatic Rotation]\n            MESH3[Traffic Policies&lt;br/&gt;Circuit Breakers]\n            MESH4[Observability&lt;br/&gt;Metrics &amp; Tracing]\n        end\n\n        subgraph \"Pod Network (CNI)\"\n            CNI1[Container Network Interface&lt;br/&gt;Calico/Cilium/Flannel]\n            CNI2[Pod-to-Pod Communication&lt;br/&gt;Overlay Network]\n            CNI3[Network Policies&lt;br/&gt;Micro-segmentation]\n            CNI4[IPAM&lt;br/&gt;IP Address Management]\n        end\n\n        subgraph \"Node Network\"\n            NODE1[Worker Nodes&lt;br/&gt;Kubernetes Hosts]\n            NODE2[Control Plane Nodes&lt;br/&gt;API Server Access]\n            NODE3[Storage Nodes&lt;br/&gt;Persistent Volumes]\n            NODE4[Monitoring Nodes&lt;br/&gt;Observability Stack]\n        end\n    end\n\n    subgraph \"Data Layer Network\"\n        DATA1[Database Network&lt;br/&gt;PostgreSQL Cluster]\n        DATA2[Cache Network&lt;br/&gt;Redis Cluster]\n        DATA3[Search Network&lt;br/&gt;Elasticsearch Cluster]\n        DATA4[Storage Network&lt;br/&gt;Object Storage]\n    end\n\n    EXT1 --&gt; EDGE1\n    EDGE1 --&gt; ING1\n    ING1 --&gt; MESH1\n    MESH1 --&gt; CNI1\n    CNI1 --&gt; NODE1\n    NODE1 --&gt; DATA1</code></pre>"},{"location":"architecture/network-architecture/#network-topology","title":"Network Topology","text":""},{"location":"architecture/network-architecture/#physical-network-layout","title":"Physical Network Layout","text":""},{"location":"architecture/network-architecture/#multi-zone-deployment","title":"Multi-Zone Deployment","text":"<pre><code>network_topology:\n  regions:\n    primary:\n      name: us-east-1\n      zones:\n        - us-east-1a\n        - us-east-1b\n        - us-east-1c\n      vpc_cidr: 10.0.0.0/16\n\n    secondary:\n      name: us-west-2\n      zones:\n        - us-west-2a\n        - us-west-2b\n        - us-west-2c\n      vpc_cidr: 10.1.0.0/16\n\n  subnets:\n    public:\n      - cidr: 10.0.1.0/24    # us-east-1a public\n      - cidr: 10.0.2.0/24    # us-east-1b public\n      - cidr: 10.0.3.0/24    # us-east-1c public\n      purpose: Load balancers, NAT gateways\n\n    private:\n      - cidr: 10.0.10.0/24   # us-east-1a private\n      - cidr: 10.0.20.0/24   # us-east-1b private\n      - cidr: 10.0.30.0/24   # us-east-1c private\n      purpose: Kubernetes nodes, applications\n\n    database:\n      - cidr: 10.0.100.0/24  # us-east-1a database\n      - cidr: 10.0.101.0/24  # us-east-1b database\n      - cidr: 10.0.102.0/24  # us-east-1c database\n      purpose: Database clusters, storage\n</code></pre>"},{"location":"architecture/network-architecture/#kubernetes-network-configuration","title":"Kubernetes Network Configuration","text":"<pre><code>kubernetes_network:\n  cluster_cidr: 10.244.0.0/16\n  service_cidr: 10.96.0.0/12\n  pod_cidr: 10.244.0.0/16\n\n  dns:\n    cluster_dns: 10.96.0.10\n    domain: cluster.local\n\n  cni:\n    plugin: calico\n    mtu: 1500\n    backend: vxlan\n\n  node_port_range: 30000-32767\n</code></pre>"},{"location":"architecture/network-architecture/#container-network-interface-cni","title":"Container Network Interface (CNI)","text":""},{"location":"architecture/network-architecture/#calico-configuration","title":"Calico Configuration","text":""},{"location":"architecture/network-architecture/#network-policy-engine","title":"Network Policy Engine","text":"<pre><code># Calico Global Network Policy\napiVersion: projectcalico.org/v3\nkind: GlobalNetworkPolicy\nmetadata:\n  name: temporal-global-policy\nspec:\n  order: 100\n  namespaceSelector: has(name) &amp;&amp; name in {\"temporal-backend\", \"temporal-product\"}\n  types:\n  - Ingress\n  - Egress\n  egress:\n  # Allow DNS\n  - action: Allow\n    protocol: UDP\n    destination:\n      selector: k8s-app == \"kube-dns\"\n      ports:\n      - 53\n  # Allow access to Kubernetes API\n  - action: Allow\n    protocol: TCP\n    destination:\n      nets:\n      - 10.96.0.1/32  # Kubernetes API service\n      ports:\n      - 443\n  # Deny all other traffic by default\n  - action: Deny\n\n---\n# Calico IP Pool Configuration\napiVersion: projectcalico.org/v3\nkind: IPPool\nmetadata:\n  name: temporal-pool\nspec:\n  cidr: 10.244.0.0/16\n  ipipMode: Always\n  natOutgoing: true\n  nodeSelector: all()\n</code></pre>"},{"location":"architecture/network-architecture/#felix-configuration","title":"Felix Configuration","text":"<pre><code># Calico Felix Configuration\napiVersion: projectcalico.org/v3\nkind: FelixConfiguration\nmetadata:\n  name: default\nspec:\n  bpfLogLevel: \"Off\"\n  floatingIPs: Disabled\n  healthPort: 9099\n  logSeverityScreen: Info\n  prometheusMetricsEnabled: true\n  prometheusMetricsPort: 9091\n  reportingInterval: 30s\n  wireguardEnabled: true\n  wireguardInterfaceName: wireguard.cali\n</code></pre>"},{"location":"architecture/network-architecture/#network-policies","title":"Network Policies","text":""},{"location":"architecture/network-architecture/#namespace-level-policies","title":"Namespace-Level Policies","text":"<pre><code># Default deny-all policy for temporal-backend\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: default-deny-all\n  namespace: temporal-backend\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\n\n---\n# Allow temporal-backend internal communication\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: temporal-backend-internal\n  namespace: temporal-backend\nspec:\n  podSelector:\n    matchLabels:\n      app.kubernetes.io/part-of: temporal\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  - from:\n    - podSelector:\n        matchLabels:\n          app.kubernetes.io/part-of: temporal\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-product\n    - namespaceSelector:\n        matchLabels:\n          name: monitoring\n    ports:\n    - protocol: TCP\n      port: 7233  # Frontend service\n    - protocol: TCP\n      port: 7234  # History service\n    - protocol: TCP\n      port: 7235  # Matching service\n    - protocol: TCP\n      port: 7239  # Worker service\n    - protocol: TCP\n      port: 8080  # Web UI\n    - protocol: TCP\n      port: 9090  # Metrics\n  egress:\n  - to:\n    - podSelector:\n        matchLabels:\n          app.kubernetes.io/part-of: temporal\n  - to:\n    - podSelector:\n        matchLabels:\n          app: postgresql\n    ports:\n    - protocol: TCP\n      port: 5432\n  - to:\n    - podSelector:\n        matchLabels:\n          app: elasticsearch\n    ports:\n    - protocol: TCP\n      port: 9200\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 53\n    - protocol: UDP\n      port: 53\n\n---\n# Database access policy\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: database-access\n  namespace: temporal-backend\nspec:\n  podSelector:\n    matchLabels:\n      app: postgresql\n  policyTypes:\n  - Ingress\n  ingress:\n  - from:\n    - podSelector:\n        matchLabels:\n          app.kubernetes.io/part-of: temporal\n    - namespaceSelector:\n        matchLabels:\n          name: monitoring\n      podSelector:\n        matchLabels:\n          app: postgres-exporter\n    ports:\n    - protocol: TCP\n      port: 5432\n\n---\n# Elasticsearch access policy\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: elasticsearch-access\n  namespace: temporal-backend\nspec:\n  podSelector:\n    matchLabels:\n      app: elasticsearch\n  policyTypes:\n  - Ingress\n  ingress:\n  - from:\n    - podSelector:\n        matchLabels:\n          app.kubernetes.io/part-of: temporal\n    - namespaceSelector:\n        matchLabels:\n          name: monitoring\n    ports:\n    - protocol: TCP\n      port: 9200\n    - protocol: TCP\n      port: 9300\n</code></pre>"},{"location":"architecture/network-architecture/#application-level-policies","title":"Application-Level Policies","text":"<pre><code># Temporal worker egress policy\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: temporal-worker-egress\n  namespace: temporal-product\nspec:\n  podSelector:\n    matchLabels:\n      app: temporal-worker\n  policyTypes:\n  - Egress\n  egress:\n  # Allow connection to Temporal frontend\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-backend\n      podSelector:\n        matchLabels:\n          app: temporal-frontend\n    ports:\n    - protocol: TCP\n      port: 7233\n  # Allow DNS resolution\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 53\n    - protocol: UDP\n      port: 53\n  # Allow connection to external APIs (specific endpoints)\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 443\n    - protocol: TCP\n      port: 80\n\n---\n# FastAPI service policies\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: fastapi-service-policy\n  namespace: temporal-product\nspec:\n  podSelector:\n    matchLabels:\n      app: fastapi-service\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  # Allow ingress controller traffic\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: ingress-nginx\n    ports:\n    - protocol: TCP\n      port: 8000\n  # Allow monitoring\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: monitoring\n    ports:\n    - protocol: TCP\n      port: 8080  # Metrics endpoint\n  egress:\n  # Allow connection to Temporal\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-backend\n    ports:\n    - protocol: TCP\n      port: 7233\n  # Allow database access (if needed)\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-backend\n      podSelector:\n        matchLabels:\n          app: postgresql\n    ports:\n    - protocol: TCP\n      port: 5432\n  # Allow DNS\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 53\n    - protocol: UDP\n      port: 53\n</code></pre>"},{"location":"architecture/network-architecture/#service-mesh-architecture","title":"Service Mesh Architecture","text":""},{"location":"architecture/network-architecture/#istio-configuration","title":"Istio Configuration","text":""},{"location":"architecture/network-architecture/#mesh-wide-policies","title":"Mesh-wide Policies","text":"<pre><code># Default mTLS policy\napiVersion: security.istio.io/v1beta1\nkind: PeerAuthentication\nmetadata:\n  name: default\n  namespace: istio-system\nspec:\n  mtls:\n    mode: STRICT\n\n---\n# Temporal namespace mTLS\napiVersion: security.istio.io/v1beta1\nkind: PeerAuthentication\nmetadata:\n  name: temporal-mtls\n  namespace: temporal-backend\nspec:\n  mtls:\n    mode: STRICT\n\n---\n# Destination rule for Temporal services\napiVersion: networking.istio.io/v1beta1\nkind: DestinationRule\nmetadata:\n  name: temporal-services\n  namespace: temporal-backend\nspec:\n  host: \"*.temporal-backend.svc.cluster.local\"\n  trafficPolicy:\n    tls:\n      mode: ISTIO_MUTUAL\n    connectionPool:\n      tcp:\n        maxConnections: 100\n      http:\n        http1MaxPendingRequests: 50\n        http2MaxRequests: 100\n        maxRequestsPerConnection: 10\n        maxRetries: 3\n    circuitBreaker:\n      consecutiveErrors: 3\n      interval: 30s\n      baseEjectionTime: 30s\n      maxEjectionPercent: 50\n</code></pre>"},{"location":"architecture/network-architecture/#traffic-management","title":"Traffic Management","text":"<pre><code># Virtual Service for Temporal Web UI\napiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: temporal-web-ui\n  namespace: temporal-backend\nspec:\n  hosts:\n  - temporal-ui.example.com\n  gateways:\n  - temporal-gateway\n  http:\n  - match:\n    - uri:\n        prefix: /\n    route:\n    - destination:\n        host: temporal-web.temporal-backend.svc.cluster.local\n        port:\n          number: 8080\n    fault:\n      delay:\n        percentage:\n          value: 0.1\n        fixedDelay: 5s\n    retries:\n      attempts: 3\n      perTryTimeout: 10s\n\n---\n# Gateway configuration\napiVersion: networking.istio.io/v1beta1\nkind: Gateway\nmetadata:\n  name: temporal-gateway\n  namespace: temporal-backend\nspec:\n  selector:\n    istio: ingressgateway\n  servers:\n  - port:\n      number: 443\n      name: https\n      protocol: HTTPS\n    tls:\n      mode: SIMPLE\n      credentialName: temporal-ui-tls\n    hosts:\n    - temporal-ui.example.com\n  - port:\n      number: 443\n      name: grpc-tls\n      protocol: HTTPS\n    tls:\n      mode: SIMPLE\n      credentialName: temporal-api-tls\n    hosts:\n    - temporal-api.example.com\n</code></pre>"},{"location":"architecture/network-architecture/#security-policies","title":"Security Policies","text":"<pre><code># Authorization policy for Temporal frontend\napiVersion: security.istio.io/v1beta1\nkind: AuthorizationPolicy\nmetadata:\n  name: temporal-frontend-authz\n  namespace: temporal-backend\nspec:\n  selector:\n    matchLabels:\n      app: temporal-frontend\n  rules:\n  - from:\n    - source:\n        namespaces: [\"temporal-product\"]\n    - source:\n        principals: [\"cluster.local/ns/temporal-backend/sa/temporal-web\"]\n    to:\n    - operation:\n        methods: [\"POST\", \"GET\"]\n        paths: [\"/temporal.api.workflowservice.v1.*\"]\n  - from:\n    - source:\n        namespaces: [\"monitoring\"]\n    to:\n    - operation:\n        methods: [\"GET\"]\n        paths: [\"/metrics\", \"/health\"]\n\n---\n# JWT authentication for external access\napiVersion: security.istio.io/v1beta1\nkind: RequestAuthentication\nmetadata:\n  name: temporal-jwt\n  namespace: temporal-backend\nspec:\n  selector:\n    matchLabels:\n      app: temporal-web\n  jwtRules:\n  - issuer: \"https://authentik.example.com/application/o/temporal/\"\n    jwksUri: \"https://authentik.example.com/application/o/temporal/.well-known/jwks.json\"\n    audiences:\n    - \"temporal-client\"\n</code></pre>"},{"location":"architecture/network-architecture/#load-balancing-and-traffic-distribution","title":"Load Balancing and Traffic Distribution","text":""},{"location":"architecture/network-architecture/#ingress-configuration","title":"Ingress Configuration","text":""},{"location":"architecture/network-architecture/#nginx-ingress-controller","title":"NGINX Ingress Controller","text":"<pre><code># NGINX Ingress for Temporal Web UI\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: temporal-web-ingress\n  namespace: temporal-backend\n  annotations:\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/backend-protocol: \"HTTP\"\n    nginx.ingress.kubernetes.io/upstream-hash-by: \"$remote_addr\"\n    nginx.ingress.kubernetes.io/rate-limit: \"100\"\n    nginx.ingress.kubernetes.io/rate-limit-window: \"1m\"\n    nginx.ingress.kubernetes.io/connection-proxy-header: \"keep-alive\"\n    nginx.ingress.kubernetes.io/proxy-connect-timeout: \"10\"\n    nginx.ingress.kubernetes.io/proxy-send-timeout: \"60\"\n    nginx.ingress.kubernetes.io/proxy-read-timeout: \"60\"\n    nginx.ingress.kubernetes.io/auth-url: \"https://authentik.example.com/outpost.goauthentik.io/auth/nginx\"\n    nginx.ingress.kubernetes.io/auth-signin: \"https://authentik.example.com/outpost.goauthentik.io/start?rd=$escaped_request_uri\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - temporal-ui.example.com\n    secretName: temporal-ui-tls\n  rules:\n  - host: temporal-ui.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: temporal-web\n            port:\n              number: 8080\n\n---\n# NGINX Ingress for Temporal gRPC API\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: temporal-grpc-ingress\n  namespace: temporal-backend\n  annotations:\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/backend-protocol: \"GRPC\"\n    nginx.ingress.kubernetes.io/grpc-backend: \"true\"\n    nginx.ingress.kubernetes.io/upstream-hash-by: \"$remote_addr\"\n    nginx.ingress.kubernetes.io/rate-limit: \"1000\"\n    nginx.ingress.kubernetes.io/rate-limit-window: \"1m\"\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - temporal-api.example.com\n    secretName: temporal-api-tls\n  rules:\n  - host: temporal-api.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: temporal-frontend\n            port:\n              number: 7233\n</code></pre>"},{"location":"architecture/network-architecture/#service-configuration","title":"Service Configuration","text":""},{"location":"architecture/network-architecture/#temporal-services","title":"Temporal Services","text":"<pre><code># Temporal Frontend Service\napiVersion: v1\nkind: Service\nmetadata:\n  name: temporal-frontend\n  namespace: temporal-backend\n  labels:\n    app: temporal-frontend\n  annotations:\n    service.beta.kubernetes.io/aws-load-balancer-type: \"nlb\"\n    service.beta.kubernetes.io/aws-load-balancer-backend-protocol: \"tcp\"\n    service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout: \"300\"\nspec:\n  type: ClusterIP\n  sessionAffinity: ClientIP\n  sessionAffinityConfig:\n    clientIP:\n      timeoutSeconds: 300\n  ports:\n  - name: grpc\n    port: 7233\n    targetPort: 7233\n    protocol: TCP\n  - name: membership\n    port: 6933\n    targetPort: 6933\n    protocol: TCP\n  - name: http\n    port: 7243\n    targetPort: 7243\n    protocol: TCP\n  selector:\n    app: temporal-frontend\n\n---\n# Temporal Web Service\napiVersion: v1\nkind: Service\nmetadata:\n  name: temporal-web\n  namespace: temporal-backend\n  labels:\n    app: temporal-web\nspec:\n  type: ClusterIP\n  ports:\n  - name: http\n    port: 8080\n    targetPort: 8080\n    protocol: TCP\n  selector:\n    app: temporal-web\n\n---\n# Temporal History Service (Headless for internal use)\napiVersion: v1\nkind: Service\nmetadata:\n  name: temporal-history\n  namespace: temporal-backend\n  labels:\n    app: temporal-history\nspec:\n  type: ClusterIP\n  clusterIP: None\n  ports:\n  - name: grpc\n    port: 7234\n    targetPort: 7234\n    protocol: TCP\n  - name: membership\n    port: 6934\n    targetPort: 6934\n    protocol: TCP\n  selector:\n    app: temporal-history\n</code></pre>"},{"location":"architecture/network-architecture/#dns-and-service-discovery","title":"DNS and Service Discovery","text":""},{"location":"architecture/network-architecture/#coredns-configuration","title":"CoreDNS Configuration","text":"<pre><code># CoreDNS ConfigMap\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: coredns\n  namespace: kube-system\ndata:\n  Corefile: |\n    .:53 {\n        errors\n        health {\n            lameduck 5s\n        }\n        ready\n        kubernetes cluster.local in-addr.arpa ip6.arpa {\n            pods insecure\n            fallthrough in-addr.arpa ip6.arpa\n            ttl 30\n        }\n        prometheus :9153\n        forward . /etc/resolv.conf {\n            max_concurrent 1000\n        }\n        cache 30\n        loop\n        reload\n        loadbalance\n    }\n\n    # Custom zone for temporal services\n    temporal.local:53 {\n        errors\n        cache 30\n        kubernetes cluster.local in-addr.arpa ip6.arpa {\n            pods insecure\n            fallthrough in-addr.arpa ip6.arpa\n            ttl 30\n        }\n        rewrite name temporal-frontend.temporal.local temporal-frontend.temporal-backend.svc.cluster.local\n        rewrite name temporal-web.temporal.local temporal-web.temporal-backend.svc.cluster.local\n    }\n</code></pre>"},{"location":"architecture/network-architecture/#service-discovery-patterns","title":"Service Discovery Patterns","text":"<pre><code># Temporal Client Service Discovery\ntemporal_endpoints:\n  frontend:\n    fqdn: temporal-frontend.temporal-backend.svc.cluster.local\n    port: 7233\n    protocol: grpc\n    health_check: /temporal.api.workflowservice.v1.WorkflowService/GetSystemInfo\n\n  web_ui:\n    fqdn: temporal-web.temporal-backend.svc.cluster.local\n    port: 8080\n    protocol: http\n    health_check: /health\n\n  history:\n    fqdn: temporal-history.temporal-backend.svc.cluster.local\n    port: 7234\n    protocol: grpc\n    discovery_type: headless\n\n  matching:\n    fqdn: temporal-matching.temporal-backend.svc.cluster.local\n    port: 7235\n    protocol: grpc\n    discovery_type: headless\n</code></pre>"},{"location":"architecture/network-architecture/#network-monitoring-and-observability","title":"Network Monitoring and Observability","text":""},{"location":"architecture/network-architecture/#traffic-flow-monitoring","title":"Traffic Flow Monitoring","text":"<pre><code># Network monitoring configuration\nnetwork_monitoring:\n  flow_logs:\n    enabled: true\n    destinations:\n      - cloudwatch_logs\n      - elasticsearch\n    retention: 7_days\n\n  packet_capture:\n    enabled: false  # Enable only for debugging\n    tools:\n      - tcpdump\n      - wireshark\n      - istio_proxy_debug\n\n  metrics:\n    - connection_count\n    - bandwidth_utilization\n    - packet_loss\n    - latency_percentiles\n    - error_rates\n\n  alerts:\n    - name: high_connection_count\n      threshold: 10000\n      duration: 5m\n    - name: packet_loss\n      threshold: 1%\n      duration: 2m\n    - name: high_latency\n      threshold: 100ms\n      duration: 5m\n</code></pre>"},{"location":"architecture/network-architecture/#network-performance-metrics","title":"Network Performance Metrics","text":"<pre><code># Prometheus metrics for network monitoring\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: network-monitoring-rules\n  namespace: monitoring\ndata:\n  network.yml: |\n    groups:\n    - name: network.rules\n      rules:\n      - alert: HighNetworkLatency\n        expr: histogram_quantile(0.99, rate(istio_request_duration_milliseconds_bucket[5m])) &gt; 100\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High network latency detected\"\n          description: \"99th percentile latency is {{ $value }}ms\"\n\n      - alert: NetworkPacketLoss\n        expr: rate(node_network_receive_drop_total[5m]) &gt; 0.01\n        for: 2m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Network packet loss detected\"\n          description: \"Packet loss rate: {{ $value }}\"\n\n      - alert: ConnectionPoolExhaustion\n        expr: envoy_cluster_upstream_cx_active / envoy_cluster_upstream_cx_max &gt; 0.9\n        for: 1m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"Connection pool nearly exhausted\"\n          description: \"Active connections: {{ $value }}\"\n</code></pre>"},{"location":"architecture/network-architecture/#network-security-controls","title":"Network Security Controls","text":""},{"location":"architecture/network-architecture/#firewall-rules","title":"Firewall Rules","text":"<pre><code># AWS Security Group rules (example)\nsecurity_groups:\n  temporal_backend:\n    description: \"Temporal backend security group\"\n    ingress_rules:\n      - protocol: tcp\n        from_port: 7233\n        to_port: 7233\n        source_security_group: temporal_workers\n        description: \"Temporal gRPC API\"\n      - protocol: tcp\n        from_port: 8080\n        to_port: 8080\n        source_security_group: load_balancer\n        description: \"Web UI\"\n      - protocol: tcp\n        from_port: 9090\n        to_port: 9090\n        source_security_group: monitoring\n        description: \"Metrics endpoint\"\n    egress_rules:\n      - protocol: tcp\n        from_port: 5432\n        to_port: 5432\n        destination_security_group: database\n        description: \"PostgreSQL access\"\n      - protocol: tcp\n        from_port: 9200\n        to_port: 9200\n        destination_security_group: elasticsearch\n        description: \"Elasticsearch access\"\n\n  temporal_workers:\n    description: \"Temporal workers security group\"\n    ingress_rules:\n      - protocol: tcp\n        from_port: 8080\n        to_port: 8080\n        source_security_group: monitoring\n        description: \"Metrics endpoint\"\n    egress_rules:\n      - protocol: tcp\n        from_port: 7233\n        to_port: 7233\n        destination_security_group: temporal_backend\n        description: \"Temporal frontend access\"\n      - protocol: tcp\n        from_port: 443\n        to_port: 443\n        destination: 0.0.0.0/0\n        description: \"HTTPS outbound\"\n</code></pre>"},{"location":"architecture/network-architecture/#network-intrusion-detection","title":"Network Intrusion Detection","text":"<pre><code># Falco network rules\nnetwork_security_rules:\n  - rule: Unauthorized Network Connection\n    desc: Detect unauthorized network connections from Temporal containers\n    condition: &gt;\n      inbound_outbound and\n      container and\n      container.image.repository contains \"temporal\" and\n      (fd.rip != \"\" and not fd.rip in (allowed_ips))\n    output: &gt;\n      Unauthorized network connection from Temporal container\n      (user=%user.name command=%proc.cmdline connection=%fd.name container=%container.name)\n    priority: WARNING\n\n  - rule: Suspicious Port Activity\n    desc: Detect connections to unusual ports\n    condition: &gt;\n      inbound_outbound and\n      container and\n      container.image.repository contains \"temporal\" and\n      fd.rport != \"\" and\n      not fd.rport in (7233, 7234, 7235, 7239, 8080, 5432, 9200, 53, 443, 80)\n    output: &gt;\n      Suspicious port activity from Temporal container\n      (user=%user.name port=%fd.rport container=%container.name)\n    priority: WARNING\n</code></pre>"},{"location":"architecture/network-architecture/#disaster-recovery-network-configuration","title":"Disaster Recovery Network Configuration","text":""},{"location":"architecture/network-architecture/#multi-region-connectivity","title":"Multi-Region Connectivity","text":"<pre><code># Cross-region network configuration\nmulti_region_setup:\n  primary_region:\n    name: us-east-1\n    vpc_cidr: 10.0.0.0/16\n    cluster_cidr: 10.244.0.0/16\n\n  secondary_region:\n    name: us-west-2\n    vpc_cidr: 10.1.0.0/16\n    cluster_cidr: 10.245.0.0/16\n\n  vpc_peering:\n    enabled: true\n    routes:\n      - destination: 10.1.0.0/16\n        target: pcx-12345678\n\n  transit_gateway:\n    enabled: true\n    asn: 64512\n    routes:\n      - cidr: 10.0.0.0/8\n        attachment: primary_cluster\n\n  vpn_connections:\n    site_to_site:\n      enabled: true\n      bgp_asn: 65000\n      tunnels: 2\n      encryption: aes-256\n</code></pre>"},{"location":"architecture/network-architecture/#network-failover","title":"Network Failover","text":"<pre><code># DNS failover configuration\ndns_failover:\n  health_checks:\n    - name: temporal-frontend-primary\n      fqdn: temporal-api.example.com\n      port: 443\n      protocol: https\n      path: /health\n      interval: 30s\n\n  failover_policies:\n    - name: temporal-api-failover\n      primary:\n        region: us-east-1\n        weight: 100\n      secondary:\n        region: us-west-2\n        weight: 0\n      health_check: temporal-frontend-primary\n      failover_threshold: 2\n</code></pre> <p>This comprehensive network architecture ensures secure, scalable, and resilient connectivity for the Temporal.io enterprise deployment while maintaining performance and observability across all network layers.</p>"},{"location":"architecture/security-design/","title":"Security Design","text":"<p>This document outlines the comprehensive security architecture for the Temporal.io enterprise deployment, implementing defense-in-depth strategies and zero-trust principles across all system components.</p>"},{"location":"architecture/security-design/#security-architecture-overview","title":"Security Architecture Overview","text":"<p>The security design follows a layered approach with multiple security controls at different levels of the stack, ensuring comprehensive protection against various threat vectors.</p> <pre><code>graph TB\n    subgraph \"External Security Perimeter\"\n        EXT1[Web Application Firewall&lt;br/&gt;ModSecurity/CloudFlare]\n        EXT2[DDoS Protection&lt;br/&gt;CloudFlare/AWS Shield]\n        EXT3[CDN Security&lt;br/&gt;Geographic Restrictions]\n    end\n\n    subgraph \"Network Security Layer\"\n        NET1[Network Policies&lt;br/&gt;Kubernetes CNI]\n        NET2[Service Mesh Security&lt;br/&gt;Istio/Linkerd mTLS]\n        NET3[Ingress Security&lt;br/&gt;NGINX/Traefik TLS]\n        NET4[Firewall Rules&lt;br/&gt;iptables/Cilium]\n    end\n\n    subgraph \"Identity &amp; Access Management\"\n        IAM1[SSO Provider&lt;br/&gt;Authentik/Keycloak]\n        IAM2[Identity Broker&lt;br/&gt;OIDC/SAML]\n        IAM3[Service Accounts&lt;br/&gt;Kubernetes RBAC]\n        IAM4[API Keys&lt;br/&gt;Temporal Authorization]\n    end\n\n    subgraph \"Secrets Management\"\n        SEC1[External Secrets&lt;br/&gt;HashiCorp Vault]\n        SEC2[Certificate Management&lt;br/&gt;cert-manager]\n        SEC3[Encryption at Rest&lt;br/&gt;LUKS/Cloud KMS]\n        SEC4[Secret Rotation&lt;br/&gt;Automated Lifecycle]\n    end\n\n    subgraph \"Application Security\"\n        APP1[Code Scanning&lt;br/&gt;SAST/DAST Tools]\n        APP2[Container Security&lt;br/&gt;Trivy/Twistlock]\n        APP3[Runtime Security&lt;br/&gt;Falco/Sysdig]\n        APP4[Admission Controllers&lt;br/&gt;OPA/Gatekeeper]\n    end\n\n    subgraph \"Data Security\"\n        DATA1[Encryption in Transit&lt;br/&gt;TLS 1.3]\n        DATA2[Database Encryption&lt;br/&gt;Transparent Data Encryption]\n        DATA3[Backup Encryption&lt;br/&gt;Client-side Encryption]\n        DATA4[Data Classification&lt;br/&gt;PII/PHI Tagging]\n    end\n\n    subgraph \"Monitoring &amp; Compliance\"\n        MON1[Security Monitoring&lt;br/&gt;SIEM Integration]\n        MON2[Audit Logging&lt;br/&gt;Centralized Logs]\n        MON3[Compliance Reporting&lt;br/&gt;SOC2/GDPR]\n        MON4[Threat Detection&lt;br/&gt;AI/ML Analytics]\n    end\n\n    EXT1 --&gt; NET1\n    NET1 --&gt; IAM1\n    IAM1 --&gt; SEC1\n    SEC1 --&gt; APP1\n    APP1 --&gt; DATA1\n    DATA1 --&gt; MON1</code></pre>"},{"location":"architecture/security-design/#zero-trust-architecture","title":"Zero Trust Architecture","text":""},{"location":"architecture/security-design/#core-principles","title":"Core Principles","text":"<ol> <li>Never Trust, Always Verify</li> <li>Every request requires authentication and authorization</li> <li>Identity verification for both users and services</li> <li> <p>Continuous validation of security posture</p> </li> <li> <p>Principle of Least Privilege</p> </li> <li>Minimal access rights by default</li> <li>Just-in-time access provisioning</li> <li> <p>Regular access reviews and rotation</p> </li> <li> <p>Assume Breach</p> </li> <li>Micro-segmentation to limit blast radius</li> <li>Continuous monitoring and detection</li> <li> <p>Rapid incident response capabilities</p> </li> <li> <p>Explicit Verification</p> </li> <li>Multi-factor authentication</li> <li>Device trust verification</li> <li>Location and behavior analysis</li> </ol>"},{"location":"architecture/security-design/#implementation-strategy","title":"Implementation Strategy","text":"<pre><code>graph LR\n    subgraph \"Trust Verification\"\n        A[User/Service Identity] --&gt; B[Device Trust]\n        B --&gt; C[Network Location]\n        C --&gt; D[Behavior Analysis]\n    end\n\n    subgraph \"Access Decision\"\n        D --&gt; E[Policy Engine]\n        E --&gt; F[Risk Assessment]\n        F --&gt; G[Access Grant/Deny]\n    end\n\n    subgraph \"Continuous Monitoring\"\n        G --&gt; H[Session Monitoring]\n        H --&gt; I[Anomaly Detection]\n        I --&gt; J[Adaptive Response]\n    end</code></pre>"},{"location":"architecture/security-design/#identity-and-access-management-iam","title":"Identity and Access Management (IAM)","text":""},{"location":"architecture/security-design/#authentication-architecture","title":"Authentication Architecture","text":""},{"location":"architecture/security-design/#single-sign-on-sso-with-authentik","title":"Single Sign-On (SSO) with Authentik","text":"<pre><code># Authentik Configuration\nauthentik_config:\n  providers:\n    temporal_oidc:\n      type: oauth2_openid\n      name: \"Temporal Enterprise\"\n      client_id: temporal-client\n      client_secret: !vault:secret/temporal/oidc#client_secret\n      redirect_uris:\n        - https://temporal-ui.example.com/auth/callback\n        - https://temporal-api.example.com/auth/callback\n      scopes:\n        - openid\n        - profile\n        - email\n        - groups\n\n  applications:\n    temporal_web:\n      name: \"Temporal Web UI\"\n      slug: temporal-web\n      provider: temporal_oidc\n      policy_engine_mode: any\n\n    temporal_api:\n      name: \"Temporal API\"\n      slug: temporal-api\n      provider: temporal_oidc\n      policy_engine_mode: all\n\n  policies:\n    temporal_access:\n      name: \"Temporal Access Policy\"\n      policy_type: expression\n      expression: |\n        return request.user.is_in_group(name=\"temporal-users\") and\n               request.user.attributes.get(\"department\") in [\"engineering\", \"devops\"]\n</code></pre>"},{"location":"architecture/security-design/#multi-factor-authentication-mfa","title":"Multi-Factor Authentication (MFA)","text":"<pre><code>mfa_configuration:\n  required_for:\n    - administrative_access\n    - production_environments\n    - privileged_operations\n\n  methods:\n    - totp: \"Time-based One-Time Password\"\n    - webauthn: \"Hardware Security Keys\"\n    - sms: \"SMS-based (fallback only)\"\n\n  policies:\n    admin_users:\n      require_methods: [\"totp\", \"webauthn\"]\n      session_timeout: 8_hours\n\n    regular_users:\n      require_methods: [\"totp\"]\n      session_timeout: 24_hours\n</code></pre>"},{"location":"architecture/security-design/#authorization-framework","title":"Authorization Framework","text":""},{"location":"architecture/security-design/#role-based-access-control-rbac","title":"Role-Based Access Control (RBAC)","text":"<pre><code># Temporal Authorization Roles\ntemporal_roles:\n  temporal_admin:\n    description: \"Full administrative access\"\n    permissions:\n      - temporal:admin:*\n      - temporal:system:*\n      - temporal:namespace:*\n\n  temporal_developer:\n    description: \"Development and testing access\"\n    permissions:\n      - temporal:workflow:read\n      - temporal:workflow:write\n      - temporal:activity:execute\n      - temporal:namespace:default:*\n\n  temporal_operator:\n    description: \"Operational monitoring access\"\n    permissions:\n      - temporal:workflow:read\n      - temporal:system:health\n      - temporal:metrics:read\n\n  temporal_viewer:\n    description: \"Read-only access\"\n    permissions:\n      - temporal:workflow:read\n      - temporal:activity:read\n      - temporal:metrics:read\n</code></pre>"},{"location":"architecture/security-design/#kubernetes-rbac-integration","title":"Kubernetes RBAC Integration","text":"<pre><code># Kubernetes Role Definitions\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  namespace: temporal-backend\n  name: temporal-operator\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"services\", \"endpoints\", \"configmaps\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"apps\"]\n  resources: [\"deployments\", \"replicasets\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"extensions\", \"networking.k8s.io\"]\n  resources: [\"ingresses\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: temporal-operators\n  namespace: temporal-backend\nsubjects:\n- kind: User\n  name: temporal-operator@example.com\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: temporal-operator\n  apiGroup: rbac.authorization.k8s.io\n</code></pre>"},{"location":"architecture/security-design/#secrets-management","title":"Secrets Management","text":""},{"location":"architecture/security-design/#hashicorp-vault-integration","title":"HashiCorp Vault Integration","text":""},{"location":"architecture/security-design/#vault-configuration","title":"Vault Configuration","text":"<pre><code># Vault Secrets Engine Configuration\npath \"secret/\" {\n  type = \"kv-v2\"\n  description = \"Temporal secrets storage\"\n}\n\n# Database dynamic secrets\npath \"database/\" {\n  type = \"database\"\n  description = \"Database credentials\"\n}\n\n# PKI for certificate management\npath \"pki/\" {\n  type = \"pki\"\n  description = \"Certificate authority\"\n  max_lease_ttl = \"8760h\"\n}\n\n# Kubernetes authentication\nauth \"kubernetes/\" {\n  type = \"kubernetes\"\n  description = \"Kubernetes cluster authentication\"\n}\n</code></pre>"},{"location":"architecture/security-design/#secret-policies","title":"Secret Policies","text":"<pre><code># Temporal backend secrets policy\npath \"secret/data/temporal/backend/*\" {\n  capabilities = [\"read\", \"list\"]\n}\n\npath \"secret/data/temporal/database/*\" {\n  capabilities = [\"read\"]\n}\n\npath \"database/creds/temporal-role\" {\n  capabilities = [\"read\"]\n}\n\n# Certificate issuance\npath \"pki/issue/temporal-server\" {\n  capabilities = [\"create\", \"update\"]\n}\n</code></pre>"},{"location":"architecture/security-design/#external-secrets-operator","title":"External Secrets Operator","text":"<pre><code># External Secret Configuration\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: temporal-database-credentials\n  namespace: temporal-backend\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: temporal-db-secret\n    creationPolicy: Owner\n    template:\n      type: Opaque\n      data:\n        username: \"{{ .username }}\"\n        password: \"{{ .password }}\"\n        connection-string: \"postgresql://{{ .username }}:{{ .password }}@postgresql:5432/temporal\"\n  data:\n    - secretKey: username\n      remoteRef:\n        key: database/creds/temporal-role\n        property: username\n    - secretKey: password\n      remoteRef:\n        key: database/creds/temporal-role\n        property: password\n</code></pre>"},{"location":"architecture/security-design/#secret-rotation-strategy","title":"Secret Rotation Strategy","text":"<pre><code>rotation_policies:\n  database_credentials:\n    frequency: 24_hours\n    method: vault_dynamic_secrets\n    notification: true\n\n  api_keys:\n    frequency: 30_days\n    method: manual_rotation\n    notification: true\n\n  certificates:\n    frequency: 90_days\n    method: cert_manager_auto\n    notification: false\n\n  encryption_keys:\n    frequency: 365_days\n    method: manual_rotation\n    notification: true\n</code></pre>"},{"location":"architecture/security-design/#network-security","title":"Network Security","text":""},{"location":"architecture/security-design/#network-policies","title":"Network Policies","text":""},{"location":"architecture/security-design/#namespace-isolation","title":"Namespace Isolation","text":"<pre><code># Deny all traffic by default\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: default-deny-all\n  namespace: temporal-backend\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\n\n---\n# Allow temporal-backend internal communication\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: temporal-backend-internal\n  namespace: temporal-backend\nspec:\n  podSelector:\n    matchLabels:\n      app.kubernetes.io/part-of: temporal\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-product\n    - namespaceSelector:\n        matchLabels:\n          name: monitoring\n    - podSelector:\n        matchLabels:\n          app.kubernetes.io/part-of: temporal\n  egress:\n  - to:\n    - podSelector:\n        matchLabels:\n          app.kubernetes.io/part-of: temporal\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: kube-system\n    ports:\n    - protocol: TCP\n      port: 53\n    - protocol: UDP\n      port: 53\n\n---\n# Allow temporal-product to temporal-backend\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: temporal-product-egress\n  namespace: temporal-product\nspec:\n  podSelector: {}\n  policyTypes:\n  - Egress\n  egress:\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-backend\n    ports:\n    - protocol: TCP\n      port: 7233  # Temporal frontend\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 53\n    - protocol: UDP\n      port: 53\n</code></pre>"},{"location":"architecture/security-design/#service-mesh-security-istio","title":"Service Mesh Security (Istio)","text":""},{"location":"architecture/security-design/#mtls-configuration","title":"mTLS Configuration","text":"<pre><code># Default mTLS policy\napiVersion: security.istio.io/v1beta1\nkind: PeerAuthentication\nmetadata:\n  name: default\n  namespace: temporal-backend\nspec:\n  mtls:\n    mode: STRICT\n\n---\n# Authorization policies\napiVersion: security.istio.io/v1beta1\nkind: AuthorizationPolicy\nmetadata:\n  name: temporal-frontend-access\n  namespace: temporal-backend\nspec:\n  selector:\n    matchLabels:\n      app: temporal-frontend\n  rules:\n  - from:\n    - source:\n        namespaces: [\"temporal-product\"]\n    - source:\n        principals: [\"cluster.local/ns/temporal-backend/sa/temporal-web\"]\n    to:\n    - operation:\n        methods: [\"POST\", \"GET\"]\n        paths: [\"/temporal.api.workflowservice.v1.*\"]\n</code></pre>"},{"location":"architecture/security-design/#encryption","title":"Encryption","text":""},{"location":"architecture/security-design/#encryption-in-transit","title":"Encryption in Transit","text":""},{"location":"architecture/security-design/#tls-configuration","title":"TLS Configuration","text":"<pre><code># Temporal Server TLS Configuration\nserver:\n  config:\n    tls:\n      frontend:\n        server:\n          certFile: /etc/temporal/certs/tls.crt\n          keyFile: /etc/temporal/certs/tls.key\n          requireClientAuth: true\n          clientCaFiles:\n            - /etc/temporal/certs/ca.crt\n          enableHostVerification: true\n          serverName: temporal-frontend.temporal-backend.svc.cluster.local\n        client:\n          serverName: temporal-frontend\n          rootCaFiles:\n            - /etc/temporal/certs/ca.crt\n          certFile: /etc/temporal/certs/client.crt\n          keyFile: /etc/temporal/certs/client.key\n\n      internode:\n        server:\n          certFile: /etc/temporal/certs/internode.crt\n          keyFile: /etc/temporal/certs/internode.key\n          requireClientAuth: true\n          clientCaFiles:\n            - /etc/temporal/certs/ca.crt\n        client:\n          serverName: temporal-internode\n          rootCaFiles:\n            - /etc/temporal/certs/ca.crt\n</code></pre>"},{"location":"architecture/security-design/#certificate-management","title":"Certificate Management","text":"<pre><code># Certificate Issuer\napiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: temporal-ca-issuer\nspec:\n  ca:\n    secretName: temporal-ca-secret\n\n---\n# Server Certificate\napiVersion: cert-manager.io/v1\nkind: Certificate\nmetadata:\n  name: temporal-server-cert\n  namespace: temporal-backend\nspec:\n  secretName: temporal-server-tls\n  issuerRef:\n    name: temporal-ca-issuer\n    kind: ClusterIssuer\n  commonName: temporal-frontend.temporal-backend.svc.cluster.local\n  dnsNames:\n    - temporal-frontend\n    - temporal-frontend.temporal-backend\n    - temporal-frontend.temporal-backend.svc\n    - temporal-frontend.temporal-backend.svc.cluster.local\n    - temporal.example.com\n  duration: 2160h # 90 days\n  renewBefore: 720h # 30 days\n</code></pre>"},{"location":"architecture/security-design/#encryption-at-rest","title":"Encryption at Rest","text":""},{"location":"architecture/security-design/#database-encryption","title":"Database Encryption","text":"<pre><code># PostgreSQL Encryption Configuration\npostgresql:\n  auth:\n    enablePostgresUser: true\n    database: temporal\n\n  primary:\n    initdb:\n      args: \"--auth-host=md5 --auth-local=md5\"\n    configuration: |\n      ssl = on\n      ssl_cert_file = '/etc/ssl/certs/server.crt'\n      ssl_key_file = '/etc/ssl/private/server.key'\n      ssl_ca_file = '/etc/ssl/certs/ca.crt'\n      ssl_crl_file = ''\n      ssl_ciphers = 'HIGH:!aNULL:!MD5'\n      ssl_prefer_server_ciphers = on\n      wal_level = replica\n      archive_mode = on\n      archive_command = 'pgbackrest --stanza=main archive-push %p'\n\n  tls:\n    enabled: true\n    certificatesSecret: postgresql-tls\n    certFilename: tls.crt\n    certKeyFilename: tls.key\n    certCAFilename: ca.crt\n</code></pre>"},{"location":"architecture/security-design/#kubernetes-secrets-encryption","title":"Kubernetes Secrets Encryption","text":"<pre><code># EncryptionConfiguration for etcd\napiVersion: apiserver.config.k8s.io/v1\nkind: EncryptionConfiguration\nresources:\n- resources:\n  - secrets\n  providers:\n  - aescbc:\n      keys:\n      - name: key1\n        secret: !vault:secret/kubernetes/encryption#key\n  - identity: {}\n</code></pre>"},{"location":"architecture/security-design/#container-and-runtime-security","title":"Container and Runtime Security","text":""},{"location":"architecture/security-design/#container-image-security","title":"Container Image Security","text":""},{"location":"architecture/security-design/#image-scanning-pipeline","title":"Image Scanning Pipeline","text":"<pre><code># GitLab CI Security Scanning\nsecurity_scan:\n  stage: security\n  image: aquasec/trivy:latest\n  script:\n    - trivy image --exit-code 1 --severity HIGH,CRITICAL $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\n    - trivy fs --exit-code 1 --severity HIGH,CRITICAL .\n  artifacts:\n    reports:\n      container_scanning: gl-container-scanning-report.json\n  only:\n    - main\n    - develop\n</code></pre>"},{"location":"architecture/security-design/#admission-controllers","title":"Admission Controllers","text":"<pre><code># OPA Gatekeeper Constraint\napiVersion: templates.gatekeeper.sh/v1beta1\nkind: ConstraintTemplate\nmetadata:\n  name: requiredlabels\nspec:\n  crd:\n    spec:\n      names:\n        kind: RequiredLabels\n      validation:\n        type: object\n        properties:\n          labels:\n            type: array\n            items:\n              type: string\n  targets:\n    - target: admission.k8s.gatekeeper.sh\n      rego: |\n        package requiredlabels\n\n        violation[{\"msg\": msg}] {\n          provided := input.review.object.metadata.labels\n          required := input.parameters.labels\n          missing := required[_]\n          not provided[missing]\n          msg := sprintf(\"Missing required label: %v\", [missing])\n        }\n\n---\napiVersion: constraints.gatekeeper.sh/v1beta1\nkind: RequiredLabels\nmetadata:\n  name: temporal-must-have-labels\nspec:\n  match:\n    kinds:\n      - apiGroups: [\"apps\"]\n        kinds: [\"Deployment\"]\n    namespaces: [\"temporal-backend\", \"temporal-product\"]\n  parameters:\n    labels: [\"app.kubernetes.io/name\", \"app.kubernetes.io/version\", \"security.level\"]\n</code></pre>"},{"location":"architecture/security-design/#runtime-security","title":"Runtime Security","text":""},{"location":"architecture/security-design/#falco-rules","title":"Falco Rules","text":"<pre><code># Falco Security Rules\n- rule: Temporal Container Privilege Escalation\n  desc: Detect privilege escalation in Temporal containers\n  condition: &gt;\n    spawned_process and\n    container and\n    container.image.repository contains \"temporal\" and\n    (proc.name in (sudo, su, setuid_binary))\n  output: &gt;\n    Privilege escalation detected in Temporal container\n    (user=%user.name command=%proc.cmdline container=%container.name image=%container.image.repository)\n  priority: WARNING\n  tags: [temporal, privilege_escalation]\n\n- rule: Temporal Sensitive File Access\n  desc: Detect access to sensitive files in Temporal containers\n  condition: &gt;\n    open_read and\n    container and\n    container.image.repository contains \"temporal\" and\n    (fd.filename startswith /etc/passwd or\n     fd.filename startswith /etc/shadow or\n     fd.filename startswith /etc/ssh/ or\n     fd.filename startswith /root/.ssh/)\n  output: &gt;\n    Sensitive file accessed in Temporal container\n    (user=%user.name file=%fd.name container=%container.name image=%container.image.repository)\n  priority: WARNING\n  tags: [temporal, file_access]\n</code></pre>"},{"location":"architecture/security-design/#compliance-and-audit","title":"Compliance and Audit","text":""},{"location":"architecture/security-design/#audit-logging","title":"Audit Logging","text":""},{"location":"architecture/security-design/#kubernetes-audit-policy","title":"Kubernetes Audit Policy","text":"<pre><code># Audit Policy Configuration\napiVersion: audit.k8s.io/v1\nkind: Policy\nrules:\n- level: Metadata\n  namespaces: [\"temporal-backend\", \"temporal-product\"]\n  resources:\n  - group: \"\"\n    resources: [\"secrets\", \"configmaps\"]\n  - group: \"apps\"\n    resources: [\"deployments\", \"statefulsets\"]\n\n- level: Request\n  users: [\"admin@example.com\"]\n  verbs: [\"create\", \"update\", \"patch\", \"delete\"]\n\n- level: RequestResponse\n  namespaces: [\"temporal-backend\"]\n  resources:\n  - group: \"\"\n    resources: [\"pods/exec\", \"pods/portforward\"]\n</code></pre>"},{"location":"architecture/security-design/#temporal-audit-configuration","title":"Temporal Audit Configuration","text":"<pre><code># Temporal Server Audit Configuration\nserver:\n  config:\n    auditLogger:\n      enabled: true\n      logLevel: \"info\"\n      outputFormat: \"json\"\n      includeRequest: true\n      includeResponse: false\n      filters:\n        - resource: \"workflow\"\n          actions: [\"start\", \"terminate\", \"cancel\"]\n        - resource: \"activity\"\n          actions: [\"complete\", \"fail\"]\n        - resource: \"namespace\"\n          actions: [\"create\", \"update\", \"delete\"]\n</code></pre>"},{"location":"architecture/security-design/#compliance-frameworks","title":"Compliance Frameworks","text":""},{"location":"architecture/security-design/#soc-2-type-ii-controls","title":"SOC 2 Type II Controls","text":"<pre><code>soc2_controls:\n  cc1_control_environment:\n    - identity_management: \"Authentik SSO implementation\"\n    - access_reviews: \"Quarterly access reviews\"\n    - segregation_of_duties: \"Role-based access control\"\n\n  cc2_communication:\n    - security_policies: \"Documented security procedures\"\n    - incident_response: \"24/7 security monitoring\"\n    - change_management: \"GitOps deployment pipeline\"\n\n  cc3_risk_assessment:\n    - vulnerability_scanning: \"Automated container scanning\"\n    - penetration_testing: \"Annual third-party testing\"\n    - threat_modeling: \"Regular architecture reviews\"\n\n  cc4_monitoring:\n    - siem_integration: \"Centralized log analysis\"\n    - anomaly_detection: \"AI-powered threat detection\"\n    - continuous_monitoring: \"Real-time alerting\"\n\n  cc5_control_activities:\n    - encryption: \"TLS 1.3 and AES-256 encryption\"\n    - backup_procedures: \"Automated backup and recovery\"\n    - disaster_recovery: \"Multi-region deployment\"\n</code></pre>"},{"location":"architecture/security-design/#gdpr-compliance","title":"GDPR Compliance","text":"<pre><code>gdpr_compliance:\n  data_protection:\n    - encryption_at_rest: \"AES-256 encryption\"\n    - encryption_in_transit: \"TLS 1.3\"\n    - data_classification: \"PII/PHI tagging system\"\n\n  privacy_by_design:\n    - data_minimization: \"Workflow data retention policies\"\n    - purpose_limitation: \"Explicit consent tracking\"\n    - storage_limitation: \"Automated data purging\"\n\n  individual_rights:\n    - right_to_access: \"Data export APIs\"\n    - right_to_rectification: \"Data correction workflows\"\n    - right_to_erasure: \"Data deletion capabilities\"\n    - right_to_portability: \"Standardized data formats\"\n</code></pre>"},{"location":"architecture/security-design/#security-monitoring-and-incident-response","title":"Security Monitoring and Incident Response","text":""},{"location":"architecture/security-design/#security-information-and-event-management-siem","title":"Security Information and Event Management (SIEM)","text":""},{"location":"architecture/security-design/#log-aggregation","title":"Log Aggregation","text":"<pre><code># Fluentd Configuration for Security Logs\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: fluentd-security-config\ndata:\n  fluent.conf: |\n    &lt;source&gt;\n      @type tail\n      path /var/log/audit/audit.log\n      pos_file /var/log/fluentd-audit.log.pos\n      tag security.audit\n      format json\n    &lt;/source&gt;\n\n    &lt;source&gt;\n      @type tail\n      path /var/log/containers/*temporal*.log\n      pos_file /var/log/fluentd-temporal.log.pos\n      tag security.temporal\n      format json\n    &lt;/source&gt;\n\n    &lt;filter security.**&gt;\n      @type record_transformer\n      &lt;record&gt;\n        cluster_name \"#{ENV['CLUSTER_NAME']}\"\n        environment \"#{ENV['ENVIRONMENT']}\"\n        timestamp ${time}\n      &lt;/record&gt;\n    &lt;/filter&gt;\n\n    &lt;match security.**&gt;\n      @type elasticsearch\n      host elasticsearch.monitoring.svc.cluster.local\n      port 9200\n      index_name security-logs-${+YYYY.MM.dd}\n      type_name _doc\n    &lt;/match&gt;\n</code></pre>"},{"location":"architecture/security-design/#threat-detection","title":"Threat Detection","text":""},{"location":"architecture/security-design/#anomaly-detection-rules","title":"Anomaly Detection Rules","text":"<pre><code>detection_rules:\n  failed_authentication:\n    query: |\n      SELECT COUNT(*) as failed_attempts\n      FROM auth_logs \n      WHERE status = 'failed' \n      AND timestamp &gt; NOW() - INTERVAL 5 MINUTE\n      GROUP BY source_ip\n      HAVING failed_attempts &gt; 10\n\n  privilege_escalation:\n    query: |\n      SELECT *\n      FROM audit_logs\n      WHERE action IN ('sudo', 'su', 'setuid')\n      AND container_name LIKE '%temporal%'\n      AND timestamp &gt; NOW() - INTERVAL 1 HOUR\n\n  data_exfiltration:\n    query: |\n      SELECT *\n      FROM network_logs\n      WHERE bytes_out &gt; 100MB\n      AND destination NOT IN (known_endpoints)\n      AND source_namespace IN ('temporal-backend', 'temporal-product')\n</code></pre>"},{"location":"architecture/security-design/#incident-response","title":"Incident Response","text":""},{"location":"architecture/security-design/#automated-response-actions","title":"Automated Response Actions","text":"<pre><code># Falco Response Configuration\nresponse_actions:\n  high_priority:\n    - alert: \"Send to security team\"\n    - isolate: \"Block suspicious IP addresses\"\n    - scale_down: \"Reduce affected service replicas\"\n\n  medium_priority:\n    - alert: \"Log to SIEM\"\n    - monitor: \"Increase logging verbosity\"\n\n  low_priority:\n    - log: \"Record for analysis\"\n</code></pre>"},{"location":"architecture/security-design/#incident-response-playbook","title":"Incident Response Playbook","text":"<pre><code>incident_response:\n  security_breach:\n    steps:\n      1. \"Isolate affected systems\"\n      2. \"Preserve evidence\"\n      3. \"Assess impact\"\n      4. \"Notify stakeholders\"\n      5. \"Implement containment\"\n      6. \"Eradicate threat\"\n      7. \"Recover systems\"\n      8. \"Lessons learned\"\n\n  data_loss:\n    steps:\n      1. \"Stop data processing\"\n      2. \"Identify affected data\"\n      3. \"Assess legal requirements\"\n      4. \"Notify authorities\"\n      5. \"Restore from backup\"\n      6. \"Validate data integrity\"\n\n  service_disruption:\n    steps:\n      1. \"Activate incident response team\"\n      2. \"Implement business continuity\"\n      3. \"Communicate with users\"\n      4. \"Investigate root cause\"\n      5. \"Implement fixes\"\n      6. \"Post-incident review\"\n</code></pre> <p>This comprehensive security design ensures that the Temporal.io enterprise deployment meets the highest security standards while maintaining operational efficiency and compliance requirements.</p>"},{"location":"architecture/system-architecture/","title":"System Architecture","text":"<p>This document provides a comprehensive overview of the Temporal.io enterprise deployment system architecture, designed for production Kubernetes environments with enterprise-grade requirements.</p>"},{"location":"architecture/system-architecture/#overview","title":"Overview","text":"<p>The Temporal.io deployment follows a microservices architecture pattern with clear separation of concerns, high availability, and scalability built-in from the ground up. The system is designed to handle enterprise workloads while maintaining security, observability, and operational excellence.</p>"},{"location":"architecture/system-architecture/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>graph TB\n    subgraph \"External Layer\"\n        EXT1[API Manager&lt;br/&gt;Gravitee.io]\n        EXT2[Load Balancer&lt;br/&gt;NGINX/HAProxy]\n        EXT3[CDN&lt;br/&gt;CloudFlare]\n        EXT4[External Monitoring&lt;br/&gt;Datadog/New Relic]\n    end\n\n    subgraph \"Security Layer\"\n        SEC1[WAF&lt;br/&gt;Web Application Firewall]\n        SEC2[SSO Provider&lt;br/&gt;Authentik]\n        SEC3[Secrets Management&lt;br/&gt;HashiCorp Vault]\n        SEC4[Certificate Management&lt;br/&gt;cert-manager]\n    end\n\n    subgraph \"Kubernetes Cluster\"\n        subgraph \"Ingress Layer\"\n            ING1[Ingress Controller&lt;br/&gt;NGINX/Traefik]\n            ING2[Service Mesh&lt;br/&gt;Istio/Linkerd]\n        end\n\n        subgraph \"temporal-backend Namespace\"\n            TB1[Temporal Server&lt;br/&gt;Frontend Service]\n            TB2[Temporal Server&lt;br/&gt;History Service]\n            TB3[Temporal Server&lt;br/&gt;Matching Service]\n            TB4[Temporal Server&lt;br/&gt;Worker Service]\n            TB5[Temporal Web UI]\n            TB6[Admin Tools]\n        end\n\n        subgraph \"temporal-product Namespace\"\n            TP1[Business Workers&lt;br/&gt;Python/Go]\n            TP2[FastAPI Services&lt;br/&gt;REST APIs]\n            TP3[Background Jobs&lt;br/&gt;Schedulers]\n        end\n\n        subgraph \"Data Layer\"\n            DB1[PostgreSQL Primary&lt;br/&gt;Persistence Store]\n            DB2[PostgreSQL Replica&lt;br/&gt;Read Replicas]\n            DB3[Elasticsearch&lt;br/&gt;Visibility Store]\n            DB4[Redis&lt;br/&gt;Caching Layer]\n        end\n\n        subgraph \"Monitoring Layer\"\n            MON1[Prometheus&lt;br/&gt;Metrics Collection]\n            MON2[Grafana&lt;br/&gt;Dashboards]\n            MON3[Jaeger&lt;br/&gt;Distributed Tracing]\n            MON4[Fluent Bit&lt;br/&gt;Log Collection]\n            MON5[OpenTelemetry&lt;br/&gt;Observability]\n        end\n\n        subgraph \"Infrastructure Services\"\n            INF1[ArgoCD&lt;br/&gt;GitOps Controller]\n            INF2[External Secrets&lt;br/&gt;Secrets Sync]\n            INF3[Backup Controller&lt;br/&gt;Velero]\n        end\n    end\n\n    subgraph \"External Dependencies\"\n        DEP1[GitLab&lt;br/&gt;Source Control &amp; CI/CD]\n        DEP2[JFrog Artifactory&lt;br/&gt;Artifact Repository]\n        DEP3[External Database&lt;br/&gt;Cloud SQL/RDS]\n        DEP4[Object Storage&lt;br/&gt;S3/GCS/Azure Blob]\n    end\n\n    EXT1 --&gt; SEC1\n    SEC1 --&gt; ING1\n    EXT2 --&gt; ING1\n    SEC2 --&gt; TB1\n    SEC3 --&gt; INF2\n\n    ING1 --&gt; TB5\n    ING1 --&gt; TP2\n\n    TB1 --&gt; TB2\n    TB1 --&gt; TB3\n    TB1 --&gt; TB4\n\n    TP1 --&gt; TB1\n    TP2 --&gt; TB1\n\n    TB2 --&gt; DB1\n    TB3 --&gt; DB1\n    TB4 --&gt; DB1\n    TB1 --&gt; DB3\n\n    MON1 --&gt; TB1\n    MON1 --&gt; TP1\n    MON2 --&gt; MON1\n    MON3 --&gt; TB1\n\n    INF1 --&gt; DEP1\n    INF2 --&gt; SEC3\n    DEP2 --&gt; TP1</code></pre>"},{"location":"architecture/system-architecture/#architecture-principles","title":"Architecture Principles","text":""},{"location":"architecture/system-architecture/#1-separation-of-concerns","title":"1. Separation of Concerns","text":"<ul> <li>Control Plane: Temporal server components (frontend, history, matching, worker)</li> <li>Data Plane: Business applications and workers</li> <li>Infrastructure Plane: Monitoring, security, and operational tools</li> </ul>"},{"location":"architecture/system-architecture/#2-high-availability","title":"2. High Availability","text":"<ul> <li>Multi-node Kubernetes cluster with zone distribution</li> <li>Database replication and failover capabilities</li> <li>Load balancing across all service instances</li> <li>Circuit breakers and retry mechanisms</li> </ul>"},{"location":"architecture/system-architecture/#3-scalability","title":"3. Scalability","text":"<ul> <li>Horizontal scaling for all Temporal components</li> <li>Auto-scaling based on metrics (CPU, memory, custom metrics)</li> <li>Partitioned databases with sharding support</li> <li>Queue-based task distribution</li> </ul>"},{"location":"architecture/system-architecture/#4-security-by-design","title":"4. Security by Design","text":"<ul> <li>Zero-trust network architecture</li> <li>End-to-end encryption (TLS 1.3)</li> <li>Identity and access management integration</li> <li>Secrets management with rotation</li> <li>Network segmentation with policies</li> </ul>"},{"location":"architecture/system-architecture/#5-observability","title":"5. Observability","text":"<ul> <li>Comprehensive metrics collection</li> <li>Distributed tracing</li> <li>Structured logging</li> <li>Real-time monitoring and alerting</li> </ul>"},{"location":"architecture/system-architecture/#component-architecture","title":"Component Architecture","text":""},{"location":"architecture/system-architecture/#temporal-server-components","title":"Temporal Server Components","text":""},{"location":"architecture/system-architecture/#frontend-service","title":"Frontend Service","text":"<pre><code>Component: temporal-frontend\nPurpose: gRPC API endpoint for client connections\nResponsibilities:\n  - Client request handling\n  - Authentication and authorization\n  - Request routing and load balancing\n  - Rate limiting and throttling\nScaling: Horizontal (3+ instances)\nDependencies: Database, Elasticsearch\n</code></pre>"},{"location":"architecture/system-architecture/#history-service","title":"History Service","text":"<pre><code>Component: temporal-history\nPurpose: Workflow execution state management\nResponsibilities:\n  - Workflow state persistence\n  - Event history management\n  - Decision task processing\n  - Timer management\nScaling: Horizontal with sharding (512 shards)\nDependencies: Database (primary dependency)\n</code></pre>"},{"location":"architecture/system-architecture/#matching-service","title":"Matching Service","text":"<pre><code>Component: temporal-matching\nPurpose: Task queue management and distribution\nResponsibilities:\n  - Task queue operations\n  - Task routing to workers\n  - Load balancing across workers\n  - Sticky worker assignments\nScaling: Horizontal (2+ instances)\nDependencies: Database\n</code></pre>"},{"location":"architecture/system-architecture/#worker-service","title":"Worker Service","text":"<pre><code>Component: temporal-worker\nPurpose: Internal system operations\nResponsibilities:\n  - System workflow execution\n  - Archival operations\n  - Replication tasks\n  - System maintenance\nScaling: Horizontal (1+ instances)\nDependencies: Database, Object Storage\n</code></pre>"},{"location":"architecture/system-architecture/#business-application-layer","title":"Business Application Layer","text":""},{"location":"architecture/system-architecture/#temporal-workers","title":"Temporal Workers","text":"<pre><code>Component: business-workers\nTechnology: Python/Go applications\nPurpose: Execute business workflows and activities\nCharacteristics:\n  - Stateless execution\n  - Auto-scaling based on queue depth\n  - Circuit breaker patterns\n  - Health monitoring\nDeployment: Kubernetes Deployment with HPA\n</code></pre>"},{"location":"architecture/system-architecture/#api-services","title":"API Services","text":"<pre><code>Component: fastapi-services\nTechnology: Python FastAPI\nPurpose: REST API endpoints for business operations\nCharacteristics:\n  - Async/await patterns\n  - Database connection pooling\n  - Caching layer integration\n  - Rate limiting\nDeployment: Kubernetes Deployment with Ingress\n</code></pre>"},{"location":"architecture/system-architecture/#data-architecture","title":"Data Architecture","text":""},{"location":"architecture/system-architecture/#primary-database-postgresql","title":"Primary Database (PostgreSQL)","text":""},{"location":"architecture/system-architecture/#temporal-default-store","title":"Temporal Default Store","text":"<pre><code>-- Core Temporal tables\nTables:\n  - executions: Workflow execution state\n  - history_tree: Workflow history events\n  - tasks: Task queue items\n  - timers: Scheduled operations\n  - activity_info: Activity execution state\n  - child_execution_info: Child workflow tracking\n</code></pre>"},{"location":"architecture/system-architecture/#temporal-visibility-store","title":"Temporal Visibility Store","text":"<pre><code>-- Search and filtering capabilities\nTables:\n  - executions_visibility: Searchable execution data\n  - workflow_search_attributes: Custom search fields\nIndexes:\n  - Execution time ranges\n  - Workflow types\n  - Custom search attributes\n</code></pre>"},{"location":"architecture/system-architecture/#search-layer-elasticsearch","title":"Search Layer (Elasticsearch)","text":""},{"location":"architecture/system-architecture/#advanced-visibility","title":"Advanced Visibility","text":"<pre><code>{\n  \"temporal_visibility_v1_prod\": {\n    \"mappings\": {\n      \"properties\": {\n        \"WorkflowId\": {\"type\": \"keyword\"},\n        \"WorkflowType\": {\"type\": \"keyword\"},\n        \"StartTime\": {\"type\": \"date\"},\n        \"CloseTime\": {\"type\": \"date\"},\n        \"ExecutionStatus\": {\"type\": \"keyword\"},\n        \"CustomSearchAttributes\": {\"type\": \"object\"}\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"architecture/system-architecture/#network-architecture","title":"Network Architecture","text":""},{"location":"architecture/system-architecture/#namespace-segmentation","title":"Namespace Segmentation","text":"<pre><code>Namespaces:\n  temporal-backend:\n    purpose: Temporal server components and infrastructure\n    network_policy: restricted_ingress_egress\n    resources: high_priority\n\n  temporal-product:\n    purpose: Business applications and workers\n    network_policy: restricted_egress_to_backend\n    resources: auto_scaling\n\n  monitoring:\n    purpose: Observability stack\n    network_policy: metrics_collection_only\n    resources: persistent_storage\n\n  security:\n    purpose: Security tools and certificate management\n    network_policy: cluster_wide_access\n    resources: minimal\n</code></pre>"},{"location":"architecture/system-architecture/#service-communication","title":"Service Communication","text":""},{"location":"architecture/system-architecture/#internal-communication","title":"Internal Communication","text":"<ul> <li>gRPC: Temporal client-server communication</li> <li>HTTP/REST: Web UI and API services</li> <li>Database Protocol: PostgreSQL native protocol</li> <li>HTTP: Elasticsearch REST API</li> </ul>"},{"location":"architecture/system-architecture/#external-communication","title":"External Communication","text":"<ul> <li>HTTPS: All external traffic (TLS 1.3)</li> <li>mTLS: Service-to-service communication</li> <li>gRPC-TLS: Temporal client connections</li> </ul>"},{"location":"architecture/system-architecture/#deployment-architecture","title":"Deployment Architecture","text":""},{"location":"architecture/system-architecture/#multi-environment-strategy","title":"Multi-Environment Strategy","text":"<pre><code>Environments:\n  development:\n    cluster_size: 3_nodes\n    database: single_instance\n    monitoring: basic\n    security: development_tls\n\n  staging:\n    cluster_size: 6_nodes\n    database: replica_setup\n    monitoring: full_stack\n    security: production_like\n\n  production:\n    cluster_size: 12_nodes\n    database: ha_cluster\n    monitoring: enterprise_grade\n    security: zero_trust\n</code></pre>"},{"location":"architecture/system-architecture/#resource-distribution","title":"Resource Distribution","text":""},{"location":"architecture/system-architecture/#node-classification","title":"Node Classification","text":"<pre><code>Node Types:\n  control-plane:\n    count: 3\n    purpose: Kubernetes control plane\n    taints: NoSchedule\n\n  temporal-backend:\n    count: 4\n    purpose: Temporal server components\n    labels: tier=backend\n    resources: cpu_optimized\n\n  temporal-workers:\n    count: 4\n    purpose: Business application workers\n    labels: tier=workers\n    resources: memory_optimized\n\n  data-layer:\n    count: 3\n    purpose: Database and storage\n    labels: tier=data\n    resources: storage_optimized\n\n  monitoring:\n    count: 2\n    purpose: Observability stack\n    labels: tier=monitoring\n    resources: balanced\n</code></pre>"},{"location":"architecture/system-architecture/#integration-patterns","title":"Integration Patterns","text":""},{"location":"architecture/system-architecture/#event-driven-architecture","title":"Event-Driven Architecture","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant API_Gateway\n    participant FastAPI\n    participant Temporal_Client\n    participant Temporal_Server\n    participant Worker\n    participant Database\n\n    Client-&gt;&gt;API_Gateway: HTTP Request\n    API_Gateway-&gt;&gt;FastAPI: Authenticated Request\n    FastAPI-&gt;&gt;Temporal_Client: Start Workflow\n    Temporal_Client-&gt;&gt;Temporal_Server: gRPC StartWorkflow\n    Temporal_Server-&gt;&gt;Database: Persist Execution\n    Temporal_Server-&gt;&gt;Worker: Schedule Activity\n    Worker-&gt;&gt;Temporal_Server: Complete Activity\n    Temporal_Server-&gt;&gt;Database: Update State\n    Temporal_Server-&gt;&gt;Temporal_Client: Workflow Complete\n    Temporal_Client-&gt;&gt;FastAPI: Result\n    FastAPI-&gt;&gt;API_Gateway: HTTP Response\n    API_Gateway-&gt;&gt;Client: Response</code></pre>"},{"location":"architecture/system-architecture/#workflow-patterns","title":"Workflow Patterns","text":""},{"location":"architecture/system-architecture/#long-running-processes","title":"Long-Running Processes","text":"<pre><code>@workflow.defn\nclass OrderProcessingWorkflow:\n    @workflow.run\n    async def run(self, order_id: str) -&gt; OrderResult:\n        # Validate order (Activity)\n        validation = await workflow.execute_activity(\n            validate_order,\n            order_id,\n            start_to_close_timeout=timedelta(minutes=5)\n        )\n\n        # Process payment (Activity with retry)\n        payment = await workflow.execute_activity(\n            process_payment,\n            validation.payment_info,\n            start_to_close_timeout=timedelta(minutes=10),\n            retry_policy=RetryPolicy(maximum_attempts=3)\n        )\n\n        # Wait for fulfillment (Signal/Timer)\n        await workflow.wait_condition(\n            lambda: self.fulfillment_complete,\n            timeout=timedelta(days=7)\n        )\n\n        return OrderResult(order_id=order_id, status=\"completed\")\n</code></pre>"},{"location":"architecture/system-architecture/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"architecture/system-architecture/#throughput-specifications","title":"Throughput Specifications","text":"<pre><code>Performance Targets:\n  workflow_starts_per_second: 1000+\n  activity_executions_per_second: 10000+\n  concurrent_workflows: 100000+\n  history_events_per_workflow: unlimited\n\nDatabase Performance:\n  read_iops: 10000+\n  write_iops: 5000+\n  connection_pool_size: 100\n  query_timeout: 5s\n\nNetwork Performance:\n  internal_latency: &lt;1ms\n  external_latency: &lt;10ms\n  throughput: 10Gbps\n</code></pre>"},{"location":"architecture/system-architecture/#scaling-characteristics","title":"Scaling Characteristics","text":""},{"location":"architecture/system-architecture/#horizontal-scaling-limits","title":"Horizontal Scaling Limits","text":"<pre><code>Component Scaling:\n  temporal_frontend: 1-20_instances\n  temporal_history: 1-50_instances\n  temporal_matching: 1-10_instances\n  temporal_worker: 1-5_instances\n  business_workers: 1-100_instances\n\nDatabase Scaling:\n  postgresql_connections: 100-1000\n  elasticsearch_nodes: 3-20\n  redis_instances: 1-10\n</code></pre>"},{"location":"architecture/system-architecture/#disaster-recovery-architecture","title":"Disaster Recovery Architecture","text":""},{"location":"architecture/system-architecture/#backup-strategy","title":"Backup Strategy","text":"<pre><code>Backup Components:\n  database:\n    frequency: continuous_wal_streaming\n    retention: 30_days\n    rto: 15_minutes\n    rpo: 1_minute\n\n  elasticsearch:\n    frequency: hourly_snapshots\n    retention: 7_days\n    rto: 30_minutes\n    rpo: 1_hour\n\n  kubernetes_state:\n    frequency: daily_etcd_backup\n    retention: 14_days\n    rto: 1_hour\n    rpo: 24_hours\n</code></pre>"},{"location":"architecture/system-architecture/#multi-region-setup","title":"Multi-Region Setup","text":"<pre><code>Region Strategy:\n  primary_region: us-east-1\n  secondary_region: us-west-2\n\n  replication:\n    database: async_streaming\n    object_storage: cross_region_sync\n    kubernetes: independent_clusters\n\n  failover:\n    automatic: database_only\n    manual: full_stack\n    rto: 1_hour\n    rpo: 5_minutes\n</code></pre>"},{"location":"architecture/system-architecture/#security-architecture-integration","title":"Security Architecture Integration","text":""},{"location":"architecture/system-architecture/#zero-trust-implementation","title":"Zero Trust Implementation","text":"<ul> <li>All communication encrypted (TLS 1.3)</li> <li>Identity verification for every request</li> <li>Principle of least privilege access</li> <li>Network micro-segmentation</li> <li>Continuous security monitoring</li> </ul>"},{"location":"architecture/system-architecture/#compliance-requirements","title":"Compliance Requirements","text":"<ul> <li>SOC 2 Type II compliance</li> <li>GDPR data protection</li> <li>PCI DSS for payment processing</li> <li>HIPAA for healthcare workflows</li> <li>Custom audit logging</li> </ul>"},{"location":"architecture/system-architecture/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"architecture/system-architecture/#metrics-collection","title":"Metrics Collection","text":"<pre><code>Metric Categories:\n  business_metrics:\n    - workflow_completion_rate\n    - activity_success_rate\n    - processing_duration\n\n  system_metrics:\n    - resource_utilization\n    - error_rates\n    - response_times\n\n  infrastructure_metrics:\n    - node_health\n    - network_performance\n    - storage_usage\n</code></pre>"},{"location":"architecture/system-architecture/#alerting-strategy","title":"Alerting Strategy","text":"<pre><code>Alert Levels:\n  critical:\n    - service_unavailable\n    - data_loss_risk\n    - security_breach\n\n  warning:\n    - performance_degradation\n    - resource_constraints\n    - configuration_drift\n\n  info:\n    - deployment_events\n    - scaling_operations\n    - maintenance_windows\n</code></pre>"},{"location":"architecture/system-architecture/#future-architecture-considerations","title":"Future Architecture Considerations","text":""},{"location":"architecture/system-architecture/#roadmap-items","title":"Roadmap Items","text":"<ol> <li>Multi-tenancy: Namespace isolation per tenant</li> <li>Edge Computing: Regional Temporal clusters</li> <li>AI/ML Integration: Workflow optimization</li> <li>Serverless Workers: FaaS-based activity execution</li> <li>Advanced Analytics: Real-time business intelligence</li> </ol>"},{"location":"architecture/system-architecture/#technology-evolution","title":"Technology Evolution","text":"<ul> <li>Container Runtime: Docker \u2192 containerd \u2192 gVisor</li> <li>Service Mesh: Istio \u2192 Linkerd \u2192 Cilium</li> <li>Database: PostgreSQL \u2192 CockroachDB (for global scale)</li> <li>Monitoring: Prometheus \u2192 OpenTelemetry native</li> </ul> <p>This system architecture provides a robust foundation for enterprise Temporal.io deployments with built-in scalability, security, and operational excellence.</p>"},{"location":"development/cicd-pipeline/","title":"CI/CD Pipeline","text":"<p>This document provides comprehensive CI/CD pipeline implementation for Temporal.io enterprise deployments, covering automated testing, building, security scanning, deployment, and monitoring.</p>"},{"location":"development/cicd-pipeline/#overview","title":"Overview","text":"<p>The CI/CD pipeline ensures reliable, secure, and automated delivery of Temporal workflows and applications. This guide covers GitHub Actions workflows, GitLab CI, Jenkins pipelines, and deployment strategies for enterprise environments.</p>"},{"location":"development/cicd-pipeline/#pipeline-architecture","title":"Pipeline Architecture","text":"<pre><code>graph TD\n    A[Code Commit] --&gt; B[Pre-commit Hooks]\n    B --&gt; C[CI Pipeline Trigger]\n    C --&gt; D[Code Quality Checks]\n    D --&gt; E[Unit Tests]\n    E --&gt; F[Integration Tests]\n    F --&gt; G[Security Scans]\n    G --&gt; H[Build Artifacts]\n    H --&gt; I[Container Images]\n    I --&gt; J[Deploy to Staging]\n    J --&gt; K[E2E Tests]\n    K --&gt; L[Performance Tests]\n    L --&gt; M[Deploy to Production]\n    M --&gt; N[Health Checks]\n    N --&gt; O[Monitoring &amp; Alerts]</code></pre>"},{"location":"development/cicd-pipeline/#github-actions-workflows","title":"GitHub Actions Workflows","text":""},{"location":"development/cicd-pipeline/#main-cicd-workflow","title":"Main CI/CD Workflow","text":"<pre><code># .github/workflows/cicd.yml\nname: CI/CD Pipeline\n\non:\n  push:\n    branches: [ main, develop ]\n  pull_request:\n    branches: [ main ]\n  release:\n    types: [ published ]\n\nenv:\n  REGISTRY: ghcr.io\n  IMAGE_NAME: ${{ github.repository }}\n  PYTHON_VERSION: \"3.11\"\n\njobs:\n  # =====================================================================\n  # Code Quality and Security\n  # =====================================================================\n  code-quality:\n    name: Code Quality Checks\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install black isort flake8 mypy bandit safety\n          pip install -r requirements.txt\n\n      - name: Code formatting check (Black)\n        run: black --check --diff .\n\n      - name: Import sorting check (isort)\n        run: isort --check-only --diff .\n\n      - name: Linting (flake8)\n        run: flake8 --max-line-length=88 --extend-ignore=E203,W503 .\n\n      - name: Type checking (mypy)\n        run: mypy src/ --ignore-missing-imports\n\n      - name: Security check (Bandit)\n        run: bandit -r src/ -f json -o bandit-report.json\n        continue-on-error: true\n\n      - name: Dependency security check (Safety)\n        run: safety check --json --output safety-report.json\n        continue-on-error: true\n\n      - name: Upload security reports\n        uses: actions/upload-artifact@v3\n        if: always()\n        with:\n          name: security-reports\n          path: |\n            bandit-report.json\n            safety-report.json\n\n  # =====================================================================\n  # Unit Tests\n  # =====================================================================\n  unit-tests:\n    name: Unit Tests\n    runs-on: ubuntu-latest\n    needs: code-quality\n    strategy:\n      matrix:\n        python-version: [\"3.9\", \"3.10\", \"3.11\"]\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Set up Python ${{ matrix.python-version }}\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ matrix.python-version }}\n\n      - name: Cache dependencies\n        uses: actions/cache@v3\n        with:\n          path: ~/.cache/pip\n          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}\n          restore-keys: |\n            ${{ runner.os }}-pip-\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install -r requirements.txt\n          pip install -r requirements-test.txt\n\n      - name: Run unit tests\n        run: |\n          pytest tests/unit/ -v \\\n            --cov=src \\\n            --cov-report=xml \\\n            --cov-report=html \\\n            --junitxml=junit.xml\n\n      - name: Upload coverage to Codecov\n        uses: codecov/codecov-action@v3\n        with:\n          file: ./coverage.xml\n          fail_ci_if_error: true\n\n      - name: Upload test results\n        uses: actions/upload-artifact@v3\n        if: always()\n        with:\n          name: test-results-${{ matrix.python-version }}\n          path: |\n            junit.xml\n            htmlcov/\n\n  # =====================================================================\n  # Integration Tests\n  # =====================================================================\n  integration-tests:\n    name: Integration Tests\n    runs-on: ubuntu-latest\n    needs: unit-tests\n\n    services:\n      postgres:\n        image: postgres:13\n        ports:\n          - 5432:5432\n        env:\n          POSTGRES_PASSWORD: temporal\n          POSTGRES_USER: temporal\n          POSTGRES_DB: temporal\n        options: &gt;-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n\n      temporal:\n        image: temporalio/auto-setup:1.20.0\n        ports:\n          - 7233:7233\n        env:\n          DB: postgresql\n          DB_PORT: 5432\n          POSTGRES_USER: temporal\n          POSTGRES_PWD: temporal\n          POSTGRES_SEEDS: postgres\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install -r requirements.txt\n          pip install -r requirements-test.txt\n\n      - name: Wait for services to be ready\n        run: |\n          timeout 60 bash -c 'until curl -f http://localhost:7233/; do sleep 2; done'\n\n      - name: Run integration tests\n        run: |\n          pytest tests/integration/ -v \\\n            --junitxml=integration-junit.xml\n        env:\n          TEMPORAL_SERVER_URL: localhost:7233\n          TEMPORAL_NAMESPACE: default\n          DATABASE_URL: postgresql://temporal:temporal@localhost:5432/temporal\n\n      - name: Upload integration test results\n        uses: actions/upload-artifact@v3\n        if: always()\n        with:\n          name: integration-test-results\n          path: integration-junit.xml\n\n  # =====================================================================\n  # Build and Push Container Images\n  # =====================================================================\n  build-images:\n    name: Build Container Images\n    runs-on: ubuntu-latest\n    needs: [unit-tests, integration-tests]\n    if: github.event_name != 'pull_request'\n\n    outputs:\n      image-tag: ${{ steps.meta.outputs.tags }}\n      image-digest: ${{ steps.build.outputs.digest }}\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n\n      - name: Log in to Container Registry\n        uses: docker/login-action@v3\n        with:\n          registry: ${{ env.REGISTRY }}\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Extract metadata\n        id: meta\n        uses: docker/metadata-action@v5\n        with:\n          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\n          tags: |\n            type=ref,event=branch\n            type=ref,event=pr\n            type=sha,prefix={{branch}}-\n            type=raw,value=latest,enable={{is_default_branch}}\n\n      - name: Build and push API image\n        id: build\n        uses: docker/build-push-action@v5\n        with:\n          context: .\n          file: ./docker/api/Dockerfile\n          push: true\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n          platforms: linux/amd64,linux/arm64\n\n      - name: Build and push Worker image\n        uses: docker/build-push-action@v5\n        with:\n          context: .\n          file: ./docker/worker/Dockerfile\n          push: true\n          tags: ${{ steps.meta.outputs.tags }}-worker\n          labels: ${{ steps.meta.outputs.labels }}\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n          platforms: linux/amd64,linux/arm64\n\n  # =====================================================================\n  # Security Scanning\n  # =====================================================================\n  security-scan:\n    name: Container Security Scan\n    runs-on: ubuntu-latest\n    needs: build-images\n    if: github.event_name != 'pull_request'\n\n    steps:\n      - name: Run Trivy vulnerability scanner\n        uses: aquasecurity/trivy-action@master\n        with:\n          image-ref: ${{ needs.build-images.outputs.image-tag }}\n          format: 'sarif'\n          output: 'trivy-results.sarif'\n\n      - name: Upload Trivy scan results to GitHub Security tab\n        uses: github/codeql-action/upload-sarif@v2\n        if: always()\n        with:\n          sarif_file: 'trivy-results.sarif'\n\n  # =====================================================================\n  # Deploy to Staging\n  # =====================================================================\n  deploy-staging:\n    name: Deploy to Staging\n    runs-on: ubuntu-latest\n    needs: [build-images, security-scan]\n    if: github.ref == 'refs/heads/develop'\n    environment: staging\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Set up kubectl\n        uses: azure/setup-kubectl@v3\n        with:\n          version: 'v1.28.0'\n\n      - name: Configure AWS credentials\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n          aws-region: us-west-2\n\n      - name: Update kubeconfig\n        run: |\n          aws eks update-kubeconfig --region us-west-2 --name temporal-staging-cluster\n\n      - name: Deploy to staging\n        run: |\n          helm upgrade --install temporal-staging ./helm/temporal-stack \\\n            --namespace temporal-staging \\\n            --create-namespace \\\n            --set image.tag=${{ needs.build-images.outputs.image-tag }} \\\n            --set environment=staging \\\n            --values ./helm/values/staging.yaml \\\n            --wait --timeout=10m\n\n      - name: Run smoke tests\n        run: |\n          kubectl wait --for=condition=ready pod -l app=temporal-api -n temporal-staging --timeout=300s\n          kubectl port-forward svc/temporal-api 8080:80 -n temporal-staging &amp;\n          sleep 10\n          curl -f http://localhost:8080/health || exit 1\n\n  # =====================================================================\n  # End-to-End Tests\n  # =====================================================================\n  e2e-tests:\n    name: End-to-End Tests\n    runs-on: ubuntu-latest\n    needs: deploy-staging\n    if: github.ref == 'refs/heads/develop'\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install -r requirements-test.txt\n\n      - name: Run E2E tests\n        run: |\n          pytest tests/e2e/ -v \\\n            --junitxml=e2e-junit.xml \\\n            --base-url=${{ secrets.STAGING_BASE_URL }} \\\n            --api-key=${{ secrets.STAGING_API_KEY }}\n\n      - name: Upload E2E test results\n        uses: actions/upload-artifact@v3\n        if: always()\n        with:\n          name: e2e-test-results\n          path: e2e-junit.xml\n\n  # =====================================================================\n  # Performance Tests\n  # =====================================================================\n  performance-tests:\n    name: Performance Tests\n    runs-on: ubuntu-latest\n    needs: deploy-staging\n    if: github.ref == 'refs/heads/develop'\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      - name: Install Locust\n        run: pip install locust\n\n      - name: Run performance tests\n        run: |\n          locust -f tests/performance/locustfile.py \\\n            --headless \\\n            --users 50 \\\n            --spawn-rate 5 \\\n            --run-time 5m \\\n            --host ${{ secrets.STAGING_BASE_URL }} \\\n            --html performance-report.html \\\n            --csv performance\n\n      - name: Upload performance test results\n        uses: actions/upload-artifact@v3\n        if: always()\n        with:\n          name: performance-test-results\n          path: |\n            performance-report.html\n            performance*.csv\n\n  # =====================================================================\n  # Deploy to Production\n  # =====================================================================\n  deploy-production:\n    name: Deploy to Production\n    runs-on: ubuntu-latest\n    needs: [e2e-tests, performance-tests]\n    if: github.event_name == 'release' &amp;&amp; github.event.action == 'published'\n    environment: production\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Set up kubectl\n        uses: azure/setup-kubectl@v3\n        with:\n          version: 'v1.28.0'\n\n      - name: Configure AWS credentials\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n          aws-region: us-west-2\n\n      - name: Update kubeconfig\n        run: |\n          aws eks update-kubeconfig --region us-west-2 --name temporal-production-cluster\n\n      - name: Deploy to production\n        run: |\n          helm upgrade --install temporal-production ./helm/temporal-stack \\\n            --namespace temporal-production \\\n            --create-namespace \\\n            --set image.tag=${{ github.event.release.tag_name }} \\\n            --set environment=production \\\n            --values ./helm/values/production.yaml \\\n            --wait --timeout=15m\n\n      - name: Post-deployment verification\n        run: |\n          kubectl wait --for=condition=ready pod -l app=temporal-api -n temporal-production --timeout=600s\n          kubectl get pods -n temporal-production\n          curl -f ${{ secrets.PRODUCTION_BASE_URL }}/health\n\n      - name: Notify deployment success\n        uses: 8398a7/action-slack@v3\n        with:\n          status: success\n          text: \"\u2705 Production deployment successful: ${{ github.event.release.tag_name }}\"\n        env:\n          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}\n</code></pre>"},{"location":"development/cicd-pipeline/#feature-branch-workflow","title":"Feature Branch Workflow","text":"<pre><code># .github/workflows/feature-branch.yml\nname: Feature Branch CI\n\non:\n  push:\n    branches-ignore: [ main, develop ]\n  pull_request:\n    branches: [ main, develop ]\n\njobs:\n  validate:\n    name: Validate Feature Branch\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: \"3.11\"\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install -r requirements.txt\n          pip install -r requirements-test.txt\n\n      - name: Code quality checks\n        run: |\n          black --check .\n          isort --check-only .\n          flake8 .\n          mypy src/\n\n      - name: Run unit tests\n        run: |\n          pytest tests/unit/ -v --cov=src\n\n      - name: Build test image\n        run: |\n          docker build -t temporal-test:${{ github.sha }} -f docker/api/Dockerfile .\n\n      - name: Comment PR\n        uses: actions/github-script@v6\n        if: github.event_name == 'pull_request'\n        with:\n          script: |\n            github.rest.issues.createComment({\n              issue_number: context.issue.number,\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              body: '\u2705 Feature branch validation passed! Ready for review.'\n            })\n</code></pre>"},{"location":"development/cicd-pipeline/#gitlab-ci-configuration","title":"GitLab CI Configuration","text":""},{"location":"development/cicd-pipeline/#complete-pipeline","title":"Complete Pipeline","text":"<pre><code># .gitlab-ci.yml\nstages:\n  - validate\n  - test\n  - build\n  - security\n  - deploy-staging\n  - test-staging\n  - deploy-production\n\nvariables:\n  DOCKER_DRIVER: overlay2\n  DOCKER_TLS_CERTDIR: \"/certs\"\n  PYTHON_VERSION: \"3.11\"\n  PIP_CACHE_DIR: \"$CI_PROJECT_DIR/.cache/pip\"\n\ncache:\n  paths:\n    - .cache/pip\n    - venv/\n\nbefore_script:\n  - python -m venv venv\n  - source venv/bin/activate\n  - pip install --upgrade pip\n\n# =====================================================================\n# Validation Stage\n# =====================================================================\ncode-quality:\n  stage: validate\n  image: python:$PYTHON_VERSION\n  script:\n    - pip install black isort flake8 mypy bandit\n    - black --check --diff .\n    - isort --check-only --diff .\n    - flake8 --max-line-length=88 .\n    - mypy src/ --ignore-missing-imports\n    - bandit -r src/\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n    - if: $CI_COMMIT_BRANCH == \"main\"\n    - if: $CI_COMMIT_BRANCH == \"develop\"\n\n# =====================================================================\n# Test Stage\n# =====================================================================\nunit-tests:\n  stage: test\n  image: python:$PYTHON_VERSION\n  services:\n    - name: postgres:13\n      alias: postgres\n  variables:\n    POSTGRES_DB: test_db\n    POSTGRES_USER: test_user\n    POSTGRES_PASSWORD: test_pass\n  script:\n    - pip install -r requirements.txt -r requirements-test.txt\n    - pytest tests/unit/ -v --cov=src --cov-report=xml --junitxml=report.xml\n  coverage: '/(?i)total.*? (100(?:\\.0+)?\\%|[1-9]?\\d(?:\\.\\d+)?\\%)$/'\n  artifacts:\n    reports:\n      junit: report.xml\n      coverage_report:\n        coverage_format: cobertura\n        path: coverage.xml\n    paths:\n      - coverage.xml\n    expire_in: 1 week\n\nintegration-tests:\n  stage: test\n  image: python:$PYTHON_VERSION\n  services:\n    - name: postgres:13\n      alias: postgres\n    - name: temporalio/auto-setup:1.20.0\n      alias: temporal\n  variables:\n    POSTGRES_DB: temporal\n    POSTGRES_USER: temporal\n    POSTGRES_PASSWORD: temporal\n    TEMPORAL_SERVER_URL: temporal:7233\n  script:\n    - pip install -r requirements.txt -r requirements-test.txt\n    - sleep 30 # Wait for Temporal to start\n    - pytest tests/integration/ -v --junitxml=integration-report.xml\n  artifacts:\n    reports:\n      junit: integration-report.xml\n    expire_in: 1 week\n\n# =====================================================================\n# Build Stage\n# =====================================================================\nbuild-api:\n  stage: build\n  image: docker:latest\n  services:\n    - docker:dind\n  before_script:\n    - echo $CI_REGISTRY_PASSWORD | docker login -u $CI_REGISTRY_USER --password-stdin $CI_REGISTRY\n  script:\n    - docker build -t $CI_REGISTRY_IMAGE/api:$CI_COMMIT_SHA -f docker/api/Dockerfile .\n    - docker push $CI_REGISTRY_IMAGE/api:$CI_COMMIT_SHA\n    - |\n      if [ \"$CI_COMMIT_BRANCH\" == \"main\" ]; then\n        docker tag $CI_REGISTRY_IMAGE/api:$CI_COMMIT_SHA $CI_REGISTRY_IMAGE/api:latest\n        docker push $CI_REGISTRY_IMAGE/api:latest\n      fi\n  rules:\n    - if: $CI_COMMIT_BRANCH == \"main\"\n    - if: $CI_COMMIT_BRANCH == \"develop\"\n    - if: $CI_COMMIT_TAG\n\nbuild-worker:\n  stage: build\n  image: docker:latest\n  services:\n    - docker:dind\n  before_script:\n    - echo $CI_REGISTRY_PASSWORD | docker login -u $CI_REGISTRY_USER --password-stdin $CI_REGISTRY\n  script:\n    - docker build -t $CI_REGISTRY_IMAGE/worker:$CI_COMMIT_SHA -f docker/worker/Dockerfile .\n    - docker push $CI_REGISTRY_IMAGE/worker:$CI_COMMIT_SHA\n    - |\n      if [ \"$CI_COMMIT_BRANCH\" == \"main\" ]; then\n        docker tag $CI_REGISTRY_IMAGE/worker:$CI_COMMIT_SHA $CI_REGISTRY_IMAGE/worker:latest\n        docker push $CI_REGISTRY_IMAGE/worker:latest\n      fi\n  rules:\n    - if: $CI_COMMIT_BRANCH == \"main\"\n    - if: $CI_COMMIT_BRANCH == \"develop\"\n    - if: $CI_COMMIT_TAG\n\n# =====================================================================\n# Security Stage\n# =====================================================================\ncontainer-scanning:\n  stage: security\n  image: docker:stable\n  services:\n    - docker:dind\n  script:\n    - docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \n      -v $PWD:/tmp aquasec/trivy:latest image --exit-code 1 --format template \n      --template \"@contrib/gitlab.tpl\" -o gl-container-scanning-report.json \n      $CI_REGISTRY_IMAGE/api:$CI_COMMIT_SHA\n  artifacts:\n    reports:\n      container_scanning: gl-container-scanning-report.json\n  rules:\n    - if: $CI_COMMIT_BRANCH == \"main\"\n    - if: $CI_COMMIT_BRANCH == \"develop\"\n\ndependency-scanning:\n  stage: security\n  image: python:$PYTHON_VERSION\n  script:\n    - pip install safety\n    - safety check --json --output safety-report.json --continue-on-error\n  artifacts:\n    reports:\n      dependency_scanning: safety-report.json\n  allow_failure: true\n\n# =====================================================================\n# Staging Deployment\n# =====================================================================\ndeploy-staging:\n  stage: deploy-staging\n  image: \n    name: alpine/helm:latest\n    entrypoint: [\"\"]\n  before_script:\n    - apk add --no-cache curl\n    - curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n    - chmod +x kubectl &amp;&amp; mv kubectl /usr/local/bin/\n  script:\n    - echo $KUBE_CONFIG | base64 -d &gt; ~/.kube/config\n    - |\n      helm upgrade --install temporal-staging ./helm/temporal-stack \\\n        --namespace temporal-staging \\\n        --create-namespace \\\n        --set image.tag=$CI_COMMIT_SHA \\\n        --set environment=staging \\\n        --values ./helm/values/staging.yaml \\\n        --wait --timeout=10m\n  environment:\n    name: staging\n    url: https://temporal-staging.example.com\n  rules:\n    - if: $CI_COMMIT_BRANCH == \"develop\"\n\n# =====================================================================\n# Staging Tests\n# =====================================================================\ne2e-tests-staging:\n  stage: test-staging\n  image: python:$PYTHON_VERSION\n  script:\n    - pip install -r requirements-test.txt\n    - pytest tests/e2e/ -v --base-url=$STAGING_BASE_URL --api-key=$STAGING_API_KEY\n  rules:\n    - if: $CI_COMMIT_BRANCH == \"develop\"\n\n# =====================================================================\n# Production Deployment\n# =====================================================================\ndeploy-production:\n  stage: deploy-production\n  image: \n    name: alpine/helm:latest\n    entrypoint: [\"\"]\n  before_script:\n    - apk add --no-cache curl\n    - curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n    - chmod +x kubectl &amp;&amp; mv kubectl /usr/local/bin/\n  script:\n    - echo $KUBE_CONFIG_PROD | base64 -d &gt; ~/.kube/config\n    - |\n      helm upgrade --install temporal-production ./helm/temporal-stack \\\n        --namespace temporal-production \\\n        --create-namespace \\\n        --set image.tag=$CI_COMMIT_TAG \\\n        --set environment=production \\\n        --values ./helm/values/production.yaml \\\n        --wait --timeout=15m\n  environment:\n    name: production\n    url: https://temporal.example.com\n  rules:\n    - if: $CI_COMMIT_TAG\n  when: manual\n</code></pre>"},{"location":"development/cicd-pipeline/#jenkins-pipeline","title":"Jenkins Pipeline","text":""},{"location":"development/cicd-pipeline/#jenkinsfile","title":"Jenkinsfile","text":"<pre><code>// Jenkinsfile\npipeline {\n    agent any\n\n    environment {\n        REGISTRY = 'your-registry.com'\n        IMAGE_NAME = 'temporal-app'\n        PYTHON_VERSION = '3.11'\n        KUBECONFIG = credentials('kubeconfig')\n    }\n\n    options {\n        buildDiscarder(logRotator(numToKeepStr: '10'))\n        timeout(time: 60, unit: 'MINUTES')\n        skipStagesAfterUnstable()\n    }\n\n    stages {\n        stage('Checkout') {\n            steps {\n                checkout scm\n                script {\n                    env.GIT_COMMIT_SHORT = sh(\n                        script: \"git rev-parse --short HEAD\",\n                        returnStdout: true\n                    ).trim()\n                }\n            }\n        }\n\n        stage('Setup Python Environment') {\n            steps {\n                sh \"\"\"\n                    python${PYTHON_VERSION} -m venv venv\n                    . venv/bin/activate\n                    pip install --upgrade pip\n                    pip install -r requirements.txt\n                    pip install -r requirements-test.txt\n                \"\"\"\n            }\n        }\n\n        stage('Code Quality') {\n            parallel {\n                stage('Linting') {\n                    steps {\n                        sh \"\"\"\n                            . venv/bin/activate\n                            black --check --diff .\n                            isort --check-only --diff .\n                            flake8 --max-line-length=88 .\n                        \"\"\"\n                    }\n                }\n                stage('Type Checking') {\n                    steps {\n                        sh \"\"\"\n                            . venv/bin/activate\n                            mypy src/ --ignore-missing-imports\n                        \"\"\"\n                    }\n                }\n                stage('Security Check') {\n                    steps {\n                        sh \"\"\"\n                            . venv/bin/activate\n                            bandit -r src/ -f json -o bandit-report.json\n                            safety check --json --output safety-report.json\n                        \"\"\"\n                        publishHTML([\n                            allowMissing: false,\n                            alwaysLinkToLastBuild: true,\n                            keepAll: true,\n                            reportDir: '.',\n                            reportFiles: '*-report.json',\n                            reportName: 'Security Reports'\n                        ])\n                    }\n                }\n            }\n        }\n\n        stage('Tests') {\n            parallel {\n                stage('Unit Tests') {\n                    steps {\n                        sh \"\"\"\n                            . venv/bin/activate\n                            pytest tests/unit/ -v --cov=src --cov-report=xml --junitxml=unit-test-results.xml\n                        \"\"\"\n                        junit 'unit-test-results.xml'\n                        publishCoverage adapters: [\n                            coberturaAdapter('coverage.xml')\n                        ], sourceFileResolver: sourceFiles('STORE_LAST_BUILD')\n                    }\n                }\n                stage('Integration Tests') {\n                    when {\n                        anyOf {\n                            branch 'main'\n                            branch 'develop'\n                        }\n                    }\n                    steps {\n                        sh \"\"\"\n                            docker-compose -f docker-compose.test.yml up -d\n                            sleep 30\n                            . venv/bin/activate\n                            pytest tests/integration/ -v --junitxml=integration-test-results.xml\n                            docker-compose -f docker-compose.test.yml down\n                        \"\"\"\n                        junit 'integration-test-results.xml'\n                    }\n                }\n            }\n        }\n\n        stage('Build Images') {\n            when {\n                anyOf {\n                    branch 'main'\n                    branch 'develop'\n                    buildingTag()\n                }\n            }\n            parallel {\n                stage('API Image') {\n                    steps {\n                        script {\n                            def apiImage = docker.build(\"${REGISTRY}/${IMAGE_NAME}-api:${GIT_COMMIT_SHORT}\", \"-f docker/api/Dockerfile .\")\n                            docker.withRegistry(\"https://${REGISTRY}\", 'docker-registry-credentials') {\n                                apiImage.push()\n                                if (env.BRANCH_NAME == 'main') {\n                                    apiImage.push('latest')\n                                }\n                            }\n                        }\n                    }\n                }\n                stage('Worker Image') {\n                    steps {\n                        script {\n                            def workerImage = docker.build(\"${REGISTRY}/${IMAGE_NAME}-worker:${GIT_COMMIT_SHORT}\", \"-f docker/worker/Dockerfile .\")\n                            docker.withRegistry(\"https://${REGISTRY}\", 'docker-registry-credentials') {\n                                workerImage.push()\n                                if (env.BRANCH_NAME == 'main') {\n                                    workerImage.push('latest')\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n        }\n\n        stage('Security Scan') {\n            when {\n                anyOf {\n                    branch 'main'\n                    branch 'develop'\n                }\n            }\n            steps {\n                sh \"\"\"\n                    docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \\\\\n                        aquasec/trivy:latest image \\\\\n                        --format json --output trivy-report.json \\\\\n                        ${REGISTRY}/${IMAGE_NAME}-api:${GIT_COMMIT_SHORT}\n                \"\"\"\n                archiveArtifacts artifacts: 'trivy-report.json', fingerprint: true\n            }\n        }\n\n        stage('Deploy to Staging') {\n            when {\n                branch 'develop'\n            }\n            steps {\n                sh \"\"\"\n                    helm upgrade --install temporal-staging ./helm/temporal-stack \\\\\n                        --namespace temporal-staging \\\\\n                        --create-namespace \\\\\n                        --set image.tag=${GIT_COMMIT_SHORT} \\\\\n                        --set environment=staging \\\\\n                        --values ./helm/values/staging.yaml \\\\\n                        --wait --timeout=10m\n                \"\"\"\n            }\n        }\n\n        stage('E2E Tests') {\n            when {\n                branch 'develop'\n            }\n            steps {\n                sh \"\"\"\n                    . venv/bin/activate\n                    pytest tests/e2e/ -v --junitxml=e2e-test-results.xml \\\\\n                        --base-url=\\$STAGING_BASE_URL \\\\\n                        --api-key=\\$STAGING_API_KEY\n                \"\"\"\n                junit 'e2e-test-results.xml'\n            }\n        }\n\n        stage('Deploy to Production') {\n            when {\n                buildingTag()\n            }\n            steps {\n                input message: 'Deploy to production?', ok: 'Deploy'\n                sh \"\"\"\n                    helm upgrade --install temporal-production ./helm/temporal-stack \\\\\n                        --namespace temporal-production \\\\\n                        --create-namespace \\\\\n                        --set image.tag=${env.TAG_NAME} \\\\\n                        --set environment=production \\\\\n                        --values ./helm/values/production.yaml \\\\\n                        --wait --timeout=15m\n                \"\"\"\n            }\n        }\n    }\n\n    post {\n        always {\n            cleanWs()\n        }\n        success {\n            slackSend(\n                channel: '#deployments',\n                color: 'good',\n                message: \"\u2705 Build succeeded: ${env.JOB_NAME} - ${env.BUILD_NUMBER}\"\n            )\n        }\n        failure {\n            slackSend(\n                channel: '#deployments',\n                color: 'danger',\n                message: \"\u274c Build failed: ${env.JOB_NAME} - ${env.BUILD_NUMBER}\"\n            )\n        }\n    }\n}\n</code></pre>"},{"location":"development/cicd-pipeline/#docker-configuration","title":"Docker Configuration","text":""},{"location":"development/cicd-pipeline/#multi-stage-dockerfile-for-api","title":"Multi-stage Dockerfile for API","text":"<pre><code># docker/api/Dockerfile\nFROM python:3.11-slim as builder\n\nWORKDIR /app\n\n# Install build dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    gcc \\\n    g++ \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Copy requirements first for better caching\nCOPY requirements.txt .\nRUN pip install --no-cache-dir --user -r requirements.txt\n\n# Production stage\nFROM python:3.11-slim as production\n\nWORKDIR /app\n\n# Install runtime dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    curl \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/* \\\n    &amp;&amp; groupadd -r temporal &amp;&amp; useradd -r -g temporal temporal\n\n# Copy installed packages from builder\nCOPY --from=builder /root/.local /home/temporal/.local\n\n# Copy application code\nCOPY src/ ./src/\nCOPY alembic.ini ./\nCOPY alembic/ ./alembic/\n\n# Set up permissions\nRUN chown -R temporal:temporal /app\nUSER temporal\n\n# Add local packages to PATH\nENV PATH=/home/temporal/.local/bin:$PATH\nENV PYTHONPATH=/app/src\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=10s --start-period=30s --retries=3 \\\n    CMD curl -f http://localhost:8000/health || exit 1\n\n# Expose port\nEXPOSE 8000\n\n# Run application\nCMD [\"uvicorn\", \"temporal_api.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre>"},{"location":"development/cicd-pipeline/#worker-dockerfile","title":"Worker Dockerfile","text":"<pre><code># docker/worker/Dockerfile\nFROM python:3.11-slim as builder\n\nWORKDIR /app\n\n# Install build dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    gcc \\\n    g++ \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Copy requirements first for better caching\nCOPY requirements.txt .\nRUN pip install --no-cache-dir --user -r requirements.txt\n\n# Production stage\nFROM python:3.11-slim as production\n\nWORKDIR /app\n\n# Install runtime dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    curl \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/* \\\n    &amp;&amp; groupadd -r temporal &amp;&amp; useradd -r -g temporal temporal\n\n# Copy installed packages from builder\nCOPY --from=builder /root/.local /home/temporal/.local\n\n# Copy application code\nCOPY src/ ./src/\n\n# Set up permissions\nRUN chown -R temporal:temporal /app\nUSER temporal\n\n# Add local packages to PATH\nENV PATH=/home/temporal/.local/bin:$PATH\nENV PYTHONPATH=/app/src\n\n# Run worker\nCMD [\"python\", \"-m\", \"temporal_workflows.worker\"]\n</code></pre>"},{"location":"development/cicd-pipeline/#deployment-scripts","title":"Deployment Scripts","text":""},{"location":"development/cicd-pipeline/#deployment-automation-script","title":"Deployment Automation Script","text":"<pre><code>#!/bin/bash\n# scripts/deploy.sh\n\nset -euo pipefail\n\n# Configuration\nENVIRONMENT=${1:-staging}\nIMAGE_TAG=${2:-latest}\nNAMESPACE=\"temporal-${ENVIRONMENT}\"\nHELM_CHART=\"./helm/temporal-stack\"\nVALUES_FILE=\"./helm/values/${ENVIRONMENT}.yaml\"\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m' # No Color\n\nlog() {\n    echo -e \"${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}\"\n}\n\nwarn() {\n    echo -e \"${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}\"\n}\n\nerror() {\n    echo -e \"${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}\"\n    exit 1\n}\n\n# Pre-deployment checks\npre_deploy_checks() {\n    log \"Running pre-deployment checks...\"\n\n    # Check if kubectl is configured\n    if ! kubectl cluster-info &gt; /dev/null 2&gt;&amp;1; then\n        error \"kubectl is not configured or cluster is not reachable\"\n    fi\n\n    # Check if namespace exists\n    if ! kubectl get namespace \"$NAMESPACE\" &gt; /dev/null 2&gt;&amp;1; then\n        log \"Creating namespace: $NAMESPACE\"\n        kubectl create namespace \"$NAMESPACE\"\n    fi\n\n    # Check if Helm chart exists\n    if [[ ! -d \"$HELM_CHART\" ]]; then\n        error \"Helm chart not found at: $HELM_CHART\"\n    fi\n\n    # Check if values file exists\n    if [[ ! -f \"$VALUES_FILE\" ]]; then\n        error \"Values file not found at: $VALUES_FILE\"\n    fi\n\n    log \"Pre-deployment checks passed \u2713\"\n}\n\n# Deploy application\ndeploy() {\n    log \"Deploying to $ENVIRONMENT environment...\"\n    log \"Image tag: $IMAGE_TAG\"\n    log \"Namespace: $NAMESPACE\"\n\n    helm upgrade --install \"temporal-${ENVIRONMENT}\" \"$HELM_CHART\" \\\n        --namespace \"$NAMESPACE\" \\\n        --set image.tag=\"$IMAGE_TAG\" \\\n        --set environment=\"$ENVIRONMENT\" \\\n        --values \"$VALUES_FILE\" \\\n        --wait --timeout=15m \\\n        --history-max=10\n\n    log \"Deployment completed \u2713\"\n}\n\n# Post-deployment verification\npost_deploy_verification() {\n    log \"Running post-deployment verification...\"\n\n    # Wait for pods to be ready\n    log \"Waiting for pods to be ready...\"\n    kubectl wait --for=condition=ready pod \\\n        -l app.kubernetes.io/instance=\"temporal-${ENVIRONMENT}\" \\\n        -n \"$NAMESPACE\" \\\n        --timeout=300s\n\n    # Check pod status\n    log \"Pod status:\"\n    kubectl get pods -n \"$NAMESPACE\" -l app.kubernetes.io/instance=\"temporal-${ENVIRONMENT}\"\n\n    # Health check\n    if [[ \"$ENVIRONMENT\" == \"production\" ]]; then\n        log \"Running health check...\"\n        if curl -f \"https://temporal.example.com/health\" &gt; /dev/null 2&gt;&amp;1; then\n            log \"Health check passed \u2713\"\n        else\n            error \"Health check failed\"\n        fi\n    fi\n\n    log \"Post-deployment verification completed \u2713\"\n}\n\n# Rollback function\nrollback() {\n    warn \"Rolling back deployment...\"\n\n    helm rollback \"temporal-${ENVIRONMENT}\" -n \"$NAMESPACE\"\n\n    log \"Rollback completed\"\n}\n\n# Main execution\nmain() {\n    log \"Starting deployment process...\"\n    log \"Environment: $ENVIRONMENT\"\n    log \"Image tag: $IMAGE_TAG\"\n\n    # Set trap for cleanup on failure\n    trap rollback ERR\n\n    pre_deploy_checks\n    deploy\n    post_deploy_verification\n\n    log \"Deployment successful! \ud83c\udf89\"\n}\n\n# Execute main function\nmain \"$@\"\n</code></pre>"},{"location":"development/cicd-pipeline/#database-migration-script","title":"Database Migration Script","text":"<pre><code>#!/bin/bash\n# scripts/migrate.sh\n\nset -euo pipefail\n\nENVIRONMENT=${1:-staging}\nNAMESPACE=\"temporal-${ENVIRONMENT}\"\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\nerror() {\n    echo -e \"\\033[0;31m[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1\\033[0m\"\n    exit 1\n}\n\n# Run database migrations\nmigrate_database() {\n    log \"Running database migrations for $ENVIRONMENT...\"\n\n    # Get database connection details from secret\n    DB_HOST=$(kubectl get secret temporal-db-credentials -n \"$NAMESPACE\" -o jsonpath='{.data.host}' | base64 -d)\n    DB_USER=$(kubectl get secret temporal-db-credentials -n \"$NAMESPACE\" -o jsonpath='{.data.username}' | base64 -d)\n    DB_PASS=$(kubectl get secret temporal-db-credentials -n \"$NAMESPACE\" -o jsonpath='{.data.password}' | base64 -d)\n    DB_NAME=$(kubectl get secret temporal-db-credentials -n \"$NAMESPACE\" -o jsonpath='{.data.database}' | base64 -d)\n\n    # Run migrations using kubectl job\n    kubectl create job --from=cronjob/temporal-migration \"migration-$(date +%s)\" -n \"$NAMESPACE\"\n\n    # Wait for migration to complete\n    kubectl wait --for=condition=complete job -l job-name=migration -n \"$NAMESPACE\" --timeout=300s\n\n    log \"Database migrations completed \u2713\"\n}\n\nmigrate_database\n</code></pre> <p>This comprehensive CI/CD pipeline guide provides enterprise-grade automation for Temporal.io deployments with robust testing, security scanning, and deployment strategies across multiple environments.</p>"},{"location":"development/fastapi-integration/","title":"FastAPI Integration","text":"<p>This document provides comprehensive guidance for integrating FastAPI with Temporal.io in enterprise environments, creating robust REST APIs that orchestrate workflows and provide business functionality.</p>"},{"location":"development/fastapi-integration/#overview","title":"Overview","text":"<p>FastAPI serves as the HTTP interface layer for Temporal workflows, providing REST endpoints for workflow initiation, monitoring, and interaction. This integration enables web applications, mobile apps, and other services to interact with Temporal workflows through standard HTTP APIs.</p>"},{"location":"development/fastapi-integration/#project-structure","title":"Project Structure","text":"<pre><code>fastapi-temporal-service/\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 temporal_api/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 main.py              # FastAPI application\n\u2502       \u251c\u2500\u2500 api/\n\u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502       \u2502   \u251c\u2500\u2500 v1/\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 orders.py    # Order endpoints\n\u2502       \u2502   \u2502   \u251c\u2500\u2500 workflows.py # Workflow management\n\u2502       \u2502   \u2502   \u2514\u2500\u2500 health.py    # Health checks\n\u2502       \u2502   \u2514\u2500\u2500 dependencies.py  # API dependencies\n\u2502       \u251c\u2500\u2500 models/\n\u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502       \u2502   \u251c\u2500\u2500 api_models.py    # API request/response models\n\u2502       \u2502   \u2514\u2500\u2500 temporal_models.py # Temporal data models\n\u2502       \u251c\u2500\u2500 services/\n\u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502       \u2502   \u251c\u2500\u2500 temporal_client.py\n\u2502       \u2502   \u2514\u2500\u2500 workflow_service.py\n\u2502       \u251c\u2500\u2500 middleware/\n\u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502       \u2502   \u251c\u2500\u2500 auth.py          # Authentication middleware\n\u2502       \u2502   \u251c\u2500\u2500 logging.py       # Request logging\n\u2502       \u2502   \u2514\u2500\u2500 metrics.py       # Metrics collection\n\u2502       \u2514\u2500\u2500 utils/\n\u2502           \u251c\u2500\u2500 __init__.py\n\u2502           \u251c\u2500\u2500 config.py\n\u2502           \u2514\u2500\u2500 exceptions.py\n</code></pre>"},{"location":"development/fastapi-integration/#fastapi-application-setup","title":"FastAPI Application Setup","text":""},{"location":"development/fastapi-integration/#main-application","title":"Main Application","text":"<pre><code># src/temporal_api/main.py\nimport logging\nfrom contextlib import asynccontextmanager\nfrom typing import AsyncGenerator\n\nfrom fastapi import FastAPI, Request, status\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.middleware.gzip import GZipMiddleware\nfrom fastapi.responses import JSONResponse\nfrom prometheus_fastapi_instrumentator import Instrumentator\n\nfrom .api.v1 import orders, workflows, health\nfrom .middleware.auth import AuthMiddleware\nfrom .middleware.logging import LoggingMiddleware\nfrom .services.temporal_client import TemporalClientService\nfrom .utils.config import get_settings\nfrom .utils.exceptions import TemporalAPIException\n\n# Global temporal client service\ntemporal_service: TemporalClientService = None\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI) -&gt; AsyncGenerator:\n    \"\"\"Application lifespan manager\"\"\"\n    global temporal_service\n\n    # Startup\n    settings = get_settings()\n    temporal_service = TemporalClientService(settings)\n    await temporal_service.connect()\n\n    # Add to app state\n    app.state.temporal_service = temporal_service\n\n    yield\n\n    # Shutdown\n    if temporal_service:\n        await temporal_service.disconnect()\n\n# Create FastAPI application\napp = FastAPI(\n    title=\"Temporal Enterprise API\",\n    description=\"REST API for Temporal workflow orchestration\",\n    version=\"1.0.0\",\n    lifespan=lifespan,\n    docs_url=\"/docs\",\n    redoc_url=\"/redoc\",\n    openapi_url=\"/openapi.json\"\n)\n\n# Middleware setup\napp.add_middleware(GZipMiddleware, minimum_size=1000)\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=get_settings().allowed_origins,\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\napp.add_middleware(AuthMiddleware)\napp.add_middleware(LoggingMiddleware)\n\n# Metrics instrumentation\nInstrumentator().instrument(app).expose(app, endpoint=\"/metrics\")\n\n# Exception handlers\n@app.exception_handler(TemporalAPIException)\nasync def temporal_api_exception_handler(request: Request, exc: TemporalAPIException):\n    return JSONResponse(\n        status_code=exc.status_code,\n        content={\n            \"error\": exc.error_type,\n            \"message\": exc.message,\n            \"details\": exc.details,\n            \"request_id\": getattr(request.state, \"request_id\", None)\n        }\n    )\n\n@app.exception_handler(Exception)\nasync def general_exception_handler(request: Request, exc: Exception):\n    logging.error(f\"Unhandled exception: {exc}\", exc_info=True)\n    return JSONResponse(\n        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n        content={\n            \"error\": \"internal_server_error\",\n            \"message\": \"An internal server error occurred\",\n            \"request_id\": getattr(request.state, \"request_id\", None)\n        }\n    )\n\n# Include routers\napp.include_router(health.router, prefix=\"/health\", tags=[\"health\"])\napp.include_router(orders.router, prefix=\"/api/v1/orders\", tags=[\"orders\"])\napp.include_router(workflows.router, prefix=\"/api/v1/workflows\", tags=[\"workflows\"])\n\n@app.get(\"/\", include_in_schema=False)\nasync def root():\n    return {\"message\": \"Temporal Enterprise API\", \"version\": \"1.0.0\"}\n</code></pre>"},{"location":"development/fastapi-integration/#api-models","title":"API Models","text":""},{"location":"development/fastapi-integration/#requestresponse-models","title":"Request/Response Models","text":"<pre><code># src/temporal_api/models/api_models.py\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom enum import Enum\nfrom typing import List, Optional, Dict, Any\nfrom uuid import UUID\n\nfrom pydantic import BaseModel, Field, validator\n\nclass OrderStatus(str, Enum):\n    PENDING = \"pending\"\n    CONFIRMED = \"confirmed\"\n    PROCESSING = \"processing\"\n    SHIPPED = \"shipped\"\n    DELIVERED = \"delivered\"\n    CANCELLED = \"cancelled\"\n\nclass CreateOrderRequest(BaseModel):\n    customer_id: str = Field(..., min_length=1)\n    items: List[Dict[str, Any]] = Field(..., min_items=1)\n    shipping_address: Dict[str, str]\n    payment_method: str\n    payment_details: Dict[str, Any]\n\n    class Config:\n        schema_extra = {\n            \"example\": {\n                \"customer_id\": \"cust_123\",\n                \"items\": [\n                    {\n                        \"id\": \"item_1\",\n                        \"name\": \"Product A\",\n                        \"sku\": \"SKU-001\",\n                        \"quantity\": 2,\n                        \"unit_price\": 29.99\n                    }\n                ],\n                \"shipping_address\": {\n                    \"street\": \"123 Main St\",\n                    \"city\": \"Anytown\",\n                    \"state\": \"CA\",\n                    \"zip_code\": \"12345\"\n                },\n                \"payment_method\": \"credit_card\",\n                \"payment_details\": {\n                    \"token\": \"tok_123456789\"\n                }\n            }\n        }\n\nclass OrderResponse(BaseModel):\n    id: str\n    customer_id: str\n    status: OrderStatus\n    total_amount: Decimal\n    created_at: datetime\n    workflow_id: Optional[str] = None\n\nclass WorkflowExecutionRequest(BaseModel):\n    workflow_type: str\n    task_queue: str = \"temporal-product-queue\"\n    input_data: Dict[str, Any]\n    workflow_id: Optional[str] = None\n    execution_timeout_seconds: Optional[int] = 3600\n\nclass WorkflowExecutionResponse(BaseModel):\n    workflow_id: str\n    run_id: str\n    status: str = \"RUNNING\"\n    result: Optional[Dict[str, Any]] = None\n\nclass WorkflowStatusResponse(BaseModel):\n    workflow_id: str\n    run_id: str\n    status: str\n    result: Optional[Dict[str, Any]] = None\n    history_length: Optional[int] = None\n    execution_time_seconds: Optional[float] = None\n\nclass WorkflowSignalRequest(BaseModel):\n    signal_name: str\n    signal_input: Optional[Dict[str, Any]] = None\n\nclass WorkflowQueryRequest(BaseModel):\n    query_name: str\n    query_args: Optional[Dict[str, Any]] = None\n\nclass HealthCheckResponse(BaseModel):\n    status: str = \"healthy\"\n    timestamp: datetime = Field(default_factory=datetime.utcnow)\n    services: Dict[str, str] = Field(default_factory=dict)\n    version: str = \"1.0.0\"\n</code></pre>"},{"location":"development/fastapi-integration/#temporal-client-service","title":"Temporal Client Service","text":""},{"location":"development/fastapi-integration/#client-management","title":"Client Management","text":"<pre><code># src/temporal_api/services/temporal_client.py\nimport asyncio\nimport logging\nfrom typing import Any, Dict, Optional, Type\nfrom datetime import timedelta\n\nfrom temporalio.client import Client, WorkflowHandle\nfrom temporalio.common import RetryPolicy\nfrom temporalio.exceptions import WorkflowAlreadyStartedError\n\nfrom ..utils.config import Settings\nfrom ..utils.exceptions import TemporalAPIException\n\nclass TemporalClientService:\n    \"\"\"Service for managing Temporal client connections and operations\"\"\"\n\n    def __init__(self, settings: Settings):\n        self.settings = settings\n        self.client: Optional[Client] = None\n        self.logger = logging.getLogger(__name__)\n\n    async def connect(self) -&gt; None:\n        \"\"\"Connect to Temporal server\"\"\"\n        try:\n            self.client = await Client.connect(\n                self.settings.temporal_server_url,\n                namespace=self.settings.temporal_namespace,\n                tls=self.settings.temporal_tls_config if self.settings.temporal_tls_enabled else False\n            )\n            self.logger.info(f\"Connected to Temporal server: {self.settings.temporal_server_url}\")\n        except Exception as e:\n            self.logger.error(f\"Failed to connect to Temporal server: {e}\")\n            raise TemporalAPIException(\n                \"temporal_connection_error\",\n                \"Failed to connect to Temporal server\",\n                status_code=503,\n                details={\"error\": str(e)}\n            )\n\n    async def disconnect(self) -&gt; None:\n        \"\"\"Disconnect from Temporal server\"\"\"\n        if self.client:\n            await self.client.close()\n            self.logger.info(\"Disconnected from Temporal server\")\n\n    async def start_workflow(\n        self,\n        workflow_type: str,\n        workflow_input: Any,\n        workflow_id: Optional[str] = None,\n        task_queue: str = \"temporal-product-queue\",\n        execution_timeout: Optional[timedelta] = None,\n        retry_policy: Optional[RetryPolicy] = None\n    ) -&gt; WorkflowHandle:\n        \"\"\"Start a new workflow execution\"\"\"\n\n        if not self.client:\n            raise TemporalAPIException(\n                \"temporal_not_connected\",\n                \"Temporal client not connected\",\n                status_code=503\n            )\n\n        try:\n            handle = await self.client.start_workflow(\n                workflow_type,\n                workflow_input,\n                id=workflow_id,\n                task_queue=task_queue,\n                execution_timeout=execution_timeout,\n                retry_policy=retry_policy\n            )\n\n            self.logger.info(\n                f\"Started workflow {workflow_type}\",\n                extra={\n                    \"workflow_id\": handle.id,\n                    \"run_id\": handle.result_run_id,\n                    \"task_queue\": task_queue\n                }\n            )\n\n            return handle\n\n        except WorkflowAlreadyStartedError:\n            # Get existing workflow handle\n            handle = self.client.get_workflow_handle(workflow_id)\n            self.logger.warning(f\"Workflow {workflow_id} already exists, returning existing handle\")\n            return handle\n\n        except Exception as e:\n            self.logger.error(f\"Failed to start workflow: {e}\")\n            raise TemporalAPIException(\n                \"workflow_start_error\",\n                f\"Failed to start workflow: {str(e)}\",\n                status_code=400,\n                details={\"workflow_type\": workflow_type, \"error\": str(e)}\n            )\n\n    async def get_workflow_status(self, workflow_id: str) -&gt; Dict[str, Any]:\n        \"\"\"Get workflow execution status\"\"\"\n\n        if not self.client:\n            raise TemporalAPIException(\n                \"temporal_not_connected\",\n                \"Temporal client not connected\",\n                status_code=503\n            )\n\n        try:\n            handle = self.client.get_workflow_handle(workflow_id)\n\n            # Get workflow description\n            description = await handle.describe()\n\n            status_info = {\n                \"workflow_id\": workflow_id,\n                \"run_id\": description.run_id,\n                \"status\": description.status.name,\n                \"workflow_type\": description.workflow_type,\n                \"task_queue\": description.task_queue,\n                \"start_time\": description.start_time.isoformat() if description.start_time else None,\n                \"close_time\": description.close_time.isoformat() if description.close_time else None,\n                \"execution_time_seconds\": None,\n                \"history_length\": description.history_length,\n                \"result\": None\n            }\n\n            # Calculate execution time if workflow is closed\n            if description.start_time and description.close_time:\n                execution_time = description.close_time - description.start_time\n                status_info[\"execution_time_seconds\"] = execution_time.total_seconds()\n\n            # Get result if workflow is completed\n            if description.status.name in [\"COMPLETED\", \"FAILED\", \"CANCELED\"]:\n                try:\n                    if description.status.name == \"COMPLETED\":\n                        result = await handle.result()\n                        if hasattr(result, 'dict'):\n                            status_info[\"result\"] = result.dict()\n                        else:\n                            status_info[\"result\"] = result\n                except Exception as e:\n                    self.logger.warning(f\"Failed to get workflow result: {e}\")\n\n            return status_info\n\n        except Exception as e:\n            self.logger.error(f\"Failed to get workflow status: {e}\")\n            raise TemporalAPIException(\n                \"workflow_status_error\",\n                f\"Failed to get workflow status: {str(e)}\",\n                status_code=404,\n                details={\"workflow_id\": workflow_id, \"error\": str(e)}\n            )\n\n    async def signal_workflow(\n        self,\n        workflow_id: str,\n        signal_name: str,\n        signal_input: Any = None\n    ) -&gt; None:\n        \"\"\"Send signal to workflow\"\"\"\n\n        if not self.client:\n            raise TemporalAPIException(\n                \"temporal_not_connected\",\n                \"Temporal client not connected\",\n                status_code=503\n            )\n\n        try:\n            handle = self.client.get_workflow_handle(workflow_id)\n            await handle.signal(signal_name, signal_input)\n\n            self.logger.info(\n                f\"Sent signal {signal_name} to workflow {workflow_id}\",\n                extra={\"signal_input\": signal_input}\n            )\n\n        except Exception as e:\n            self.logger.error(f\"Failed to signal workflow: {e}\")\n            raise TemporalAPIException(\n                \"workflow_signal_error\",\n                f\"Failed to signal workflow: {str(e)}\",\n                status_code=400,\n                details={\n                    \"workflow_id\": workflow_id,\n                    \"signal_name\": signal_name,\n                    \"error\": str(e)\n                }\n            )\n\n    async def query_workflow(\n        self,\n        workflow_id: str,\n        query_name: str,\n        query_args: Any = None\n    ) -&gt; Any:\n        \"\"\"Query workflow for information\"\"\"\n\n        if not self.client:\n            raise TemporalAPIException(\n                \"temporal_not_connected\",\n                \"Temporal client not connected\",\n                status_code=503\n            )\n\n        try:\n            handle = self.client.get_workflow_handle(workflow_id)\n            result = await handle.query(query_name, query_args)\n\n            self.logger.info(\n                f\"Queried workflow {workflow_id} with {query_name}\",\n                extra={\"query_args\": query_args}\n            )\n\n            return result\n\n        except Exception as e:\n            self.logger.error(f\"Failed to query workflow: {e}\")\n            raise TemporalAPIException(\n                \"workflow_query_error\",\n                f\"Failed to query workflow: {str(e)}\",\n                status_code=400,\n                details={\n                    \"workflow_id\": workflow_id,\n                    \"query_name\": query_name,\n                    \"error\": str(e)\n                }\n            )\n</code></pre>"},{"location":"development/fastapi-integration/#api-endpoints","title":"API Endpoints","text":""},{"location":"development/fastapi-integration/#order-management-endpoints","title":"Order Management Endpoints","text":"<pre><code># src/temporal_api/api/v1/orders.py\nfrom datetime import timedelta\nfrom typing import List\nfrom uuid import uuid4\n\nfrom fastapi import APIRouter, Depends, HTTPException, status\nfrom fastapi.responses import JSONResponse\n\nfrom ...models.api_models import (\n    CreateOrderRequest, OrderResponse, WorkflowStatusResponse\n)\nfrom ...services.temporal_client import TemporalClientService\nfrom ...utils.exceptions import TemporalAPIException\nfrom ..dependencies import get_temporal_service, get_current_user\n\nrouter = APIRouter()\n\n@router.post(\"/\", response_model=OrderResponse, status_code=status.HTTP_201_CREATED)\nasync def create_order(\n    order_request: CreateOrderRequest,\n    temporal_service: TemporalClientService = Depends(get_temporal_service),\n    current_user: dict = Depends(get_current_user)\n) -&gt; OrderResponse:\n    \"\"\"Create a new order and start order processing workflow\"\"\"\n\n    try:\n        # Generate unique order ID\n        order_id = str(uuid4())\n\n        # Prepare workflow input\n        workflow_input = {\n            \"id\": order_id,\n            \"customer_id\": order_request.customer_id,\n            \"items\": order_request.items,\n            \"shipping_address\": order_request.shipping_address,\n            \"payment_method\": order_request.payment_method,\n            \"payment_details\": order_request.payment_details\n        }\n\n        # Start order processing workflow\n        handle = await temporal_service.start_workflow(\n            workflow_type=\"order_processing\",\n            workflow_input=workflow_input,\n            workflow_id=f\"order-{order_id}\",\n            task_queue=\"temporal-product-queue\",\n            execution_timeout=timedelta(hours=2)\n        )\n\n        # Calculate total amount (simplified)\n        total_amount = sum(\n            item.get(\"quantity\", 0) * item.get(\"unit_price\", 0)\n            for item in order_request.items\n        )\n\n        return OrderResponse(\n            id=order_id,\n            customer_id=order_request.customer_id,\n            status=\"PENDING\",\n            total_amount=total_amount,\n            created_at=datetime.utcnow(),\n            workflow_id=handle.id\n        )\n\n    except TemporalAPIException:\n        raise\n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Failed to create order: {str(e)}\"\n        )\n\n@router.get(\"/{order_id}\", response_model=WorkflowStatusResponse)\nasync def get_order_status(\n    order_id: str,\n    temporal_service: TemporalClientService = Depends(get_temporal_service),\n    current_user: dict = Depends(get_current_user)\n) -&gt; WorkflowStatusResponse:\n    \"\"\"Get order processing status\"\"\"\n\n    try:\n        workflow_id = f\"order-{order_id}\"\n        status_info = await temporal_service.get_workflow_status(workflow_id)\n\n        return WorkflowStatusResponse(**status_info)\n\n    except TemporalAPIException:\n        raise\n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Failed to get order status: {str(e)}\"\n        )\n\n@router.post(\"/{order_id}/cancel\", status_code=status.HTTP_204_NO_CONTENT)\nasync def cancel_order(\n    order_id: str,\n    temporal_service: TemporalClientService = Depends(get_temporal_service),\n    current_user: dict = Depends(get_current_user)\n):\n    \"\"\"Cancel an order by sending cancel signal to workflow\"\"\"\n\n    try:\n        workflow_id = f\"order-{order_id}\"\n        await temporal_service.signal_workflow(\n            workflow_id=workflow_id,\n            signal_name=\"cancel\",\n            signal_input={\"reason\": \"customer_request\"}\n        )\n\n        return JSONResponse(\n            status_code=status.HTTP_204_NO_CONTENT,\n            content=None\n        )\n\n    except TemporalAPIException:\n        raise\n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Failed to cancel order: {str(e)}\"\n        )\n</code></pre>"},{"location":"development/fastapi-integration/#health-check-endpoints","title":"Health Check Endpoints","text":"<pre><code># src/temporal_api/api/v1/health.py\nfrom datetime import datetime\nfrom fastapi import APIRouter, Depends\nfrom ...models.api_models import HealthCheckResponse\nfrom ...services.temporal_client import TemporalClientService\nfrom ..dependencies import get_temporal_service\n\nrouter = APIRouter()\n\n@router.get(\"/\", response_model=HealthCheckResponse)\nasync def health_check(\n    temporal_service: TemporalClientService = Depends(get_temporal_service)\n) -&gt; HealthCheckResponse:\n    \"\"\"Application health check\"\"\"\n\n    services = {}\n\n    # Check Temporal connection\n    if temporal_service and temporal_service.client:\n        try:\n            # Simple check - list workflows (limited)\n            services[\"temporal\"] = \"healthy\"\n        except Exception:\n            services[\"temporal\"] = \"unhealthy\"\n    else:\n        services[\"temporal\"] = \"disconnected\"\n\n    # Determine overall status\n    overall_status = \"healthy\" if all(\n        status == \"healthy\" for status in services.values()\n    ) else \"unhealthy\"\n\n    return HealthCheckResponse(\n        status=overall_status,\n        timestamp=datetime.utcnow(),\n        services=services\n    )\n\n@router.get(\"/ready\")\nasync def readiness_check():\n    \"\"\"Kubernetes readiness probe\"\"\"\n    return {\"status\": \"ready\"}\n\n@router.get(\"/live\")\nasync def liveness_check():\n    \"\"\"Kubernetes liveness probe\"\"\"\n    return {\"status\": \"alive\"}\n</code></pre>"},{"location":"development/fastapi-integration/#dependencies-and-middleware","title":"Dependencies and Middleware","text":""},{"location":"development/fastapi-integration/#api-dependencies","title":"API Dependencies","text":"<pre><code># src/temporal_api/api/dependencies.py\nfrom fastapi import Depends, HTTPException, Request, status\nfrom fastapi.security import HTTPBearer, HTTPAuthorizationCredentials\n\nfrom ..services.temporal_client import TemporalClientService\nfrom ..utils.exceptions import TemporalAPIException\n\nsecurity = HTTPBearer()\n\ndef get_temporal_service(request: Request) -&gt; TemporalClientService:\n    \"\"\"Get Temporal client service from app state\"\"\"\n    temporal_service = getattr(request.app.state, \"temporal_service\", None)\n    if not temporal_service:\n        raise TemporalAPIException(\n            \"service_unavailable\",\n            \"Temporal service not available\",\n            status_code=503\n        )\n    return temporal_service\n\nasync def get_current_user(\n    credentials: HTTPAuthorizationCredentials = Depends(security)\n) -&gt; dict:\n    \"\"\"Get current authenticated user (simplified)\"\"\"\n    # In production, validate JWT token and extract user info\n    # This is a simplified example\n    return {\n        \"user_id\": \"user_123\",\n        \"username\": \"test_user\",\n        \"roles\": [\"user\"]\n    }\n</code></pre>"},{"location":"development/fastapi-integration/#authentication-middleware","title":"Authentication Middleware","text":"<pre><code># src/temporal_api/middleware/auth.py\nimport logging\nfrom fastapi import Request, HTTPException, status\nfrom starlette.middleware.base import BaseHTTPMiddleware\n\nclass AuthMiddleware(BaseHTTPMiddleware):\n    \"\"\"Authentication middleware for API requests\"\"\"\n\n    EXCLUDED_PATHS = {\"/health\", \"/metrics\", \"/docs\", \"/redoc\", \"/openapi.json\"}\n\n    async def dispatch(self, request: Request, call_next):\n        # Skip authentication for excluded paths\n        if any(request.url.path.startswith(path) for path in self.EXCLUDED_PATHS):\n            return await call_next(request)\n\n        # Check for Authorization header\n        auth_header = request.headers.get(\"Authorization\")\n        if not auth_header or not auth_header.startswith(\"Bearer \"):\n            raise HTTPException(\n                status_code=status.HTTP_401_UNAUTHORIZED,\n                detail=\"Missing or invalid authorization header\"\n            )\n\n        # In production, validate JWT token here\n        token = auth_header.split(\" \")[1]\n\n        # Add user context to request\n        request.state.user = {\"user_id\": \"user_123\", \"token\": token}\n\n        response = await call_next(request)\n        return response\n</code></pre>"},{"location":"development/fastapi-integration/#configuration-and-utilities","title":"Configuration and Utilities","text":""},{"location":"development/fastapi-integration/#exception-handling","title":"Exception Handling","text":"<pre><code># src/temporal_api/utils/exceptions.py\nfrom typing import Optional, Dict, Any\n\nclass TemporalAPIException(Exception):\n    \"\"\"Custom exception for Temporal API errors\"\"\"\n\n    def __init__(\n        self,\n        error_type: str,\n        message: str,\n        status_code: int = 400,\n        details: Optional[Dict[str, Any]] = None\n    ):\n        self.error_type = error_type\n        self.message = message\n        self.status_code = status_code\n        self.details = details or {}\n        super().__init__(message)\n</code></pre>"},{"location":"development/fastapi-integration/#docker-configuration","title":"Docker Configuration","text":""},{"location":"development/fastapi-integration/#dockerfile","title":"Dockerfile","text":"<pre><code>FROM python:3.11-slim\n\nWORKDIR /app\n\n# Install system dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    gcc \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Copy requirements and install Python dependencies\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy application code\nCOPY src/ ./src/\n\n# Set environment variables\nENV PYTHONPATH=\"/app/src\"\nENV PYTHONUNBUFFERED=1\n\n# Expose port\nEXPOSE 8000\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \\\n    CMD curl -f http://localhost:8000/health || exit 1\n\n# Run application\nCMD [\"uvicorn\", \"temporal_api.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre> <p>This FastAPI integration provides a robust HTTP interface for Temporal workflows with enterprise features including authentication, monitoring, error handling, and comprehensive API documentation.</p>"},{"location":"development/python-sdk/","title":"Python SDK Guide","text":"<p>This document provides comprehensive guidance for using the Temporal Python SDK in enterprise environments, covering setup, configuration, best practices, and advanced features for building production-ready Temporal applications.</p>"},{"location":"development/python-sdk/#overview","title":"Overview","text":"<p>The Temporal Python SDK enables developers to build workflows and activities using Python, providing a powerful and flexible foundation for orchestrating business processes. This guide focuses on enterprise-specific considerations including performance, reliability, observability, and maintainability.</p>"},{"location":"development/python-sdk/#installation-and-setup","title":"Installation and Setup","text":""},{"location":"development/python-sdk/#project-structure","title":"Project Structure","text":"<pre><code>temporal-python-project/\n\u251c\u2500\u2500 pyproject.toml              # Project configuration with uv\n\u251c\u2500\u2500 uv.lock                     # Dependency lock file\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 .github/\n\u2502   \u2514\u2500\u2500 workflows/\n\u2502       \u2514\u2500\u2500 ci.yml\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 temporal_app/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 activities/\n\u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502       \u2502   \u251c\u2500\u2500 base.py         # Base activity class\n\u2502       \u2502   \u251c\u2500\u2500 payment.py      # Payment activities\n\u2502       \u2502   \u251c\u2500\u2500 inventory.py    # Inventory activities\n\u2502       \u2502   \u2514\u2500\u2500 notification.py # Notification activities\n\u2502       \u251c\u2500\u2500 workflows/\n\u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502       \u2502   \u251c\u2500\u2500 base.py         # Base workflow class\n\u2502       \u2502   \u251c\u2500\u2500 order_processing.py\n\u2502       \u2502   \u2514\u2500\u2500 user_onboarding.py\n\u2502       \u251c\u2500\u2500 models/\n\u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502       \u2502   \u251c\u2500\u2500 orders.py       # Order-related data models\n\u2502       \u2502   \u2514\u2500\u2500 users.py        # User-related data models\n\u2502       \u251c\u2500\u2500 workers/\n\u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502       \u2502   \u251c\u2500\u2500 main.py         # Main worker entry point\n\u2502       \u2502   \u2514\u2500\u2500 config.py       # Worker configuration\n\u2502       \u251c\u2500\u2500 clients/\n\u2502       \u2502   \u251c\u2500\u2500 __init__.py\n\u2502       \u2502   \u251c\u2500\u2500 temporal_client.py\n\u2502       \u2502   \u2514\u2500\u2500 external_apis.py\n\u2502       \u2514\u2500\u2500 utils/\n\u2502           \u251c\u2500\u2500 __init__.py\n\u2502           \u251c\u2500\u2500 logging.py      # Logging configuration\n\u2502           \u251c\u2500\u2500 metrics.py      # Metrics utilities\n\u2502           \u2514\u2500\u2500 config.py       # Application configuration\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 conftest.py\n\u2502   \u251c\u2500\u2500 unit/\n\u2502   \u2502   \u251c\u2500\u2500 test_activities.py\n\u2502   \u2502   \u2514\u2500\u2500 test_workflows.py\n\u2502   \u251c\u2500\u2500 integration/\n\u2502   \u2502   \u2514\u2500\u2500 test_workflows_integration.py\n\u2502   \u2514\u2500\u2500 fixtures/\n\u2502       \u2514\u2500\u2500 sample_data.py\n\u251c\u2500\u2500 docker/\n\u2502   \u251c\u2500\u2500 Dockerfile\n\u2502   \u2514\u2500\u2500 docker-compose.yml\n\u2514\u2500\u2500 k8s/\n    \u251c\u2500\u2500 deployment.yaml\n    \u251c\u2500\u2500 service.yaml\n    \u2514\u2500\u2500 configmap.yaml\n</code></pre>"},{"location":"development/python-sdk/#dependencies-configuration","title":"Dependencies Configuration","text":"<pre><code># pyproject.toml\n[project]\nname = \"temporal-enterprise-app\"\nversion = \"1.0.0\"\ndescription = \"Enterprise Temporal application\"\nauthors = [\n    {name = \"DevOps Team\", email = \"devops@example.com\"}\n]\nreadme = \"README.md\"\nlicense = {text = \"MIT\"}\nrequires-python = \"&gt;=3.11\"\n\ndependencies = [\n    # Temporal SDK\n    \"temporalio&gt;=1.18.2\",\n\n    # Async HTTP client\n    \"httpx&gt;=0.25.0\",\n\n    # Data validation and serialization\n    \"pydantic&gt;=2.5.0\",\n    \"pydantic-settings&gt;=2.1.0\",\n\n    # Database\n    \"asyncpg&gt;=0.29.0\",\n    \"sqlalchemy[asyncio]&gt;=2.0.0\",\n    \"alembic&gt;=1.13.0\",\n\n    # Observability\n    \"structlog&gt;=23.2.0\",\n    \"prometheus-client&gt;=0.19.0\",\n    \"opentelemetry-api&gt;=1.21.0\",\n    \"opentelemetry-sdk&gt;=1.21.0\",\n    \"opentelemetry-exporter-prometheus&gt;=1.12.0\",\n    \"opentelemetry-instrumentation-sqlalchemy&gt;=0.42b0\",\n\n    # Configuration\n    \"python-dotenv&gt;=1.0.0\",\n\n    # Utilities\n    \"tenacity&gt;=8.2.0\",\n    \"click&gt;=8.1.0\",\n    \"rich&gt;=13.7.0\",\n]\n\n[project.optional-dependencies]\ndev = [\n    # Testing\n    \"pytest&gt;=7.4.0\",\n    \"pytest-asyncio&gt;=0.21.0\",\n    \"pytest-cov&gt;=4.0.0\",\n    \"pytest-mock&gt;=3.12.0\",\n    \"factory-boy&gt;=3.3.0\",\n\n    # Code quality\n    \"black&gt;=23.11.0\",\n    \"ruff&gt;=0.1.6\",\n    \"mypy&gt;=1.7.0\",\n    \"pre-commit&gt;=3.6.0\",\n\n    # Documentation\n    \"mkdocs&gt;=1.5.0\",\n    \"mkdocs-material&gt;=9.4.0\",\n\n    # Development tools\n    \"ipython&gt;=8.17.0\",\n    \"rich&gt;=13.7.0\",\n]\n\n[project.scripts]\ntemporal-worker = \"temporal_app.workers.main:main\"\ntemporal-client = \"temporal_app.clients.temporal_client:cli\"\n\n[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n\n# Tool configurations\n[tool.black]\nline-length = 88\ntarget-version = ['py311']\ninclude = '\\.pyi?$'\nextend-exclude = '''\n/(\n  # directories\n  \\.eggs\n  | \\.git\n  | \\.hg\n  | \\.mypy_cache\n  | \\.tox\n  | \\.venv\n  | build\n  | dist\n)/\n'''\n\n[tool.ruff]\ntarget-version = \"py311\"\nline-length = 88\nselect = [\n    \"E\",   # pycodestyle errors\n    \"W\",   # pycodestyle warnings\n    \"F\",   # pyflakes\n    \"UP\",  # pyupgrade\n    \"B\",   # flake8-bugbear\n    \"SIM\", # flake8-simplify\n    \"I\",   # isort\n    \"N\",   # pep8-naming\n    \"C4\",  # flake8-comprehensions\n    \"PTH\", # flake8-use-pathlib\n]\n\n[tool.mypy]\npython_version = \"3.11\"\nstrict = true\nwarn_return_any = true\nwarn_unused_configs = true\ndisallow_untyped_defs = true\ndisallow_incomplete_defs = true\ncheck_untyped_defs = true\ndisallow_untyped_decorators = true\n\n[[tool.mypy.overrides]]\nmodule = \"tests.*\"\ndisallow_untyped_defs = false\n\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\npython_files = [\"test_*.py\"]\npython_classes = [\"Test*\"]\npython_functions = [\"test_*\"]\naddopts = [\n    \"-ra\",\n    \"--strict-markers\",\n    \"--strict-config\",\n    \"--cov=temporal_app\",\n    \"--cov-report=html\",\n    \"--cov-report=term-missing\",\n]\nmarkers = [\n    \"slow: marks tests as slow (deselect with '-m \\\"not slow\\\"')\",\n    \"integration: marks tests as integration tests\",\n    \"unit: marks tests as unit tests\",\n]\nasyncio_mode = \"auto\"\n</code></pre>"},{"location":"development/python-sdk/#base-classes-and-utilities","title":"Base Classes and Utilities","text":""},{"location":"development/python-sdk/#base-activity-class","title":"Base Activity Class","text":"<pre><code># src/temporal_app/activities/base.py\nimport asyncio\nimport logging\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Dict, Optional, Type, TypeVar\nfrom datetime import datetime\n\nfrom temporalio import activity\nfrom pydantic import BaseModel, ValidationError\nfrom opentelemetry import trace\n\nfrom ..utils.metrics import ActivityMetrics\nfrom ..utils.logging import get_structured_logger\n\nT = TypeVar('T', bound=BaseModel)\n\nclass BaseActivity(ABC):\n    \"\"\"Base class for all Temporal activities with enterprise features\"\"\"\n\n    def __init__(self):\n        self.logger = get_structured_logger(self.__class__.__name__)\n        self.metrics = ActivityMetrics()\n        self.tracer = trace.get_tracer(__name__)\n\n    async def execute_with_instrumentation(\n        self, \n        input_data: BaseModel,\n        operation_name: Optional[str] = None\n    ) -&gt; Any:\n        \"\"\"Execute activity with comprehensive instrumentation\"\"\"\n\n        operation_name = operation_name or self.__class__.__name__\n\n        # Start metrics timer\n        timer = self.metrics.start_timer(operation_name)\n\n        # Start OpenTelemetry span\n        with self.tracer.start_as_current_span(operation_name) as span:\n            try:\n                # Add span attributes\n                span.set_attribute(\"activity.name\", self.__class__.__name__)\n                span.set_attribute(\"activity.input_type\", type(input_data).__name__)\n\n                # Log activity start\n                self.logger.info(\n                    \"Activity started\",\n                    activity_name=self.__class__.__name__,\n                    input_type=type(input_data).__name__,\n                    workflow_id=activity.info().workflow_id,\n                    activity_id=activity.info().activity_id\n                )\n\n                # Send heartbeat\n                activity.heartbeat(\"Activity execution started\")\n\n                # Execute the actual activity logic\n                result = await self.execute(input_data)\n\n                # Log success\n                self.logger.info(\n                    \"Activity completed successfully\",\n                    activity_name=self.__class__.__name__,\n                    execution_time=timer.stop()\n                )\n\n                # Record success metrics\n                self.metrics.record_success(operation_name)\n                span.set_attribute(\"activity.status\", \"success\")\n\n                return result\n\n            except ValidationError as e:\n                # Handle validation errors\n                self.logger.error(\n                    \"Activity validation error\",\n                    activity_name=self.__class__.__name__,\n                    error=str(e),\n                    execution_time=timer.stop()\n                )\n\n                self.metrics.record_error(operation_name, \"validation_error\")\n                span.set_attribute(\"activity.status\", \"validation_error\")\n                span.record_exception(e)\n\n                raise\n\n            except Exception as e:\n                # Handle all other errors\n                self.logger.error(\n                    \"Activity execution failed\",\n                    activity_name=self.__class__.__name__,\n                    error=str(e),\n                    error_type=type(e).__name__,\n                    execution_time=timer.stop()\n                )\n\n                self.metrics.record_error(operation_name, type(e).__name__)\n                span.set_attribute(\"activity.status\", \"error\")\n                span.record_exception(e)\n\n                raise\n\n    @abstractmethod\n    async def execute(self, input_data: BaseModel) -&gt; Any:\n        \"\"\"Execute the activity logic - to be implemented by subclasses\"\"\"\n        pass\n\n    async def validate_input(self, input_data: Any, model_class: Type[T]) -&gt; T:\n        \"\"\"Validate and parse input data using Pydantic model\"\"\"\n        try:\n            if isinstance(input_data, model_class):\n                return input_data\n            elif isinstance(input_data, dict):\n                return model_class(**input_data)\n            else:\n                return model_class.model_validate(input_data)\n        except ValidationError as e:\n            self.logger.error(\n                \"Input validation failed\",\n                error=str(e),\n                input_type=type(input_data).__name__\n            )\n            raise\n\n    async def call_external_service(\n        self,\n        service_name: str,\n        method: str,\n        *args,\n        **kwargs\n    ) -&gt; Any:\n        \"\"\"Call external service with retry and instrumentation\"\"\"\n\n        with self.tracer.start_as_current_span(f\"external_call_{service_name}\") as span:\n            span.set_attribute(\"service.name\", service_name)\n            span.set_attribute(\"service.method\", method)\n\n            try:\n                # Implement your external service call logic here\n                # This is a placeholder for demonstration\n                result = await self._make_external_call(service_name, method, *args, **kwargs)\n\n                span.set_attribute(\"external_call.status\", \"success\")\n                return result\n\n            except Exception as e:\n                span.set_attribute(\"external_call.status\", \"error\")\n                span.record_exception(e)\n\n                self.logger.error(\n                    \"External service call failed\",\n                    service=service_name,\n                    method=method,\n                    error=str(e)\n                )\n                raise\n\n    async def _make_external_call(self, service_name: str, method: str, *args, **kwargs) -&gt; Any:\n        \"\"\"Placeholder for actual external service calls\"\"\"\n        # Implement actual external service calling logic\n        pass\n\n# Activity decorator with base class integration\ndef enterprise_activity(name: Optional[str] = None):\n    \"\"\"Decorator for enterprise activities with built-in instrumentation\"\"\"\n    def decorator(cls: Type[BaseActivity]):\n\n        @activity.defn(name=name or cls.__name__)\n        async def activity_wrapper(*args, **kwargs):\n            instance = cls()\n\n            # Assume first argument is the input data\n            input_data = args[0] if args else kwargs.get('input_data')\n\n            return await instance.execute_with_instrumentation(input_data)\n\n        # Store original class for reference\n        activity_wrapper._original_class = cls\n        return activity_wrapper\n\n    return decorator\n</code></pre>"},{"location":"development/python-sdk/#base-workflow-class","title":"Base Workflow Class","text":"<pre><code># src/temporal_app/workflows/base.py\nimport asyncio\nfrom abc import ABC, abstractmethod\nfrom typing import Any, Dict, Optional, Type, TypeVar\nfrom datetime import datetime, timedelta\n\nfrom temporalio import workflow\nfrom temporalio.common import RetryPolicy\nfrom pydantic import BaseModel\n\nfrom ..utils.logging import get_structured_logger\nfrom ..utils.metrics import WorkflowMetrics\n\nT = TypeVar('T', bound=BaseModel)\n\nclass BaseWorkflow(ABC):\n    \"\"\"Base class for all Temporal workflows with enterprise features\"\"\"\n\n    def __init__(self):\n        self.logger = get_structured_logger(self.__class__.__name__)\n        self.metrics = WorkflowMetrics()\n        self._execution_started = workflow.now()\n        self._steps_completed: set[str] = set()\n\n    async def execute_with_instrumentation(self, input_data: BaseModel) -&gt; Any:\n        \"\"\"Execute workflow with comprehensive instrumentation\"\"\"\n\n        try:\n            # Log workflow start\n            workflow.logger.info(\n                \"Workflow started\",\n                workflow_name=self.__class__.__name__,\n                workflow_id=workflow.info().workflow_id,\n                run_id=workflow.info().run_id,\n                input_type=type(input_data).__name__\n            )\n\n            # Execute the actual workflow logic\n            result = await self.execute(input_data)\n\n            # Calculate execution time\n            execution_time = workflow.now() - self._execution_started\n\n            # Log workflow completion\n            workflow.logger.info(\n                \"Workflow completed successfully\",\n                workflow_name=self.__class__.__name__,\n                execution_time=execution_time.total_seconds(),\n                steps_completed=len(self._steps_completed)\n            )\n\n            return result\n\n        except Exception as e:\n            # Calculate execution time for failed workflow\n            execution_time = workflow.now() - self._execution_started\n\n            # Log workflow failure\n            workflow.logger.error(\n                \"Workflow execution failed\",\n                workflow_name=self.__class__.__name__,\n                error=str(e),\n                error_type=type(e).__name__,\n                execution_time=execution_time.total_seconds(),\n                steps_completed=len(self._steps_completed)\n            )\n\n            raise\n\n    @abstractmethod\n    async def execute(self, input_data: BaseModel) -&gt; Any:\n        \"\"\"Execute the workflow logic - to be implemented by subclasses\"\"\"\n        pass\n\n    async def execute_activity_step(\n        self,\n        activity_function: Any,\n        input_data: Any,\n        step_name: str,\n        timeout: timedelta = timedelta(minutes=10),\n        retry_policy: Optional[RetryPolicy] = None,\n        heartbeat_timeout: Optional[timedelta] = None,\n        task_queue: Optional[str] = None\n    ) -&gt; Any:\n        \"\"\"Execute an activity with standardized error handling and logging\"\"\"\n\n        # Check if step was already completed (for replay safety)\n        if step_name in self._steps_completed:\n            workflow.logger.debug(f\"Step '{step_name}' already completed, skipping\")\n            return\n\n        # Default retry policy for enterprise activities\n        if retry_policy is None:\n            retry_policy = RetryPolicy(\n                initial_interval=timedelta(seconds=1),\n                maximum_interval=timedelta(seconds=60),\n                maximum_attempts=3,\n                non_retryable_error_types=[\n                    \"ValidationError\",\n                    \"AuthenticationError\",\n                    \"AuthorizationError\"\n                ]\n            )\n\n        try:\n            workflow.logger.info(f\"Starting activity step: {step_name}\")\n\n            result = await workflow.execute_activity(\n                activity_function,\n                input_data,\n                start_to_close_timeout=timeout,\n                retry_policy=retry_policy,\n                heartbeat_timeout=heartbeat_timeout,\n                task_queue=task_queue\n            )\n\n            # Mark step as completed\n            self._steps_completed.add(step_name)\n\n            workflow.logger.info(f\"Completed activity step: {step_name}\")\n            return result\n\n        except Exception as e:\n            workflow.logger.error(\n                f\"Activity step failed: {step_name}\",\n                error=str(e),\n                error_type=type(e).__name__\n            )\n            raise\n\n    async def execute_parallel_activities(\n        self,\n        activities: Dict[str, tuple],  # step_name -&gt; (activity_function, input_data, options)\n        gather_exceptions: bool = True\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Execute multiple activities in parallel\"\"\"\n\n        workflow.logger.info(f\"Starting {len(activities)} parallel activities\")\n\n        # Create tasks for all activities\n        tasks = {}\n        for step_name, (activity_func, input_data, options) in activities.items():\n            task = workflow.execute_activity(\n                activity_func,\n                input_data,\n                **options\n            )\n            tasks[step_name] = task\n\n        # Wait for all tasks to complete\n        if gather_exceptions:\n            results = {}\n            for step_name, task in tasks.items():\n                try:\n                    results[step_name] = await task\n                    self._steps_completed.add(step_name)\n                except Exception as e:\n                    workflow.logger.error(f\"Parallel activity failed: {step_name}\", error=str(e))\n                    results[step_name] = e\n            return results\n        else:\n            # Use asyncio.gather for fail-fast behavior\n            task_list = list(tasks.values())\n            step_names = list(tasks.keys())\n\n            results_list = await asyncio.gather(*task_list)\n\n            # Mark all steps as completed\n            for step_name in step_names:\n                self._steps_completed.add(step_name)\n\n            return dict(zip(step_names, results_list))\n\n    async def wait_for_condition_with_timeout(\n        self,\n        condition: callable,\n        timeout: timedelta,\n        check_interval: timedelta = timedelta(seconds=1)\n    ) -&gt; bool:\n        \"\"\"Wait for a condition with timeout\"\"\"\n\n        start_time = workflow.now()\n\n        while workflow.now() - start_time &lt; timeout:\n            if condition():\n                return True\n            await asyncio.sleep(check_interval.total_seconds())\n\n        return False\n\n    def get_execution_metrics(self) -&gt; Dict[str, Any]:\n        \"\"\"Get workflow execution metrics\"\"\"\n        execution_time = workflow.now() - self._execution_started\n\n        return {\n            \"workflow_name\": self.__class__.__name__,\n            \"workflow_id\": workflow.info().workflow_id,\n            \"run_id\": workflow.info().run_id,\n            \"execution_time_seconds\": execution_time.total_seconds(),\n            \"steps_completed\": len(self._steps_completed),\n            \"completed_steps\": list(self._steps_completed)\n        }\n\n# Workflow decorator with base class integration\ndef enterprise_workflow(name: Optional[str] = None):\n    \"\"\"Decorator for enterprise workflows with built-in instrumentation\"\"\"\n    def decorator(cls: Type[BaseWorkflow]):\n\n        @workflow.defn(name=name or cls.__name__)\n        class WorkflowWrapper:\n            async def run(self, *args, **kwargs):\n                instance = cls()\n\n                # Assume first argument is the input data\n                input_data = args[0] if args else kwargs.get('input_data')\n\n                return await instance.execute_with_instrumentation(input_data)\n\n        # Store original class for reference\n        WorkflowWrapper._original_class = cls\n        return WorkflowWrapper\n\n    return decorator\n</code></pre>"},{"location":"development/python-sdk/#data-models-and-validation","title":"Data Models and Validation","text":""},{"location":"development/python-sdk/#pydantic-models-for-type-safety","title":"Pydantic Models for Type Safety","text":"<pre><code># src/temporal_app/models/orders.py\nfrom datetime import datetime\nfrom decimal import Decimal\nfrom enum import Enum\nfrom typing import List, Optional, Dict, Any\nfrom uuid import UUID, uuid4\n\nfrom pydantic import BaseModel, Field, validator, root_validator\n\nclass OrderStatus(str, Enum):\n    PENDING = \"pending\"\n    CONFIRMED = \"confirmed\"\n    PROCESSING = \"processing\"\n    SHIPPED = \"shipped\"\n    DELIVERED = \"delivered\"\n    CANCELLED = \"cancelled\"\n    REFUNDED = \"refunded\"\n\nclass PaymentMethod(str, Enum):\n    CREDIT_CARD = \"credit_card\"\n    DEBIT_CARD = \"debit_card\"\n    PAYPAL = \"paypal\"\n    BANK_TRANSFER = \"bank_transfer\"\n\nclass Address(BaseModel):\n    \"\"\"Shipping/billing address model\"\"\"\n    street: str = Field(..., min_length=1, max_length=255)\n    city: str = Field(..., min_length=1, max_length=100)\n    state: str = Field(..., min_length=2, max_length=50)\n    zip_code: str = Field(..., regex=r'^\\d{5}(-\\d{4})?$')\n    country: str = Field(default=\"US\", min_length=2, max_length=2)\n\n    class Config:\n        schema_extra = {\n            \"example\": {\n                \"street\": \"123 Main St\",\n                \"city\": \"Anytown\",\n                \"state\": \"CA\",\n                \"zip_code\": \"12345\",\n                \"country\": \"US\"\n            }\n        }\n\nclass OrderItem(BaseModel):\n    \"\"\"Individual order item\"\"\"\n    id: str = Field(..., min_length=1)\n    name: str = Field(..., min_length=1, max_length=255)\n    sku: str = Field(..., min_length=1, max_length=100)\n    quantity: int = Field(..., gt=0, le=1000)\n    unit_price: Decimal = Field(..., gt=0, max_digits=10, decimal_places=2)\n    total_price: Optional[Decimal] = None\n\n    @root_validator\n    def calculate_total_price(cls, values):\n        quantity = values.get('quantity')\n        unit_price = values.get('unit_price')\n        if quantity is not None and unit_price is not None:\n            values['total_price'] = quantity * unit_price\n        return values\n\nclass Order(BaseModel):\n    \"\"\"Complete order model\"\"\"\n    id: str = Field(default_factory=lambda: str(uuid4()))\n    customer_id: str = Field(..., min_length=1)\n    items: List[OrderItem] = Field(..., min_items=1)\n    shipping_address: Address\n    billing_address: Optional[Address] = None\n    payment_method: PaymentMethod\n    payment_details: Dict[str, Any] = Field(default_factory=dict)\n\n    subtotal: Optional[Decimal] = None\n    tax_amount: Optional[Decimal] = None\n    shipping_amount: Optional[Decimal] = None\n    total_amount: Optional[Decimal] = None\n\n    status: OrderStatus = OrderStatus.PENDING\n    created_at: datetime = Field(default_factory=datetime.utcnow)\n    updated_at: Optional[datetime] = None\n\n    notes: Optional[str] = Field(None, max_length=1000)\n    metadata: Dict[str, Any] = Field(default_factory=dict)\n\n    @root_validator\n    def calculate_totals(cls, values):\n        items = values.get('items', [])\n\n        # Calculate subtotal\n        subtotal = sum(item.total_price or Decimal('0') for item in items)\n        values['subtotal'] = subtotal\n\n        # Calculate tax (example: 8.5%)\n        tax_rate = Decimal('0.085')\n        tax_amount = subtotal * tax_rate\n        values['tax_amount'] = tax_amount.quantize(Decimal('0.01'))\n\n        # Calculate shipping (example: flat rate)\n        shipping_amount = Decimal('9.99') if subtotal &lt; 100 else Decimal('0')\n        values['shipping_amount'] = shipping_amount\n\n        # Calculate total\n        total_amount = subtotal + tax_amount + shipping_amount\n        values['total_amount'] = total_amount.quantize(Decimal('0.01'))\n\n        return values\n\n    @validator('billing_address', always=True)\n    def set_billing_address(cls, v, values):\n        if v is None:\n            return values.get('shipping_address')\n        return v\n\n# Activity input/output models\nclass OrderValidationRequest(BaseModel):\n    order: Order\n\nclass OrderValidationResult(BaseModel):\n    is_valid: bool\n    order_id: str\n    validation_errors: List[str] = Field(default_factory=list)\n    estimated_shipping_date: Optional[datetime] = None\n\nclass PaymentProcessingRequest(BaseModel):\n    order_id: str\n    amount: Decimal\n    payment_method: PaymentMethod\n    payment_details: Dict[str, Any]\n    idempotency_key: str\n\nclass PaymentProcessingResult(BaseModel):\n    success: bool\n    transaction_id: Optional[str] = None\n    error_message: Optional[str] = None\n    payment_method_verified: bool = False\n\nclass ShippingRequest(BaseModel):\n    order_id: str\n    items: List[OrderItem]\n    shipping_address: Address\n    shipping_method: str = \"standard\"\n\nclass ShippingResult(BaseModel):\n    success: bool\n    tracking_number: Optional[str] = None\n    estimated_delivery_date: Optional[datetime] = None\n    shipping_cost: Optional[Decimal] = None\n    carrier: Optional[str] = None\n\n# Workflow result models\nclass OrderProcessingResult(BaseModel):\n    order_id: str\n    status: OrderStatus\n    validation_result: Optional[OrderValidationResult] = None\n    payment_result: Optional[PaymentProcessingResult] = None\n    shipping_result: Optional[ShippingResult] = None\n    processing_duration_seconds: Optional[float] = None\n    completed_at: datetime = Field(default_factory=datetime.utcnow)\n</code></pre>"},{"location":"development/python-sdk/#activity-implementation-examples","title":"Activity Implementation Examples","text":""},{"location":"development/python-sdk/#payment-processing-activity","title":"Payment Processing Activity","text":"<pre><code># src/temporal_app/activities/payment.py\nimport asyncio\nfrom decimal import Decimal\nfrom typing import Optional\nimport httpx\nfrom temporalio import activity\nfrom temporalio.exceptions import ApplicationError\n\nfrom .base import BaseActivity, enterprise_activity\nfrom ..models.orders import PaymentProcessingRequest, PaymentProcessingResult, PaymentMethod\nfrom ..utils.config import get_settings\n\nclass PaymentProcessor(BaseActivity):\n    \"\"\"Payment processing activity with enterprise features\"\"\"\n\n    def __init__(self):\n        super().__init__()\n        self.settings = get_settings()\n        self.client = httpx.AsyncClient(\n            timeout=30.0,\n            limits=httpx.Limits(max_connections=10, max_keepalive_connections=5)\n        )\n\n    async def execute(self, input_data: PaymentProcessingRequest) -&gt; PaymentProcessingResult:\n        \"\"\"Process payment with comprehensive error handling\"\"\"\n\n        # Validate input\n        request = await self.validate_input(input_data, PaymentProcessingRequest)\n\n        # Send heartbeat\n        activity.heartbeat(\"Starting payment processing\")\n\n        try:\n            # Verify payment method\n            is_verified = await self._verify_payment_method(request)\n            if not is_verified:\n                return PaymentProcessingResult(\n                    success=False,\n                    error_message=\"Payment method verification failed\",\n                    payment_method_verified=False\n                )\n\n            # Process payment based on method\n            if request.payment_method == PaymentMethod.CREDIT_CARD:\n                result = await self._process_credit_card_payment(request)\n            elif request.payment_method == PaymentMethod.PAYPAL:\n                result = await self._process_paypal_payment(request)\n            else:\n                raise ApplicationError(\n                    f\"Unsupported payment method: {request.payment_method}\",\n                    type=\"UnsupportedPaymentMethod\"\n                )\n\n            # Log successful payment\n            self.logger.info(\n                \"Payment processed successfully\",\n                order_id=request.order_id,\n                transaction_id=result.transaction_id,\n                amount=str(request.amount)\n            )\n\n            return result\n\n        except Exception as e:\n            self.logger.error(\n                \"Payment processing failed\",\n                order_id=request.order_id,\n                error=str(e),\n                payment_method=request.payment_method\n            )\n\n            # Return structured error result\n            return PaymentProcessingResult(\n                success=False,\n                error_message=str(e),\n                payment_method_verified=is_verified if 'is_verified' in locals() else False\n            )\n\n    async def _verify_payment_method(self, request: PaymentProcessingRequest) -&gt; bool:\n        \"\"\"Verify payment method details\"\"\"\n        activity.heartbeat(\"Verifying payment method\")\n\n        try:\n            # Simulate payment method verification\n            await asyncio.sleep(0.1)  # Simulate API call\n\n            # Add actual payment method verification logic here\n            return True\n\n        except Exception as e:\n            self.logger.error(f\"Payment method verification failed: {e}\")\n            return False\n\n    async def _process_credit_card_payment(\n        self, \n        request: PaymentProcessingRequest\n    ) -&gt; PaymentProcessingResult:\n        \"\"\"Process credit card payment\"\"\"\n        activity.heartbeat(\"Processing credit card payment\")\n\n        # Prepare payment request\n        payment_data = {\n            \"amount\": str(request.amount),\n            \"currency\": \"USD\",\n            \"payment_method\": request.payment_details,\n            \"idempotency_key\": request.idempotency_key,\n            \"metadata\": {\n                \"order_id\": request.order_id\n            }\n        }\n\n        try:\n            # Call external payment processor\n            response = await self.call_external_service(\n                \"payment_processor\",\n                \"charge\",\n                data=payment_data\n            )\n\n            if response.get(\"status\") == \"succeeded\":\n                return PaymentProcessingResult(\n                    success=True,\n                    transaction_id=response.get(\"id\"),\n                    payment_method_verified=True\n                )\n            else:\n                return PaymentProcessingResult(\n                    success=False,\n                    error_message=response.get(\"error\", \"Payment failed\"),\n                    payment_method_verified=True\n                )\n\n        except Exception as e:\n            raise ApplicationError(\n                f\"Credit card payment processing failed: {str(e)}\",\n                type=\"PaymentProcessingError\"\n            )\n\n    async def _process_paypal_payment(\n        self, \n        request: PaymentProcessingRequest\n    ) -&gt; PaymentProcessingResult:\n        \"\"\"Process PayPal payment\"\"\"\n        activity.heartbeat(\"Processing PayPal payment\")\n\n        # Implement PayPal-specific payment logic\n        try:\n            # Simulate PayPal API call\n            await asyncio.sleep(0.2)\n\n            return PaymentProcessingResult(\n                success=True,\n                transaction_id=f\"pp_{request.idempotency_key}\",\n                payment_method_verified=True\n            )\n\n        except Exception as e:\n            raise ApplicationError(\n                f\"PayPal payment processing failed: {str(e)}\",\n                type=\"PaymentProcessingError\"\n            )\n\n# Register the activity\n@enterprise_activity(\"process_payment\")\nclass ProcessPaymentActivity(PaymentProcessor):\n    pass\n</code></pre>"},{"location":"development/python-sdk/#inventory-management-activity","title":"Inventory Management Activity","text":"<pre><code># src/temporal_app/activities/inventory.py\nimport asyncio\nfrom typing import Dict, List\nfrom temporalio import activity\nfrom temporalio.exceptions import ApplicationError\n\nfrom .base import BaseActivity, enterprise_activity\nfrom ..models.orders import OrderItem\nfrom ..utils.database import get_database_connection\n\nclass InventoryManager(BaseActivity):\n    \"\"\"Inventory management activity\"\"\"\n\n    async def execute(self, order_items: List[OrderItem]) -&gt; Dict[str, bool]:\n        \"\"\"Check and reserve inventory for order items\"\"\"\n\n        activity.heartbeat(\"Starting inventory check\")\n\n        results = {}\n\n        try:\n            async with get_database_connection() as db:\n                for item in order_items:\n                    # Check availability\n                    available_quantity = await self._check_inventory(db, item.sku)\n\n                    if available_quantity &gt;= item.quantity:\n                        # Reserve inventory\n                        success = await self._reserve_inventory(\n                            db, item.sku, item.quantity\n                        )\n                        results[item.sku] = success\n                    else:\n                        self.logger.warning(\n                            \"Insufficient inventory\",\n                            sku=item.sku,\n                            requested=item.quantity,\n                            available=available_quantity\n                        )\n                        results[item.sku] = False\n\n                # Check if all items were successfully reserved\n                if not all(results.values()):\n                    # Rollback reservations for failed order\n                    await self._rollback_reservations(db, order_items, results)\n                    raise ApplicationError(\n                        \"Insufficient inventory for some items\",\n                        type=\"InsufficientInventory\",\n                        details={\"failed_items\": [sku for sku, success in results.items() if not success]}\n                    )\n\n                activity.heartbeat(\"Inventory reservation completed\")\n                return results\n\n        except Exception as e:\n            self.logger.error(f\"Inventory management failed: {e}\")\n            raise\n\n    async def _check_inventory(self, db, sku: str) -&gt; int:\n        \"\"\"Check available inventory for SKU\"\"\"\n        query = \"SELECT available_quantity FROM inventory WHERE sku = $1\"\n        result = await db.fetchval(query, sku)\n        return result or 0\n\n    async def _reserve_inventory(self, db, sku: str, quantity: int) -&gt; bool:\n        \"\"\"Reserve inventory for SKU\"\"\"\n        query = \"\"\"\n        UPDATE inventory \n        SET available_quantity = available_quantity - $2,\n            reserved_quantity = reserved_quantity + $2\n        WHERE sku = $1 AND available_quantity &gt;= $2\n        \"\"\"\n        result = await db.execute(query, sku, quantity)\n        return result == \"UPDATE 1\"\n\n    async def _rollback_reservations(self, db, order_items: List[OrderItem], results: Dict[str, bool]):\n        \"\"\"Rollback successful reservations\"\"\"\n        for item in order_items:\n            if results.get(item.sku, False):\n                query = \"\"\"\n                UPDATE inventory \n                SET available_quantity = available_quantity + $2,\n                    reserved_quantity = reserved_quantity - $2\n                WHERE sku = $1\n                \"\"\"\n                await db.execute(query, item.sku, item.quantity)\n\n@enterprise_activity(\"reserve_inventory\")\nclass ReserveInventoryActivity(InventoryManager):\n    pass\n</code></pre>"},{"location":"development/python-sdk/#workflow-implementation-example","title":"Workflow Implementation Example","text":""},{"location":"development/python-sdk/#order-processing-workflow","title":"Order Processing Workflow","text":"<pre><code># src/temporal_app/workflows/order_processing.py\nfrom datetime import timedelta\nfrom temporalio import workflow\nfrom temporalio.common import RetryPolicy\nfrom temporalio.exceptions import ApplicationError\n\nfrom .base import BaseWorkflow, enterprise_workflow\nfrom ..models.orders import (\n    Order, OrderProcessingResult, OrderStatus,\n    OrderValidationRequest, PaymentProcessingRequest, ShippingRequest\n)\nfrom ..activities.payment import ProcessPaymentActivity\nfrom ..activities.inventory import ReserveInventoryActivity\n\nclass OrderProcessingWorkflow(BaseWorkflow):\n    \"\"\"Enterprise order processing workflow with comprehensive error handling\"\"\"\n\n    async def execute(self, order: Order) -&gt; OrderProcessingResult:\n        \"\"\"Execute order processing workflow\"\"\"\n\n        result = OrderProcessingResult(\n            order_id=order.id,\n            status=OrderStatus.PENDING\n        )\n\n        try:\n            # Step 1: Validate order\n            validation_result = await self.execute_activity_step(\n                self._validate_order,\n                OrderValidationRequest(order=order),\n                step_name=\"validate_order\",\n                timeout=timedelta(minutes=5)\n            )\n            result.validation_result = validation_result\n\n            if not validation_result.is_valid:\n                result.status = OrderStatus.CANCELLED\n                raise ApplicationError(\n                    \"Order validation failed\",\n                    type=\"OrderValidationError\",\n                    details={\"errors\": validation_result.validation_errors}\n                )\n\n            # Step 2: Reserve inventory\n            inventory_result = await self.execute_activity_step(\n                ReserveInventoryActivity,\n                order.items,\n                step_name=\"reserve_inventory\",\n                timeout=timedelta(minutes=10)\n            )\n\n            # Step 3: Process payment\n            payment_request = PaymentProcessingRequest(\n                order_id=order.id,\n                amount=order.total_amount,\n                payment_method=order.payment_method,\n                payment_details=order.payment_details,\n                idempotency_key=f\"payment_{order.id}\"\n            )\n\n            payment_result = await self.execute_activity_step(\n                ProcessPaymentActivity,\n                payment_request,\n                step_name=\"process_payment\",\n                timeout=timedelta(minutes=15),\n                retry_policy=RetryPolicy(\n                    initial_interval=timedelta(seconds=2),\n                    maximum_interval=timedelta(minutes=1),\n                    maximum_attempts=3,\n                    non_retryable_error_types=[\"InsufficientFunds\", \"InvalidPaymentMethod\"]\n                )\n            )\n            result.payment_result = payment_result\n\n            if not payment_result.success:\n                # Payment failed - release inventory\n                await self._compensate_inventory_reservation(order.items)\n                result.status = OrderStatus.CANCELLED\n                raise ApplicationError(\n                    \"Payment processing failed\",\n                    type=\"PaymentError\",\n                    details={\"error\": payment_result.error_message}\n                )\n\n            # Step 4: Create shipping label\n            shipping_request = ShippingRequest(\n                order_id=order.id,\n                items=order.items,\n                shipping_address=order.shipping_address\n            )\n\n            shipping_result = await self.execute_activity_step(\n                self._create_shipping_label,\n                shipping_request,\n                step_name=\"create_shipping\",\n                timeout=timedelta(minutes=10)\n            )\n            result.shipping_result = shipping_result\n\n            # Step 5: Send confirmation notifications\n            await self.execute_activity_step(\n                self._send_order_confirmation,\n                {\n                    \"order_id\": order.id,\n                    \"customer_id\": order.customer_id,\n                    \"payment_result\": payment_result,\n                    \"shipping_result\": shipping_result\n                },\n                step_name=\"send_confirmation\",\n                timeout=timedelta(minutes=5)\n            )\n\n            # Mark order as confirmed\n            result.status = OrderStatus.CONFIRMED\n\n            # Calculate processing duration\n            execution_metrics = self.get_execution_metrics()\n            result.processing_duration_seconds = execution_metrics[\"execution_time_seconds\"]\n\n            workflow.logger.info(\n                \"Order processing completed successfully\",\n                order_id=order.id,\n                processing_time=result.processing_duration_seconds\n            )\n\n            return result\n\n        except Exception as e:\n            # Handle workflow failure\n            await self._handle_workflow_failure(order, result, e)\n            raise\n\n    async def _validate_order(self, request: OrderValidationRequest):\n        \"\"\"Validate order details\"\"\"\n        # This would be implemented as a separate activity\n        pass\n\n    async def _create_shipping_label(self, request: ShippingRequest):\n        \"\"\"Create shipping label\"\"\"\n        # This would be implemented as a separate activity\n        pass\n\n    async def _send_order_confirmation(self, data: dict):\n        \"\"\"Send order confirmation\"\"\"\n        # This would be implemented as a separate activity\n        pass\n\n    async def _compensate_inventory_reservation(self, items):\n        \"\"\"Release reserved inventory (compensation)\"\"\"\n        try:\n            await workflow.execute_activity(\n                self._release_inventory,\n                items,\n                start_to_close_timeout=timedelta(minutes=5)\n            )\n        except Exception as e:\n            workflow.logger.error(f\"Failed to release inventory: {e}\")\n\n    async def _release_inventory(self, items):\n        \"\"\"Release inventory activity\"\"\"\n        # This would be implemented as a separate activity\n        pass\n\n    async def _handle_workflow_failure(self, order: Order, result: OrderProcessingResult, error: Exception):\n        \"\"\"Handle workflow failure with proper cleanup\"\"\"\n        workflow.logger.error(\n            \"Order processing workflow failed\",\n            order_id=order.id,\n            error=str(error),\n            error_type=type(error).__name__\n        )\n\n        # Attempt to send failure notification\n        try:\n            await workflow.execute_activity(\n                self._send_failure_notification,\n                {\n                    \"order_id\": order.id,\n                    \"customer_id\": order.customer_id,\n                    \"error\": str(error)\n                },\n                start_to_close_timeout=timedelta(minutes=2)\n            )\n        except Exception as notification_error:\n            workflow.logger.error(f\"Failed to send failure notification: {notification_error}\")\n\n# Register the workflow\n@enterprise_workflow(\"order_processing\")\nclass OrderProcessingWorkflowRegistered(OrderProcessingWorkflow):\n    pass\n</code></pre>"},{"location":"development/python-sdk/#worker-configuration-and-startup","title":"Worker Configuration and Startup","text":""},{"location":"development/python-sdk/#worker-implementation","title":"Worker Implementation","text":"<pre><code># src/temporal_app/workers/main.py\nimport asyncio\nimport signal\nimport sys\nfrom contextlib import asynccontextmanager\nfrom typing import Optional\n\nimport click\nfrom temporalio.client import Client\nfrom temporalio.worker import Worker\n\nfrom ..activities.payment import ProcessPaymentActivity\nfrom ..activities.inventory import ReserveInventoryActivity\nfrom ..workflows.order_processing import OrderProcessingWorkflowRegistered\nfrom ..utils.config import get_settings\nfrom ..utils.logging import setup_logging\nfrom ..utils.metrics import setup_metrics\n\nclass TemporalWorker:\n    \"\"\"Enterprise Temporal worker with comprehensive configuration\"\"\"\n\n    def __init__(self, settings):\n        self.settings = settings\n        self.client: Optional[Client] = None\n        self.worker: Optional[Worker] = None\n        self.running = False\n\n    async def start(self):\n        \"\"\"Start the Temporal worker\"\"\"\n\n        # Setup logging and metrics\n        setup_logging(self.settings.log_level)\n        setup_metrics()\n\n        # Connect to Temporal server\n        self.client = await Client.connect(\n            self.settings.temporal_server_url,\n            namespace=self.settings.temporal_namespace,\n            tls=self.settings.temporal_tls_config if self.settings.temporal_tls_enabled else False\n        )\n\n        # Create worker\n        self.worker = Worker(\n            self.client,\n            task_queue=self.settings.task_queue,\n            workflows=[OrderProcessingWorkflowRegistered],\n            activities=[\n                ProcessPaymentActivity,\n                ReserveInventoryActivity,\n            ],\n            max_concurrent_activities=self.settings.max_concurrent_activities,\n            max_concurrent_workflows=self.settings.max_concurrent_workflows,\n            max_concurrent_local_activities=self.settings.max_concurrent_local_activities,\n        )\n\n        print(f\"Starting Temporal worker on task queue: {self.settings.task_queue}\")\n        print(f\"Connected to: {self.settings.temporal_server_url}\")\n        print(f\"Namespace: {self.settings.temporal_namespace}\")\n\n        # Start worker\n        self.running = True\n        await self.worker.run()\n\n    async def stop(self):\n        \"\"\"Stop the Temporal worker gracefully\"\"\"\n        if self.running and self.worker:\n            print(\"Shutting down Temporal worker...\")\n            self.running = False\n            await self.worker.shutdown()\n\n        if self.client:\n            await self.client.close()\n\n# Global worker instance\nworker_instance = None\n\nasync def create_worker():\n    \"\"\"Create and configure worker instance\"\"\"\n    settings = get_settings()\n    worker = TemporalWorker(settings)\n    return worker\n\ndef signal_handler(signum, frame):\n    \"\"\"Handle shutdown signals\"\"\"\n    print(f\"\\nReceived signal {signum}. Initiating graceful shutdown...\")\n    if worker_instance:\n        # Create a new event loop if needed\n        try:\n            loop = asyncio.get_event_loop()\n        except RuntimeError:\n            loop = asyncio.new_event_loop()\n            asyncio.set_event_loop(loop)\n\n        loop.run_until_complete(worker_instance.stop())\n    sys.exit(0)\n\n@click.command()\n@click.option('--task-queue', default='temporal-product-queue', help='Task queue name')\n@click.option('--log-level', default='INFO', help='Logging level')\n@click.option('--max-concurrent-activities', default=100, type=int, help='Max concurrent activities')\n@click.option('--max-concurrent-workflows', default=100, type=int, help='Max concurrent workflows')\ndef main(task_queue: str, log_level: str, max_concurrent_activities: int, max_concurrent_workflows: int):\n    \"\"\"Start the Temporal worker\"\"\"\n    global worker_instance\n\n    # Setup signal handlers\n    signal.signal(signal.SIGINT, signal_handler)\n    signal.signal(signal.SIGTERM, signal_handler)\n\n    async def run_worker():\n        global worker_instance\n\n        # Override settings with CLI arguments\n        settings = get_settings()\n        settings.task_queue = task_queue\n        settings.log_level = log_level\n        settings.max_concurrent_activities = max_concurrent_activities\n        settings.max_concurrent_workflows = max_concurrent_workflows\n\n        worker_instance = TemporalWorker(settings)\n\n        try:\n            await worker_instance.start()\n        except KeyboardInterrupt:\n            print(\"\\nReceived interrupt signal. Shutting down...\")\n        except Exception as e:\n            print(f\"Worker error: {e}\")\n            raise\n        finally:\n            if worker_instance:\n                await worker_instance.stop()\n\n    # Run the worker\n    asyncio.run(run_worker())\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"development/python-sdk/#configuration-management","title":"Configuration Management","text":""},{"location":"development/python-sdk/#settings-configuration","title":"Settings Configuration","text":"<pre><code># src/temporal_app/utils/config.py\nfrom functools import lru_cache\nfrom typing import Optional, Dict, Any\nfrom pydantic import BaseSettings, Field\n\nclass Settings(BaseSettings):\n    \"\"\"Application settings with environment variable support\"\"\"\n\n    # Temporal configuration\n    temporal_server_url: str = Field(default=\"localhost:7233\", env=\"TEMPORAL_SERVER_URL\")\n    temporal_namespace: str = Field(default=\"default\", env=\"TEMPORAL_NAMESPACE\")\n    temporal_tls_enabled: bool = Field(default=False, env=\"TEMPORAL_TLS_ENABLED\")\n    temporal_tls_config: Optional[Dict[str, Any]] = None\n\n    # Worker configuration\n    task_queue: str = Field(default=\"temporal-product-queue\", env=\"TASK_QUEUE\")\n    max_concurrent_activities: int = Field(default=100, env=\"MAX_CONCURRENT_ACTIVITIES\")\n    max_concurrent_workflows: int = Field(default=100, env=\"MAX_CONCURRENT_WORKFLOWS\")\n    max_concurrent_local_activities: int = Field(default=100, env=\"MAX_CONCURRENT_LOCAL_ACTIVITIES\")\n\n    # Database configuration\n    database_url: str = Field(..., env=\"DATABASE_URL\")\n    database_pool_size: int = Field(default=10, env=\"DATABASE_POOL_SIZE\")\n    database_max_overflow: int = Field(default=20, env=\"DATABASE_MAX_OVERFLOW\")\n\n    # External services\n    payment_processor_url: str = Field(..., env=\"PAYMENT_PROCESSOR_URL\")\n    payment_processor_api_key: str = Field(..., env=\"PAYMENT_PROCESSOR_API_KEY\")\n\n    # Logging configuration\n    log_level: str = Field(default=\"INFO\", env=\"LOG_LEVEL\")\n    log_format: str = Field(default=\"json\", env=\"LOG_FORMAT\")\n\n    # Metrics configuration\n    metrics_port: int = Field(default=8080, env=\"METRICS_PORT\")\n    metrics_enabled: bool = Field(default=True, env=\"METRICS_ENABLED\")\n\n    # Application configuration\n    environment: str = Field(default=\"development\", env=\"ENVIRONMENT\")\n    debug: bool = Field(default=False, env=\"DEBUG\")\n\n    class Config:\n        env_file = \".env\"\n        env_file_encoding = \"utf-8\"\n\n@lru_cache()\ndef get_settings() -&gt; Settings:\n    \"\"\"Get cached settings instance\"\"\"\n    return Settings()\n</code></pre> <p>This comprehensive Python SDK guide provides enterprise-ready patterns and practices for building robust Temporal applications with proper error handling, observability, and maintainability.</p>"},{"location":"development/testing/","title":"Testing","text":"<p>This document provides comprehensive testing strategies and implementation guidelines for Temporal.io workflows, activities, and FastAPI integrations in enterprise environments.</p>"},{"location":"development/testing/#overview","title":"Overview","text":"<p>Testing Temporal applications requires specialized approaches due to their distributed, asynchronous nature. This guide covers unit testing, integration testing, load testing, and end-to-end testing strategies using Temporal's testing framework and best practices.</p>"},{"location":"development/testing/#testing-framework-setup","title":"Testing Framework Setup","text":""},{"location":"development/testing/#dependencies","title":"Dependencies","text":"<pre><code># requirements-test.txt\npytest&gt;=7.0.0\npytest-asyncio&gt;=0.21.0\npytest-cov&gt;=4.0.0\npytest-mock&gt;=3.10.0\ntemporalio[testing]&gt;=1.0.0\nhttpx&gt;=0.24.0  # For FastAPI testing\nfactory-boy&gt;=3.2.0  # For test data generation\nfreezegun&gt;=1.2.0  # For time mocking\n</code></pre>"},{"location":"development/testing/#test-configuration","title":"Test Configuration","text":"<pre><code># tests/conftest.py\nimport asyncio\nimport pytest\nfrom temporalio.testing import WorkflowEnvironment\nfrom temporalio.worker import Worker\nfrom httpx import AsyncClient\n\nfrom src.temporal_workflows.workflows import OrderProcessingWorkflow\nfrom src.temporal_workflows.activities import PaymentActivity, InventoryActivity\nfrom src.temporal_api.main import app\n\n@pytest.fixture(scope=\"session\")\ndef event_loop():\n    \"\"\"Create event loop for async tests\"\"\"\n    policy = asyncio.get_event_loop_policy()\n    loop = policy.new_event_loop()\n    yield loop\n    loop.close()\n\n@pytest.fixture\nasync def temporal_env():\n    \"\"\"Create Temporal test environment\"\"\"\n    async with WorkflowEnvironment() as env:\n        yield env\n\n@pytest.fixture\nasync def temporal_worker(temporal_env):\n    \"\"\"Create Temporal worker for testing\"\"\"\n    async with Worker(\n        temporal_env.client,\n        task_queue=\"test-queue\",\n        workflows=[OrderProcessingWorkflow],\n        activities=[\n            PaymentActivity.process_payment,\n            InventoryActivity.reserve_inventory,\n            InventoryActivity.release_inventory,\n        ]\n    ):\n        yield\n\n@pytest.fixture\nasync def fastapi_client():\n    \"\"\"Create FastAPI test client\"\"\"\n    async with AsyncClient(app=app, base_url=\"http://test\") as client:\n        yield client\n\n@pytest.fixture\ndef sample_order_data():\n    \"\"\"Sample order data for testing\"\"\"\n    return {\n        \"id\": \"order-123\",\n        \"customer_id\": \"cust-456\",\n        \"items\": [\n            {\n                \"id\": \"item-1\",\n                \"name\": \"Test Product\",\n                \"sku\": \"TEST-001\",\n                \"quantity\": 2,\n                \"unit_price\": 50.00\n            }\n        ],\n        \"shipping_address\": {\n            \"street\": \"123 Test St\",\n            \"city\": \"Test City\",\n            \"state\": \"TS\",\n            \"zip_code\": \"12345\"\n        },\n        \"payment_method\": \"credit_card\",\n        \"payment_details\": {\"token\": \"test_token_123\"}\n    }\n</code></pre>"},{"location":"development/testing/#unit-testing-workflows","title":"Unit Testing Workflows","text":""},{"location":"development/testing/#workflow-testing","title":"Workflow Testing","text":"<pre><code># tests/test_workflows.py\nimport pytest\nfrom datetime import timedelta\nfrom temporalio.testing import WorkflowEnvironment\nfrom temporalio.common import RetryPolicy\n\nfrom src.temporal_workflows.workflows import OrderProcessingWorkflow\nfrom src.temporal_workflows.models import OrderData, OrderStatus\n\nclass TestOrderProcessingWorkflow:\n    \"\"\"Test cases for order processing workflow\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_successful_order_processing(self, temporal_env, sample_order_data):\n        \"\"\"Test successful order processing flow\"\"\"\n\n        async with Worker(\n            temporal_env.client,\n            task_queue=\"test-queue\",\n            workflows=[OrderProcessingWorkflow],\n            activities=[\n                # Mock activities that always succeed\n                self.mock_payment_success,\n                self.mock_inventory_success,\n                self.mock_shipping_success,\n            ]\n        ):\n            # Start workflow\n            handle = await temporal_env.client.start_workflow(\n                OrderProcessingWorkflow.run,\n                OrderData(**sample_order_data),\n                id=\"test-order-123\",\n                task_queue=\"test-queue\",\n                execution_timeout=timedelta(minutes=5)\n            )\n\n            # Wait for completion\n            result = await handle.result()\n\n            # Assertions\n            assert result.status == OrderStatus.COMPLETED\n            assert result.id == \"order-123\"\n            assert result.total_amount == 100.00\n\n    @pytest.mark.asyncio\n    async def test_payment_failure_rollback(self, temporal_env, sample_order_data):\n        \"\"\"Test rollback when payment fails\"\"\"\n\n        async with Worker(\n            temporal_env.client,\n            task_queue=\"test-queue\",\n            workflows=[OrderProcessingWorkflow],\n            activities=[\n                self.mock_payment_failure,  # Payment fails\n                self.mock_inventory_success,\n                self.mock_inventory_release,  # Should be called for rollback\n            ]\n        ):\n            handle = await temporal_env.client.start_workflow(\n                OrderProcessingWorkflow.run,\n                OrderData(**sample_order_data),\n                id=\"test-order-payment-fail\",\n                task_queue=\"test-queue\"\n            )\n\n            result = await handle.result()\n\n            assert result.status == OrderStatus.FAILED\n            assert \"payment_failed\" in result.failure_reason\n\n    @pytest.mark.asyncio\n    async def test_workflow_signals(self, temporal_env, sample_order_data):\n        \"\"\"Test workflow signal handling\"\"\"\n\n        async with Worker(\n            temporal_env.client,\n            task_queue=\"test-queue\",\n            workflows=[OrderProcessingWorkflow],\n            activities=[self.mock_long_running_activity]\n        ):\n            handle = await temporal_env.client.start_workflow(\n                OrderProcessingWorkflow.run,\n                OrderData(**sample_order_data),\n                id=\"test-order-signal\",\n                task_queue=\"test-queue\"\n            )\n\n            # Send cancel signal\n            await handle.signal(OrderProcessingWorkflow.cancel, {\"reason\": \"customer_request\"})\n\n            result = await handle.result()\n\n            assert result.status == OrderStatus.CANCELLED\n            assert result.cancellation_reason == \"customer_request\"\n\n    @pytest.mark.asyncio\n    async def test_workflow_queries(self, temporal_env, sample_order_data):\n        \"\"\"Test workflow query handling\"\"\"\n\n        async with Worker(\n            temporal_env.client,\n            task_queue=\"test-queue\",\n            workflows=[OrderProcessingWorkflow],\n            activities=[self.mock_slow_activity]\n        ):\n            handle = await temporal_env.client.start_workflow(\n                OrderProcessingWorkflow.run,\n                OrderData(**sample_order_data),\n                id=\"test-order-query\",\n                task_queue=\"test-queue\"\n            )\n\n            # Query workflow status\n            status = await handle.query(OrderProcessingWorkflow.get_status)\n\n            assert status[\"current_step\"] in [\"payment\", \"inventory\", \"shipping\"]\n            assert status[\"progress\"] &gt;= 0\n\n    # Mock activity implementations\n    async def mock_payment_success(self, payment_data):\n        return {\"status\": \"success\", \"transaction_id\": \"txn_123\"}\n\n    async def mock_payment_failure(self, payment_data):\n        raise Exception(\"Payment processing failed\")\n\n    async def mock_inventory_success(self, items):\n        return {\"status\": \"reserved\", \"reservation_id\": \"res_123\"}\n\n    async def mock_inventory_release(self, reservation_id):\n        return {\"status\": \"released\"}\n\n    async def mock_shipping_success(self, shipping_data):\n        return {\"status\": \"scheduled\", \"tracking_number\": \"TRK_123\"}\n\n    async def mock_long_running_activity(self, data):\n        # Simulate long-running activity for signal testing\n        await asyncio.sleep(10)\n        return {\"status\": \"completed\"}\n\n    async def mock_slow_activity(self, data):\n        # Simulate activity for query testing\n        await asyncio.sleep(2)\n        return {\"status\": \"completed\"}\n</code></pre>"},{"location":"development/testing/#unit-testing-activities","title":"Unit Testing Activities","text":""},{"location":"development/testing/#activity-testing","title":"Activity Testing","text":"<pre><code># tests/test_activities.py\nimport pytest\nfrom unittest.mock import AsyncMock, patch\nfrom decimal import Decimal\n\nfrom src.temporal_workflows.activities import PaymentActivity, InventoryActivity\n\nclass TestPaymentActivity:\n    \"\"\"Test cases for payment activities\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_process_payment_success(self):\n        \"\"\"Test successful payment processing\"\"\"\n\n        payment_data = {\n            \"amount\": Decimal(\"100.00\"),\n            \"currency\": \"USD\",\n            \"payment_method\": \"credit_card\",\n            \"customer_id\": \"cust_123\",\n            \"payment_details\": {\"token\": \"tok_123\"}\n        }\n\n        with patch('src.temporal_workflows.activities.PaymentClient') as mock_client:\n            mock_client.return_value.process_payment.return_value = {\n                \"status\": \"success\",\n                \"transaction_id\": \"txn_123456\",\n                \"amount_charged\": Decimal(\"100.00\")\n            }\n\n            result = await PaymentActivity.process_payment(payment_data)\n\n            assert result[\"status\"] == \"success\"\n            assert result[\"transaction_id\"] == \"txn_123456\"\n            assert result[\"amount_charged\"] == Decimal(\"100.00\")\n\n    @pytest.mark.asyncio\n    async def test_process_payment_insufficient_funds(self):\n        \"\"\"Test payment failure due to insufficient funds\"\"\"\n\n        payment_data = {\n            \"amount\": Decimal(\"1000.00\"),\n            \"currency\": \"USD\",\n            \"payment_method\": \"credit_card\",\n            \"customer_id\": \"cust_123\",\n            \"payment_details\": {\"token\": \"tok_invalid\"}\n        }\n\n        with patch('src.temporal_workflows.activities.PaymentClient') as mock_client:\n            mock_client.return_value.process_payment.side_effect = Exception(\"Insufficient funds\")\n\n            with pytest.raises(Exception) as exc_info:\n                await PaymentActivity.process_payment(payment_data)\n\n            assert \"Insufficient funds\" in str(exc_info.value)\n\n    @pytest.mark.asyncio\n    async def test_refund_payment(self):\n        \"\"\"Test payment refund\"\"\"\n\n        refund_data = {\n            \"transaction_id\": \"txn_123456\",\n            \"amount\": Decimal(\"50.00\"),\n            \"reason\": \"partial_refund\"\n        }\n\n        with patch('src.temporal_workflows.activities.PaymentClient') as mock_client:\n            mock_client.return_value.refund_payment.return_value = {\n                \"status\": \"success\",\n                \"refund_id\": \"ref_789\",\n                \"amount_refunded\": Decimal(\"50.00\")\n            }\n\n            result = await PaymentActivity.refund_payment(refund_data)\n\n            assert result[\"status\"] == \"success\"\n            assert result[\"refund_id\"] == \"ref_789\"\n\nclass TestInventoryActivity:\n    \"\"\"Test cases for inventory activities\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_reserve_inventory_success(self):\n        \"\"\"Test successful inventory reservation\"\"\"\n\n        items = [\n            {\"sku\": \"TEST-001\", \"quantity\": 2},\n            {\"sku\": \"TEST-002\", \"quantity\": 1}\n        ]\n\n        with patch('src.temporal_workflows.activities.InventoryClient') as mock_client:\n            mock_client.return_value.reserve_items.return_value = {\n                \"status\": \"success\",\n                \"reservation_id\": \"res_123\",\n                \"reserved_items\": items\n            }\n\n            result = await InventoryActivity.reserve_inventory(items)\n\n            assert result[\"status\"] == \"success\"\n            assert result[\"reservation_id\"] == \"res_123\"\n            assert len(result[\"reserved_items\"]) == 2\n\n    @pytest.mark.asyncio\n    async def test_reserve_inventory_insufficient_stock(self):\n        \"\"\"Test inventory reservation with insufficient stock\"\"\"\n\n        items = [{\"sku\": \"OUT-OF-STOCK\", \"quantity\": 10}]\n\n        with patch('src.temporal_workflows.activities.InventoryClient') as mock_client:\n            mock_client.return_value.reserve_items.side_effect = Exception(\"Insufficient stock\")\n\n            with pytest.raises(Exception) as exc_info:\n                await InventoryActivity.reserve_inventory(items)\n\n            assert \"Insufficient stock\" in str(exc_info.value)\n</code></pre>"},{"location":"development/testing/#integration-testing","title":"Integration Testing","text":""},{"location":"development/testing/#fastapi-integration-tests","title":"FastAPI Integration Tests","text":"<pre><code># tests/test_api_integration.py\nimport pytest\nfrom unittest.mock import AsyncMock, patch\nfrom httpx import AsyncClient\n\nfrom src.temporal_api.main import app\n\nclass TestOrderAPI:\n    \"\"\"Integration tests for order API endpoints\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_create_order_success(self, fastapi_client: AsyncClient):\n        \"\"\"Test successful order creation via API\"\"\"\n\n        order_request = {\n            \"customer_id\": \"cust_123\",\n            \"items\": [\n                {\n                    \"id\": \"item_1\",\n                    \"name\": \"Test Product\",\n                    \"sku\": \"TEST-001\",\n                    \"quantity\": 2,\n                    \"unit_price\": 29.99\n                }\n            ],\n            \"shipping_address\": {\n                \"street\": \"123 Test St\",\n                \"city\": \"Test City\",\n                \"state\": \"TS\",\n                \"zip_code\": \"12345\"\n            },\n            \"payment_method\": \"credit_card\",\n            \"payment_details\": {\"token\": \"tok_123\"}\n        }\n\n        with patch('src.temporal_api.services.temporal_client.TemporalClientService') as mock_service:\n            mock_handle = AsyncMock()\n            mock_handle.id = \"order-test-123\"\n            mock_service.return_value.start_workflow.return_value = mock_handle\n\n            response = await fastapi_client.post(\n                \"/api/v1/orders/\",\n                json=order_request,\n                headers={\"Authorization\": \"Bearer test-token\"}\n            )\n\n        assert response.status_code == 201\n        data = response.json()\n        assert data[\"customer_id\"] == \"cust_123\"\n        assert data[\"status\"] == \"PENDING\"\n        assert data[\"total_amount\"] == 59.98\n        assert data[\"workflow_id\"] == \"order-test-123\"\n\n    @pytest.mark.asyncio\n    async def test_get_order_status(self, fastapi_client: AsyncClient):\n        \"\"\"Test getting order status via API\"\"\"\n\n        with patch('src.temporal_api.services.temporal_client.TemporalClientService') as mock_service:\n            mock_service.return_value.get_workflow_status.return_value = {\n                \"workflow_id\": \"order-test-123\",\n                \"run_id\": \"run-456\",\n                \"status\": \"RUNNING\",\n                \"workflow_type\": \"order_processing\",\n                \"history_length\": 15\n            }\n\n            response = await fastapi_client.get(\n                \"/api/v1/orders/test-123\",\n                headers={\"Authorization\": \"Bearer test-token\"}\n            )\n\n        assert response.status_code == 200\n        data = response.json()\n        assert data[\"workflow_id\"] == \"order-test-123\"\n        assert data[\"status\"] == \"RUNNING\"\n\n    @pytest.mark.asyncio\n    async def test_cancel_order(self, fastapi_client: AsyncClient):\n        \"\"\"Test order cancellation via API\"\"\"\n\n        with patch('src.temporal_api.services.temporal_client.TemporalClientService') as mock_service:\n            mock_service.return_value.signal_workflow.return_value = None\n\n            response = await fastapi_client.post(\n                \"/api/v1/orders/test-123/cancel\",\n                headers={\"Authorization\": \"Bearer test-token\"}\n            )\n\n        assert response.status_code == 204\n\n    @pytest.mark.asyncio\n    async def test_unauthorized_request(self, fastapi_client: AsyncClient):\n        \"\"\"Test API request without authorization\"\"\"\n\n        response = await fastapi_client.get(\"/api/v1/orders/test-123\")\n        assert response.status_code == 401\n</code></pre>"},{"location":"development/testing/#load-testing","title":"Load Testing","text":""},{"location":"development/testing/#temporal-load-tests","title":"Temporal Load Tests","text":"<pre><code># tests/test_load.py\nimport asyncio\nimport pytest\nfrom concurrent.futures import ThreadPoolExecutor\nfrom temporalio.testing import WorkflowEnvironment\nfrom temporalio.worker import Worker\n\nfrom src.temporal_workflows.workflows import OrderProcessingWorkflow\n\nclass TestWorkflowLoad:\n    \"\"\"Load tests for workflow execution\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_concurrent_workflow_execution(self, temporal_env):\n        \"\"\"Test concurrent workflow execution under load\"\"\"\n\n        async with Worker(\n            temporal_env.client,\n            task_queue=\"load-test-queue\",\n            workflows=[OrderProcessingWorkflow],\n            activities=[self.mock_fast_activity]\n        ):\n            # Start multiple workflows concurrently\n            concurrent_workflows = 50\n            handles = []\n\n            for i in range(concurrent_workflows):\n                handle = await temporal_env.client.start_workflow(\n                    OrderProcessingWorkflow.run,\n                    {\"id\": f\"load-test-{i}\", \"items\": [{\"sku\": \"TEST\", \"quantity\": 1}]},\n                    id=f\"load-test-workflow-{i}\",\n                    task_queue=\"load-test-queue\"\n                )\n                handles.append(handle)\n\n            # Wait for all workflows to complete\n            results = await asyncio.gather(*[handle.result() for handle in handles])\n\n            # Verify all workflows completed successfully\n            assert len(results) == concurrent_workflows\n            for result in results:\n                assert result.status in [\"COMPLETED\", \"FAILED\"]  # Allow some failures under load\n\n    async def mock_fast_activity(self, data):\n        \"\"\"Fast mock activity for load testing\"\"\"\n        await asyncio.sleep(0.1)  # Simulate minimal processing time\n        return {\"status\": \"success\"}\n</code></pre>"},{"location":"development/testing/#api-load-tests-with-locust","title":"API Load Tests with Locust","text":"<pre><code># tests/locustfile.py\nfrom locust import HttpUser, task, between\nimport json\nimport random\n\nclass OrderAPIUser(HttpUser):\n    \"\"\"Load test user for Order API\"\"\"\n\n    wait_time = between(1, 3)\n\n    def on_start(self):\n        \"\"\"Setup test user\"\"\"\n        self.auth_header = {\"Authorization\": \"Bearer test-token\"}\n\n    @task(3)\n    def create_order(self):\n        \"\"\"Create new order - most common operation\"\"\"\n        order_data = {\n            \"customer_id\": f\"cust_{random.randint(1000, 9999)}\",\n            \"items\": [\n                {\n                    \"id\": f\"item_{random.randint(1, 100)}\",\n                    \"name\": \"Test Product\",\n                    \"sku\": f\"SKU-{random.randint(100, 999)}\",\n                    \"quantity\": random.randint(1, 5),\n                    \"unit_price\": round(random.uniform(10, 100), 2)\n                }\n            ],\n            \"shipping_address\": {\n                \"street\": \"123 Load Test St\",\n                \"city\": \"Test City\",\n                \"state\": \"TS\",\n                \"zip_code\": \"12345\"\n            },\n            \"payment_method\": \"credit_card\",\n            \"payment_details\": {\"token\": f\"tok_{random.randint(10000, 99999)}\"}\n        }\n\n        response = self.client.post(\n            \"/api/v1/orders/\",\n            json=order_data,\n            headers=self.auth_header\n        )\n\n        if response.status_code == 201:\n            # Store order ID for subsequent operations\n            order_data = response.json()\n            self.order_id = order_data[\"id\"]\n\n    @task(2)\n    def get_order_status(self):\n        \"\"\"Check order status\"\"\"\n        if hasattr(self, 'order_id'):\n            self.client.get(\n                f\"/api/v1/orders/{self.order_id}\",\n                headers=self.auth_header\n            )\n\n    @task(1)\n    def cancel_order(self):\n        \"\"\"Cancel order - less common operation\"\"\"\n        if hasattr(self, 'order_id'):\n            self.client.post(\n                f\"/api/v1/orders/{self.order_id}/cancel\",\n                headers=self.auth_header\n            )\n\n    @task(1)\n    def health_check(self):\n        \"\"\"Health check endpoint\"\"\"\n        self.client.get(\"/health\")\n</code></pre>"},{"location":"development/testing/#end-to-end-testing","title":"End-to-End Testing","text":""},{"location":"development/testing/#complete-workflow-tests","title":"Complete Workflow Tests","text":"<pre><code># tests/test_e2e.py\nimport pytest\nimport asyncio\nfrom datetime import timedelta\nfrom temporalio.testing import WorkflowEnvironment\nfrom temporalio.worker import Worker\n\nclass TestEndToEndFlow:\n    \"\"\"End-to-end tests for complete order processing flow\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_complete_order_lifecycle(self, temporal_env):\n        \"\"\"Test complete order processing from start to finish\"\"\"\n\n        # Setup real-like activities (with mocked external services)\n        async with Worker(\n            temporal_env.client,\n            task_queue=\"e2e-test-queue\",\n            workflows=[OrderProcessingWorkflow],\n            activities=[\n                self.realistic_payment_activity,\n                self.realistic_inventory_activity,\n                self.realistic_shipping_activity,\n            ]\n        ):\n            order_data = {\n                \"id\": \"e2e-order-123\",\n                \"customer_id\": \"e2e-customer-456\",\n                \"items\": [\n                    {\"sku\": \"E2E-PRODUCT-1\", \"quantity\": 2, \"unit_price\": 50.00},\n                    {\"sku\": \"E2E-PRODUCT-2\", \"quantity\": 1, \"unit_price\": 25.00}\n                ],\n                \"total_amount\": 125.00,\n                \"shipping_address\": {\n                    \"street\": \"123 E2E Test St\",\n                    \"city\": \"E2E City\",\n                    \"state\": \"E2E\",\n                    \"zip_code\": \"12345\"\n                },\n                \"payment_method\": \"credit_card\",\n                \"payment_details\": {\"token\": \"e2e_test_token\"}\n            }\n\n            # Start workflow\n            handle = await temporal_env.client.start_workflow(\n                OrderProcessingWorkflow.run,\n                order_data,\n                id=\"e2e-order-workflow-123\",\n                task_queue=\"e2e-test-queue\",\n                execution_timeout=timedelta(minutes=10)\n            )\n\n            # Monitor workflow progress\n            status_checks = 0\n            while status_checks &lt; 10:  # Maximum checks to prevent infinite loop\n                try:\n                    status = await handle.query(OrderProcessingWorkflow.get_status)\n                    print(f\"Workflow status: {status}\")\n\n                    if status.get(\"current_step\") == \"completed\":\n                        break\n\n                    await asyncio.sleep(1)\n                    status_checks += 1\n                except:\n                    # Workflow might not be ready for queries yet\n                    await asyncio.sleep(1)\n                    status_checks += 1\n\n            # Get final result\n            result = await handle.result()\n\n            # Verify end-to-end flow\n            assert result.status == \"COMPLETED\"\n            assert result.payment_transaction_id is not None\n            assert result.inventory_reservation_id is not None\n            assert result.shipping_tracking_number is not None\n            assert result.total_amount == 125.00\n\n    async def realistic_payment_activity(self, payment_data):\n        \"\"\"Realistic payment processing with delays\"\"\"\n        await asyncio.sleep(2)  # Simulate external API call\n        return {\n            \"status\": \"success\",\n            \"transaction_id\": f\"txn_{payment_data['customer_id']}_123\",\n            \"amount_charged\": payment_data[\"amount\"]\n        }\n\n    async def realistic_inventory_activity(self, items):\n        \"\"\"Realistic inventory processing with delays\"\"\"\n        await asyncio.sleep(1.5)  # Simulate database operations\n        return {\n            \"status\": \"reserved\",\n            \"reservation_id\": f\"res_{len(items)}_456\",\n            \"reserved_items\": items\n        }\n\n    async def realistic_shipping_activity(self, shipping_data):\n        \"\"\"Realistic shipping processing with delays\"\"\"\n        await asyncio.sleep(3)  # Simulate shipping partner API\n        return {\n            \"status\": \"scheduled\",\n            \"tracking_number\": f\"TRK{shipping_data['zip_code']}789\",\n            \"estimated_delivery\": \"2024-01-15\"\n        }\n</code></pre>"},{"location":"development/testing/#test-data-management","title":"Test Data Management","text":""},{"location":"development/testing/#test-factories","title":"Test Factories","text":"<pre><code># tests/factories.py\nimport factory\nfrom datetime import datetime, timedelta\nfrom decimal import Decimal\n\nclass OrderDataFactory(factory.Factory):\n    \"\"\"Factory for generating test order data\"\"\"\n\n    class Meta:\n        model = dict\n\n    id = factory.Sequence(lambda n: f\"order-{n}\")\n    customer_id = factory.Sequence(lambda n: f\"customer-{n}\")\n    total_amount = factory.LazyFunction(lambda: Decimal(str(factory.Faker('pydecimal', left_digits=3, right_digits=2).generate())))\n    created_at = factory.LazyFunction(datetime.utcnow)\n\n    @factory.lazy_attribute\n    def items(self):\n        return [\n            {\n                \"id\": factory.Faker('uuid4').generate(),\n                \"name\": factory.Faker('commerce_product_name').generate(),\n                \"sku\": factory.Faker('bothify', text='SKU-###').generate(),\n                \"quantity\": factory.Faker('random_int', min=1, max=5).generate(),\n                \"unit_price\": float(factory.Faker('pydecimal', left_digits=2, right_digits=2).generate())\n            }\n            for _ in range(factory.Faker('random_int', min=1, max=3).generate())\n        ]\n\n    shipping_address = factory.SubFactory('tests.factories.AddressFactory')\n    payment_method = \"credit_card\"\n    payment_details = {\"token\": factory.Faker('uuid4')}\n\nclass AddressFactory(factory.Factory):\n    \"\"\"Factory for generating test addresses\"\"\"\n\n    class Meta:\n        model = dict\n\n    street = factory.Faker('street_address')\n    city = factory.Faker('city')\n    state = factory.Faker('state_abbr')\n    zip_code = factory.Faker('zipcode')\n</code></pre>"},{"location":"development/testing/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"development/testing/#github-actions-test-configuration","title":"GitHub Actions Test Configuration","text":"<pre><code># .github/workflows/test.yml\nname: Test Suite\n\non:\n  push:\n    branches: [ main, develop ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  unit-tests:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [3.9, 3.10, 3.11]\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Set up Python ${{ matrix.python-version }}\n      uses: actions/setup-python@v4\n      with:\n        python-version: ${{ matrix.python-version }}\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n        pip install -r requirements-test.txt\n\n    - name: Run unit tests\n      run: |\n        pytest tests/test_workflows.py tests/test_activities.py -v --cov=src --cov-report=xml\n\n    - name: Upload coverage to Codecov\n      uses: codecov/codecov-action@v3\n      with:\n        file: ./coverage.xml\n\n  integration-tests:\n    runs-on: ubuntu-latest\n    needs: unit-tests\n\n    services:\n      temporal:\n        image: temporalio/auto-setup:1.20.0\n        ports:\n          - 7233:7233\n        env:\n          - DB=postgresql\n          - DB_PORT=5432\n          - POSTGRES_USER=temporal\n          - POSTGRES_PWD=temporal\n          - POSTGRES_SEEDS=postgres\n\n      postgres:\n        image: postgres:13\n        ports:\n          - 5432:5432\n        env:\n          POSTGRES_PASSWORD: temporal\n          POSTGRES_USER: temporal\n          POSTGRES_DB: temporal\n        options: &gt;-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: 3.11\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install -r requirements.txt\n        pip install -r requirements-test.txt\n\n    - name: Wait for Temporal to be ready\n      run: |\n        sleep 30\n        curl -f http://localhost:7233/ || exit 1\n\n    - name: Run integration tests\n      run: |\n        pytest tests/test_api_integration.py tests/test_e2e.py -v\n      env:\n        TEMPORAL_SERVER_URL: localhost:7233\n        TEMPORAL_NAMESPACE: default\n\n  load-tests:\n    runs-on: ubuntu-latest\n    if: github.event_name == 'push' &amp;&amp; github.ref == 'refs/heads/main'\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: 3.11\n\n    - name: Install dependencies\n      run: |\n        pip install locust\n\n    - name: Run load tests\n      run: |\n        locust -f tests/locustfile.py --headless -u 10 -r 2 -t 60s --host http://localhost:8000\n</code></pre> <p>This comprehensive testing guide provides robust strategies for testing Temporal workflows, activities, and FastAPI integrations across unit, integration, load, and end-to-end testing scenarios.</p>"},{"location":"development/workflow-development/","title":"Workflow Development","text":"<p>This document provides comprehensive guidance for developing workflows in the Temporal.io enterprise environment, covering best practices, patterns, and advanced techniques for building robust and scalable workflow applications.</p>"},{"location":"development/workflow-development/#overview","title":"Overview","text":"<p>Temporal workflows are the core building blocks for orchestrating business processes. This guide covers the complete workflow development lifecycle from design to deployment, with enterprise-specific considerations for reliability, observability, and maintainability.</p>"},{"location":"development/workflow-development/#workflow-fundamentals","title":"Workflow Fundamentals","text":""},{"location":"development/workflow-development/#core-concepts","title":"Core Concepts","text":"<pre><code>graph TB\n    subgraph \"Workflow Components\"\n        A[Workflow Definition]\n        B[Activity Functions]\n        C[Signals &amp; Queries]\n        D[Timers &amp; Sleep]\n        E[Child Workflows]\n    end\n\n    subgraph \"Execution Context\"\n        F[Workflow Context]\n        G[Activity Context]\n        H[Task Queue]\n        I[Namespace]\n    end\n\n    subgraph \"State Management\"\n        J[Event History]\n        K[Deterministic Execution]\n        L[State Persistence]\n        M[Replay Safety]\n    end\n\n    A --&gt; F\n    B --&gt; G\n    F --&gt; H\n    G --&gt; H\n    F --&gt; J\n    J --&gt; K\n    K --&gt; L\n    L --&gt; M</code></pre>"},{"location":"development/workflow-development/#workflow-design-principles","title":"Workflow Design Principles","text":""},{"location":"development/workflow-development/#1-deterministic-execution","title":"1. Deterministic Execution","text":"<pre><code># \u274c Non-deterministic - Don't do this\n@workflow.defn\nclass BadWorkflow:\n    @workflow.run\n    async def run(self) -&gt; str:\n        import random\n        import datetime\n\n        # Non-deterministic operations\n        random_value = random.random()  # \u274c Non-deterministic\n        current_time = datetime.datetime.now()  # \u274c Non-deterministic\n\n        return f\"Value: {random_value}, Time: {current_time}\"\n\n# \u2705 Deterministic - Correct approach\n@workflow.defn\nclass GoodWorkflow:\n    @workflow.run\n    async def run(self) -&gt; str:\n        # Use workflow time\n        current_time = workflow.now()\n\n        # Use activity for random values\n        random_value = await workflow.execute_activity(\n            generate_random_value,\n            start_to_close_timeout=timedelta(seconds=30)\n        )\n\n        return f\"Value: {random_value}, Time: {current_time}\"\n\n@activity.defn\nasync def generate_random_value() -&gt; float:\n    import random\n    return random.random()\n</code></pre>"},{"location":"development/workflow-development/#2-idempotent-operations","title":"2. Idempotent Operations","text":"<pre><code>@workflow.defn\nclass IdempotentWorkflow:\n    def __init__(self) -&gt; None:\n        self._completed_steps: Set[str] = set()\n\n    @workflow.run\n    async def run(self, order_id: str) -&gt; OrderResult:\n        result = OrderResult(order_id=order_id)\n\n        # Step 1: Validate order (idempotent)\n        if \"validate\" not in self._completed_steps:\n            result.validation = await workflow.execute_activity(\n                validate_order,\n                order_id,\n                start_to_close_timeout=timedelta(minutes=5),\n                retry_policy=RetryPolicy(\n                    initial_interval=timedelta(seconds=1),\n                    maximum_interval=timedelta(seconds=60),\n                    maximum_attempts=3\n                )\n            )\n            self._completed_steps.add(\"validate\")\n\n        # Step 2: Process payment (idempotent)\n        if \"payment\" not in self._completed_steps:\n            result.payment = await workflow.execute_activity(\n                process_payment,\n                ProcessPaymentRequest(\n                    order_id=order_id,\n                    amount=result.validation.amount,\n                    idempotency_key=f\"payment-{order_id}\"\n                ),\n                start_to_close_timeout=timedelta(minutes=10),\n                retry_policy=RetryPolicy(\n                    initial_interval=timedelta(seconds=2),\n                    maximum_interval=timedelta(minutes=1),\n                    maximum_attempts=5\n                )\n            )\n            self._completed_steps.add(\"payment\")\n\n        return result\n</code></pre>"},{"location":"development/workflow-development/#workflow-patterns","title":"Workflow Patterns","text":""},{"location":"development/workflow-development/#1-sequential-processing-pattern","title":"1. Sequential Processing Pattern","text":"<pre><code>@workflow.defn\nclass SequentialProcessingWorkflow:\n    @workflow.run\n    async def run(self, request: ProcessingRequest) -&gt; ProcessingResult:\n        result = ProcessingResult(request_id=request.id)\n\n        # Step 1: Data validation\n        validation_result = await workflow.execute_activity(\n            validate_data,\n            request.data,\n            start_to_close_timeout=timedelta(minutes=5)\n        )\n        result.validation = validation_result\n\n        # Step 2: Data transformation (depends on validation)\n        if validation_result.is_valid:\n            transformation_result = await workflow.execute_activity(\n                transform_data,\n                TransformationRequest(\n                    data=request.data,\n                    rules=validation_result.transformation_rules\n                ),\n                start_to_close_timeout=timedelta(minutes=15)\n            )\n            result.transformation = transformation_result\n\n            # Step 3: Data storage (depends on transformation)\n            storage_result = await workflow.execute_activity(\n                store_data,\n                StorageRequest(\n                    transformed_data=transformation_result.data,\n                    metadata=transformation_result.metadata\n                ),\n                start_to_close_timeout=timedelta(minutes=10)\n            )\n            result.storage = storage_result\n\n        return result\n</code></pre>"},{"location":"development/workflow-development/#2-parallel-processing-pattern","title":"2. Parallel Processing Pattern","text":"<pre><code>@workflow.defn\nclass ParallelProcessingWorkflow:\n    @workflow.run\n    async def run(self, batch_request: BatchRequest) -&gt; BatchResult:\n        # Process items in parallel\n        tasks = []\n        for item in batch_request.items:\n            task = workflow.execute_activity(\n                process_item,\n                item,\n                start_to_close_timeout=timedelta(minutes=10),\n                task_queue=\"processing-queue\"\n            )\n            tasks.append(task)\n\n        # Wait for all tasks to complete\n        results = await asyncio.gather(*tasks, return_exceptions=True)\n\n        # Process results\n        successful_results = []\n        failed_results = []\n\n        for i, result in enumerate(results):\n            if isinstance(result, Exception):\n                failed_results.append({\n                    'item_id': batch_request.items[i].id,\n                    'error': str(result)\n                })\n            else:\n                successful_results.append(result)\n\n        return BatchResult(\n            successful=successful_results,\n            failed=failed_results,\n            total_processed=len(results)\n        )\n</code></pre>"},{"location":"development/workflow-development/#3-saga-pattern-distributed-transactions","title":"3. Saga Pattern (Distributed Transactions)","text":"<pre><code>@workflow.defn\nclass SagaWorkflow:\n    def __init__(self) -&gt; None:\n        self._compensations: List[Callable] = []\n\n    @workflow.run\n    async def run(self, order: Order) -&gt; OrderResult:\n        try:\n            # Step 1: Reserve inventory\n            inventory_reservation = await self._reserve_inventory(order)\n\n            # Step 2: Process payment\n            payment_result = await self._process_payment(order, inventory_reservation)\n\n            # Step 3: Ship order\n            shipping_result = await self._ship_order(order, payment_result)\n\n            return OrderResult(\n                order_id=order.id,\n                status=\"completed\",\n                inventory_reservation=inventory_reservation,\n                payment=payment_result,\n                shipping=shipping_result\n            )\n\n        except Exception as e:\n            # Execute compensations in reverse order\n            await self._execute_compensations()\n            raise\n\n    async def _reserve_inventory(self, order: Order) -&gt; InventoryReservation:\n        reservation = await workflow.execute_activity(\n            reserve_inventory,\n            order.items,\n            start_to_close_timeout=timedelta(minutes=5)\n        )\n\n        # Add compensation\n        self._compensations.append(\n            lambda: workflow.execute_activity(\n                release_inventory,\n                reservation.reservation_id,\n                start_to_close_timeout=timedelta(minutes=5)\n            )\n        )\n\n        return reservation\n\n    async def _process_payment(self, order: Order, inventory: InventoryReservation) -&gt; PaymentResult:\n        payment = await workflow.execute_activity(\n            charge_payment,\n            PaymentRequest(\n                order_id=order.id,\n                amount=order.total_amount,\n                payment_method=order.payment_method\n            ),\n            start_to_close_timeout=timedelta(minutes=10)\n        )\n\n        # Add compensation\n        self._compensations.append(\n            lambda: workflow.execute_activity(\n                refund_payment,\n                payment.transaction_id,\n                start_to_close_timeout=timedelta(minutes=10)\n            )\n        )\n\n        return payment\n\n    async def _ship_order(self, order: Order, payment: PaymentResult) -&gt; ShippingResult:\n        return await workflow.execute_activity(\n            ship_order,\n            ShippingRequest(\n                order_id=order.id,\n                address=order.shipping_address,\n                items=order.items\n            ),\n            start_to_close_timeout=timedelta(hours=24)\n        )\n\n    async def _execute_compensations(self):\n        \"\"\"Execute compensations in reverse order\"\"\"\n        for compensation in reversed(self._compensations):\n            try:\n                await compensation()\n            except Exception as e:\n                workflow.logger.error(f\"Compensation failed: {e}\")\n</code></pre>"},{"location":"development/workflow-development/#4-long-running-process-with-signals","title":"4. Long-Running Process with Signals","text":"<pre><code>@workflow.defn\nclass LongRunningProcessWorkflow:\n    def __init__(self) -&gt; None:\n        self._status = \"initialized\"\n        self._pause_requested = False\n        self._cancel_requested = False\n        self._progress = 0\n\n    @workflow.run\n    async def run(self, config: ProcessConfig) -&gt; ProcessResult:\n        self._status = \"running\"\n\n        try:\n            for i in range(config.total_steps):\n                # Check for pause/cancel signals\n                if self._cancel_requested:\n                    self._status = \"cancelled\"\n                    return ProcessResult(status=\"cancelled\", progress=self._progress)\n\n                while self._pause_requested:\n                    self._status = \"paused\"\n                    await workflow.wait_condition(lambda: not self._pause_requested)\n                    self._status = \"running\"\n\n                # Execute processing step\n                step_result = await workflow.execute_activity(\n                    process_step,\n                    ProcessStepRequest(\n                        step_number=i + 1,\n                        config=config.step_configs[i]\n                    ),\n                    start_to_close_timeout=timedelta(minutes=30)\n                )\n\n                self._progress = ((i + 1) / config.total_steps) * 100\n\n                # Optional: Wait between steps\n                if config.step_delay_seconds &gt; 0:\n                    await asyncio.sleep(config.step_delay_seconds)\n\n            self._status = \"completed\"\n            return ProcessResult(status=\"completed\", progress=100)\n\n        except Exception as e:\n            self._status = \"failed\"\n            raise\n\n    @workflow.signal\n    async def pause(self) -&gt; None:\n        \"\"\"Pause the workflow\"\"\"\n        self._pause_requested = True\n\n    @workflow.signal\n    async def resume(self) -&gt; None:\n        \"\"\"Resume the workflow\"\"\"\n        self._pause_requested = False\n\n    @workflow.signal\n    async def cancel(self) -&gt; None:\n        \"\"\"Cancel the workflow\"\"\"\n        self._cancel_requested = True\n\n    @workflow.query\n    def get_status(self) -&gt; Dict[str, Any]:\n        \"\"\"Get current workflow status\"\"\"\n        return {\n            \"status\": self._status,\n            \"progress\": self._progress,\n            \"paused\": self._pause_requested,\n            \"cancel_requested\": self._cancel_requested\n        }\n</code></pre>"},{"location":"development/workflow-development/#advanced-workflow-techniques","title":"Advanced Workflow Techniques","text":""},{"location":"development/workflow-development/#1-dynamic-workflows","title":"1. Dynamic Workflows","text":"<pre><code>@workflow.defn\nclass DynamicWorkflow:\n    @workflow.run\n    async def run(self, workflow_config: WorkflowConfig) -&gt; WorkflowResult:\n        \"\"\"Execute a dynamically configured workflow\"\"\"\n\n        # Parse workflow definition\n        steps = self._parse_workflow_definition(workflow_config.definition)\n\n        # Execute steps based on configuration\n        results = {}\n        for step in steps:\n            if step.type == \"activity\":\n                result = await self._execute_activity_step(step)\n            elif step.type == \"parallel\":\n                result = await self._execute_parallel_step(step)\n            elif step.type == \"conditional\":\n                result = await self._execute_conditional_step(step, results)\n            elif step.type == \"loop\":\n                result = await self._execute_loop_step(step, results)\n            else:\n                raise ValueError(f\"Unknown step type: {step.type}\")\n\n            results[step.name] = result\n\n            # Check if we should continue based on step result\n            if not self._should_continue(step, result):\n                break\n\n        return WorkflowResult(\n            success=True,\n            results=results,\n            workflow_id=workflow_config.id\n        )\n\n    async def _execute_activity_step(self, step: WorkflowStep) -&gt; Any:\n        \"\"\"Execute a single activity step\"\"\"\n        activity_func = self._get_activity_function(step.activity_name)\n\n        return await workflow.execute_activity(\n            activity_func,\n            step.parameters,\n            start_to_close_timeout=timedelta(seconds=step.timeout_seconds),\n            retry_policy=RetryPolicy(\n                maximum_attempts=step.max_retries,\n                initial_interval=timedelta(seconds=step.retry_interval_seconds)\n            )\n        )\n\n    async def _execute_parallel_step(self, step: WorkflowStep) -&gt; List[Any]:\n        \"\"\"Execute multiple activities in parallel\"\"\"\n        tasks = []\n        for sub_step in step.parallel_steps:\n            task = self._execute_activity_step(sub_step)\n            tasks.append(task)\n\n        return await asyncio.gather(*tasks)\n\n    async def _execute_conditional_step(self, step: WorkflowStep, previous_results: Dict) -&gt; Any:\n        \"\"\"Execute conditional logic\"\"\"\n        condition_result = self._evaluate_condition(step.condition, previous_results)\n\n        if condition_result:\n            return await self._execute_activity_step(step.if_step)\n        elif step.else_step:\n            return await self._execute_activity_step(step.else_step)\n\n        return None\n</code></pre>"},{"location":"development/workflow-development/#2-workflow-versioning","title":"2. Workflow Versioning","text":"<pre><code>from temporalio import workflow\nfrom temporalio.common import SearchAttributeKey\n\n# Version 1 of the workflow\n@workflow.defn\nclass OrderProcessingWorkflow:\n    @workflow.run\n    async def run(self, order: Order) -&gt; OrderResult:\n        version = workflow.patched(\"order-processing-v2\")\n\n        if version:\n            # New version logic\n            return await self._run_v2(order)\n        else:\n            # Legacy version logic\n            return await self._run_v1(order)\n\n    async def _run_v1(self, order: Order) -&gt; OrderResult:\n        \"\"\"Legacy workflow implementation\"\"\"\n        # Validate order\n        validation = await workflow.execute_activity(\n            validate_order_v1,\n            order,\n            start_to_close_timeout=timedelta(minutes=5)\n        )\n\n        # Process payment\n        payment = await workflow.execute_activity(\n            process_payment_v1,\n            order.payment_info,\n            start_to_close_timeout=timedelta(minutes=10)\n        )\n\n        return OrderResult(validation=validation, payment=payment)\n\n    async def _run_v2(self, order: Order) -&gt; OrderResult:\n        \"\"\"New workflow implementation with additional features\"\"\"\n        # Enhanced validation with fraud detection\n        validation = await workflow.execute_activity(\n            validate_order_v2,\n            order,\n            start_to_close_timeout=timedelta(minutes=5)\n        )\n\n        # Fraud check (new in v2)\n        fraud_check = await workflow.execute_activity(\n            fraud_detection,\n            FraudCheckRequest(\n                order_id=order.id,\n                customer_id=order.customer_id,\n                amount=order.total_amount\n            ),\n            start_to_close_timeout=timedelta(minutes=2)\n        )\n\n        if fraud_check.is_suspicious:\n            # Manual review process (new in v2)\n            await workflow.execute_activity(\n                trigger_manual_review,\n                ManualReviewRequest(\n                    order_id=order.id,\n                    fraud_score=fraud_check.score,\n                    reason=fraud_check.reason\n                ),\n                start_to_close_timeout=timedelta(hours=24)\n            )\n\n        # Enhanced payment processing\n        payment = await workflow.execute_activity(\n            process_payment_v2,\n            PaymentRequestV2(\n                order=order,\n                fraud_score=fraud_check.score\n            ),\n            start_to_close_timeout=timedelta(minutes=10)\n        )\n\n        return OrderResult(\n            validation=validation,\n            fraud_check=fraud_check,\n            payment=payment\n        )\n</code></pre>"},{"location":"development/workflow-development/#3-child-workflows","title":"3. Child Workflows","text":"<pre><code>@workflow.defn\nclass ParentWorkflow:\n    @workflow.run\n    async def run(self, batch_request: BatchProcessingRequest) -&gt; BatchResult:\n        \"\"\"Parent workflow that spawns child workflows for each item\"\"\"\n\n        # Start child workflows for each item\n        child_handles = []\n        for item in batch_request.items:\n            handle = await workflow.start_child_workflow(\n                ItemProcessingWorkflow.run,\n                item,\n                id=f\"item-processing-{item.id}\",\n                task_queue=\"item-processing-queue\",\n                execution_timeout=timedelta(hours=2)\n            )\n            child_handles.append((item.id, handle))\n\n        # Collect results from child workflows\n        results = []\n        failed_items = []\n\n        for item_id, handle in child_handles:\n            try:\n                result = await handle\n                results.append(result)\n            except Exception as e:\n                failed_items.append({\n                    'item_id': item_id,\n                    'error': str(e)\n                })\n\n        # Generate summary report\n        summary = await workflow.execute_activity(\n            generate_batch_summary,\n            BatchSummaryRequest(\n                total_items=len(batch_request.items),\n                successful_items=len(results),\n                failed_items=len(failed_items),\n                results=results\n            ),\n            start_to_close_timeout=timedelta(minutes=5)\n        )\n\n        return BatchResult(\n            summary=summary,\n            successful_results=results,\n            failed_items=failed_items\n        )\n\n@workflow.defn\nclass ItemProcessingWorkflow:\n    @workflow.run\n    async def run(self, item: ProcessingItem) -&gt; ItemResult:\n        \"\"\"Child workflow for processing individual items\"\"\"\n\n        # Validate item\n        validation = await workflow.execute_activity(\n            validate_item,\n            item,\n            start_to_close_timeout=timedelta(minutes=2)\n        )\n\n        if not validation.is_valid:\n            raise ApplicationError(\n                f\"Item validation failed: {validation.error_message}\",\n                type=\"ValidationError\"\n            )\n\n        # Process item\n        processing_result = await workflow.execute_activity(\n            process_item_data,\n            ProcessingRequest(\n                item=item,\n                validation_context=validation.context\n            ),\n            start_to_close_timeout=timedelta(minutes=30)\n        )\n\n        # Store result\n        storage_result = await workflow.execute_activity(\n            store_processed_item,\n            StorageRequest(\n                item_id=item.id,\n                processed_data=processing_result.data,\n                metadata=processing_result.metadata\n            ),\n            start_to_close_timeout=timedelta(minutes=5)\n        )\n\n        return ItemResult(\n            item_id=item.id,\n            processing_result=processing_result,\n            storage_result=storage_result\n        )\n</code></pre>"},{"location":"development/workflow-development/#error-handling-and-resilience","title":"Error Handling and Resilience","text":""},{"location":"development/workflow-development/#1-comprehensive-error-handling","title":"1. Comprehensive Error Handling","text":"<pre><code>from temporalio.exceptions import ApplicationError, ActivityError, ChildWorkflowError\n\n@workflow.defn\nclass ResilientWorkflow:\n    @workflow.run\n    async def run(self, request: ProcessingRequest) -&gt; ProcessingResult:\n        try:\n            # Critical operation with custom retry policy\n            result = await workflow.execute_activity(\n                critical_operation,\n                request.data,\n                start_to_close_timeout=timedelta(minutes=10),\n                retry_policy=RetryPolicy(\n                    initial_interval=timedelta(seconds=1),\n                    maximum_interval=timedelta(minutes=2),\n                    maximum_attempts=5,\n                    non_retryable_error_types=[\"ValidationError\", \"AuthenticationError\"]\n                )\n            )\n\n            return ProcessingResult(success=True, data=result)\n\n        except ActivityError as e:\n            # Handle activity-specific errors\n            if e.cause and isinstance(e.cause, ApplicationError):\n                if e.cause.type == \"ValidationError\":\n                    # Handle validation errors\n                    await self._handle_validation_error(request, e.cause)\n                elif e.cause.type == \"BusinessLogicError\":\n                    # Handle business logic errors\n                    await self._handle_business_error(request, e.cause)\n                else:\n                    # Handle unknown application errors\n                    await self._handle_unknown_error(request, e.cause)\n            else:\n                # Handle system errors (timeouts, network issues, etc.)\n                await self._handle_system_error(request, e)\n\n            raise  # Re-raise to fail the workflow\n\n        except ChildWorkflowError as e:\n            # Handle child workflow errors\n            workflow.logger.error(f\"Child workflow failed: {e}\")\n            await self._handle_child_workflow_error(request, e)\n            raise\n\n        except Exception as e:\n            # Handle unexpected errors\n            workflow.logger.error(f\"Unexpected error: {e}\")\n            await self._handle_unexpected_error(request, e)\n            raise\n\n    async def _handle_validation_error(self, request: ProcessingRequest, error: ApplicationError):\n        \"\"\"Handle validation errors with notification\"\"\"\n        await workflow.execute_activity(\n            send_validation_error_notification,\n            ValidationErrorNotification(\n                request_id=request.id,\n                error_message=error.message,\n                error_details=error.details\n            ),\n            start_to_close_timeout=timedelta(minutes=2)\n        )\n\n    async def _handle_business_error(self, request: ProcessingRequest, error: ApplicationError):\n        \"\"\"Handle business logic errors with escalation\"\"\"\n        await workflow.execute_activity(\n            escalate_business_error,\n            BusinessErrorEscalation(\n                request_id=request.id,\n                error_type=error.type,\n                error_message=error.message,\n                escalation_level=\"high\"\n            ),\n            start_to_close_timeout=timedelta(minutes=5)\n        )\n\n    async def _handle_system_error(self, request: ProcessingRequest, error: ActivityError):\n        \"\"\"Handle system errors with monitoring\"\"\"\n        await workflow.execute_activity(\n            log_system_error,\n            SystemErrorLog(\n                request_id=request.id,\n                error_type=\"system_error\",\n                error_message=str(error),\n                timestamp=workflow.now()\n            ),\n            start_to_close_timeout=timedelta(minutes=1)\n        )\n</code></pre>"},{"location":"development/workflow-development/#2-circuit-breaker-pattern","title":"2. Circuit Breaker Pattern","text":"<pre><code>@workflow.defn\nclass CircuitBreakerWorkflow:\n    def __init__(self) -&gt; None:\n        self._failure_count = 0\n        self._last_failure_time = None\n        self._circuit_open = False\n        self._circuit_timeout = timedelta(minutes=5)\n\n    @workflow.run\n    async def run(self, requests: List[ExternalAPIRequest]) -&gt; List[APIResponse]:\n        results = []\n\n        for request in requests:\n            if self._is_circuit_open():\n                # Circuit is open, skip external calls\n                results.append(APIResponse(\n                    request_id=request.id,\n                    success=False,\n                    error=\"Circuit breaker is open\"\n                ))\n                continue\n\n            try:\n                # Attempt external API call\n                response = await workflow.execute_activity(\n                    call_external_api,\n                    request,\n                    start_to_close_timeout=timedelta(seconds=30),\n                    retry_policy=RetryPolicy(maximum_attempts=1)  # No retries\n                )\n\n                # Success - reset failure count\n                self._failure_count = 0\n                self._circuit_open = False\n                results.append(response)\n\n            except Exception as e:\n                # Failure - increment counter and potentially open circuit\n                self._failure_count += 1\n                self._last_failure_time = workflow.now()\n\n                if self._failure_count &gt;= 5:  # Threshold\n                    self._circuit_open = True\n                    workflow.logger.warning(\"Circuit breaker opened due to failures\")\n\n                results.append(APIResponse(\n                    request_id=request.id,\n                    success=False,\n                    error=str(e)\n                ))\n\n        return results\n\n    def _is_circuit_open(self) -&gt; bool:\n        \"\"\"Check if circuit breaker should remain open\"\"\"\n        if not self._circuit_open:\n            return False\n\n        if self._last_failure_time is None:\n            return False\n\n        # Check if timeout has elapsed\n        time_since_failure = workflow.now() - self._last_failure_time\n        if time_since_failure &gt; self._circuit_timeout:\n            self._circuit_open = False\n            self._failure_count = 0\n            workflow.logger.info(\"Circuit breaker reset after timeout\")\n            return False\n\n        return True\n</code></pre>"},{"location":"development/workflow-development/#workflow-testing-and-debugging","title":"Workflow Testing and Debugging","text":""},{"location":"development/workflow-development/#1-unit-testing-workflows","title":"1. Unit Testing Workflows","text":"<pre><code>import pytest\nfrom temporalio.testing import WorkflowEnvironment\nfrom temporalio.worker import Worker\n\n@pytest.mark.asyncio\nasync def test_order_processing_workflow():\n    \"\"\"Test order processing workflow with mocked activities\"\"\"\n\n    # Create test environment\n    async with WorkflowEnvironment() as env:\n        # Mock activities\n        async def mock_validate_order(order: Order) -&gt; ValidationResult:\n            return ValidationResult(is_valid=True, amount=order.total_amount)\n\n        async def mock_process_payment(request: ProcessPaymentRequest) -&gt; PaymentResult:\n            return PaymentResult(\n                transaction_id=\"test-txn-123\",\n                success=True,\n                amount=request.amount\n            )\n\n        # Create worker with mocked activities\n        worker = Worker(\n            env.client,\n            task_queue=\"test-queue\",\n            workflows=[OrderProcessingWorkflow],\n            activities=[mock_validate_order, mock_process_payment]\n        )\n\n        # Start worker\n        async with worker:\n            # Execute workflow\n            result = await env.client.execute_workflow(\n                OrderProcessingWorkflow.run,\n                Order(\n                    id=\"test-order-123\",\n                    customer_id=\"test-customer\",\n                    total_amount=100.0,\n                    items=[OrderItem(id=\"item1\", quantity=2, price=50.0)]\n                ),\n                id=\"test-workflow-123\",\n                task_queue=\"test-queue\"\n            )\n\n            # Verify results\n            assert result.order_id == \"test-order-123\"\n            assert result.validation.is_valid\n            assert result.payment.success\n            assert result.payment.transaction_id == \"test-txn-123\"\n\n@pytest.mark.asyncio\nasync def test_workflow_with_signals():\n    \"\"\"Test workflow that handles signals\"\"\"\n\n    async with WorkflowEnvironment() as env:\n        worker = Worker(\n            env.client,\n            task_queue=\"test-queue\",\n            workflows=[LongRunningProcessWorkflow],\n            activities=[mock_process_step]\n        )\n\n        async with worker:\n            # Start workflow\n            handle = await env.client.start_workflow(\n                LongRunningProcessWorkflow.run,\n                ProcessConfig(total_steps=3, step_delay_seconds=0),\n                id=\"test-long-running\",\n                task_queue=\"test-queue\"\n            )\n\n            # Send pause signal\n            await handle.signal(LongRunningProcessWorkflow.pause)\n\n            # Check status\n            status = await handle.query(LongRunningProcessWorkflow.get_status)\n            assert status[\"paused\"] is True\n\n            # Send resume signal\n            await handle.signal(LongRunningProcessWorkflow.resume)\n\n            # Wait for completion\n            result = await handle.result()\n            assert result.status == \"completed\"\n            assert result.progress == 100\n</code></pre>"},{"location":"development/workflow-development/#2-integration-testing","title":"2. Integration Testing","text":"<pre><code>@pytest.mark.integration\n@pytest.mark.asyncio\nasync def test_full_order_processing_integration():\n    \"\"\"Integration test with real Temporal server\"\"\"\n\n    from temporalio.client import Client\n    from temporalio.worker import Worker\n\n    # Connect to test Temporal server\n    client = await Client.connect(\"localhost:7233\", namespace=\"test\")\n\n    # Create worker with real activities\n    worker = Worker(\n        client,\n        task_queue=\"integration-test-queue\",\n        workflows=[OrderProcessingWorkflow],\n        activities=[\n            validate_order,\n            process_payment,\n            ship_order\n        ]\n    )\n\n    async with worker:\n        # Execute workflow with real data\n        test_order = Order(\n            id=f\"test-order-{uuid.uuid4()}\",\n            customer_id=\"test-customer-123\",\n            total_amount=99.99,\n            items=[\n                OrderItem(id=\"book-123\", quantity=1, price=29.99),\n                OrderItem(id=\"shipping\", quantity=1, price=9.99)\n            ],\n            payment_method=PaymentMethod(\n                type=\"credit_card\",\n                token=\"test-token-123\"\n            ),\n            shipping_address=Address(\n                street=\"123 Test St\",\n                city=\"Test City\",\n                state=\"TS\",\n                zip_code=\"12345\"\n            )\n        )\n\n        result = await client.execute_workflow(\n            OrderProcessingWorkflow.run,\n            test_order,\n            id=f\"integration-test-{uuid.uuid4()}\",\n            task_queue=\"integration-test-queue\",\n            execution_timeout=timedelta(minutes=30)\n        )\n\n        # Verify integration results\n        assert result.order_id == test_order.id\n        assert result.validation.is_valid\n        assert result.payment.success\n        assert result.shipping.tracking_number is not None\n\n        # Verify side effects (database updates, external API calls, etc.)\n        # This would typically involve checking external systems\n</code></pre>"},{"location":"development/workflow-development/#performance-optimization","title":"Performance Optimization","text":""},{"location":"development/workflow-development/#1-workflow-optimization-techniques","title":"1. Workflow Optimization Techniques","text":"<pre><code>@workflow.defn\nclass OptimizedWorkflow:\n    @workflow.run\n    async def run(self, batch_request: BatchRequest) -&gt; BatchResult:\n        # Technique 1: Batch similar operations\n        validation_tasks = []\n        for item in batch_request.items:\n            task = workflow.execute_activity(\n                validate_item,\n                item,\n                start_to_close_timeout=timedelta(minutes=2),\n                task_queue=\"validation-queue\"  # Dedicated queue for validation\n            )\n            validation_tasks.append(task)\n\n        # Wait for all validations to complete\n        validation_results = await asyncio.gather(*validation_tasks)\n\n        # Technique 2: Process in chunks to avoid memory issues\n        chunk_size = 50\n        processing_results = []\n\n        for i in range(0, len(batch_request.items), chunk_size):\n            chunk = batch_request.items[i:i + chunk_size]\n            chunk_results = await self._process_chunk(chunk)\n            processing_results.extend(chunk_results)\n\n            # Optional: Brief pause between chunks to reduce system load\n            if i + chunk_size &lt; len(batch_request.items):\n                await asyncio.sleep(0.1)\n\n        # Technique 3: Use local activities for lightweight operations\n        summary = await workflow.execute_local_activity(\n            generate_summary,\n            SummaryRequest(\n                total_items=len(batch_request.items),\n                validation_results=validation_results,\n                processing_results=processing_results\n            ),\n            start_to_close_timeout=timedelta(seconds=30)\n        )\n\n        return BatchResult(\n            summary=summary,\n            item_results=processing_results\n        )\n\n    async def _process_chunk(self, chunk: List[Item]) -&gt; List[ProcessingResult]:\n        \"\"\"Process a chunk of items in parallel\"\"\"\n        tasks = []\n        for item in chunk:\n            task = workflow.execute_activity(\n                process_item,\n                item,\n                start_to_close_timeout=timedelta(minutes=10),\n                task_queue=\"processing-queue\",\n                # Use heartbeat for long-running activities\n                heartbeat_timeout=timedelta(minutes=2)\n            )\n            tasks.append(task)\n\n        return await asyncio.gather(*tasks, return_exceptions=True)\n</code></pre>"},{"location":"development/workflow-development/#2-activity-optimization","title":"2. Activity Optimization","text":"<pre><code>@activity.defn\nasync def optimized_batch_processing(request: BatchProcessingRequest) -&gt; BatchProcessingResult:\n    \"\"\"Optimized activity for batch processing\"\"\"\n\n    # Use activity heartbeat for long-running operations\n    activity.heartbeat(\"Starting batch processing\")\n\n    results = []\n    total_items = len(request.items)\n\n    # Process in smaller batches\n    batch_size = 10\n    for i in range(0, total_items, batch_size):\n        batch = request.items[i:i + batch_size]\n\n        # Process batch\n        batch_results = await process_batch_items(batch)\n        results.extend(batch_results)\n\n        # Report progress via heartbeat\n        progress = ((i + len(batch)) / total_items) * 100\n        activity.heartbeat(f\"Processed {i + len(batch)}/{total_items} items ({progress:.1f}%)\")\n\n        # Check for cancellation\n        if activity.is_cancelled():\n            activity.heartbeat(\"Processing cancelled, cleaning up...\")\n            await cleanup_partial_processing(results)\n            raise ActivityError(\"Processing was cancelled\")\n\n    activity.heartbeat(\"Batch processing completed\")\n    return BatchProcessingResult(\n        success=True,\n        processed_count=len(results),\n        results=results\n    )\n\n@activity.defn\nasync def cached_external_api_call(request: APIRequest) -&gt; APIResponse:\n    \"\"\"Activity with intelligent caching\"\"\"\n\n    # Check cache first\n    cache_key = f\"api_call:{request.endpoint}:{hash(request.parameters)}\"\n    cached_result = await get_from_cache(cache_key)\n\n    if cached_result:\n        activity.logger.info(f\"Cache hit for {cache_key}\")\n        return cached_result\n\n    # Make actual API call\n    activity.heartbeat(f\"Calling external API: {request.endpoint}\")\n\n    try:\n        response = await make_external_api_call(request)\n\n        # Cache successful responses\n        if response.success:\n            await store_in_cache(cache_key, response, ttl_seconds=300)\n\n        return response\n\n    except Exception as e:\n        activity.logger.error(f\"API call failed: {e}\")\n\n        # Return cached response if available (even if stale)\n        stale_cache = await get_from_cache(cache_key, allow_stale=True)\n        if stale_cache:\n            activity.logger.warning(\"Returning stale cached response due to API failure\")\n            return stale_cache\n\n        raise\n</code></pre> <p>This comprehensive workflow development guide provides the foundation for building robust, scalable, and maintainable workflows in the Temporal.io enterprise environment. The patterns and techniques demonstrated here address real-world challenges and follow enterprise best practices for reliability and performance.</p>"},{"location":"gitops/argocd-setup/","title":"ArgoCD Setup","text":"<p>This guide provides comprehensive setup instructions for ArgoCD to enable GitOps deployment of Temporal.io infrastructure and applications in enterprise environments.</p>"},{"location":"gitops/argocd-setup/#overview","title":"Overview","text":"<p>ArgoCD enables GitOps deployment patterns for Temporal.io infrastructure, providing: - Declarative configuration management - Automated deployment and rollback - Multi-environment management - RBAC and security controls - Application monitoring and health checks - Integration with CI/CD pipelines</p>"},{"location":"gitops/argocd-setup/#architecture","title":"Architecture","text":"<pre><code>graph TB\n    subgraph \"Git Repositories\"\n        INFRA[Infrastructure Repo]\n        APP[Application Repo]\n        CONFIG[Config Repo]\n    end\n\n    subgraph \"ArgoCD\"\n        ARGOCD[ArgoCD Server]\n        APPCONTROLLER[Application Controller]\n        REPOSERVER[Repository Server]\n        REDIS[(Redis)]\n    end\n\n    subgraph \"Kubernetes Clusters\"\n        DEV[Development Cluster]\n        STAGE[Staging Cluster]\n        PROD[Production Cluster]\n    end\n\n    subgraph \"Temporal Services\"\n        TEMPORAL[Temporal Cluster]\n        WORKERS[Application Workers]\n        API[FastAPI Services]\n    end\n\n    INFRA --&gt; ARGOCD\n    APP --&gt; ARGOCD\n    CONFIG --&gt; ARGOCD\n\n    ARGOCD --&gt; APPCONTROLLER\n    APPCONTROLLER --&gt; REPOSERVER\n    REPOSERVER --&gt; REDIS\n\n    APPCONTROLLER --&gt; DEV\n    APPCONTROLLER --&gt; STAGE\n    APPCONTROLLER --&gt; PROD\n\n    DEV --&gt; TEMPORAL\n    STAGE --&gt; TEMPORAL\n    PROD --&gt; TEMPORAL\n\n    TEMPORAL --&gt; WORKERS\n    TEMPORAL --&gt; API</code></pre>"},{"location":"gitops/argocd-setup/#prerequisites","title":"Prerequisites","text":""},{"location":"gitops/argocd-setup/#required-tools","title":"Required Tools","text":"<pre><code># Install ArgoCD CLI on macOS\nbrew install argocd\n\n# Install kubectl and helm\nbrew install kubectl helm\n\n# Verify installations\nargocd version --client\nkubectl version --client\nhelm version\n</code></pre>"},{"location":"gitops/argocd-setup/#cluster-requirements","title":"Cluster Requirements","text":"<ul> <li>Kubernetes 1.20+</li> <li>4GB+ available memory</li> <li>2 CPU cores minimum</li> <li>LoadBalancer or Ingress controller</li> <li>Persistent storage support</li> </ul>"},{"location":"gitops/argocd-setup/#argocd-installation","title":"ArgoCD Installation","text":""},{"location":"gitops/argocd-setup/#install-argocd-server","title":"Install ArgoCD Server","text":""},{"location":"gitops/argocd-setup/#namespace-setup","title":"Namespace Setup","text":"<pre><code># argocd/namespace.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: argocd\n  labels:\n    name: argocd\n    app.kubernetes.io/part-of: argocd\n</code></pre>"},{"location":"gitops/argocd-setup/#core-installation","title":"Core Installation","text":"<pre><code>#!/bin/bash\n# scripts/install-argocd.sh\n\nset -euo pipefail\n\nNAMESPACE=\"argocd\"\nARGOCD_VERSION=\"v2.8.4\"\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\nerror() {\n    echo -e \"\\033[0;31m[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1\\033[0m\"\n    exit 1\n}\n\nlog \"Installing ArgoCD ${ARGOCD_VERSION}...\"\n\n# Create namespace\nkubectl create namespace \"$NAMESPACE\" --dry-run=client -o yaml | kubectl apply -f -\n\n# Install ArgoCD\nkubectl apply -n \"$NAMESPACE\" -f \"https://raw.githubusercontent.com/argoproj/argo-cd/${ARGOCD_VERSION}/manifests/install.yaml\"\n\n# Wait for ArgoCD to be ready\nlog \"Waiting for ArgoCD to be ready...\"\nkubectl wait --for=condition=available deployment/argocd-server -n \"$NAMESPACE\" --timeout=300s\nkubectl wait --for=condition=available deployment/argocd-repo-server -n \"$NAMESPACE\" --timeout=300s\nkubectl wait --for=condition=available deployment/argocd-application-controller -n \"$NAMESPACE\" --timeout=300s\n\nlog \"ArgoCD installation completed successfully!\"\n</code></pre>"},{"location":"gitops/argocd-setup/#custom-argocd-configuration","title":"Custom ArgoCD Configuration","text":""},{"location":"gitops/argocd-setup/#argocd-server-configuration","title":"ArgoCD Server Configuration","text":"<pre><code># argocd/argocd-server-config.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: argocd-server-config\n  namespace: argocd\n  labels:\n    app.kubernetes.io/name: argocd-server-config\n    app.kubernetes.io/part-of: argocd\ndata:\n  # Server configuration\n  server.config: |\n    url: https://argocd.temporal.company.com\n    insecure: false\n    grpc.web: true\n\n    # OIDC configuration\n    oidc.config: |\n      name: Company SSO\n      issuer: https://auth.company.com\n      clientId: argocd\n      clientSecret: $argocd-oidc-secret:clientSecret\n      requestedScopes: [\"openid\", \"profile\", \"email\", \"groups\"]\n      requestedIDTokenClaims: {\"groups\": {\"essential\": true}}\n\n    # URL aliases for multiple clusters\n    application.instanceLabelKey: argocd.argoproj.io/instance\n\n    # Resource customizations\n    resource.customizations: |\n      argoproj.io/Rollout:\n        health.lua: |\n          hs = {}\n          if obj.status ~= nil then\n            if obj.status.replicas ~= nil and obj.status.updatedReplicas ~= nil and obj.status.readyReplicas ~= nil and obj.status.availableReplicas ~= nil then\n              if obj.status.replicas == obj.status.updatedReplicas and obj.status.replicas == obj.status.readyReplicas and obj.status.replicas == obj.status.availableReplicas then\n                hs.status = \"Healthy\"\n                hs.message = \"Rollout is healthy\"\n                return hs\n              end\n            end\n          end\n          hs.status = \"Progressing\"\n          hs.message = \"Waiting for rollout to finish\"\n          return hs\n\n    # Additional configuration\n    accounts.temporal-admin: login\n    accounts.temporal-admin.enabled: \"true\"\n\n  # RBAC configuration\n  policy.default: role:readonly\n  policy.csv: |\n    p, role:admin, applications, *, */*, allow\n    p, role:admin, clusters, *, *, allow\n    p, role:admin, repositories, *, *, allow\n\n    p, role:developer, applications, get, */*, allow\n    p, role:developer, applications, sync, */*, allow\n    p, role:developer, applications, action/*, */*, allow\n    p, role:developer, repositories, get, *, allow\n\n    p, role:readonly, applications, get, */*, allow\n    p, role:readonly, repositories, get, *, allow\n    p, role:readonly, clusters, get, *, allow\n\n    g, temporal-admins, role:admin\n    g, temporal-developers, role:developer\n    g, temporal-users, role:readonly\n\n    g, temporal-admin, role:admin\n</code></pre>"},{"location":"gitops/argocd-setup/#argocd-cmd-parameters","title":"ArgoCD CMD Parameters","text":"<pre><code># argocd/argocd-cmd-params.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: argocd-cmd-params-cm\n  namespace: argocd\n  labels:\n    app.kubernetes.io/name: argocd-cmd-params-cm\n    app.kubernetes.io/part-of: argocd\ndata:\n  # Server parameters\n  server.insecure: \"false\"\n  server.grpc.web: \"true\"\n  server.enable.proxy.extension: \"true\"\n\n  # Application controller parameters\n  application.controller.self.heal.timeout.seconds: \"30\"\n  application.controller.operation.processors: \"20\"\n  application.controller.status.processors: \"20\"\n  application.controller.repo.server.timeout.seconds: \"120\"\n\n  # Repository server parameters\n  reposerver.parallelism.limit: \"10\"\n  reposerver.init.timeout: \"600\"\n</code></pre>"},{"location":"gitops/argocd-setup/#high-availability-configuration","title":"High Availability Configuration","text":""},{"location":"gitops/argocd-setup/#argocd-ha-setup","title":"ArgoCD HA Setup","text":"<pre><code># argocd/argocd-ha.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: argocd-server\n  namespace: argocd\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-server\n              topologyKey: kubernetes.io/hostname\n      containers:\n      - name: argocd-server\n        image: quay.io/argoproj/argocd:v2.8.4\n        args:\n        - argocd-server\n        - --staticassets\n        - /shared/app\n        - --redis\n        - argocd-redis:6379\n        resources:\n          requests:\n            memory: \"256Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"512Mi\"\n            cpu: \"500m\"\n\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: argocd-repo-server\n  namespace: argocd\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-repo-server\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-repo-server\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app.kubernetes.io/name: argocd-repo-server\n              topologyKey: kubernetes.io/hostname\n      containers:\n      - name: argocd-repo-server\n        image: quay.io/argoproj/argocd:v2.8.4\n        args:\n        - argocd-repo-server\n        - --redis\n        - argocd-redis:6379\n        resources:\n          requests:\n            memory: \"512Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"1Gi\"\n            cpu: \"500m\"\n\n---\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: argocd-application-controller\n  namespace: argocd\nspec:\n  replicas: 1  # Application controller should be single instance\n  serviceName: argocd-application-controller\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-application-controller\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: argocd-application-controller\n    spec:\n      containers:\n      - name: argocd-application-controller\n        image: quay.io/argoproj/argocd:v2.8.4\n        args:\n        - argocd-application-controller\n        - --redis\n        - argocd-redis:6379\n        - --operation-processors\n        - \"20\"\n        - --status-processors\n        - \"20\"\n        - --kubectl-parallelism-limit\n        - \"30\"\n        resources:\n          requests:\n            memory: \"1Gi\"\n            cpu: \"500m\"\n          limits:\n            memory: \"2Gi\"\n            cpu: \"1000m\"\n</code></pre>"},{"location":"gitops/argocd-setup/#ingress-and-ssl-configuration","title":"Ingress and SSL Configuration","text":""},{"location":"gitops/argocd-setup/#argocd-ingress","title":"ArgoCD Ingress","text":"<pre><code># argocd/ingress.yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: argocd-server-ingress\n  namespace: argocd\n  annotations:\n    kubernetes.io/ingress.class: alb\n    alb.ingress.kubernetes.io/scheme: internet-facing\n    alb.ingress.kubernetes.io/target-type: ip\n    alb.ingress.kubernetes.io/certificate-arn: arn:aws:acm:us-west-2:ACCOUNT:certificate/CERT-ID\n    alb.ingress.kubernetes.io/ssl-redirect: \"443\"\n    alb.ingress.kubernetes.io/listen-ports: '[{\"HTTP\": 80}, {\"HTTPS\": 443}]'\n    alb.ingress.kubernetes.io/backend-protocol: HTTPS\n    alb.ingress.kubernetes.io/healthcheck-path: /healthz\n    nginx.ingress.kubernetes.io/backend-protocol: \"GRPC\"\n    nginx.ingress.kubernetes.io/grpc-backend: \"true\"\nspec:\n  tls:\n  - hosts:\n    - argocd.temporal.company.com\n    secretName: argocd-server-tls\n  rules:\n  - host: argocd.temporal.company.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: argocd-server\n            port:\n              number: 443\n</code></pre>"},{"location":"gitops/argocd-setup/#security-configuration","title":"Security Configuration","text":""},{"location":"gitops/argocd-setup/#rbac-setup","title":"RBAC Setup","text":"<pre><code># argocd/rbac.yaml\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: argocd-admin\n  namespace: argocd\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: argocd-admin\nrules:\n- apiGroups: [\"*\"]\n  resources: [\"*\"]\n  verbs: [\"*\"]\n- nonResourceURLs: [\"*\"]\n  verbs: [\"*\"]\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: argocd-admin\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: argocd-admin\nsubjects:\n- kind: ServiceAccount\n  name: argocd-admin\n  namespace: argocd\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: argocd-temporal-admin\nrules:\n- apiGroups: [\"\"]\n  resources: [\"*\"]\n  verbs: [\"*\"]\n- apiGroups: [\"apps\"]\n  resources: [\"*\"]\n  verbs: [\"*\"]\n- apiGroups: [\"extensions\"]\n  resources: [\"*\"]\n  verbs: [\"*\"]\n- apiGroups: [\"argoproj.io\"]\n  resources: [\"*\"]\n  verbs: [\"*\"]\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: argocd-temporal-admin\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: argocd-temporal-admin\nsubjects:\n- kind: User\n  name: temporal-admin@company.com\n  apiGroup: rbac.authorization.k8s.io\n</code></pre>"},{"location":"gitops/argocd-setup/#secrets-management","title":"Secrets Management","text":"<pre><code># argocd/secrets.yaml\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: argocd-oidc-secret\n  namespace: argocd\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: argocd-oidc-secret\n    creationPolicy: Owner\n  data:\n  - secretKey: clientSecret\n    remoteRef:\n      key: argocd/oidc\n      property: client_secret\n\n---\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: argocd-repo-credentials\n  namespace: argocd\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: argocd-repo-credentials\n    creationPolicy: Owner\n    template:\n      type: Opaque\n      data:\n        type: git\n        url: \"{{ .repo_url }}\"\n        username: \"{{ .username }}\"\n        password: \"{{ .password }}\"\n  data:\n  - secretKey: repo_url\n    remoteRef:\n      key: argocd/git\n      property: repo_url\n  - secretKey: username\n    remoteRef:\n      key: argocd/git\n      property: username\n  - secretKey: password\n    remoteRef:\n      key: argocd/git\n      property: password\n</code></pre>"},{"location":"gitops/argocd-setup/#repository-configuration","title":"Repository Configuration","text":""},{"location":"gitops/argocd-setup/#git-repository-setup","title":"Git Repository Setup","text":"<pre><code># argocd/repositories.yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: temporal-infrastructure-repo\n  namespace: argocd\n  labels:\n    argocd.argoproj.io/secret-type: repository\ntype: Opaque\nstringData:\n  type: git\n  url: https://github.com/company/temporal-infrastructure\n  username: argocd-bot\n  password: ghp_xxxxxxxxxxxxxxxxxxxx\n\n---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: temporal-applications-repo\n  namespace: argocd\n  labels:\n    argocd.argoproj.io/secret-type: repository\ntype: Opaque\nstringData:\n  type: git\n  url: https://github.com/company/temporal-applications\n  username: argocd-bot\n  password: ghp_xxxxxxxxxxxxxxxxxxxx\n\n---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: temporal-config-repo\n  namespace: argocd\n  labels:\n    argocd.argoproj.io/secret-type: repository\ntype: Opaque\nstringData:\n  type: git\n  url: https://github.com/company/temporal-config\n  username: argocd-bot\n  password: ghp_xxxxxxxxxxxxxxxxxxxx\n</code></pre>"},{"location":"gitops/argocd-setup/#cluster-credentials","title":"Cluster Credentials","text":"<pre><code># argocd/clusters.yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: temporal-development-cluster\n  namespace: argocd\n  labels:\n    argocd.argoproj.io/secret-type: cluster\ntype: Opaque\nstringData:\n  name: temporal-development\n  server: https://eks-dev.us-west-2.eks.amazonaws.com\n  config: |\n    {\n      \"bearerToken\": \"eyJhbGciOiJSUzI1NiIsImtpZCI6...\",\n      \"tlsClientConfig\": {\n        \"insecure\": false,\n        \"caData\": \"LS0tLS1CRUdJTi...\"\n      }\n    }\n\n---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: temporal-staging-cluster\n  namespace: argocd\n  labels:\n    argocd.argoproj.io/secret-type: cluster\ntype: Opaque\nstringData:\n  name: temporal-staging\n  server: https://eks-staging.us-west-2.eks.amazonaws.com\n  config: |\n    {\n      \"bearerToken\": \"eyJhbGciOiJSUzI1NiIsImtpZCI6...\",\n      \"tlsClientConfig\": {\n        \"insecure\": false,\n        \"caData\": \"LS0tLS1CRUdJTi...\"\n      }\n    }\n\n---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: temporal-production-cluster\n  namespace: argocd\n  labels:\n    argocd.argoproj.io/secret-type: cluster\ntype: Opaque\nstringData:\n  name: temporal-production\n  server: https://eks-prod.us-west-2.eks.amazonaws.com\n  config: |\n    {\n      \"bearerToken\": \"eyJhbGciOiJSUzI1NiIsImtpZCI6...\",\n      \"tlsClientConfig\": {\n        \"insecure\": false,\n        \"caData\": \"LS0tLS1CRUdJTi...\"\n      }\n    }\n</code></pre>"},{"location":"gitops/argocd-setup/#application-projects","title":"Application Projects","text":""},{"location":"gitops/argocd-setup/#temporal-project","title":"Temporal Project","text":"<pre><code># argocd/projects/temporal-project.yaml\napiVersion: argoproj.io/v1alpha1\nkind: AppProject\nmetadata:\n  name: temporal\n  namespace: argocd\n  finalizers:\n    - resources-finalizer.argocd.argoproj.io\nspec:\n  description: Temporal.io deployment project\n\n  sourceRepos:\n  - 'https://github.com/company/temporal-infrastructure'\n  - 'https://github.com/company/temporal-applications'\n  - 'https://github.com/company/temporal-config'\n  - 'https://helm.temporal.io'\n\n  destinations:\n  - namespace: 'temporal-*'\n    server: '*'\n  - namespace: 'argocd'\n    server: '*'\n\n  clusterResourceWhitelist:\n  - group: ''\n    kind: Namespace\n  - group: 'rbac.authorization.k8s.io'\n    kind: ClusterRole\n  - group: 'rbac.authorization.k8s.io'\n    kind: ClusterRoleBinding\n  - group: 'networking.k8s.io'\n    kind: NetworkPolicy\n  - group: 'policy'\n    kind: PodSecurityPolicy\n  - group: 'apiextensions.k8s.io'\n    kind: CustomResourceDefinition\n\n  namespaceResourceWhitelist:\n  - group: ''\n    kind: '*'\n  - group: 'apps'\n    kind: '*'\n  - group: 'extensions'\n    kind: '*'\n  - group: 'networking.k8s.io'\n    kind: '*'\n  - group: 'policy'\n    kind: '*'\n  - group: 'autoscaling'\n    kind: '*'\n  - group: 'monitoring.coreos.com'\n    kind: '*'\n  - group: 'external-secrets.io'\n    kind: '*'\n\n  roles:\n  - name: temporal-admin\n    description: Admin access to Temporal project\n    policies:\n    - p, proj:temporal:temporal-admin, applications, *, temporal/*, allow\n    - p, proj:temporal:temporal-admin, repositories, *, *, allow\n    groups:\n    - temporal-admins\n\n  - name: temporal-developer\n    description: Developer access to Temporal project\n    policies:\n    - p, proj:temporal:temporal-developer, applications, get, temporal/*, allow\n    - p, proj:temporal:temporal-developer, applications, sync, temporal/*, allow\n    - p, proj:temporal:temporal-developer, applications, action/*, temporal/*, allow\n    groups:\n    - temporal-developers\n\n  - name: temporal-readonly\n    description: Read-only access to Temporal project\n    policies:\n    - p, proj:temporal:temporal-readonly, applications, get, temporal/*, allow\n    groups:\n    - temporal-users\n\n  syncWindows:\n  - kind: allow\n    schedule: '0 2 * * *'\n    duration: 1h\n    applications:\n    - '*'\n    manualSync: true\n\n  - kind: deny\n    schedule: '0 12 * * 1-5'\n    duration: 8h\n    applications:\n    - 'temporal-production-*'\n    manualSync: false\n</code></pre>"},{"location":"gitops/argocd-setup/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"gitops/argocd-setup/#prometheus-servicemonitor","title":"Prometheus ServiceMonitor","text":"<pre><code># argocd/monitoring/service-monitor.yaml\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: argocd-metrics\n  namespace: argocd\n  labels:\n    app.kubernetes.io/component: metrics\n    app.kubernetes.io/name: argocd-metrics\n    app.kubernetes.io/part-of: argocd\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: argocd-metrics\n  endpoints:\n  - port: metrics\n    interval: 30s\n    path: /metrics\n  - port: metrics\n    interval: 30s\n    path: /metrics\n    targetPort: 8083\n\n---\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: argocd-server-metrics\n  namespace: argocd\n  labels:\n    app.kubernetes.io/component: server\n    app.kubernetes.io/name: argocd-server-metrics\n    app.kubernetes.io/part-of: argocd\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: server\n      app.kubernetes.io/name: argocd-server-metrics\n      app.kubernetes.io/part-of: argocd\n  endpoints:\n  - port: metrics\n    interval: 30s\n    path: /metrics\n\n---\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: argocd-repo-server-metrics\n  namespace: argocd\n  labels:\n    app.kubernetes.io/component: repo-server\n    app.kubernetes.io/name: argocd-repo-server\n    app.kubernetes.io/part-of: argocd\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: repo-server\n      app.kubernetes.io/name: argocd-repo-server\n      app.kubernetes.io/part-of: argocd\n  endpoints:\n  - port: metrics\n    interval: 30s\n    path: /metrics\n</code></pre>"},{"location":"gitops/argocd-setup/#grafana-dashboard","title":"Grafana Dashboard","text":"<pre><code>{\n  \"dashboard\": {\n    \"id\": null,\n    \"title\": \"ArgoCD Dashboard\",\n    \"tags\": [\"argocd\", \"gitops\"],\n    \"style\": \"dark\",\n    \"timezone\": \"browser\",\n    \"panels\": [\n      {\n        \"id\": 1,\n        \"title\": \"Application Health\",\n        \"type\": \"stat\",\n        \"targets\": [\n          {\n            \"expr\": \"argocd_app_health_status{name=~\\\"temporal.*\\\"}\",\n            \"legendFormat\": \"{{name}}\"\n          }\n        ],\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 0}\n      },\n      {\n        \"id\": 2,\n        \"title\": \"Sync Status\",\n        \"type\": \"stat\",\n        \"targets\": [\n          {\n            \"expr\": \"argocd_app_sync_total{name=~\\\"temporal.*\\\"}\",\n            \"legendFormat\": \"{{name}}\"\n          }\n        ],\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 0}\n      },\n      {\n        \"id\": 3,\n        \"title\": \"Repository Activity\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(argocd_git_request_total[5m])\",\n            \"legendFormat\": \"Git Requests/sec\"\n          }\n        ],\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 8}\n      },\n      {\n        \"id\": 4,\n        \"title\": \"Controller Performance\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"argocd_app_reconcile_bucket\",\n            \"legendFormat\": \"Reconcile Time\"\n          }\n        ],\n        \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 8}\n      }\n    ],\n    \"time\": {\n      \"from\": \"now-1h\",\n      \"to\": \"now\"\n    },\n    \"refresh\": \"30s\"\n  }\n}\n</code></pre>"},{"location":"gitops/argocd-setup/#operations-and-maintenance","title":"Operations and Maintenance","text":""},{"location":"gitops/argocd-setup/#backup-configuration","title":"Backup Configuration","text":"<pre><code>#!/bin/bash\n# scripts/backup-argocd.sh\n\nset -euo pipefail\n\nNAMESPACE=\"argocd\"\nBACKUP_DIR=\"/backups/argocd\"\nTIMESTAMP=$(date +%Y%m%d_%H%M%S)\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\nlog \"Starting ArgoCD backup...\"\n\n# Create backup directory\nmkdir -p \"$BACKUP_DIR\"\n\n# Backup ArgoCD resources\nkubectl get applications -n \"$NAMESPACE\" -o yaml &gt; \"$BACKUP_DIR/applications-${TIMESTAMP}.yaml\"\nkubectl get appprojects -n \"$NAMESPACE\" -o yaml &gt; \"$BACKUP_DIR/appprojects-${TIMESTAMP}.yaml\"\nkubectl get secrets -n \"$NAMESPACE\" -o yaml &gt; \"$BACKUP_DIR/secrets-${TIMESTAMP}.yaml\"\nkubectl get configmaps -n \"$NAMESPACE\" -o yaml &gt; \"$BACKUP_DIR/configmaps-${TIMESTAMP}.yaml\"\n\n# Backup to S3\ntar -czf \"$BACKUP_DIR/argocd-backup-${TIMESTAMP}.tar.gz\" -C \"$BACKUP_DIR\" .\naws s3 cp \"$BACKUP_DIR/argocd-backup-${TIMESTAMP}.tar.gz\" \"s3://temporal-backups/argocd/\"\n\n# Clean up local files older than 7 days\nfind \"$BACKUP_DIR\" -name \"*.yaml\" -mtime +7 -delete\nfind \"$BACKUP_DIR\" -name \"*.tar.gz\" -mtime +7 -delete\n\nlog \"ArgoCD backup completed: argocd-backup-${TIMESTAMP}.tar.gz\"\n</code></pre>"},{"location":"gitops/argocd-setup/#health-check-script","title":"Health Check Script","text":"<pre><code>#!/bin/bash\n# scripts/health-check-argocd.sh\n\nset -euo pipefail\n\nNAMESPACE=\"argocd\"\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\nerror() {\n    echo -e \"\\033[0;31m[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1\\033[0m\"\n}\n\nwarn() {\n    echo -e \"\\033[1;33m[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1\\033[0m\"\n}\n\nlog \"Running ArgoCD health checks...\"\n\n# Check pod status\nPODS_NOT_READY=$(kubectl get pods -n \"$NAMESPACE\" -o jsonpath='{.items[?(@.status.phase!=\"Running\")].metadata.name}')\nif [[ -n \"$PODS_NOT_READY\" ]]; then\n    warn \"Pods not ready: $PODS_NOT_READY\"\nelse\n    log \"\u2713 All pods are running\"\nfi\n\n# Check ArgoCD server health\nkubectl run argocd-health --image=curlimages/curl:latest --rm -i --restart=Never -- \\\n    curl -f \"http://argocd-server.${NAMESPACE}.svc.cluster.local:80/healthz\" &gt; /dev/null 2&gt;&amp;1\nif [[ $? -eq 0 ]]; then\n    log \"\u2713 ArgoCD server health check passed\"\nelse\n    error \"\u2717 ArgoCD server health check failed\"\nfi\n\n# Check application sync status\nUNHEALTHY_APPS=$(argocd app list --output json | jq -r '.[] | select(.status.health.status != \"Healthy\") | .metadata.name' || true)\nif [[ -n \"$UNHEALTHY_APPS\" ]]; then\n    warn \"Unhealthy applications: $UNHEALTHY_APPS\"\nelse\n    log \"\u2713 All applications are healthy\"\nfi\n\nlog \"ArgoCD health check completed\"\n</code></pre> <p>This comprehensive ArgoCD setup guide provides enterprise-grade GitOps capabilities for Temporal.io deployments with high availability, security, monitoring, and operational automation.</p>"},{"location":"gitops/environment-management/","title":"Environment Management","text":"<p>This guide provides comprehensive strategies for managing multiple environments in Temporal.io deployments using GitOps patterns, ensuring consistent, scalable, and secure infrastructure across development, staging, and production environments.</p>"},{"location":"gitops/environment-management/#overview","title":"Overview","text":"<p>Environment management in GitOps involves: - Declarative environment definitions - Automated promotion pipelines - Environment-specific configurations - Security boundaries and access controls - Monitoring and observability per environment - Disaster recovery and backup strategies</p>"},{"location":"gitops/environment-management/#architecture","title":"Architecture","text":"<pre><code>graph TB\n    subgraph \"Git Repositories\"\n        INFRA[Infrastructure Repo]\n        CONFIG[Config Repo]\n        APP[Application Repo]\n        ENVDEF[Environment Definitions]\n    end\n\n    subgraph \"ArgoCD\"\n        ARGOCD[ArgoCD Controller]\n        APPSETS[ApplicationSets]\n        PROJECTS[App Projects]\n    end\n\n    subgraph \"Development Environment\"\n        DEV_K8S[Dev Kubernetes]\n        DEV_TEMPORAL[Dev Temporal Cluster]\n        DEV_WORKERS[Dev Workers]\n        DEV_DB[(Dev Database)]\n    end\n\n    subgraph \"Staging Environment\"\n        STAGE_K8S[Staging Kubernetes]\n        STAGE_TEMPORAL[Staging Temporal Cluster]\n        STAGE_WORKERS[Staging Workers]\n        STAGE_DB[(Staging Database)]\n    end\n\n    subgraph \"Production Environment\"\n        PROD_K8S[Production Kubernetes]\n        PROD_TEMPORAL[Production Temporal Cluster]\n        PROD_WORKERS[Production Workers]\n        PROD_DB[(Production Database)]\n    end\n\n    subgraph \"Monitoring Stack\"\n        PROMETHEUS[Prometheus]\n        GRAFANA[Grafana]\n        ALERTMANAGER[AlertManager]\n    end\n\n    INFRA --&gt; ARGOCD\n    CONFIG --&gt; ARGOCD\n    APP --&gt; ARGOCD\n    ENVDEF --&gt; ARGOCD\n\n    ARGOCD --&gt; APPSETS\n    APPSETS --&gt; PROJECTS\n\n    PROJECTS --&gt; DEV_K8S\n    PROJECTS --&gt; STAGE_K8S\n    PROJECTS --&gt; PROD_K8S\n\n    DEV_K8S --&gt; DEV_TEMPORAL\n    DEV_TEMPORAL --&gt; DEV_WORKERS\n    DEV_TEMPORAL --&gt; DEV_DB\n\n    STAGE_K8S --&gt; STAGE_TEMPORAL\n    STAGE_TEMPORAL --&gt; STAGE_WORKERS\n    STAGE_TEMPORAL --&gt; STAGE_DB\n\n    PROD_K8S --&gt; PROD_TEMPORAL\n    PROD_TEMPORAL --&gt; PROD_WORKERS\n    PROD_TEMPORAL --&gt; PROD_DB\n\n    DEV_K8S --&gt; PROMETHEUS\n    STAGE_K8S --&gt; PROMETHEUS\n    PROD_K8S --&gt; PROMETHEUS\n\n    PROMETHEUS --&gt; GRAFANA\n    PROMETHEUS --&gt; ALERTMANAGER</code></pre>"},{"location":"gitops/environment-management/#environment-strategy","title":"Environment Strategy","text":""},{"location":"gitops/environment-management/#environment-types","title":"Environment Types","text":""},{"location":"gitops/environment-management/#development-environment","title":"Development Environment","text":"<ul> <li>Purpose: Feature development and testing</li> <li>Characteristics: </li> <li>Shared resources</li> <li>Relaxed security policies</li> <li>Frequent deployments</li> <li>Cost-optimized configurations</li> <li>Extended logging and debugging</li> </ul>"},{"location":"gitops/environment-management/#staging-environment","title":"Staging Environment","text":"<ul> <li>Purpose: Pre-production validation</li> <li>Characteristics:</li> <li>Production-like configuration</li> <li>Performance testing</li> <li>Security validation</li> <li>Data migration testing</li> <li>User acceptance testing</li> </ul>"},{"location":"gitops/environment-management/#production-environment","title":"Production Environment","text":"<ul> <li>Purpose: Live workloads</li> <li>Characteristics:</li> <li>High availability</li> <li>Security hardened</li> <li>Performance optimized</li> <li>Comprehensive monitoring</li> <li>Disaster recovery enabled</li> </ul>"},{"location":"gitops/environment-management/#environment-lifecycle","title":"Environment Lifecycle","text":"<pre><code>graph LR\n    DEV[Development] --&gt; STAGE[Staging]\n    STAGE --&gt; PROD[Production]\n\n    subgraph \"Promotion Gates\"\n        TESTS[Automated Tests]\n        SECURITY[Security Scans]\n        APPROVAL[Manual Approval]\n    end\n\n    DEV --&gt; TESTS\n    TESTS --&gt; STAGE\n    STAGE --&gt; SECURITY\n    SECURITY --&gt; APPROVAL\n    APPROVAL --&gt; PROD</code></pre>"},{"location":"gitops/environment-management/#repository-structure","title":"Repository Structure","text":""},{"location":"gitops/environment-management/#environment-configuration-repository","title":"Environment Configuration Repository","text":"<pre><code>temporal-environments/\n\u251c\u2500\u2500 environments/\n\u2502   \u251c\u2500\u2500 dev/\n\u2502   \u2502   \u251c\u2500\u2500 kustomization.yaml\n\u2502   \u2502   \u251c\u2500\u2500 namespace.yaml\n\u2502   \u2502   \u251c\u2500\u2500 temporal/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 values.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 server-config.yaml\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 worker-config.yaml\n\u2502   \u2502   \u251c\u2500\u2500 observability/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 prometheus.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 grafana.yaml\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 jaeger.yaml\n\u2502   \u2502   \u2514\u2500\u2500 security/\n\u2502   \u2502       \u251c\u2500\u2500 rbac.yaml\n\u2502   \u2502       \u251c\u2500\u2500 network-policies.yaml\n\u2502   \u2502       \u2514\u2500\u2500 pod-security.yaml\n\u2502   \u251c\u2500\u2500 staging/\n\u2502   \u2502   \u251c\u2500\u2500 kustomization.yaml\n\u2502   \u2502   \u251c\u2500\u2500 namespace.yaml\n\u2502   \u2502   \u251c\u2500\u2500 temporal/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 values.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 server-config.yaml\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 worker-config.yaml\n\u2502   \u2502   \u251c\u2500\u2500 observability/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 prometheus.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 grafana.yaml\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 jaeger.yaml\n\u2502   \u2502   \u2514\u2500\u2500 security/\n\u2502   \u2502       \u251c\u2500\u2500 rbac.yaml\n\u2502   \u2502       \u251c\u2500\u2500 network-policies.yaml\n\u2502   \u2502       \u2514\u2500\u2500 pod-security.yaml\n\u2502   \u2514\u2500\u2500 production/\n\u2502       \u251c\u2500\u2500 kustomization.yaml\n\u2502       \u251c\u2500\u2500 namespace.yaml\n\u2502       \u251c\u2500\u2500 temporal/\n\u2502       \u2502   \u251c\u2500\u2500 values.yaml\n\u2502       \u2502   \u251c\u2500\u2500 server-config.yaml\n\u2502       \u2502   \u2514\u2500\u2500 worker-config.yaml\n\u2502       \u251c\u2500\u2500 observability/\n\u2502       \u2502   \u251c\u2500\u2500 prometheus.yaml\n\u2502       \u2502   \u251c\u2500\u2500 grafana.yaml\n\u2502       \u2502   \u2514\u2500\u2500 jaeger.yaml\n\u2502       \u2514\u2500\u2500 security/\n\u2502           \u251c\u2500\u2500 rbac.yaml\n\u2502           \u251c\u2500\u2500 network-policies.yaml\n\u2502           \u2514\u2500\u2500 pod-security.yaml\n\u251c\u2500\u2500 base/\n\u2502   \u251c\u2500\u2500 temporal/\n\u2502   \u2502   \u251c\u2500\u2500 deployment.yaml\n\u2502   \u2502   \u251c\u2500\u2500 service.yaml\n\u2502   \u2502   \u251c\u2500\u2500 configmap.yaml\n\u2502   \u2502   \u2514\u2500\u2500 ingress.yaml\n\u2502   \u251c\u2500\u2500 observability/\n\u2502   \u2502   \u251c\u2500\u2500 prometheus/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 deployment.yaml\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 configmap.yaml\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 service.yaml\n\u2502   \u2502   \u2514\u2500\u2500 grafana/\n\u2502   \u2502       \u251c\u2500\u2500 deployment.yaml\n\u2502   \u2502       \u251c\u2500\u2500 configmap.yaml\n\u2502   \u2502       \u2514\u2500\u2500 service.yaml\n\u2502   \u2514\u2500\u2500 security/\n\u2502       \u251c\u2500\u2500 rbac-template.yaml\n\u2502       \u251c\u2500\u2500 network-policy-template.yaml\n\u2502       \u2514\u2500\u2500 pod-security-template.yaml\n\u251c\u2500\u2500 argocd/\n\u2502   \u251c\u2500\u2500 applications/\n\u2502   \u2502   \u251c\u2500\u2500 dev-environment.yaml\n\u2502   \u2502   \u251c\u2500\u2500 staging-environment.yaml\n\u2502   \u2502   \u2514\u2500\u2500 production-environment.yaml\n\u2502   \u251c\u2500\u2500 applicationsets/\n\u2502   \u2502   \u2514\u2500\u2500 temporal-environments.yaml\n\u2502   \u2514\u2500\u2500 projects/\n\u2502       \u251c\u2500\u2500 temporal-dev.yaml\n\u2502       \u251c\u2500\u2500 temporal-staging.yaml\n\u2502       \u2514\u2500\u2500 temporal-production.yaml\n\u2514\u2500\u2500 scripts/\n    \u251c\u2500\u2500 promote-environment.sh\n    \u251c\u2500\u2500 validate-environment.sh\n    \u2514\u2500\u2500 rollback-environment.sh\n</code></pre>"},{"location":"gitops/environment-management/#environment-definitions","title":"Environment Definitions","text":""},{"location":"gitops/environment-management/#base-configuration-template","title":"Base Configuration Template","text":"<pre><code># base/temporal/deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: temporal-server\n  labels:\n    app: temporal-server\n    component: server\nspec:\n  selector:\n    matchLabels:\n      app: temporal-server\n  template:\n    metadata:\n      labels:\n        app: temporal-server\n        component: server\n    spec:\n      containers:\n      - name: temporal\n        image: temporalio/auto-setup:1.22.0\n        ports:\n        - containerPort: 7233\n          name: rpc\n        - containerPort: 7234\n          name: membership\n        - containerPort: 7235\n          name: history\n        - containerPort: 7239\n          name: worker\n        env:\n        - name: DB\n          value: \"postgresql\"\n        - name: DB_PORT\n          value: \"5432\"\n        - name: POSTGRES_USER\n          valueFrom:\n            secretKeyRef:\n              name: temporal-postgres\n              key: username\n        - name: POSTGRES_PWD\n          valueFrom:\n            secretKeyRef:\n              name: temporal-postgres\n              key: password\n        - name: POSTGRES_SEEDS\n          valueFrom:\n            configMapKeyRef:\n              name: temporal-config\n              key: postgres-hosts\n        - name: DYNAMIC_CONFIG_FILE_PATH\n          value: config/dynamicconfig/development.yaml\n        volumeMounts:\n        - name: config\n          mountPath: /etc/temporal/config\n        - name: dynamic-config\n          mountPath: /etc/temporal/config/dynamicconfig\n        resources:\n          requests:\n            memory: \"512Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"1Gi\"\n            cpu: \"500m\"\n      volumes:\n      - name: config\n        configMap:\n          name: temporal-config\n      - name: dynamic-config\n        configMap:\n          name: temporal-dynamic-config\n</code></pre>"},{"location":"gitops/environment-management/#development-environment_1","title":"Development Environment","text":"<pre><code># environments/dev/kustomization.yaml\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\nnamespace: temporal-dev\n\nresources:\n- ../../base/temporal\n- ../../base/observability\n- namespace.yaml\n\npatchesStrategicMerge:\n- temporal/values.yaml\n\nconfigMapGenerator:\n- name: temporal-config\n  files:\n  - temporal/server-config.yaml\n- name: temporal-dynamic-config\n  files:\n  - temporal/dynamic-config.yaml\n\nimages:\n- name: temporalio/auto-setup\n  newTag: 1.22.0-dev\n\nreplicas:\n- name: temporal-server\n  count: 1\n\ncommonLabels:\n  environment: development\n  project: temporal\n</code></pre> <pre><code># environments/dev/namespace.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: temporal-dev\n  labels:\n    name: temporal-dev\n    environment: development\n    project: temporal\n  annotations:\n    argocd.argoproj.io/sync-wave: \"0\"\n</code></pre> <pre><code># environments/dev/temporal/values.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: temporal-server\nspec:\n  replicas: 1\n  template:\n    spec:\n      containers:\n      - name: temporal\n        env:\n        - name: LOG_LEVEL\n          value: debug\n        - name: SERVICES\n          value: history,matching,worker,frontend\n        - name: TEMPORAL_CLI_ADDRESS\n          value: temporal-server:7233\n        resources:\n          requests:\n            memory: 256Mi\n            cpu: 100m\n          limits:\n            memory: 512Mi\n            cpu: 250m\n</code></pre>"},{"location":"gitops/environment-management/#staging-environment_1","title":"Staging Environment","text":"<pre><code># environments/staging/kustomization.yaml\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\nnamespace: temporal-staging\n\nresources:\n- ../../base/temporal\n- ../../base/observability\n- ../../base/security\n- namespace.yaml\n\npatchesStrategicMerge:\n- temporal/values.yaml\n- security/rbac.yaml\n\nconfigMapGenerator:\n- name: temporal-config\n  files:\n  - temporal/server-config.yaml\n- name: temporal-dynamic-config\n  files:\n  - temporal/dynamic-config.yaml\n\nsecretGenerator:\n- name: temporal-tls\n  files:\n  - temporal/tls/ca.crt\n  - temporal/tls/tls.crt\n  - temporal/tls/tls.key\n\nimages:\n- name: temporalio/auto-setup\n  newTag: 1.22.0\n\nreplicas:\n- name: temporal-server\n  count: 2\n\ncommonLabels:\n  environment: staging\n  project: temporal\n</code></pre> <pre><code># environments/staging/temporal/values.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: temporal-server\nspec:\n  replicas: 2\n  template:\n    spec:\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchLabels:\n                  app: temporal-server\n              topologyKey: kubernetes.io/hostname\n      containers:\n      - name: temporal\n        env:\n        - name: LOG_LEVEL\n          value: info\n        - name: SERVICES\n          value: history,matching,worker,frontend\n        - name: TLS_ENABLED\n          value: \"true\"\n        - name: TLS_CERT_FILE\n          value: /etc/temporal/tls/tls.crt\n        - name: TLS_KEY_FILE\n          value: /etc/temporal/tls/tls.key\n        - name: TLS_CA_FILE\n          value: /etc/temporal/tls/ca.crt\n        volumeMounts:\n        - name: tls\n          mountPath: /etc/temporal/tls\n          readOnly: true\n        resources:\n          requests:\n            memory: 512Mi\n            cpu: 250m\n          limits:\n            memory: 1Gi\n            cpu: 500m\n      volumes:\n      - name: tls\n        secret:\n          secretName: temporal-tls\n</code></pre>"},{"location":"gitops/environment-management/#production-environment_1","title":"Production Environment","text":"<pre><code># environments/production/kustomization.yaml\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\nnamespace: temporal-production\n\nresources:\n- ../../base/temporal\n- ../../base/observability\n- ../../base/security\n- namespace.yaml\n\npatchesStrategicMerge:\n- temporal/values.yaml\n- security/rbac.yaml\n- security/network-policies.yaml\n- security/pod-security.yaml\n\nconfigMapGenerator:\n- name: temporal-config\n  files:\n  - temporal/server-config.yaml\n- name: temporal-dynamic-config\n  files:\n  - temporal/dynamic-config.yaml\n\nsecretGenerator:\n- name: temporal-tls\n  files:\n  - temporal/tls/ca.crt\n  - temporal/tls/tls.crt\n  - temporal/tls/tls.key\n\nimages:\n- name: temporalio/auto-setup\n  newTag: 1.22.0\n\nreplicas:\n- name: temporal-server\n  count: 3\n\ncommonLabels:\n  environment: production\n  project: temporal\n</code></pre> <pre><code># environments/production/temporal/values.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: temporal-server\nspec:\n  replicas: 3\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 1\n      maxSurge: 1\n  template:\n    spec:\n      affinity:\n        podAntiAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app: temporal-server\n            topologyKey: kubernetes.io/hostname\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: node-type\n                operator: In\n                values:\n                - temporal\n      tolerations:\n      - key: temporal\n        operator: Equal\n        value: \"true\"\n        effect: NoSchedule\n      containers:\n      - name: temporal\n        env:\n        - name: LOG_LEVEL\n          value: warn\n        - name: SERVICES\n          value: history,matching,worker,frontend\n        - name: TLS_ENABLED\n          value: \"true\"\n        - name: TLS_CERT_FILE\n          value: /etc/temporal/tls/tls.crt\n        - name: TLS_KEY_FILE\n          value: /etc/temporal/tls/tls.key\n        - name: TLS_CA_FILE\n          value: /etc/temporal/tls/ca.crt\n        - name: TEMPORAL_BROADCAST_ADDRESS\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        volumeMounts:\n        - name: tls\n          mountPath: /etc/temporal/tls\n          readOnly: true\n        resources:\n          requests:\n            memory: 2Gi\n            cpu: 1000m\n          limits:\n            memory: 4Gi\n            cpu: 2000m\n        livenessProbe:\n          exec:\n            command:\n            - temporal\n            - workflow\n            - list\n            - --namespace\n            - default\n          initialDelaySeconds: 60\n          periodSeconds: 30\n          timeoutSeconds: 10\n          failureThreshold: 3\n        readinessProbe:\n          exec:\n            command:\n            - temporal\n            - workflow\n            - list\n            - --namespace\n            - default\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          timeoutSeconds: 5\n          failureThreshold: 3\n      volumes:\n      - name: tls\n        secret:\n          secretName: temporal-tls\n</code></pre>"},{"location":"gitops/environment-management/#argocd-applicationsets","title":"ArgoCD ApplicationSets","text":""},{"location":"gitops/environment-management/#environment-applicationset","title":"Environment ApplicationSet","text":"<pre><code># argocd/applicationsets/temporal-environments.yaml\napiVersion: argoproj.io/v1alpha1\nkind: ApplicationSet\nmetadata:\n  name: temporal-environments\n  namespace: argocd\nspec:\n  generators:\n  - git:\n      repoURL: https://github.com/company/temporal-environments\n      revision: HEAD\n      directories:\n      - path: environments/*\n  - matrix:\n      generators:\n      - git:\n          repoURL: https://github.com/company/temporal-environments\n          revision: HEAD\n          directories:\n          - path: environments/*\n      - clusters: {}\n  template:\n    metadata:\n      name: '{{path.basename}}-{{cluster.name}}'\n      labels:\n        environment: '{{path.basename}}'\n        cluster: '{{cluster.name}}'\n    spec:\n      project: 'temporal-{{path.basename}}'\n      source:\n        repoURL: https://github.com/company/temporal-environments\n        targetRevision: HEAD\n        path: '{{path}}'\n      destination:\n        server: '{{cluster.server}}'\n        namespace: 'temporal-{{path.basename}}'\n      syncPolicy:\n        automated:\n          prune: true\n          selfHeal: true\n        syncOptions:\n        - CreateNamespace=true\n        - ApplyOutOfSyncOnly=true\n      ignoreDifferences:\n      - group: apps\n        kind: Deployment\n        jsonPointers:\n        - /spec/replicas\n  syncPolicy:\n    preserveResourcesOnDeletion: false\n</code></pre>"},{"location":"gitops/environment-management/#progressive-deployment-applicationset","title":"Progressive Deployment ApplicationSet","text":"<pre><code># argocd/applicationsets/progressive-deployment.yaml\napiVersion: argoproj.io/v1alpha1\nkind: ApplicationSet\nmetadata:\n  name: temporal-progressive-deployment\n  namespace: argocd\nspec:\n  generators:\n  - pullRequest:\n      github:\n        owner: company\n        repo: temporal-environments\n        tokenRef:\n          secretName: github-token\n          key: token\n      requeueAfterSeconds: 300\n  template:\n    metadata:\n      name: 'pr-{{number}}-{{head_sha}}'\n      labels:\n        pull-request: '{{number}}'\n        branch: '{{branch}}'\n    spec:\n      project: temporal-dev\n      source:\n        repoURL: '{{head_sha}}'\n        targetRevision: '{{head_sha}}'\n        path: environments/dev\n      destination:\n        server: https://kubernetes.default.svc\n        namespace: 'temporal-pr-{{number}}'\n      syncPolicy:\n        automated:\n          prune: true\n          selfHeal: true\n        syncOptions:\n        - CreateNamespace=true\n      info:\n      - name: 'Pull Request'\n        value: 'https://github.com/company/temporal-environments/pull/{{number}}'\n</code></pre>"},{"location":"gitops/environment-management/#environment-specific-configurations","title":"Environment-Specific Configurations","text":""},{"location":"gitops/environment-management/#security-configurations","title":"Security Configurations","text":""},{"location":"gitops/environment-management/#development-security","title":"Development Security","text":"<pre><code># environments/dev/security/rbac.yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  namespace: temporal-dev\n  name: temporal-dev-access\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"services\", \"configmaps\", \"secrets\"]\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n- apiGroups: [\"apps\"]\n  resources: [\"deployments\", \"replicasets\"]\n  verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\", \"delete\"]\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: temporal-dev-binding\n  namespace: temporal-dev\nsubjects:\n- kind: Group\n  name: temporal-developers\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: temporal-dev-access\n  apiGroup: rbac.authorization.k8s.io\n</code></pre>"},{"location":"gitops/environment-management/#production-security","title":"Production Security","text":"<pre><code># environments/production/security/rbac.yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  namespace: temporal-production\n  name: temporal-prod-readonly\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"services\", \"configmaps\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"apps\"]\n  resources: [\"deployments\", \"replicasets\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  namespace: temporal-production\n  name: temporal-prod-admin\nrules:\n- apiGroups: [\"\"]\n  resources: [\"*\"]\n  verbs: [\"*\"]\n- apiGroups: [\"apps\"]\n  resources: [\"*\"]\n  verbs: [\"*\"]\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: temporal-prod-readonly-binding\n  namespace: temporal-production\nsubjects:\n- kind: Group\n  name: temporal-users\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: temporal-prod-readonly\n  apiGroup: rbac.authorization.k8s.io\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: temporal-prod-admin-binding\n  namespace: temporal-production\nsubjects:\n- kind: Group\n  name: temporal-admins\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: temporal-prod-admin\n  apiGroup: rbac.authorization.k8s.io\n</code></pre>"},{"location":"gitops/environment-management/#network-policies","title":"Network Policies","text":"<pre><code># environments/production/security/network-policies.yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: temporal-server-netpol\n  namespace: temporal-production\nspec:\n  podSelector:\n    matchLabels:\n      app: temporal-server\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-production\n    - namespaceSelector:\n        matchLabels:\n          name: monitoring\n    ports:\n    - protocol: TCP\n      port: 7233\n    - protocol: TCP\n      port: 7234\n  egress:\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-production\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 5432  # PostgreSQL\n    - protocol: TCP\n      port: 53    # DNS\n    - protocol: UDP\n      port: 53    # DNS\n\n---\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: deny-all-default\n  namespace: temporal-production\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\n</code></pre>"},{"location":"gitops/environment-management/#pod-security-standards","title":"Pod Security Standards","text":"<pre><code># environments/production/security/pod-security.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: temporal-production\n  labels:\n    pod-security.kubernetes.io/enforce: restricted\n    pod-security.kubernetes.io/audit: restricted\n    pod-security.kubernetes.io/warn: restricted\n\n---\napiVersion: policy/v1beta1\nkind: PodSecurityPolicy\nmetadata:\n  name: temporal-psp\n  namespace: temporal-production\nspec:\n  privileged: false\n  allowPrivilegeEscalation: false\n  requiredDropCapabilities:\n    - ALL\n  volumes:\n    - 'configMap'\n    - 'emptyDir'\n    - 'projected'\n    - 'secret'\n    - 'downwardAPI'\n    - 'persistentVolumeClaim'\n  runAsUser:\n    rule: 'MustRunAsNonRoot'\n  seLinux:\n    rule: 'RunAsAny'\n  fsGroup:\n    rule: 'RunAsAny'\n</code></pre>"},{"location":"gitops/environment-management/#environment-promotion","title":"Environment Promotion","text":""},{"location":"gitops/environment-management/#promotion-workflow","title":"Promotion Workflow","text":"<pre><code>#!/bin/bash\n# scripts/promote-environment.sh\n\nset -euo pipefail\n\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" &amp;&amp; pwd)\"\nPROJECT_ROOT=\"$(dirname \"$SCRIPT_DIR\")\"\n\n# Configuration\nSOURCE_ENV=\"\"\nTARGET_ENV=\"\"\nDRY_RUN=\"false\"\nAUTO_APPROVE=\"false\"\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\nerror() {\n    echo -e \"\\033[0;31m[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1\\033[0m\"\n    exit 1\n}\n\nwarn() {\n    echo -e \"\\033[1;33m[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1\\033[0m\"\n}\n\nusage() {\n    cat &lt;&lt; EOF\nUsage: $0 [OPTIONS]\n\nOptions:\n    -s, --source-env ENV        Source environment (dev, staging)\n    -t, --target-env ENV        Target environment (staging, production)\n    -d, --dry-run              Perform dry run without applying changes\n    -a, --auto-approve         Skip manual approval prompts\n    -h, --help                 Show this help message\n\nExamples:\n    $0 --source-env dev --target-env staging\n    $0 --source-env staging --target-env production --dry-run\nEOF\n}\n\nvalidate_environments() {\n    local valid_envs=(\"dev\" \"staging\" \"production\")\n\n    if [[ ! \" ${valid_envs[@]} \" =~ \" ${SOURCE_ENV} \" ]]; then\n        error \"Invalid source environment: $SOURCE_ENV\"\n    fi\n\n    if [[ ! \" ${valid_envs[@]} \" =~ \" ${TARGET_ENV} \" ]]; then\n        error \"Invalid target environment: $TARGET_ENV\"\n    fi\n\n    if [[ \"$SOURCE_ENV\" == \"$TARGET_ENV\" ]]; then\n        error \"Source and target environments cannot be the same\"\n    fi\n\n    # Validate promotion path\n    case \"$SOURCE_ENV:$TARGET_ENV\" in\n        \"dev:staging\"|\"staging:production\")\n            log \"\u2713 Valid promotion path: $SOURCE_ENV \u2192 $TARGET_ENV\"\n            ;;\n        *)\n            error \"Invalid promotion path: $SOURCE_ENV \u2192 $TARGET_ENV. Valid paths: dev\u2192staging, staging\u2192production\"\n            ;;\n    esac\n}\n\nget_current_versions() {\n    local env=\"$1\"\n    local env_file=\"$PROJECT_ROOT/environments/$env/kustomization.yaml\"\n\n    if [[ ! -f \"$env_file\" ]]; then\n        error \"Environment file not found: $env_file\"\n    fi\n\n    # Extract image versions\n    yq eval '.images[] | .name + \":\" + .newTag' \"$env_file\"\n}\n\nrun_tests() {\n    local env=\"$1\"\n\n    log \"Running validation tests for $env environment...\"\n\n    # Kustomize validation\n    if ! kustomize build \"$PROJECT_ROOT/environments/$env\" &gt; /dev/null; then\n        error \"Kustomize validation failed for $env environment\"\n    fi\n\n    # Kubernetes validation\n    if ! kustomize build \"$PROJECT_ROOT/environments/$env\" | kubectl apply --dry-run=client -f -; then\n        error \"Kubernetes validation failed for $env environment\"\n    fi\n\n    # Security scanning\n    if command -v kubesec &amp;&gt; /dev/null; then\n        log \"Running security scan...\"\n        kustomize build \"$PROJECT_ROOT/environments/$env\" | kubesec scan -\n    fi\n\n    # Policy validation\n    if command -v conftest &amp;&gt; /dev/null; then\n        log \"Running policy validation...\"\n        kustomize build \"$PROJECT_ROOT/environments/$env\" | conftest verify --policy \"$PROJECT_ROOT/policies/\"\n    fi\n\n    log \"\u2713 All validation tests passed for $env environment\"\n}\n\npromote_configuration() {\n    local source_env=\"$1\"\n    local target_env=\"$2\"\n\n    log \"Promoting configuration from $source_env to $target_env...\"\n\n    # Get source versions\n    local source_file=\"$PROJECT_ROOT/environments/$source_env/kustomization.yaml\"\n    local target_file=\"$PROJECT_ROOT/environments/$target_env/kustomization.yaml\"\n\n    # Create backup\n    cp \"$target_file\" \"$target_file.backup.$(date +%Y%m%d_%H%M%S)\"\n\n    # Extract and update image versions\n    while IFS= read -r image_line; do\n        local image_name=$(echo \"$image_line\" | cut -d: -f1)\n        local new_tag=$(echo \"$image_line\" | cut -d: -f2)\n\n        log \"Updating $image_name to $new_tag in $target_env\"\n\n        # Update the target kustomization file\n        yq eval \"(.images[] | select(.name == \\\"$image_name\\\") | .newTag) = \\\"$new_tag\\\"\" -i \"$target_file\"\n    done &lt; &lt;(get_current_versions \"$source_env\")\n\n    log \"\u2713 Configuration promoted successfully\"\n}\n\ncreate_pull_request() {\n    local source_env=\"$1\"\n    local target_env=\"$2\"\n\n    # Create feature branch\n    local branch_name=\"promote-${source_env}-to-${target_env}-$(date +%Y%m%d_%H%M%S)\"\n\n    git checkout -b \"$branch_name\"\n    git add .\n    git commit -m \"Promote $source_env configuration to $target_env\n\n    - Updated image versions from $source_env environment\n    - Validated configurations and security policies\n    - Ready for $target_env deployment\"\n\n    git push origin \"$branch_name\"\n\n    # Create PR using GitHub CLI if available\n    if command -v gh &amp;&gt; /dev/null; then\n        gh pr create \\\n            --title \"Promote $source_env to $target_env\" \\\n            --body \"Automated promotion of configuration from $source_env to $target_env environment.\" \\\n            --label \"promotion\" \\\n            --label \"$target_env\"\n    else\n        log \"GitHub CLI not available. Please create PR manually for branch: $branch_name\"\n    fi\n}\n\nmain() {\n    # Parse arguments\n    while [[ $# -gt 0 ]]; do\n        case $1 in\n            -s|--source-env)\n                SOURCE_ENV=\"$2\"\n                shift 2\n                ;;\n            -t|--target-env)\n                TARGET_ENV=\"$2\"\n                shift 2\n                ;;\n            -d|--dry-run)\n                DRY_RUN=\"true\"\n                shift\n                ;;\n            -a|--auto-approve)\n                AUTO_APPROVE=\"true\"\n                shift\n                ;;\n            -h|--help)\n                usage\n                exit 0\n                ;;\n            *)\n                error \"Unknown option: $1\"\n                ;;\n        esac\n    done\n\n    # Validate required parameters\n    if [[ -z \"$SOURCE_ENV\" || -z \"$TARGET_ENV\" ]]; then\n        error \"Source and target environments are required\"\n    fi\n\n    validate_environments\n\n    log \"Starting promotion: $SOURCE_ENV \u2192 $TARGET_ENV\"\n\n    # Show current versions\n    log \"Current versions in $SOURCE_ENV:\"\n    get_current_versions \"$SOURCE_ENV\"\n\n    log \"Current versions in $TARGET_ENV:\"\n    get_current_versions \"$TARGET_ENV\"\n\n    # Run validation tests\n    run_tests \"$SOURCE_ENV\"\n    run_tests \"$TARGET_ENV\"\n\n    # Manual approval for production\n    if [[ \"$TARGET_ENV\" == \"production\" &amp;&amp; \"$AUTO_APPROVE\" != \"true\" ]]; then\n        echo\n        warn \"PRODUCTION DEPLOYMENT DETECTED\"\n        echo \"Source Environment: $SOURCE_ENV\"\n        echo \"Target Environment: $TARGET_ENV\"\n        echo\n        read -p \"Are you sure you want to promote to production? (yes/no): \" confirm\n\n        if [[ \"$confirm\" != \"yes\" ]]; then\n            log \"Promotion cancelled by user\"\n            exit 0\n        fi\n    fi\n\n    if [[ \"$DRY_RUN\" == \"true\" ]]; then\n        log \"DRY RUN: Would promote $SOURCE_ENV configuration to $TARGET_ENV\"\n        exit 0\n    fi\n\n    # Perform promotion\n    promote_configuration \"$SOURCE_ENV\" \"$TARGET_ENV\"\n\n    # Validate promoted configuration\n    run_tests \"$TARGET_ENV\"\n\n    # Create pull request\n    create_pull_request \"$SOURCE_ENV\" \"$TARGET_ENV\"\n\n    log \"\u2713 Promotion completed successfully!\"\n}\n\nmain \"$@\"\n</code></pre>"},{"location":"gitops/environment-management/#environment-validation","title":"Environment Validation","text":"<pre><code>#!/bin/bash\n# scripts/validate-environment.sh\n\nset -euo pipefail\n\nENVIRONMENT=\"\"\nVERBOSE=\"false\"\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\nerror() {\n    echo -e \"\\033[0;31m[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1\\033[0m\"\n    exit 1\n}\n\nverbose() {\n    if [[ \"$VERBOSE\" == \"true\" ]]; then\n        echo -e \"\\033[0;36m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n    fi\n}\n\nusage() {\n    cat &lt;&lt; EOF\nUsage: $0 [OPTIONS]\n\nOptions:\n    -e, --environment ENV      Environment to validate (dev, staging, production)\n    -v, --verbose             Enable verbose output\n    -h, --help                Show this help message\n\nExamples:\n    $0 --environment dev\n    $0 --environment production --verbose\nEOF\n}\n\nvalidate_structure() {\n    local env=\"$1\"\n    local env_dir=\"environments/$env\"\n\n    log \"Validating structure for $env environment...\"\n\n    # Check required files\n    local required_files=(\n        \"$env_dir/kustomization.yaml\"\n        \"$env_dir/namespace.yaml\"\n        \"$env_dir/temporal/values.yaml\"\n    )\n\n    for file in \"${required_files[@]}\"; do\n        if [[ ! -f \"$file\" ]]; then\n            error \"Required file missing: $file\"\n        fi\n        verbose \"\u2713 Found: $file\"\n    done\n\n    log \"\u2713 Structure validation passed\"\n}\n\nvalidate_syntax() {\n    local env=\"$1\"\n    local env_dir=\"environments/$env\"\n\n    log \"Validating YAML syntax for $env environment...\"\n\n    # Validate all YAML files\n    while IFS= read -r -d '' file; do\n        if ! yq eval '.' \"$file\" &gt; /dev/null 2&gt;&amp;1; then\n            error \"Invalid YAML syntax in: $file\"\n        fi\n        verbose \"\u2713 Valid YAML: $file\"\n    done &lt; &lt;(find \"$env_dir\" -name \"*.yaml\" -print0)\n\n    log \"\u2713 YAML syntax validation passed\"\n}\n\nvalidate_kustomize() {\n    local env=\"$1\"\n    local env_dir=\"environments/$env\"\n\n    log \"Validating Kustomize build for $env environment...\"\n\n    if ! kustomize build \"$env_dir\" &gt; /dev/null; then\n        error \"Kustomize build failed for $env environment\"\n    fi\n\n    verbose \"\u2713 Kustomize build successful\"\n    log \"\u2713 Kustomize validation passed\"\n}\n\nvalidate_kubernetes() {\n    local env=\"$1\"\n    local env_dir=\"environments/$env\"\n\n    log \"Validating Kubernetes manifests for $env environment...\"\n\n    # Dry-run apply\n    if ! kustomize build \"$env_dir\" | kubectl apply --dry-run=client -f -; then\n        error \"Kubernetes manifest validation failed for $env environment\"\n    fi\n\n    log \"\u2713 Kubernetes validation passed\"\n}\n\nvalidate_security() {\n    local env=\"$1\"\n    local env_dir=\"environments/$env\"\n\n    log \"Validating security policies for $env environment...\"\n\n    # Check for security configurations in production\n    if [[ \"$env\" == \"production\" ]]; then\n        local security_files=(\n            \"$env_dir/security/rbac.yaml\"\n            \"$env_dir/security/network-policies.yaml\"\n            \"$env_dir/security/pod-security.yaml\"\n        )\n\n        for file in \"${security_files[@]}\"; do\n            if [[ ! -f \"$file\" ]]; then\n                error \"Security file missing in production: $file\"\n            fi\n            verbose \"\u2713 Found security file: $file\"\n        done\n    fi\n\n    # Validate with kubesec if available\n    if command -v kubesec &amp;&gt; /dev/null; then\n        verbose \"Running kubesec security scan...\"\n        local temp_file=$(mktemp)\n        kustomize build \"$env_dir\" &gt; \"$temp_file\"\n\n        if ! kubesec scan \"$temp_file\" | jq -e '.[] | select(.score &lt; 0)' &gt; /dev/null; then\n            verbose \"\u2713 Security scan passed\"\n        else\n            warn \"Security scan found issues. Review kubesec output.\"\n        fi\n\n        rm \"$temp_file\"\n    fi\n\n    log \"\u2713 Security validation passed\"\n}\n\nvalidate_resources() {\n    local env=\"$1\"\n    local env_dir=\"environments/$env\"\n\n    log \"Validating resource configurations for $env environment...\"\n\n    # Extract and validate resource configurations\n    local temp_file=$(mktemp)\n    kustomize build \"$env_dir\" &gt; \"$temp_file\"\n\n    # Check that all containers have resource limits\n    local containers_without_limits=$(kubectl apply --dry-run=client -f \"$temp_file\" -o json | \\\n        jq -r '.items[] | select(.kind == \"Deployment\") | \n               .spec.template.spec.containers[] | \n               select(.resources.limits == null) | \n               .name' || true)\n\n    if [[ -n \"$containers_without_limits\" ]]; then\n        warn \"Containers without resource limits found: $containers_without_limits\"\n    else\n        verbose \"\u2713 All containers have resource limits\"\n    fi\n\n    # Validate environment-specific resource requirements\n    case \"$env\" in\n        \"dev\")\n            # Check that dev has minimal resources\n            ;;\n        \"staging\")\n            # Check that staging has moderate resources\n            ;;\n        \"production\")\n            # Check that production has adequate resources\n            local min_memory=\"1Gi\"\n            local min_cpu=\"500m\"\n            ;;\n    esac\n\n    rm \"$temp_file\"\n    log \"\u2713 Resource validation passed\"\n}\n\nvalidate_environment_specific() {\n    local env=\"$1\"\n\n    log \"Running environment-specific validations for $env...\"\n\n    case \"$env\" in\n        \"dev\")\n            # Development-specific validations\n            verbose \"Validating development environment specifics...\"\n            ;;\n        \"staging\")\n            # Staging-specific validations\n            verbose \"Validating staging environment specifics...\"\n            ;;\n        \"production\")\n            # Production-specific validations\n            verbose \"Validating production environment specifics...\"\n\n            # Ensure high availability\n            local env_dir=\"environments/$env\"\n            local replicas=$(kustomize build \"$env_dir\" | yq eval 'select(.kind == \"Deployment\") | .spec.replicas' -)\n            if [[ \"$replicas\" -lt 2 ]]; then\n                warn \"Production deployment should have at least 2 replicas for high availability\"\n            fi\n            ;;\n    esac\n\n    log \"\u2713 Environment-specific validation passed\"\n}\n\nmain() {\n    # Parse arguments\n    while [[ $# -gt 0 ]]; do\n        case $1 in\n            -e|--environment)\n                ENVIRONMENT=\"$2\"\n                shift 2\n                ;;\n            -v|--verbose)\n                VERBOSE=\"true\"\n                shift\n                ;;\n            -h|--help)\n                usage\n                exit 0\n                ;;\n            *)\n                error \"Unknown option: $1\"\n                ;;\n        esac\n    done\n\n    # Validate required parameters\n    if [[ -z \"$ENVIRONMENT\" ]]; then\n        error \"Environment is required\"\n    fi\n\n    # Validate environment\n    local valid_envs=(\"dev\" \"staging\" \"production\")\n    if [[ ! \" ${valid_envs[@]} \" =~ \" ${ENVIRONMENT} \" ]]; then\n        error \"Invalid environment: $ENVIRONMENT. Valid options: ${valid_envs[*]}\"\n    fi\n\n    log \"Starting validation for $ENVIRONMENT environment...\"\n\n    # Run all validations\n    validate_structure \"$ENVIRONMENT\"\n    validate_syntax \"$ENVIRONMENT\"\n    validate_kustomize \"$ENVIRONMENT\"\n    validate_kubernetes \"$ENVIRONMENT\"\n    validate_security \"$ENVIRONMENT\"\n    validate_resources \"$ENVIRONMENT\"\n    validate_environment_specific \"$ENVIRONMENT\"\n\n    log \"\u2705 All validations passed for $ENVIRONMENT environment!\"\n}\n\nmain \"$@\"\n</code></pre>"},{"location":"gitops/environment-management/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"gitops/environment-management/#environment-specific-monitoring","title":"Environment-Specific Monitoring","text":"<pre><code># environments/production/observability/prometheus.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: prometheus-config\n  namespace: temporal-production\ndata:\n  prometheus.yml: |\n    global:\n      scrape_interval: 15s\n      evaluation_interval: 15s\n\n    rule_files:\n      - \"temporal-rules.yml\"\n      - \"infrastructure-rules.yml\"\n\n    scrape_configs:\n    - job_name: 'temporal-server'\n      kubernetes_sd_configs:\n      - role: endpoints\n        namespaces:\n          names:\n          - temporal-production\n      relabel_configs:\n      - source_labels: [__meta_kubernetes_service_name]\n        action: keep\n        regex: temporal-server\n      - source_labels: [__meta_kubernetes_endpoint_port_name]\n        action: keep\n        regex: metrics\n      - source_labels: [__meta_kubernetes_pod_name]\n        target_label: pod\n      - source_labels: [__meta_kubernetes_service_name]\n        target_label: service\n      - target_label: environment\n        replacement: production\n\n    - job_name: 'temporal-workers'\n      kubernetes_sd_configs:\n      - role: endpoints\n        namespaces:\n          names:\n          - temporal-production\n      relabel_configs:\n      - source_labels: [__meta_kubernetes_service_name]\n        action: keep\n        regex: temporal-worker\n      - target_label: environment\n        replacement: production\n\n    alerting:\n      alertmanagers:\n      - static_configs:\n        - targets:\n          - alertmanager.monitoring.svc.cluster.local:9093\n</code></pre>"},{"location":"gitops/environment-management/#environment-health-checks","title":"Environment Health Checks","text":"<pre><code># argocd/applications/environment-health.yaml\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: environment-health-checks\n  namespace: argocd\nspec:\n  project: temporal-monitoring\n  source:\n    repoURL: https://github.com/company/temporal-environments\n    targetRevision: HEAD\n    path: monitoring/health-checks\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: temporal-monitoring\n  syncPolicy:\n    automated:\n      prune: true\n      selfHeal: true\n    syncOptions:\n    - CreateNamespace=true\n</code></pre>"},{"location":"gitops/environment-management/#disaster-recovery","title":"Disaster Recovery","text":""},{"location":"gitops/environment-management/#environment-backup-strategy","title":"Environment Backup Strategy","text":"<pre><code>#!/bin/bash\n# scripts/backup-environment.sh\n\nset -euo pipefail\n\nENVIRONMENT=\"\"\nBACKUP_LOCATION=\"\"\n\nbackup_environment() {\n    local env=\"$1\"\n    local backup_dir=\"$2/$(date +%Y%m%d_%H%M%S)\"\n\n    mkdir -p \"$backup_dir\"\n\n    # Backup Kubernetes resources\n    kubectl get all -n \"temporal-$env\" -o yaml &gt; \"$backup_dir/k8s-resources.yaml\"\n    kubectl get secrets -n \"temporal-$env\" -o yaml &gt; \"$backup_dir/secrets.yaml\"\n    kubectl get configmaps -n \"temporal-$env\" -o yaml &gt; \"$backup_dir/configmaps.yaml\"\n\n    # Backup Git configuration\n    tar -czf \"$backup_dir/git-config.tar.gz\" \"environments/$env\"\n\n    # Backup database if applicable\n    if kubectl get secret temporal-postgres -n \"temporal-$env\" &amp;&gt; /dev/null; then\n        pg_dump \"$(kubectl get secret temporal-postgres -n \"temporal-$env\" -o jsonpath='{.data.connection-string}' | base64 -d)\" &gt; \"$backup_dir/database.sql\"\n    fi\n\n    log \"\u2713 Environment backup completed: $backup_dir\"\n}\n</code></pre> <p>This comprehensive environment management guide provides enterprise-grade GitOps practices for managing multiple Temporal.io environments with proper security, monitoring, and operational procedures.</p>"},{"location":"gitops/helm-configuration/","title":"Temporal Helm Deployment Guide","text":"<p>This guide covers deploying Temporal using Helm with specific enterprise requirements including external PostgreSQL, security context configuration, Docker proxy registry, nginx ingress, and external-secrets integration.</p>"},{"location":"gitops/helm-configuration/#prerequisites","title":"Prerequisites","text":"<ul> <li>Kubernetes cluster (1.19+)</li> <li>Helm 3.x</li> <li>kubectl configured</li> <li>PostgreSQL database (external)</li> <li>nginx-ingress controller</li> <li>external-secrets operator (optional)</li> </ul>"},{"location":"gitops/helm-configuration/#helm-charts-dependencies","title":"Helm Charts Dependencies","text":"<p>The Temporal Helm chart includes the following dependencies:</p> Chart Name Version Repository URL App Version Purpose temporal 0.64.0 https://go.temporal.io/helm-charts 1.28.0 Main Temporal orchestration engine cassandra 0.14.3 https://charts.helm.sh/incubator 3.11.3 Database storage (optional) prometheus 25.22.0 https://prometheus-community.github.io/helm-charts v2.53.0 Metrics collection and monitoring elasticsearch 7.17.3 https://helm.elastic.co 7.17.3 Advanced visibility store (optional) grafana 8.0.2 https://grafana.github.io/helm-charts 10.4.2 Monitoring dashboards"},{"location":"gitops/helm-configuration/#prometheus-sub-dependencies","title":"Prometheus Sub-Dependencies","text":"<p>The Prometheus chart includes additional sub-charts:</p> Chart Name Version Repository URL Purpose alertmanager 1.11.* https://prometheus-community.github.io/helm-charts Alert management kube-state-metrics 5.20.* https://prometheus-community.github.io/helm-charts Kubernetes metrics prometheus-node-exporter 4.36.* https://prometheus-community.github.io/helm-charts Node-level metrics prometheus-pushgateway 2.13.* https://prometheus-community.github.io/helm-charts Push gateway for batch jobs"},{"location":"gitops/helm-configuration/#repository-setup","title":"Repository Setup","text":"<p>To add all required Helm repositories:</p> <pre><code># Add Temporal repository\nhelm repo add temporalio https://go.temporal.io/helm-charts\n\n# Add dependency repositories (if deploying components separately)\nhelm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm repo add elastic https://helm.elastic.co\nhelm repo add grafana https://grafana.github.io/helm-charts\nhelm repo add incubator https://charts.helm.sh/incubator\n\n# Update repositories\nhelm repo update\n</code></pre>"},{"location":"gitops/helm-configuration/#external-postgresql-database-configuration","title":"External PostgreSQL Database Configuration","text":""},{"location":"gitops/helm-configuration/#basic-postgresql-configuration","title":"Basic PostgreSQL Configuration","text":"<p>Create a custom values file (<code>values-postgresql.yaml</code>) to configure Temporal with external PostgreSQL:</p> <pre><code>server:\n  config:\n    persistence:\n      default:\n        driver: \"sql\"\n        sql:\n          driver: \"postgres12\"\n          host: \"postgresql.example.com\"\n          port: 5432\n          database: \"temporal\"\n          user: \"temporal_user\"\n          # Use existingSecret instead of password for production\n          existingSecret: \"temporal-default-store\"\n          maxConns: 20\n          maxIdleConns: 20\n          maxConnLifetime: \"1h\"\n\n      visibility:\n        driver: \"sql\"\n        sql:\n          driver: \"postgres12\"\n          host: \"postgresql.example.com\"\n          port: 5432\n          database: \"temporal_visibility\"\n          user: \"temporal_user\"\n          existingSecret: \"temporal-visibility-store\"\n          maxConns: 20\n          maxIdleConns: 20\n          maxConnLifetime: \"1h\"\n\n# Disable embedded databases\ncassandra:\n  enabled: false\nmysql:\n  enabled: false\npostgresql:\n  enabled: false\n</code></pre>"},{"location":"gitops/helm-configuration/#kubernetes-secrets-for-database-credentials","title":"Kubernetes Secrets for Database Credentials","text":"<p>Create secrets for database credentials:</p> <pre><code># Create secret for default store\nkubectl create secret generic temporal-default-store \\\n  --from-literal=password='your-password-here'\n\n# Create secret for visibility store\nkubectl create secret generic temporal-visibility-store \\\n  --from-literal=password='your-password-here'\n</code></pre>"},{"location":"gitops/helm-configuration/#postgresql-with-tls","title":"PostgreSQL with TLS","text":"<p>For TLS-enabled PostgreSQL connections:</p> <pre><code>server:\n  config:\n    persistence:\n      default:\n        sql:\n          tls:\n            enabled: true\n            enableHostVerification: true\n            serverName: \"postgresql.example.com\"\n            caFile: /etc/temporal/certs/ca.crt\n            certFile: /etc/temporal/certs/client.crt\n            keyFile: /etc/temporal/certs/client.key\n\n  additionalVolumes:\n    - name: postgres-tls-certs\n      secret:\n        secretName: postgres-tls-certs\n\n  additionalVolumeMounts:\n    - name: postgres-tls-certs\n      mountPath: /etc/temporal/certs\n      readOnly: true\n</code></pre>"},{"location":"gitops/helm-configuration/#security-context-configuration-uidgid-10000","title":"Security Context Configuration (UID/GID &gt; 10000)","text":"<p>Configure security context with UID/GID greater than 10000 for compliance:</p> <pre><code>server:\n  securityContext:\n    fsGroup: 10001\n    runAsUser: 10001\n    runAsGroup: 10001\n    runAsNonRoot: true\n\nadmintools:\n  securityContext:\n    fsGroup: 10001\n    runAsUser: 10001\n    runAsGroup: 10001\n    runAsNonRoot: true\n  containerSecurityContext:\n    allowPrivilegeEscalation: false\n    readOnlyRootFilesystem: true\n    capabilities:\n      drop:\n        - ALL\n\nweb:\n  securityContext:\n    fsGroup: 10001\n    runAsUser: 10001\n    runAsGroup: 10001\n    runAsNonRoot: true\n  containerSecurityContext:\n    allowPrivilegeEscalation: false\n    readOnlyRootFilesystem: true\n    capabilities:\n      drop:\n        - ALL\n</code></pre>"},{"location":"gitops/helm-configuration/#docker-registry-proxy-configuration","title":"Docker Registry Proxy Configuration","text":"<p>Configure all Temporal components to use <code>docker.proxyregistry.org</code> as the registry proxy:</p> <pre><code>server:\n  image:\n    repository: docker.proxyregistry.org/temporalio/server\n    tag: 1.29.1\n    pullPolicy: IfNotPresent\n\nadmintools:\n  image:\n    repository: docker.proxyregistry.org/temporalio/admin-tools\n    tag: 1.29.1-tctl-1.18.2-cli-1.3.0\n    pullPolicy: IfNotPresent\n\nweb:\n  image:\n    repository: docker.proxyregistry.org/temporalio/ui\n    tag: 2.37.1\n    pullPolicy: IfNotPresent\n\n# Configure image pull secrets if required\nimagePullSecrets:\n  - name: docker-proxy-registry-secret\n\n# Override dependency chart images\nelasticsearch:\n  image: docker.proxyregistry.org/elasticsearch/elasticsearch\n  imageTag: 7.17.3\n\nprometheus:\n  server:\n    image:\n      repository: docker.proxyregistry.org/prom/prometheus\n  alertmanager:\n    image:\n      repository: docker.proxyregistry.org/prom/alertmanager\n\ngrafana:\n  image:\n    repository: docker.proxyregistry.org/grafana/grafana\n</code></pre>"},{"location":"gitops/helm-configuration/#nginx-ingress-configuration","title":"Nginx Ingress Configuration","text":""},{"location":"gitops/helm-configuration/#web-ui-ingress","title":"Web UI Ingress","text":"<p>Configure ingress for the Temporal Web UI:</p> <pre><code>web:\n  ingress:\n    enabled: true\n    className: \"nginx\"\n    annotations:\n      nginx.ingress.kubernetes.io/rewrite-target: /\n      nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n      nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\n      cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n      nginx.ingress.kubernetes.io/proxy-body-size: \"100m\"\n      nginx.ingress.kubernetes.io/proxy-read-timeout: \"300\"\n      nginx.ingress.kubernetes.io/proxy-send-timeout: \"300\"\n    hosts:\n      - \"temporal-ui.example.com\"\n    tls:\n      - secretName: temporal-ui-tls\n        hosts:\n          - \"temporal-ui.example.com\"\n</code></pre>"},{"location":"gitops/helm-configuration/#frontend-service-ingress","title":"Frontend Service Ingress","text":"<p>Configure ingress for the Temporal frontend service (gRPC):</p> <pre><code>server:\n  frontend:\n    ingress:\n      enabled: true\n      className: \"nginx\"\n      annotations:\n        nginx.ingress.kubernetes.io/backend-protocol: \"GRPC\"\n        nginx.ingress.kubernetes.io/grpc-backend: \"true\"\n        nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n        cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n      hosts:\n        - \"temporal-grpc.example.com\"\n      tls:\n        - secretName: temporal-grpc-tls\n          hosts:\n            - \"temporal-grpc.example.com\"\n</code></pre>"},{"location":"gitops/helm-configuration/#grafana-ingress","title":"Grafana Ingress","text":"<p>Configure ingress for the Grafana dashboard:</p> <pre><code>grafana:\n  ingress:\n    enabled: true\n    ingressClassName: \"nginx\"\n    annotations:\n      nginx.ingress.kubernetes.io/rewrite-target: /\n      nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n      nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\n      cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n      nginx.ingress.kubernetes.io/proxy-body-size: \"100m\"\n      nginx.ingress.kubernetes.io/auth-type: basic\n      nginx.ingress.kubernetes.io/auth-secret: grafana-basic-auth\n      nginx.ingress.kubernetes.io/auth-realm: 'Authentication Required - Grafana'\n    path: /\n    pathType: Prefix\n    hosts:\n      - \"grafana.example.com\"\n    tls:\n      - secretName: grafana-tls\n        hosts:\n          - \"grafana.example.com\"\n</code></pre>"},{"location":"gitops/helm-configuration/#external-secrets-integration","title":"External Secrets Integration","text":""},{"location":"gitops/helm-configuration/#using-external-secrets-operator","title":"Using External Secrets Operator","text":"<p>Configure ExternalSecret resources to manage database credentials dynamically:</p> <pre><code># external-secrets-config.yaml\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: temporal-database-credentials\n  namespace: temporal\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: temporal-default-store\n    creationPolicy: Owner\n  data:\n    - secretKey: password\n      remoteRef:\n        key: secret/temporal/database\n        property: default_password\n\n---\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: temporal-visibility-credentials\n  namespace: temporal\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: temporal-visibility-store\n    creationPolicy: Owner\n  data:\n    - secretKey: password\n      remoteRef:\n        key: secret/temporal/database\n        property: visibility_password\n</code></pre>"},{"location":"gitops/helm-configuration/#tls-certificate-management","title":"TLS Certificate Management","text":"<p>Use external-secrets for automatic certificate provisioning:</p> <pre><code>apiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: temporal-tls-certificates\n  namespace: temporal\nspec:\n  refreshInterval: 24h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: postgres-tls-certs\n    creationPolicy: Owner\n    template:\n      type: kubernetes.io/tls\n  data:\n    - secretKey: ca.crt\n      remoteRef:\n        key: secret/temporal/certs\n        property: ca_certificate\n    - secretKey: tls.crt\n      remoteRef:\n        key: secret/temporal/certs\n        property: client_certificate\n    - secretKey: tls.key\n      remoteRef:\n        key: secret/temporal/certs\n        property: client_key\n</code></pre>"},{"location":"gitops/helm-configuration/#grafana-authentication","title":"Grafana Authentication","text":"<p>For Grafana basic authentication with external secrets:</p> <pre><code>apiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: grafana-credentials\n  namespace: temporal\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: grafana-basic-auth\n    creationPolicy: Owner\n    template:\n      type: Opaque\n      data:\n        auth: \"{{ .username }}:{{ .password | htpasswd }}\"\n  data:\n    - secretKey: username\n      remoteRef:\n        key: secret/temporal/grafana\n        property: admin_username\n    - secretKey: password\n      remoteRef:\n        key: secret/temporal/grafana\n        property: admin_password\n</code></pre> <p>Alternatively, create the basic auth secret manually:</p> <pre><code># Create basic auth secret for Grafana\nhtpasswd -c auth admin\nkubectl create secret generic grafana-basic-auth \\\n  --from-file=auth \\\n  --namespace=temporal\n</code></pre>"},{"location":"gitops/helm-configuration/#oidc-configuration","title":"OIDC Configuration","text":"<p>Configure OpenID Connect (OIDC) authentication for various components in the Temporal stack.</p>"},{"location":"gitops/helm-configuration/#temporal-server-oidcjwt-authorization","title":"Temporal Server OIDC/JWT Authorization","text":"<p>Temporal supports JWT-based authorization with OIDC providers. Configure JWT key provider and authorization:</p> <pre><code>server:\n  config:\n    # Define your Authorizer and ClaimMapper configuration\n    # See https://docs.temporal.io/self-hosted-guide/security#authorization\n    authorization:\n      jwtKeyProvider:\n        keySourceURIs:\n          - \"https://your-oidc-provider.com/.well-known/jwks.json\"\n          - \"https://your-oidc-provider.com/oauth2/v1/keys\"\n        refreshInterval: \"1h\"\n      permissionsClaimName: \"permissions\"\n      authorizer: \"default\"\n      claimMapper: \"default\"\n\n  # Mount OIDC certificates if needed\n  additionalVolumes:\n    - name: oidc-certs\n      secret:\n        secretName: oidc-tls-certs\n\n  additionalVolumeMounts:\n    - name: oidc-certs\n      mountPath: /etc/temporal/oidc-certs\n      readOnly: true\n</code></pre>"},{"location":"gitops/helm-configuration/#grafana-oidc-configuration","title":"Grafana OIDC Configuration","text":"<p>Configure Grafana to use OIDC for authentication:</p> <pre><code>grafana:\n  grafana.ini:\n    server:\n      domain: \"grafana.example.com\"\n      root_url: \"https://grafana.example.com\"\n\n    auth.generic_oauth:\n      enabled: true\n      name: \"OIDC\"\n      allow_sign_up: true\n      auto_login: false\n      client_id: \"grafana-client-id\"\n      client_secret: \"${OIDC_CLIENT_SECRET}\"\n      scopes: \"openid profile email groups\"\n      empty_scopes: false\n      auth_url: \"https://your-oidc-provider.com/oauth2/v1/authorize\"\n      token_url: \"https://your-oidc-provider.com/oauth2/v1/token\"\n      api_url: \"https://your-oidc-provider.com/oauth2/v1/userinfo\"\n      allowed_domains: \"example.com\"\n      team_ids: \"\"\n      allowed_organizations: \"\"\n      role_attribute_path: \"contains(groups[*], 'grafana-admin') &amp;&amp; 'Admin' || contains(groups[*], 'grafana-editor') &amp;&amp; 'Editor' || 'Viewer'\"\n      role_attribute_strict: false\n      allow_assign_grafana_admin: true\n      skip_org_role_sync: false\n      use_pkce: true\n\n  # Store OIDC client secret securely\n  envFromSecrets:\n    - name: grafana-oidc-secret\n      keys:\n        - key: client-secret\n          name: OIDC_CLIENT_SECRET\n</code></pre>"},{"location":"gitops/helm-configuration/#prometheus-oidc-with-oauth-proxy","title":"Prometheus OIDC with OAuth Proxy","text":"<p>Prometheus doesn't natively support OIDC, but you can use oauth2-proxy as a sidecar:</p> <pre><code>prometheus:\n  server:\n    # Add oauth2-proxy as sidecar\n    extraContainers:\n      - name: oauth2-proxy\n        image: quay.io/oauth2-proxy/oauth2-proxy:v7.4.0\n        args:\n          - --provider=oidc\n          - --email-domain=*\n          - --upstream=http://localhost:9090\n          - --http-address=0.0.0.0:4180\n          - --oidc-issuer-url=https://your-oidc-provider.com\n          - --client-id=$(OAUTH2_PROXY_CLIENT_ID)\n          - --client-secret=$(OAUTH2_PROXY_CLIENT_SECRET)\n          - --cookie-secret=$(OAUTH2_PROXY_COOKIE_SECRET)\n          - --cookie-secure=true\n          - --skip-provider-button=true\n        ports:\n          - containerPort: 4180\n            name: oauth-proxy\n        env:\n          - name: OAUTH2_PROXY_CLIENT_ID\n            valueFrom:\n              secretKeyRef:\n                name: prometheus-oidc-secret\n                key: client-id\n          - name: OAUTH2_PROXY_CLIENT_SECRET\n            valueFrom:\n              secretKeyRef:\n                name: prometheus-oidc-secret\n                key: client-secret\n          - name: OAUTH2_PROXY_COOKIE_SECRET\n            valueFrom:\n              secretKeyRef:\n                name: prometheus-oidc-secret\n                key: cookie-secret\n\n    # Update service to expose oauth2-proxy port\n    service:\n      additionalPorts:\n        - name: oauth-proxy\n          port: 4180\n          targetPort: 4180\n\n  # Update ingress to point to oauth2-proxy\n  server:\n    ingress:\n      enabled: true\n      className: \"nginx\"\n      annotations:\n        nginx.ingress.kubernetes.io/backend-protocol: \"HTTP\"\n        nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n        cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n      hosts:\n        - \"prometheus.example.com\"\n      tls:\n        - secretName: prometheus-tls\n          hosts:\n            - \"prometheus.example.com\"\n      # Override port to use oauth2-proxy\n      paths:\n        - path: /\n          pathType: Prefix\n          backend:\n            service:\n              name: temporal-prometheus-server\n              port:\n                number: 4180\n</code></pre>"},{"location":"gitops/helm-configuration/#oidc-secrets-management-with-external-secrets","title":"OIDC Secrets Management with External Secrets","text":"<p>Manage OIDC secrets using external-secrets:</p> <pre><code># Temporal OIDC secrets\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: temporal-oidc-config\n  namespace: temporal\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: temporal-oidc-secret\n    creationPolicy: Owner\n  data:\n    - secretKey: jwks-url\n      remoteRef:\n        key: secret/temporal/oidc\n        property: jwks_url\n\n---\n# Grafana OIDC secrets\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: grafana-oidc-config\n  namespace: temporal\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: grafana-oidc-secret\n    creationPolicy: Owner\n  data:\n    - secretKey: client-secret\n      remoteRef:\n        key: secret/temporal/grafana-oidc\n        property: client_secret\n\n---\n# Prometheus OAuth2-Proxy secrets\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: prometheus-oidc-config\n  namespace: temporal\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: prometheus-oidc-secret\n    creationPolicy: Owner\n    template:\n      type: Opaque\n      data:\n        cookie-secret: \"{{ .cookie_secret | b64enc }}\"\n  data:\n    - secretKey: client-id\n      remoteRef:\n        key: secret/temporal/prometheus-oidc\n        property: client_id\n    - secretKey: client-secret\n      remoteRef:\n        key: secret/temporal/prometheus-oidc\n        property: client_secret\n    - secretKey: cookie_secret\n      remoteRef:\n        key: secret/temporal/prometheus-oidc\n        property: cookie_secret\n</code></pre>"},{"location":"gitops/helm-configuration/#oidc-provider-configuration-requirements","title":"OIDC Provider Configuration Requirements","text":"<p>For each component, configure your OIDC provider with the following redirect URIs:</p> <ul> <li>Temporal: No redirect URI needed (JWT validation only)</li> <li>Grafana: <code>https://grafana.example.com/login/generic_oauth</code></li> <li>Prometheus (oauth2-proxy): <code>https://prometheus.example.com/oauth2/callback</code></li> </ul>"},{"location":"gitops/helm-configuration/#claims-and-groups-mapping","title":"Claims and Groups Mapping","text":"<p>Configure role mapping based on OIDC claims:</p> <pre><code># Example for Keycloak groups mapping\n# Grafana role mapping in grafana.ini:\nauth.generic_oauth:\n  role_attribute_path: \"contains(groups[*], 'temporal-admins') &amp;&amp; 'Admin' || contains(groups[*], 'temporal-editors') &amp;&amp; 'Editor' || 'Viewer'\"\n\n# Temporal permissions in JWT claims:\n# {\n#   \"sub\": \"user@example.com\",\n#   \"groups\": [\"temporal-admins\", \"temporal-users\"],\n#   \"permissions\": [\"temporal:read\", \"temporal:write\", \"temporal:admin\"]\n# }\n</code></pre>"},{"location":"gitops/helm-configuration/#complete-deployment-example","title":"Complete Deployment Example","text":""},{"location":"gitops/helm-configuration/#1-create-namespace","title":"1. Create Namespace","text":"<pre><code>kubectl create namespace temporal\n</code></pre>"},{"location":"gitops/helm-configuration/#2-deploy-external-secrets-if-using","title":"2. Deploy External Secrets (if using)","text":"<pre><code>kubectl apply -f external-secrets-config.yaml\n</code></pre>"},{"location":"gitops/helm-configuration/#3-add-helm-repositories","title":"3. Add Helm Repositories","text":"<p>If not already done, add the required Helm repositories (see Repository Setup section above):</p> <pre><code>helm repo add temporalio https://go.temporal.io/helm-charts\nhelm repo update\n</code></pre>"},{"location":"gitops/helm-configuration/#4-create-values-file","title":"4. Create Values File","text":"<p>Combine all configurations into a single <code>values-production.yaml</code>:</p> <pre><code># Complete production configuration\nnameOverride: \"\"\nfullnameOverride: \"\"\n\nimagePullSecrets:\n  - name: docker-proxy-registry-secret\n\nserver:\n  image:\n    repository: docker.proxyregistry.org/temporalio/server\n    tag: 1.29.1\n    pullPolicy: IfNotPresent\n\n  securityContext:\n    fsGroup: 10001\n    runAsUser: 10001\n    runAsGroup: 10001\n    runAsNonRoot: true\n\n  config:\n    persistence:\n      default:\n        driver: \"sql\"\n        sql:\n          driver: \"postgres12\"\n          host: \"postgresql.example.com\"\n          port: 5432\n          database: \"temporal\"\n          user: \"temporal_user\"\n          existingSecret: \"temporal-default-store\"\n          maxConns: 20\n          maxIdleConns: 20\n          maxConnLifetime: \"1h\"\n\n      visibility:\n        driver: \"sql\"\n        sql:\n          driver: \"postgres12\"\n          host: \"postgresql.example.com\"\n          port: 5432\n          database: \"temporal_visibility\"\n          user: \"temporal_user\"\n          existingSecret: \"temporal-visibility-store\"\n          maxConns: 20\n          maxIdleConns: 20\n          maxConnLifetime: \"1h\"\n\nweb:\n  image:\n    repository: docker.proxyregistry.org/temporalio/ui\n    tag: 2.37.1\n    pullPolicy: IfNotPresent\n\n  securityContext:\n    fsGroup: 10001\n    runAsUser: 10001\n    runAsGroup: 10001\n    runAsNonRoot: true\n\n  ingress:\n    enabled: true\n    className: \"nginx\"\n    annotations:\n      nginx.ingress.kubernetes.io/rewrite-target: /\n      nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n      cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    hosts:\n      - \"temporal-ui.example.com\"\n    tls:\n      - secretName: temporal-ui-tls\n        hosts:\n          - \"temporal-ui.example.com\"\n\nadmintools:\n  image:\n    repository: docker.proxyregistry.org/temporalio/admin-tools\n    tag: 1.29.1-tctl-1.18.2-cli-1.3.0\n    pullPolicy: IfNotPresent\n\n  securityContext:\n    fsGroup: 10001\n    runAsUser: 10001\n    runAsGroup: 10001\n    runAsNonRoot: true\n\n# Disable embedded databases\ncassandra:\n  enabled: false\nmysql:\n  enabled: false\npostgresql:\n  enabled: false\n\n# Configure monitoring stack with proxy registry\nprometheus:\n  enabled: true\n  server:\n    image:\n      repository: docker.proxyregistry.org/prom/prometheus\n\ngrafana:\n  enabled: true\n  image:\n    repository: docker.proxyregistry.org/grafana/grafana\n  ingress:\n    enabled: true\n    ingressClassName: \"nginx\"\n    annotations:\n      nginx.ingress.kubernetes.io/rewrite-target: /\n      nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n      cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    path: /\n    pathType: Prefix\n    hosts:\n      - \"grafana.example.com\"\n    tls:\n      - secretName: grafana-tls\n        hosts:\n          - \"grafana.example.com\"\n\nelasticsearch:\n  enabled: true\n  image: docker.proxyregistry.org/elasticsearch/elasticsearch\n  imageTag: 7.17.3\n</code></pre>"},{"location":"gitops/helm-configuration/#5-deploy-temporal","title":"5. Deploy Temporal","text":"<pre><code>helm install temporal temporalio/temporal \\\n  --namespace temporal \\\n  --values values-production.yaml \\\n  --wait\n</code></pre>"},{"location":"gitops/helm-configuration/#6-verify-deployment","title":"6. Verify Deployment","text":"<pre><code># Check pods\nkubectl get pods -n temporal\n\n# Check services\nkubectl get svc -n temporal\n\n# Check ingress\nkubectl get ingress -n temporal\n\n# Check secrets\nkubectl get secrets -n temporal\n</code></pre>"},{"location":"gitops/helm-configuration/#7-access-services","title":"7. Access Services","text":"<p>After successful deployment, you can access the following services:</p> <ul> <li>Temporal Web UI: https://temporal-ui.example.com</li> <li>Temporal gRPC Frontend: temporal-grpc.example.com:443 (for client connections)</li> <li>Grafana Dashboard: https://grafana.example.com (with basic auth if configured)</li> </ul>"},{"location":"gitops/helm-configuration/#default-grafana-credentials","title":"Default Grafana Credentials","text":"<p>If not using external secrets, Grafana uses default credentials: - Username: <code>admin</code> - Password: Check the grafana secret: <code>kubectl get secret temporal-grafana -n temporal -o jsonpath=\"{.data.admin-password}\" | base64 --decode</code></p>"},{"location":"gitops/helm-configuration/#temporal-cli-access","title":"Temporal CLI Access","text":"<p>Connect to Temporal using the CLI:</p> <pre><code># Using external endpoint\ntctl --address temporal-grpc.example.com:443 --tls namespace list\n\n# Using port-forward for testing\nkubectl port-forward -n temporal svc/temporal-frontend 7233:7233\ntctl --address localhost:7233 namespace list\n</code></pre>"},{"location":"gitops/helm-configuration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"gitops/helm-configuration/#common-issues","title":"Common Issues","text":"<ol> <li>Database Connection Issues: Verify secrets and network connectivity</li> <li>Image Pull Errors: Check imagePullSecrets and registry configuration</li> <li>Permission Denied: Verify securityContext and volume permissions</li> <li>Ingress Not Working: Check ingress controller and DNS configuration</li> </ol>"},{"location":"gitops/helm-configuration/#useful-commands","title":"Useful Commands","text":"<pre><code># View logs\nkubectl logs -n temporal deployment/temporal-frontend\n\n# Port forward for testing\nkubectl port-forward -n temporal svc/temporal-frontend 7233:7233\n\n# Execute into admintools\nkubectl exec -n temporal deployment/temporal-admintools -it -- bash\n</code></pre> <p>This comprehensive guide enables enterprise-grade deployment of Temporal with external dependencies, security compliance, and operational best practices.</p>"},{"location":"implementation/application-deployment/","title":"Application Deployment","text":"<p>This guide provides comprehensive deployment instructions for Temporal.io application services including workers, FastAPI services, and supporting infrastructure in enterprise environments.</p>"},{"location":"implementation/application-deployment/#overview","title":"Overview","text":"<p>The application deployment includes: - Temporal workers for workflow and activity execution - FastAPI services for REST API functionality - Application configuration management - Service mesh integration - Auto-scaling and load balancing - Monitoring and observability</p>"},{"location":"implementation/application-deployment/#architecture-components","title":"Architecture Components","text":""},{"location":"implementation/application-deployment/#application-services","title":"Application Services","text":"<pre><code>graph TB\n    subgraph \"External Traffic\"\n        USERS[Users]\n        MOBILE[Mobile Apps]\n        APIs[External APIs]\n    end\n\n    subgraph \"Load Balancer\"\n        ALB[Application Load Balancer]\n        NLB[Network Load Balancer]\n    end\n\n    subgraph \"Application Layer\"\n        FASTAPI[FastAPI Services]\n        WORKERS[Temporal Workers]\n        SCHEDULER[Task Scheduler]\n    end\n\n    subgraph \"Temporal Cluster\"\n        FRONTEND[Temporal Frontend]\n        HISTORY[Temporal History]\n        MATCHING[Temporal Matching]\n    end\n\n    subgraph \"Data &amp; Cache\"\n        POSTGRES[(PostgreSQL)]\n        REDIS[(Redis)]\n        S3[(S3 Storage)]\n    end\n\n    subgraph \"External Services\"\n        PAYMENT[Payment Gateway]\n        EMAIL[Email Service]\n        SMS[SMS Service]\n    end\n\n    USERS --&gt; ALB\n    MOBILE --&gt; ALB\n    APIs --&gt; NLB\n\n    ALB --&gt; FASTAPI\n    NLB --&gt; FASTAPI\n\n    FASTAPI --&gt; FRONTEND\n    WORKERS --&gt; FRONTEND\n    SCHEDULER --&gt; FRONTEND\n\n    FRONTEND --&gt; HISTORY\n    FRONTEND --&gt; MATCHING\n\n    FASTAPI --&gt; POSTGRES\n    FASTAPI --&gt; REDIS\n    WORKERS --&gt; POSTGRES\n    WORKERS --&gt; REDIS\n\n    WORKERS --&gt; PAYMENT\n    WORKERS --&gt; EMAIL\n    WORKERS --&gt; SMS\n\n    FASTAPI --&gt; S3\n    WORKERS --&gt; S3</code></pre>"},{"location":"implementation/application-deployment/#fastapi-service-deployment","title":"FastAPI Service Deployment","text":""},{"location":"implementation/application-deployment/#deployment-configuration","title":"Deployment Configuration","text":"<pre><code># k8s/applications/fastapi/deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: temporal-api\n  namespace: temporal-app\n  labels:\n    app.kubernetes.io/name: temporal-api\n    app.kubernetes.io/component: api\n    app.kubernetes.io/part-of: temporal-app\nspec:\n  replicas: 3\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 1\n      maxSurge: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: temporal-api\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: temporal-api\n        app.kubernetes.io/component: api\n        app.kubernetes.io/part-of: temporal-app\n      annotations:\n        prometheus.io/scrape: \"true\"\n        prometheus.io/port: \"8000\"\n        prometheus.io/path: \"/metrics\"\n    spec:\n      serviceAccountName: temporal-api\n\n      containers:\n      - name: api\n        image: your-registry.com/temporal-api:latest\n        imagePullPolicy: Always\n\n        ports:\n        - containerPort: 8000\n          name: http\n          protocol: TCP\n\n        env:\n        - name: ENVIRONMENT\n          value: \"production\"\n        - name: LOG_LEVEL\n          value: \"INFO\"\n        - name: TEMPORAL_SERVER_URL\n          value: \"temporal-frontend.temporal-system.svc.cluster.local:7233\"\n        - name: TEMPORAL_NAMESPACE\n          value: \"default\"\n        - name: DATABASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: app-database-credentials\n              key: connection_string\n        - name: REDIS_URL\n          valueFrom:\n            secretKeyRef:\n              name: app-redis-credentials\n              key: connection_string\n        - name: JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: app-secrets\n              key: jwt_secret\n        - name: ENCRYPTION_KEY\n          valueFrom:\n            secretKeyRef:\n              name: app-secrets\n              key: encryption_key\n\n        resources:\n          requests:\n            memory: \"512Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"1Gi\"\n            cpu: \"500m\"\n\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8000\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          timeoutSeconds: 5\n          failureThreshold: 3\n\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8000\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          timeoutSeconds: 3\n          failureThreshold: 3\n\n        securityContext:\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          runAsUser: 10001\n          runAsGroup: 10001\n          capabilities:\n            drop:\n            - ALL\n\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        - name: cache\n          mountPath: /app/cache\n        - name: temporal-certs\n          mountPath: /etc/temporal/certs\n          readOnly: true\n\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cache\n        emptyDir: {}\n      - name: temporal-certs\n        secret:\n          secretName: temporal-tls-secret\n\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 10001\n        runAsGroup: 10001\n        fsGroup: 10001\n\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app.kubernetes.io/name\n                  operator: In\n                  values:\n                  - temporal-api\n              topologyKey: kubernetes.io/hostname\n</code></pre>"},{"location":"implementation/application-deployment/#service-configuration","title":"Service Configuration","text":"<pre><code># k8s/applications/fastapi/service.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: temporal-api\n  namespace: temporal-app\n  labels:\n    app.kubernetes.io/name: temporal-api\n    app.kubernetes.io/component: api\nspec:\n  type: ClusterIP\n  ports:\n  - port: 80\n    targetPort: 8000\n    protocol: TCP\n    name: http\n  selector:\n    app.kubernetes.io/name: temporal-api\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: temporal-api-external\n  namespace: temporal-app\n  annotations:\n    service.beta.kubernetes.io/aws-load-balancer-type: \"alb\"\n    service.beta.kubernetes.io/aws-load-balancer-scheme: \"internet-facing\"\n    service.beta.kubernetes.io/aws-load-balancer-target-type: \"ip\"\n    service.beta.kubernetes.io/aws-load-balancer-healthcheck-path: \"/health\"\n    service.beta.kubernetes.io/aws-load-balancer-ssl-redirect: \"443\"\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 80\n    targetPort: 8000\n    protocol: TCP\n    name: http\n  - port: 443\n    targetPort: 8000\n    protocol: TCP\n    name: https\n  selector:\n    app.kubernetes.io/name: temporal-api\n</code></pre>"},{"location":"implementation/application-deployment/#auto-scaling-configuration","title":"Auto-scaling Configuration","text":"<pre><code># k8s/applications/fastapi/hpa.yaml\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: temporal-api-hpa\n  namespace: temporal-app\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: temporal-api\n  minReplicas: 3\n  maxReplicas: 20\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  - type: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80\n  - type: Pods\n    pods:\n      metric:\n        name: http_requests_per_second\n      target:\n        type: AverageValue\n        averageValue: \"100\"\n  behavior:\n    scaleDown:\n      stabilizationWindowSeconds: 300\n      policies:\n      - type: Percent\n        value: 50\n        periodSeconds: 60\n    scaleUp:\n      stabilizationWindowSeconds: 60\n      policies:\n      - type: Percent\n        value: 100\n        periodSeconds: 60\n      - type: Pods\n        value: 2\n        periodSeconds: 60\n      selectPolicy: Max\n</code></pre>"},{"location":"implementation/application-deployment/#temporal-workers-deployment","title":"Temporal Workers Deployment","text":""},{"location":"implementation/application-deployment/#worker-deployment-configuration","title":"Worker Deployment Configuration","text":"<pre><code># k8s/applications/workers/deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: temporal-worker\n  namespace: temporal-app\n  labels:\n    app.kubernetes.io/name: temporal-worker\n    app.kubernetes.io/component: worker\n    app.kubernetes.io/part-of: temporal-app\nspec:\n  replicas: 5\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 1\n      maxSurge: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: temporal-worker\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: temporal-worker\n        app.kubernetes.io/component: worker\n        app.kubernetes.io/part-of: temporal-app\n      annotations:\n        prometheus.io/scrape: \"true\"\n        prometheus.io/port: \"9090\"\n        prometheus.io/path: \"/metrics\"\n    spec:\n      serviceAccountName: temporal-worker\n\n      containers:\n      - name: worker\n        image: your-registry.com/temporal-worker:latest\n        imagePullPolicy: Always\n\n        ports:\n        - containerPort: 9090\n          name: metrics\n          protocol: TCP\n\n        env:\n        - name: ENVIRONMENT\n          value: \"production\"\n        - name: LOG_LEVEL\n          value: \"INFO\"\n        - name: TEMPORAL_SERVER_URL\n          value: \"temporal-frontend.temporal-system.svc.cluster.local:7233\"\n        - name: TEMPORAL_NAMESPACE\n          value: \"default\"\n        - name: TASK_QUEUE\n          value: \"temporal-product-queue\"\n        - name: WORKER_IDENTITY\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: MAX_CONCURRENT_WORKFLOW_TASKS\n          value: \"100\"\n        - name: MAX_CONCURRENT_ACTIVITY_TASKS\n          value: \"1000\"\n        - name: DATABASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: app-database-credentials\n              key: connection_string\n        - name: REDIS_URL\n          valueFrom:\n            secretKeyRef:\n              name: app-redis-credentials\n              key: connection_string\n        - name: PAYMENT_API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: external-api-keys\n              key: payment_api_key\n        - name: EMAIL_API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: external-api-keys\n              key: email_api_key\n        - name: SMS_API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: external-api-keys\n              key: sms_api_key\n\n        resources:\n          requests:\n            memory: \"1Gi\"\n            cpu: \"500m\"\n          limits:\n            memory: \"2Gi\"\n            cpu: \"1000m\"\n\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 9090\n          initialDelaySeconds: 60\n          periodSeconds: 30\n          timeoutSeconds: 10\n          failureThreshold: 3\n\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 9090\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 5\n          failureThreshold: 3\n\n        securityContext:\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          runAsUser: 10001\n          runAsGroup: 10001\n          capabilities:\n            drop:\n            - ALL\n\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        - name: cache\n          mountPath: /app/cache\n        - name: temporal-certs\n          mountPath: /etc/temporal/certs\n          readOnly: true\n\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cache\n        emptyDir: {}\n      - name: temporal-certs\n        secret:\n          secretName: temporal-tls-secret\n\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 10001\n        runAsGroup: 10001\n        fsGroup: 10001\n\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app.kubernetes.io/name\n                  operator: In\n                  values:\n                  - temporal-worker\n              topologyKey: kubernetes.io/hostname\n</code></pre>"},{"location":"implementation/application-deployment/#worker-service-configuration","title":"Worker Service Configuration","text":"<pre><code># k8s/applications/workers/service.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: temporal-worker\n  namespace: temporal-app\n  labels:\n    app.kubernetes.io/name: temporal-worker\n    app.kubernetes.io/component: worker\nspec:\n  type: ClusterIP\n  ports:\n  - port: 9090\n    targetPort: 9090\n    protocol: TCP\n    name: metrics\n  selector:\n    app.kubernetes.io/name: temporal-worker\n</code></pre>"},{"location":"implementation/application-deployment/#worker-auto-scaling-configuration","title":"Worker Auto-scaling Configuration","text":"<pre><code># k8s/applications/workers/hpa.yaml\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: temporal-worker-hpa\n  namespace: temporal-app\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: temporal-worker\n  minReplicas: 3\n  maxReplicas: 50\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  - type: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80\n  - type: External\n    external:\n      metric:\n        name: temporal_task_queue_backlog\n        selector:\n          matchLabels:\n            task_queue: \"temporal-product-queue\"\n      target:\n        type: AverageValue\n        averageValue: \"10\"\n  behavior:\n    scaleDown:\n      stabilizationWindowSeconds: 600  # 10 minutes\n      policies:\n      - type: Percent\n        value: 25\n        periodSeconds: 300  # 5 minutes\n    scaleUp:\n      stabilizationWindowSeconds: 60\n      policies:\n      - type: Percent\n        value: 100\n        periodSeconds: 60\n      - type: Pods\n        value: 5\n        periodSeconds: 60\n      selectPolicy: Max\n</code></pre>"},{"location":"implementation/application-deployment/#application-secrets-management","title":"Application Secrets Management","text":""},{"location":"implementation/application-deployment/#database-credentials","title":"Database Credentials","text":"<pre><code># k8s/applications/secrets/database-credentials.yaml\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: app-database-credentials\n  namespace: temporal-app\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: app-database-credentials\n    creationPolicy: Owner\n    template:\n      type: Opaque\n      data:\n        host: \"{{ .host }}\"\n        port: \"{{ .port }}\"\n        database: \"{{ .database }}\"\n        username: \"{{ .username }}\"\n        password: \"{{ .password }}\"\n        connection_string: \"postgresql://{{ .username }}:{{ .password }}@{{ .host }}:{{ .port }}/{{ .database }}?sslmode=require\"\n  data:\n  - secretKey: host\n    remoteRef:\n      key: temporal/app/database\n      property: host\n  - secretKey: port\n    remoteRef:\n      key: temporal/app/database\n      property: port\n  - secretKey: database\n    remoteRef:\n      key: temporal/app/database\n      property: database\n  - secretKey: username\n    remoteRef:\n      key: temporal/app/database\n      property: username\n  - secretKey: password\n    remoteRef:\n      key: temporal/app/database\n      property: password\n</code></pre>"},{"location":"implementation/application-deployment/#application-secrets","title":"Application Secrets","text":"<pre><code># k8s/applications/secrets/app-secrets.yaml\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: app-secrets\n  namespace: temporal-app\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: app-secrets\n    creationPolicy: Owner\n  data:\n  - secretKey: jwt_secret\n    remoteRef:\n      key: temporal/app/auth\n      property: jwt_secret\n  - secretKey: encryption_key\n    remoteRef:\n      key: temporal/app/auth\n      property: encryption_key\n  - secretKey: api_key\n    remoteRef:\n      key: temporal/app/auth\n      property: api_key\n\n---\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: external-api-keys\n  namespace: temporal-app\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: external-api-keys\n    creationPolicy: Owner\n  data:\n  - secretKey: payment_api_key\n    remoteRef:\n      key: temporal/app/external\n      property: payment_api_key\n  - secretKey: email_api_key\n    remoteRef:\n      key: temporal/app/external\n      property: email_api_key\n  - secretKey: sms_api_key\n    remoteRef:\n      key: temporal/app/external\n      property: sms_api_key\n</code></pre>"},{"location":"implementation/application-deployment/#configuration-management","title":"Configuration Management","text":""},{"location":"implementation/application-deployment/#configmaps","title":"ConfigMaps","text":"<pre><code># k8s/applications/config/app-config.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: app-config\n  namespace: temporal-app\ndata:\n  # Application configuration\n  app.yaml: |\n    server:\n      host: \"0.0.0.0\"\n      port: 8000\n      workers: 4\n      timeout: 30\n      max_requests: 1000\n\n    temporal:\n      server_url: \"temporal-frontend.temporal-system.svc.cluster.local:7233\"\n      namespace: \"default\"\n      task_queue: \"temporal-product-queue\"\n      tls:\n        enabled: true\n        cert_file: \"/etc/temporal/certs/tls.crt\"\n        key_file: \"/etc/temporal/certs/tls.key\"\n        ca_file: \"/etc/temporal/certs/ca.crt\"\n\n    logging:\n      level: \"INFO\"\n      format: \"json\"\n      handlers:\n        - \"console\"\n        - \"file\"\n      file_path: \"/app/logs/app.log\"\n\n    metrics:\n      enabled: true\n      port: 9090\n      path: \"/metrics\"\n\n    health:\n      enabled: true\n      path: \"/health\"\n      checks:\n        - \"database\"\n        - \"redis\"\n        - \"temporal\"\n\n    cache:\n      type: \"redis\"\n      ttl: 3600\n      max_connections: 10\n\n    external_services:\n      payment_gateway:\n        base_url: \"https://api.payment.com\"\n        timeout: 30\n        retries: 3\n      email_service:\n        base_url: \"https://api.email.com\"\n        timeout: 10\n        retries: 2\n      sms_service:\n        base_url: \"https://api.sms.com\"\n        timeout: 10\n        retries: 2\n\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: worker-config\n  namespace: temporal-app\ndata:\n  # Worker configuration\n  worker.yaml: |\n    worker:\n      identity: \"${WORKER_IDENTITY}\"\n      max_concurrent_workflow_tasks: 100\n      max_concurrent_activity_tasks: 1000\n      max_concurrent_local_activity_tasks: 1000\n      sticky_schedule_to_start_timeout: \"5s\"\n      max_heartbeat_throttle_interval: \"60s\"\n      default_heartbeat_throttle_interval: \"30s\"\n\n    task_queues:\n      - name: \"temporal-product-queue\"\n        workflows:\n          - \"OrderProcessingWorkflow\"\n          - \"PaymentProcessingWorkflow\"\n          - \"InventoryManagementWorkflow\"\n        activities:\n          - \"PaymentActivity\"\n          - \"InventoryActivity\"\n          - \"ShippingActivity\"\n          - \"NotificationActivity\"\n\n    retry_policies:\n      default:\n        initial_interval: \"1s\"\n        backoff_coefficient: 2.0\n        maximum_interval: \"100s\"\n        maximum_attempts: 3\n\n      payment:\n        initial_interval: \"5s\"\n        backoff_coefficient: 2.0\n        maximum_interval: \"300s\"\n        maximum_attempts: 5\n\n      notification:\n        initial_interval: \"1s\"\n        backoff_coefficient: 1.5\n        maximum_interval: \"30s\"\n        maximum_attempts: 10\n</code></pre>"},{"location":"implementation/application-deployment/#rbac-configuration","title":"RBAC Configuration","text":""},{"location":"implementation/application-deployment/#service-accounts-and-roles","title":"Service Accounts and Roles","text":"<pre><code># k8s/applications/rbac/rbac.yaml\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: temporal-api\n  namespace: temporal-app\n  annotations:\n    eks.amazonaws.com/role-arn: arn:aws:iam::ACCOUNT:role/temporal-api-role\n\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: temporal-worker\n  namespace: temporal-app\n  annotations:\n    eks.amazonaws.com/role-arn: arn:aws:iam::ACCOUNT:role/temporal-worker-role\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  namespace: temporal-app\n  name: temporal-app-role\nrules:\n- apiGroups: [\"\"]\n  resources: [\"configmaps\", \"secrets\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"\"]\n  resources: [\"pods\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"apps\"]\n  resources: [\"deployments\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: temporal-api-binding\n  namespace: temporal-app\nsubjects:\n- kind: ServiceAccount\n  name: temporal-api\n  namespace: temporal-app\nroleRef:\n  kind: Role\n  name: temporal-app-role\n  apiGroup: rbac.authorization.k8s.io\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: temporal-worker-binding\n  namespace: temporal-app\nsubjects:\n- kind: ServiceAccount\n  name: temporal-worker\n  namespace: temporal-app\nroleRef:\n  kind: Role\n  name: temporal-app-role\n  apiGroup: rbac.authorization.k8s.io\n</code></pre>"},{"location":"implementation/application-deployment/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"implementation/application-deployment/#servicemonitor-for-prometheus","title":"ServiceMonitor for Prometheus","text":"<pre><code># k8s/applications/monitoring/service-monitor.yaml\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: temporal-app\n  namespace: temporal-app\n  labels:\n    app.kubernetes.io/part-of: temporal-app\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/part-of: temporal-app\n  endpoints:\n  - port: metrics\n    interval: 30s\n    path: /metrics\n    honorLabels: true\n  - port: http\n    interval: 30s\n    path: /metrics\n    honorLabels: true\n  namespaceSelector:\n    matchNames:\n    - temporal-app\n</code></pre>"},{"location":"implementation/application-deployment/#pod-disruption-budgets","title":"Pod Disruption Budgets","text":"<pre><code># k8s/applications/pdb/pod-disruption-budgets.yaml\napiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: temporal-api-pdb\n  namespace: temporal-app\nspec:\n  minAvailable: 2\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: temporal-api\n\n---\napiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: temporal-worker-pdb\n  namespace: temporal-app\nspec:\n  minAvailable: 2\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: temporal-worker\n</code></pre>"},{"location":"implementation/application-deployment/#deployment-automation","title":"Deployment Automation","text":""},{"location":"implementation/application-deployment/#application-deployment-script","title":"Application Deployment Script","text":"<pre><code>#!/bin/bash\n# scripts/deploy-applications.sh\n\nset -euo pipefail\n\nENVIRONMENT=${1:-development}\nNAMESPACE=\"temporal-app\"\nAPI_IMAGE_TAG=${2:-latest}\nWORKER_IMAGE_TAG=${3:-latest}\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m'\n\nlog() {\n    echo -e \"${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}\"\n}\n\nwarn() {\n    echo -e \"${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}\"\n}\n\nerror() {\n    echo -e \"${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}\"\n    exit 1\n}\n\n# Validate environment\nif [[ ! \"$ENVIRONMENT\" =~ ^(development|staging|production)$ ]]; then\n    error \"Invalid environment. Must be one of: development, staging, production\"\nfi\n\nlog \"Deploying applications to $ENVIRONMENT environment\"\nlog \"API image tag: $API_IMAGE_TAG\"\nlog \"Worker image tag: $WORKER_IMAGE_TAG\"\n\n# Check prerequisites\nlog \"Checking prerequisites...\"\nif ! command -v kubectl &amp;&gt; /dev/null; then\n    error \"kubectl is required but not installed\"\nfi\n\n# Verify cluster connectivity\nif ! kubectl cluster-info &gt; /dev/null 2&gt;&amp;1; then\n    error \"Cannot connect to Kubernetes cluster\"\nfi\n\n# Create namespace if it doesn't exist\nlog \"Ensuring namespace exists...\"\nkubectl create namespace \"$NAMESPACE\" --dry-run=client -o yaml | kubectl apply -f -\n\n# Apply RBAC\nlog \"Applying RBAC configuration...\"\nkubectl apply -f k8s/applications/rbac/\n\n# Apply secrets\nlog \"Applying secrets...\"\nkubectl apply -f k8s/applications/secrets/\n\n# Wait for secrets to be ready\nlog \"Waiting for external secrets to sync...\"\nkubectl wait --for=condition=Ready externalsecret/app-database-credentials -n \"$NAMESPACE\" --timeout=300s\nkubectl wait --for=condition=Ready externalsecret/app-secrets -n \"$NAMESPACE\" --timeout=300s\nkubectl wait --for=condition=Ready externalsecret/external-api-keys -n \"$NAMESPACE\" --timeout=300s\n\n# Apply configuration\nlog \"Applying configuration...\"\nkubectl apply -f k8s/applications/config/\n\n# Deploy FastAPI service\nlog \"Deploying FastAPI service...\"\nsed \"s|your-registry.com/temporal-api:latest|your-registry.com/temporal-api:${API_IMAGE_TAG}|g\" \\\n    k8s/applications/fastapi/deployment.yaml | kubectl apply -f -\n\nkubectl apply -f k8s/applications/fastapi/service.yaml\nkubectl apply -f k8s/applications/fastapi/hpa.yaml\n\n# Deploy Workers\nlog \"Deploying Temporal workers...\"\nsed \"s|your-registry.com/temporal-worker:latest|your-registry.com/temporal-worker:${WORKER_IMAGE_TAG}|g\" \\\n    k8s/applications/workers/deployment.yaml | kubectl apply -f -\n\nkubectl apply -f k8s/applications/workers/service.yaml\nkubectl apply -f k8s/applications/workers/hpa.yaml\n\n# Apply monitoring configuration\nlog \"Applying monitoring configuration...\"\nkubectl apply -f k8s/applications/monitoring/\nkubectl apply -f k8s/applications/pdb/\n\n# Wait for deployments to be ready\nlog \"Waiting for deployments to be ready...\"\nkubectl wait --for=condition=available deployment/temporal-api -n \"$NAMESPACE\" --timeout=600s\nkubectl wait --for=condition=available deployment/temporal-worker -n \"$NAMESPACE\" --timeout=600s\n\n# Verify deployment\nlog \"Verifying deployment...\"\nAPI_READY=$(kubectl get deployment temporal-api -n \"$NAMESPACE\" -o jsonpath='{.status.readyReplicas}')\nWORKER_READY=$(kubectl get deployment temporal-worker -n \"$NAMESPACE\" -o jsonpath='{.status.readyReplicas}')\n\nlog \"API replicas ready: $API_READY\"\nlog \"Worker replicas ready: $WORKER_READY\"\n\n# Test API connectivity\nlog \"Testing API connectivity...\"\nkubectl run api-test --image=curlimages/curl:latest --rm -i --restart=Never -- \\\n    curl -f \"http://temporal-api.${NAMESPACE}.svc.cluster.local/health\" || warn \"API connectivity test failed\"\n\n# Test worker connectivity to Temporal\nlog \"Testing worker connectivity...\"\nkubectl logs -n \"$NAMESPACE\" deployment/temporal-worker --tail=10 | grep -q \"Started Temporal worker\" || warn \"Worker connectivity test failed\"\n\nlog \"Application deployment completed successfully!\"\n\nif [[ \"$ENVIRONMENT\" == \"production\" ]]; then\n    log \"Production endpoints:\"\n    log \"- API: https://api.temporal.company.com\"\n    log \"- Health: https://api.temporal.company.com/health\"\n    log \"- Metrics: http://temporal-api.${NAMESPACE}.svc.cluster.local:8000/metrics\"\nfi\n</code></pre>"},{"location":"implementation/application-deployment/#application-health-check-script","title":"Application Health Check Script","text":"<pre><code>#!/bin/bash\n# scripts/health-check-applications.sh\n\nset -euo pipefail\n\nNAMESPACE=\"temporal-app\"\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\nerror() {\n    echo -e \"\\033[0;31m[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1\\033[0m\"\n}\n\nwarn() {\n    echo -e \"\\033[1;33m[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1\\033[0m\"\n}\n\nlog \"Running application health checks...\"\n\n# Check pod status\nlog \"Checking pod status...\"\nPODS_NOT_READY=$(kubectl get pods -n \"$NAMESPACE\" -o jsonpath='{.items[?(@.status.phase!=\"Running\")].metadata.name}')\nif [[ -n \"$PODS_NOT_READY\" ]]; then\n    warn \"Pods not ready: $PODS_NOT_READY\"\nelse\n    log \"\u2713 All pods are running\"\nfi\n\n# Check API health\nlog \"Checking API health...\"\nkubectl run api-health --image=curlimages/curl:latest --rm -i --restart=Never -- \\\n    curl -f \"http://temporal-api:80/health\" &gt; /dev/null 2&gt;&amp;1\nif [[ $? -eq 0 ]]; then\n    log \"\u2713 API health check passed\"\nelse\n    error \"\u2717 API health check failed\"\nfi\n\n# Check API readiness\nlog \"Checking API readiness...\"\nkubectl run api-ready --image=curlimages/curl:latest --rm -i --restart=Never -- \\\n    curl -f \"http://temporal-api:80/ready\" &gt; /dev/null 2&gt;&amp;1\nif [[ $? -eq 0 ]]; then\n    log \"\u2713 API readiness check passed\"\nelse\n    error \"\u2717 API readiness check failed\"\nfi\n\n# Check worker health\nlog \"Checking worker health...\"\nWORKER_PODS=$(kubectl get pods -n \"$NAMESPACE\" -l app.kubernetes.io/name=temporal-worker -o jsonpath='{.items[*].metadata.name}')\nfor pod in $WORKER_PODS; do\n    kubectl exec \"$pod\" -n \"$NAMESPACE\" -- curl -f \"http://localhost:9090/health\" &gt; /dev/null 2&gt;&amp;1\n    if [[ $? -eq 0 ]]; then\n        log \"\u2713 Worker $pod health check passed\"\n    else\n        warn \"\u2717 Worker $pod health check failed\"\n    fi\ndone\n\n# Check external service connectivity\nlog \"Checking external service connectivity...\"\nkubectl run external-test --image=curlimages/curl:latest --rm -i --restart=Never -- \\\n    curl -f \"https://httpbin.org/status/200\" &gt; /dev/null 2&gt;&amp;1\nif [[ $? -eq 0 ]]; then\n    log \"\u2713 External connectivity OK\"\nelse\n    warn \"\u2717 External connectivity failed\"\nfi\n\n# Check autoscaler status\nlog \"Checking autoscaler status...\"\nAPI_HPA=$(kubectl get hpa temporal-api-hpa -n \"$NAMESPACE\" -o jsonpath='{.status.currentReplicas}')\nWORKER_HPA=$(kubectl get hpa temporal-worker-hpa -n \"$NAMESPACE\" -o jsonpath='{.status.currentReplicas}')\n\nlog \"API current replicas: $API_HPA\"\nlog \"Worker current replicas: $WORKER_HPA\"\n\n# Check service endpoints\nlog \"Checking service endpoints...\"\nSERVICES=(\"temporal-api\" \"temporal-worker\")\nfor service in \"${SERVICES[@]}\"; do\n    ENDPOINTS=$(kubectl get endpoints \"$service\" -n \"$NAMESPACE\" -o jsonpath='{.subsets[*].addresses[*].ip}' | wc -w)\n    if [[ $ENDPOINTS -gt 0 ]]; then\n        log \"\u2713 $service has $ENDPOINTS endpoints\"\n    else\n        error \"\u2717 $service has no endpoints\"\n    fi\ndone\n\nlog \"Application health check completed\"\n</code></pre>"},{"location":"implementation/application-deployment/#rolling-update-script","title":"Rolling Update Script","text":"<pre><code>#!/bin/bash\n# scripts/rolling-update-applications.sh\n\nset -euo pipefail\n\nNAMESPACE=\"temporal-app\"\nCOMPONENT=${1:-all}  # api, worker, or all\nNEW_TAG=${2:-latest}\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\nwarn() {\n    echo -e \"\\033[1;33m[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1\\033[0m\"\n}\n\nerror() {\n    echo -e \"\\033[0;31m[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1\\033[0m\"\n    exit 1\n}\n\nupdate_deployment() {\n    local deployment=$1\n    local image=$2\n    local tag=$3\n\n    log \"Updating $deployment to $image:$tag\"\n\n    kubectl set image deployment/\"$deployment\" \\\n        \"${deployment%-*}\"=\"$image:$tag\" \\\n        -n \"$NAMESPACE\"\n\n    kubectl rollout status deployment/\"$deployment\" \\\n        -n \"$NAMESPACE\" --timeout=600s\n\n    log \"\u2713 $deployment updated successfully\"\n}\n\nlog \"Starting rolling update for $COMPONENT to tag: $NEW_TAG\"\n\ncase \"$COMPONENT\" in\n    \"api\")\n        update_deployment \"temporal-api\" \"your-registry.com/temporal-api\" \"$NEW_TAG\"\n        ;;\n    \"worker\")\n        update_deployment \"temporal-worker\" \"your-registry.com/temporal-worker\" \"$NEW_TAG\"\n        ;;\n    \"all\")\n        update_deployment \"temporal-api\" \"your-registry.com/temporal-api\" \"$NEW_TAG\"\n        update_deployment \"temporal-worker\" \"your-registry.com/temporal-worker\" \"$NEW_TAG\"\n        ;;\n    *)\n        error \"Invalid component. Must be one of: api, worker, all\"\n        ;;\nesac\n\n# Run health checks after update\nlog \"Running post-update health checks...\"\n./scripts/health-check-applications.sh\n\nlog \"Rolling update completed successfully!\"\n</code></pre> <p>This comprehensive application deployment guide provides enterprise-grade deployment configurations with high availability, auto-scaling, monitoring, and operational automation for Temporal.io applications.</p>"},{"location":"implementation/database-setup/","title":"Database Setup","text":"<p>This guide provides comprehensive database setup and configuration for Temporal.io enterprise deployment, covering PostgreSQL installation, configuration, optimization, backup, and maintenance procedures.</p>"},{"location":"implementation/database-setup/#overview","title":"Overview","text":"<p>The database setup includes: - PostgreSQL cluster deployment and configuration - High availability setup with replication - Performance tuning and optimization - Backup and recovery procedures - Monitoring and maintenance - Migration and schema management</p>"},{"location":"implementation/database-setup/#postgresql-deployment","title":"PostgreSQL Deployment","text":""},{"location":"implementation/database-setup/#high-availability-postgresql-cluster","title":"High Availability PostgreSQL Cluster","text":""},{"location":"implementation/database-setup/#postgresql-helm-chart-configuration","title":"PostgreSQL Helm Chart Configuration","text":"<pre><code># helm/values/database/postgresql-ha.yaml\npostgresql:\n  image:\n    tag: \"15.4\"\n\n  # Authentication\n  auth:\n    postgresPassword: \"\"  # Set via secret\n    username: \"temporal\"\n    password: \"\"  # Set via secret\n    database: \"temporal\"\n    existingSecret: \"postgresql-credentials\"\n    secretKeys:\n      adminPasswordKey: \"postgres-password\"\n      userPasswordKey: \"password\"\n\n  # Architecture\n  architecture: replication\n\n  # Primary configuration\n  primary:\n    name: primary\n    persistence:\n      enabled: true\n      storageClass: \"gp3\"\n      size: 100Gi\n\n    resources:\n      limits:\n        memory: 4Gi\n        cpu: 2000m\n      requests:\n        memory: 2Gi\n        cpu: 1000m\n\n    configuration: |\n      # PostgreSQL configuration\n      max_connections = 200\n      shared_buffers = 1GB\n      effective_cache_size = 3GB\n      maintenance_work_mem = 256MB\n      checkpoint_completion_target = 0.9\n      wal_buffers = 16MB\n      default_statistics_target = 100\n      random_page_cost = 1.1\n      effective_io_concurrency = 200\n      work_mem = 4MB\n      min_wal_size = 1GB\n      max_wal_size = 4GB\n\n      # Logging\n      log_destination = 'stderr'\n      logging_collector = on\n      log_directory = 'log'\n      log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'\n      log_rotation_age = 1d\n      log_rotation_size = 100MB\n      log_min_duration_statement = 1000\n      log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '\n      log_checkpoints = on\n      log_connections = on\n      log_disconnections = on\n      log_lock_waits = on\n      log_temp_files = 10MB\n\n      # SSL\n      ssl = on\n      ssl_cert_file = '/etc/ssl/certs/tls.crt'\n      ssl_key_file = '/etc/ssl/private/tls.key'\n      ssl_ca_file = '/etc/ssl/certs/ca.crt'\n\n    initdb:\n      scripts:\n        01_temporal_setup.sql: |\n          -- Create temporal databases\n          CREATE DATABASE temporal;\n          CREATE DATABASE temporal_visibility;\n\n          -- Create temporal user with proper permissions\n          CREATE USER temporal WITH PASSWORD '${TEMPORAL_PASSWORD}';\n          GRANT ALL PRIVILEGES ON DATABASE temporal TO temporal;\n          GRANT ALL PRIVILEGES ON DATABASE temporal_visibility TO temporal;\n\n          -- Create read-only user for monitoring\n          CREATE USER temporal_monitor WITH PASSWORD '${MONITOR_PASSWORD}';\n          GRANT CONNECT ON DATABASE temporal TO temporal_monitor;\n          GRANT CONNECT ON DATABASE temporal_visibility TO temporal_monitor;\n          GRANT USAGE ON SCHEMA public TO temporal_monitor;\n          GRANT SELECT ON ALL TABLES IN SCHEMA public TO temporal_monitor;\n          ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT ON TABLES TO temporal_monitor;\n\n  # Read replica configuration\n  readReplicas:\n    replicaCount: 2\n\n    persistence:\n      enabled: true\n      storageClass: \"gp3\"\n      size: 100Gi\n\n    resources:\n      limits:\n        memory: 2Gi\n        cpu: 1000m\n      requests:\n        memory: 1Gi\n        cpu: 500m\n\n  # Backup configuration\n  backup:\n    enabled: true\n    cronjob:\n      schedule: \"0 2 * * *\"  # Daily at 2 AM\n      restartPolicy: OnFailure\n      storage:\n        storageClass: \"gp3\"\n        size: 500Gi\n\n    retention:\n      days: 30\n\n    s3:\n      enabled: true\n      bucket: \"temporal-backups\"\n      region: \"us-west-2\"\n      endpoint: \"\"\n      accessKey: \"\"  # Set via secret\n      secretKey: \"\"  # Set via secret\n\n  # Metrics\n  metrics:\n    enabled: true\n    image:\n      tag: \"0.11.1\"\n\n    serviceMonitor:\n      enabled: true\n      namespace: \"monitoring\"\n      interval: \"30s\"\n\n    resources:\n      limits:\n        memory: 256Mi\n        cpu: 250m\n      requests:\n        memory: 128Mi\n        cpu: 100m\n\n  # Network policy\n  networkPolicy:\n    enabled: true\n    allowExternal: false\n    explicitNamespacesSelector:\n      matchLabels:\n        name: \"temporal-system\"\n</code></pre>"},{"location":"implementation/database-setup/#database-secrets-management","title":"Database Secrets Management","text":""},{"location":"implementation/database-setup/#postgresql-credentials-secret","title":"PostgreSQL Credentials Secret","text":"<pre><code># k8s/database/secrets/postgresql-credentials.yaml\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: postgresql-credentials\n  namespace: temporal-system\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: postgresql-credentials\n    creationPolicy: Owner\n    template:\n      type: Opaque\n      data:\n        postgres-password: \"{{ .postgres_password }}\"\n        password: \"{{ .temporal_password }}\"\n        monitor-password: \"{{ .monitor_password }}\"\n        replication-password: \"{{ .replication_password }}\"\n  data:\n  - secretKey: postgres_password\n    remoteRef:\n      key: temporal/database\n      property: postgres_password\n  - secretKey: temporal_password\n    remoteRef:\n      key: temporal/database\n      property: temporal_password\n  - secretKey: monitor_password\n    remoteRef:\n      key: temporal/database\n      property: monitor_password\n  - secretKey: replication_password\n    remoteRef:\n      key: temporal/database\n      property: replication_password\n</code></pre>"},{"location":"implementation/database-setup/#database-schema-management","title":"Database Schema Management","text":""},{"location":"implementation/database-setup/#temporal-schema-setup-job","title":"Temporal Schema Setup Job","text":"<pre><code># k8s/database/jobs/schema-setup.yaml\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: temporal-schema-setup\n  namespace: temporal-system\n  annotations:\n    \"helm.sh/hook\": post-install,post-upgrade\n    \"helm.sh/hook-weight\": \"1\"\n    \"helm.sh/hook-delete-policy\": before-hook-creation\nspec:\n  template:\n    metadata:\n      name: temporal-schema-setup\n    spec:\n      restartPolicy: OnFailure\n      containers:\n      - name: temporal-admin-tools\n        image: temporalio/admin-tools:1.20.0\n        command:\n        - /bin/bash\n        - -c\n        - |\n          set -euo pipefail\n\n          echo \"Setting up Temporal database schema...\"\n\n          # Wait for database to be ready\n          until pg_isready -h $DB_HOST -p $DB_PORT -U $DB_USER; do\n            echo \"Waiting for database to be ready...\"\n            sleep 5\n          done\n\n          # Setup default database\n          temporal-sql-tool \\\n            --plugin postgres \\\n            --ep $DB_HOST \\\n            --port $DB_PORT \\\n            --user $DB_USER \\\n            --password $DB_PASSWORD \\\n            --database $DB_NAME \\\n            setup-schema -v 0.0\n\n          temporal-sql-tool \\\n            --plugin postgres \\\n            --ep $DB_HOST \\\n            --port $DB_PORT \\\n            --user $DB_USER \\\n            --password $DB_PASSWORD \\\n            --database $DB_NAME \\\n            update-schema -d /etc/temporal/schema/postgresql/v96\n\n          # Setup visibility database\n          temporal-sql-tool \\\n            --plugin postgres \\\n            --ep $DB_HOST \\\n            --port $DB_PORT \\\n            --user $DB_USER \\\n            --password $DB_PASSWORD \\\n            --database $DB_VISIBILITY_NAME \\\n            setup-schema -v 0.0\n\n          temporal-sql-tool \\\n            --plugin postgres \\\n            --ep $DB_HOST \\\n            --port $DB_PORT \\\n            --user $DB_USER \\\n            --password $DB_PASSWORD \\\n            --database $DB_VISIBILITY_NAME \\\n            update-schema -d /etc/temporal/schema/postgresql/visibility/versioned\n\n          echo \"Temporal database schema setup completed successfully\"\n\n        env:\n        - name: DB_HOST\n          value: \"postgresql-primary\"\n        - name: DB_PORT\n          value: \"5432\"\n        - name: DB_USER\n          value: \"temporal\"\n        - name: DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: postgresql-credentials\n              key: password\n        - name: DB_NAME\n          value: \"temporal\"\n        - name: DB_VISIBILITY_NAME\n          value: \"temporal_visibility\"\n\n        resources:\n          limits:\n            memory: 512Mi\n            cpu: 500m\n          requests:\n            memory: 256Mi\n            cpu: 250m\n\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 10001\n        fsGroup: 10001\n</code></pre>"},{"location":"implementation/database-setup/#performance-optimization","title":"Performance Optimization","text":""},{"location":"implementation/database-setup/#postgresql-tuning-configuration","title":"PostgreSQL Tuning Configuration","text":""},{"location":"implementation/database-setup/#performance-tuning-configmap","title":"Performance Tuning ConfigMap","text":"<pre><code># k8s/database/config/postgresql-performance.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: postgresql-performance-config\n  namespace: temporal-system\ndata:\n  postgresql.conf: |\n    # Connection Settings\n    max_connections = 200\n    superuser_reserved_connections = 3\n\n    # Memory Settings\n    shared_buffers = 1GB                    # 25% of RAM\n    effective_cache_size = 3GB              # 75% of RAM\n    maintenance_work_mem = 256MB\n    work_mem = 4MB\n\n    # Checkpoint Settings\n    checkpoint_completion_target = 0.9\n    checkpoint_timeout = 10min\n    max_wal_size = 4GB\n    min_wal_size = 1GB\n    wal_buffers = 16MB\n\n    # Query Planning\n    default_statistics_target = 100\n    constraint_exclusion = partition\n    cursor_tuple_fraction = 0.1\n\n    # Disk I/O Settings\n    random_page_cost = 1.1                  # For SSD storage\n    effective_io_concurrency = 200\n    seq_page_cost = 1\n\n    # Background Writer\n    bgwriter_delay = 200ms\n    bgwriter_lru_maxpages = 100\n    bgwriter_lru_multiplier = 2.0\n    bgwriter_flush_after = 512kB\n\n    # Autovacuum Settings\n    autovacuum = on\n    autovacuum_max_workers = 3\n    autovacuum_naptime = 1min\n    autovacuum_vacuum_threshold = 50\n    autovacuum_analyze_threshold = 50\n    autovacuum_vacuum_scale_factor = 0.2\n    autovacuum_analyze_scale_factor = 0.1\n    autovacuum_freeze_max_age = 200000000\n    autovacuum_multixact_freeze_max_age = 400000000\n    autovacuum_vacuum_cost_delay = 20ms\n    autovacuum_vacuum_cost_limit = 200\n\n    # Logging Settings\n    log_destination = 'stderr'\n    logging_collector = on\n    log_directory = 'log'\n    log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'\n    log_rotation_age = 1d\n    log_rotation_size = 100MB\n    log_min_duration_statement = 1000\n    log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '\n    log_checkpoints = on\n    log_connections = on\n    log_disconnections = on\n    log_lock_waits = on\n    log_temp_files = 10MB\n    log_autovacuum_min_duration = 0\n    log_error_verbosity = default\n\n    # Replication Settings\n    wal_level = replica\n    max_wal_senders = 10\n    max_replication_slots = 10\n    hot_standby = on\n    hot_standby_feedback = off\n\n    # SSL Settings\n    ssl = on\n    ssl_cert_file = '/etc/ssl/certs/tls.crt'\n    ssl_key_file = '/etc/ssl/private/tls.key'\n    ssl_ca_file = '/etc/ssl/certs/ca.crt'\n    ssl_ciphers = 'ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384'\n    ssl_prefer_server_ciphers = on\n    ssl_protocols = 'TLSv1.2,TLSv1.3'\n</code></pre>"},{"location":"implementation/database-setup/#database-indexes-for-temporal","title":"Database Indexes for Temporal","text":""},{"location":"implementation/database-setup/#temporal-optimization-script","title":"Temporal Optimization Script","text":"<pre><code>-- k8s/database/sql/temporal-indexes.sql\n-- Additional indexes for Temporal performance optimization\n\n-- Indexes for executions table\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_executions_namespace_id \nON executions (namespace_id);\n\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_executions_workflow_id_run_id \nON executions (workflow_id, run_id);\n\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_executions_state_created_time \nON executions (state, created_time);\n\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_executions_start_time \nON executions (start_time) WHERE start_time IS NOT NULL;\n\n-- Indexes for history_events table\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_history_events_workflow_id_run_id_event_id \nON history_events (workflow_id, run_id, event_id);\n\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_history_events_created_time \nON history_events (created_time);\n\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_history_events_event_type \nON history_events (event_type);\n\n-- Indexes for tasks table\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_tasks_task_queue_name_state \nON tasks (task_queue_name, state);\n\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_tasks_created_time \nON tasks (created_time);\n\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_tasks_visibility_timestamp \nON tasks (visibility_timestamp) WHERE visibility_timestamp IS NOT NULL;\n\n-- Indexes for activity_info_maps table\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_activity_info_maps_workflow_id_run_id \nON activity_info_maps (workflow_id, run_id);\n\n-- Indexes for timer_info_maps table\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_timer_info_maps_workflow_id_run_id \nON timer_info_maps (workflow_id, run_id);\n\n-- Indexes for child_execution_info_maps table\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_child_execution_info_maps_workflow_id_run_id \nON child_execution_info_maps (workflow_id, run_id);\n\n-- Indexes for visibility tables\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_executions_visibility_namespace_id_start_time \nON executions_visibility (namespace_id, start_time);\n\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_executions_visibility_workflow_type_start_time \nON executions_visibility (workflow_type, start_time);\n\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_executions_visibility_status_start_time \nON executions_visibility (status, start_time);\n\n-- Composite indexes for common queries\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_executions_visibility_namespace_status_start_time \nON executions_visibility (namespace_id, status, start_time);\n\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_executions_visibility_namespace_type_start_time \nON executions_visibility (namespace_id, workflow_type, start_time);\n\n-- Update table statistics\nANALYZE executions;\nANALYZE history_events;\nANALYZE tasks;\nANALYZE activity_info_maps;\nANALYZE timer_info_maps;\nANALYZE child_execution_info_maps;\nANALYZE executions_visibility;\n</code></pre>"},{"location":"implementation/database-setup/#backup-and-recovery","title":"Backup and Recovery","text":""},{"location":"implementation/database-setup/#automated-backup-system","title":"Automated Backup System","text":""},{"location":"implementation/database-setup/#backup-cronjob","title":"Backup CronJob","text":"<pre><code># k8s/database/backup/backup-cronjob.yaml\napiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: postgresql-backup\n  namespace: temporal-system\nspec:\n  schedule: \"0 2 * * *\"  # Daily at 2 AM\n  concurrencyPolicy: Forbid\n  failedJobsHistoryLimit: 3\n  successfulJobsHistoryLimit: 3\n  jobTemplate:\n    spec:\n      template:\n        metadata:\n          annotations:\n            prometheus.io/scrape: \"false\"\n        spec:\n          restartPolicy: OnFailure\n          containers:\n          - name: postgresql-backup\n            image: postgres:15.4\n            command:\n            - /bin/bash\n            - -c\n            - |\n              set -euo pipefail\n\n              TIMESTAMP=$(date +%Y%m%d_%H%M%S)\n              BACKUP_DIR=\"/backups\"\n\n              echo \"Starting PostgreSQL backup at $(date)\"\n\n              # Create backup directory\n              mkdir -p \"$BACKUP_DIR\"\n\n              # Backup main database\n              echo \"Backing up temporal database...\"\n              PGPASSWORD=\"$DB_PASSWORD\" pg_dump \\\n                -h \"$DB_HOST\" \\\n                -U \"$DB_USER\" \\\n                -d temporal \\\n                --verbose \\\n                --no-owner \\\n                --no-privileges \\\n                --clean \\\n                --if-exists \\\n                --format=custom \\\n                -f \"$BACKUP_DIR/temporal_${TIMESTAMP}.dump\"\n\n              # Backup visibility database\n              echo \"Backing up temporal_visibility database...\"\n              PGPASSWORD=\"$DB_PASSWORD\" pg_dump \\\n                -h \"$DB_HOST\" \\\n                -U \"$DB_USER\" \\\n                -d temporal_visibility \\\n                --verbose \\\n                --no-owner \\\n                --no-privileges \\\n                --clean \\\n                --if-exists \\\n                --format=custom \\\n                -f \"$BACKUP_DIR/temporal_visibility_${TIMESTAMP}.dump\"\n\n              # Compress backups\n              echo \"Compressing backup files...\"\n              gzip \"$BACKUP_DIR/temporal_${TIMESTAMP}.dump\"\n              gzip \"$BACKUP_DIR/temporal_visibility_${TIMESTAMP}.dump\"\n\n              # Upload to S3\n              echo \"Uploading backups to S3...\"\n              aws s3 cp \"$BACKUP_DIR/temporal_${TIMESTAMP}.dump.gz\" \\\n                \"s3://${S3_BUCKET}/database/temporal_${TIMESTAMP}.dump.gz\" \\\n                --storage-class STANDARD_IA\n\n              aws s3 cp \"$BACKUP_DIR/temporal_visibility_${TIMESTAMP}.dump.gz\" \\\n                \"s3://${S3_BUCKET}/database/temporal_visibility_${TIMESTAMP}.dump.gz\" \\\n                --storage-class STANDARD_IA\n\n              # Clean up local files\n              rm -f \"$BACKUP_DIR\"/*.dump.gz\n\n              # Clean up old backups (keep last 30 days)\n              aws s3 ls \"s3://${S3_BUCKET}/database/\" | \\\n                grep \"temporal_\" | \\\n                sort | \\\n                head -n -60 | \\\n                awk '{print $4}' | \\\n                xargs -I {} aws s3 rm \"s3://${S3_BUCKET}/database/{}\" || true\n\n              echo \"Backup completed successfully at $(date)\"\n\n            env:\n            - name: DB_HOST\n              value: \"postgresql-primary\"\n            - name: DB_USER\n              value: \"temporal\"\n            - name: DB_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: postgresql-credentials\n                  key: password\n            - name: S3_BUCKET\n              value: \"temporal-backups\"\n            - name: AWS_REGION\n              value: \"us-west-2\"\n\n            volumeMounts:\n            - name: backup-storage\n              mountPath: /backups\n\n            resources:\n              limits:\n                memory: 1Gi\n                cpu: 500m\n              requests:\n                memory: 512Mi\n                cpu: 250m\n\n          volumes:\n          - name: backup-storage\n            emptyDir:\n              sizeLimit: 10Gi\n\n          serviceAccountName: postgresql-backup\n\n          securityContext:\n            runAsNonRoot: true\n            runAsUser: 999\n            fsGroup: 999\n</code></pre>"},{"location":"implementation/database-setup/#point-in-time-recovery-setup","title":"Point-in-Time Recovery Setup","text":""},{"location":"implementation/database-setup/#wal-e-configuration-for-continuous-archiving","title":"WAL-E Configuration for Continuous Archiving","text":"<pre><code># k8s/database/backup/wal-e-config.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: wal-e-config\n  namespace: temporal-system\ndata:\n  wal-e.conf: |\n    [wal-e]\n    s3_prefix = s3://temporal-backups/wal-e\n    aws_region = us-west-2\n\n    [postgresql]\n    archive_mode = on\n    archive_command = 'wal-e wal-push %p'\n    archive_timeout = 60\n\n    max_wal_senders = 10\n    wal_keep_size = 1GB\n    wal_level = replica\n\n  recovery.conf.template: |\n    standby_mode = 'on'\n    primary_conninfo = 'host=${PRIMARY_HOST} port=5432 user=replicator password=${REPLICATION_PASSWORD}'\n    restore_command = 'wal-e wal-fetch %f %p'\n    recovery_target_time = '${RECOVERY_TARGET_TIME}'\n</code></pre>"},{"location":"implementation/database-setup/#disaster-recovery-procedures","title":"Disaster Recovery Procedures","text":""},{"location":"implementation/database-setup/#recovery-script","title":"Recovery Script","text":"<pre><code>#!/bin/bash\n# scripts/database/disaster-recovery.sh\n\nset -euo pipefail\n\nBACKUP_DATE=${1:-latest}\nRECOVERY_TYPE=${2:-full}  # full, point-in-time\nTARGET_TIME=${3:-}\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m'\n\nlog() {\n    echo -e \"${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}\"\n}\n\nwarn() {\n    echo -e \"${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}\"\n}\n\nerror() {\n    echo -e \"${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}\"\n    exit 1\n}\n\nlog \"Starting disaster recovery process...\"\nlog \"Backup date: $BACKUP_DATE\"\nlog \"Recovery type: $RECOVERY_TYPE\"\n\n# Verify prerequisites\nif ! command -v kubectl &amp;&gt; /dev/null; then\n    error \"kubectl is required but not installed\"\nfi\n\nif ! command -v aws &amp;&gt; /dev/null; then\n    error \"aws CLI is required but not installed\"\nfi\n\n# Get backup file\nif [[ \"$BACKUP_DATE\" == \"latest\" ]]; then\n    BACKUP_FILE=$(aws s3 ls s3://temporal-backups/database/ | sort | tail -n 1 | awk '{print $4}')\n    if [[ -z \"$BACKUP_FILE\" ]]; then\n        error \"No backup files found\"\n    fi\n    log \"Using latest backup: $BACKUP_FILE\"\nelse\n    BACKUP_FILE=\"temporal_${BACKUP_DATE}.dump.gz\"\nfi\n\n# Download backup\nlog \"Downloading backup file...\"\naws s3 cp \"s3://temporal-backups/database/$BACKUP_FILE\" \"./backup.dump.gz\"\ngunzip backup.dump.gz\n\n# Stop Temporal services\nlog \"Stopping Temporal services...\"\nkubectl scale deployment temporal-frontend temporal-history temporal-matching temporal-worker --replicas=0 -n temporal-system\n\n# Create recovery database\nlog \"Creating recovery database...\"\nkubectl run recovery-db --image=postgres:15.4 --rm -i --restart=Never -- \\\n    createdb -h postgresql-primary -U postgres -O temporal temporal_recovery\n\n# Restore backup\nlog \"Restoring database backup...\"\nkubectl run restore-job --image=postgres:15.4 --rm -i --restart=Never -- \\\n    pg_restore -h postgresql-primary -U temporal -d temporal_recovery \\\n    --verbose --clean --if-exists &lt; backup.dump\n\nif [[ \"$RECOVERY_TYPE\" == \"point-in-time\" &amp;&amp; -n \"$TARGET_TIME\" ]]; then\n    log \"Performing point-in-time recovery to $TARGET_TIME...\"\n    # Configure recovery.conf for point-in-time recovery\n    kubectl run pitr-job --image=postgres:15.4 --rm -i --restart=Never -- \\\n        bash -c \"\n        echo \\\"recovery_target_time = '$TARGET_TIME'\\\" &gt; /tmp/recovery.conf\n        echo \\\"recovery_target_action = 'promote'\\\" &gt;&gt; /tmp/recovery.conf\n        kubectl cp /tmp/recovery.conf postgresql-primary:/var/lib/postgresql/data/recovery.conf\n        \"\nfi\n\n# Validate recovery\nlog \"Validating database recovery...\"\nRECORD_COUNT=$(kubectl run validate-job --image=postgres:15.4 --rm -i --restart=Never -- \\\n    psql -h postgresql-primary -U temporal -d temporal_recovery -t -c \"SELECT COUNT(*) FROM executions;\")\n\nlog \"Database recovery validation: $RECORD_COUNT records found\"\n\n# Switch to recovered database\nlog \"Switching to recovered database...\"\nkubectl run switch-db --image=postgres:15.4 --rm -i --restart=Never -- \\\n    bash -c \"\n    psql -h postgresql-primary -U postgres -c 'ALTER DATABASE temporal RENAME TO temporal_old;'\n    psql -h postgresql-primary -U postgres -c 'ALTER DATABASE temporal_recovery RENAME TO temporal;'\n    \"\n\n# Restart Temporal services\nlog \"Restarting Temporal services...\"\nkubectl scale deployment temporal-frontend temporal-history temporal-matching temporal-worker --replicas=1 -n temporal-system\n\n# Wait for services to be ready\nkubectl wait --for=condition=available deployment/temporal-frontend -n temporal-system --timeout=300s\n\nlog \"Disaster recovery completed successfully!\"\nlog \"Please verify system functionality before proceeding with normal operations\"\n\n# Clean up\nrm -f backup.dump\n</code></pre>"},{"location":"implementation/database-setup/#monitoring-and-maintenance","title":"Monitoring and Maintenance","text":""},{"location":"implementation/database-setup/#database-monitoring-setup","title":"Database Monitoring Setup","text":""},{"location":"implementation/database-setup/#postgresql-exporter-configuration","title":"PostgreSQL Exporter Configuration","text":"<pre><code># k8s/database/monitoring/postgres-exporter.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: postgres-exporter\n  namespace: temporal-system\n  labels:\n    app: postgres-exporter\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: postgres-exporter\n  template:\n    metadata:\n      labels:\n        app: postgres-exporter\n    spec:\n      containers:\n      - name: postgres-exporter\n        image: quay.io/prometheuscommunity/postgres-exporter:v0.11.1\n        ports:\n        - containerPort: 9187\n          name: metrics\n        env:\n        - name: DATA_SOURCE_NAME\n          valueFrom:\n            secretKeyRef:\n              name: postgres-exporter-secret\n              key: connection-string\n        - name: PG_EXPORTER_QUERIES_PATH\n          value: \"/etc/postgres_exporter/queries.yaml\"\n\n        volumeMounts:\n        - name: queries-config\n          mountPath: /etc/postgres_exporter\n\n        resources:\n          limits:\n            memory: 256Mi\n            cpu: 250m\n          requests:\n            memory: 128Mi\n            cpu: 100m\n\n        securityContext:\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          runAsUser: 65534\n\n      volumes:\n      - name: queries-config\n        configMap:\n          name: postgres-exporter-queries\n\n      serviceAccountName: postgres-exporter\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: postgres-exporter\n  namespace: temporal-system\n  labels:\n    app: postgres-exporter\nspec:\n  ports:\n  - port: 9187\n    targetPort: 9187\n    name: metrics\n  selector:\n    app: postgres-exporter\n\n---\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: postgres-exporter\n  namespace: temporal-system\nspec:\n  selector:\n    matchLabels:\n      app: postgres-exporter\n  endpoints:\n  - port: metrics\n    interval: 30s\n    path: /metrics\n</code></pre>"},{"location":"implementation/database-setup/#custom-postgresql-queries-for-monitoring","title":"Custom PostgreSQL Queries for Monitoring","text":"<pre><code># k8s/database/monitoring/postgres-queries.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: postgres-exporter-queries\n  namespace: temporal-system\ndata:\n  queries.yaml: |\n    pg_replication:\n      query: \"SELECT CASE WHEN NOT pg_is_in_recovery() THEN 0 ELSE GREATEST (0, EXTRACT(EPOCH FROM (now() - pg_last_xact_replay_timestamp()))) END AS lag\"\n      master: true\n      metrics:\n        - lag:\n            usage: \"GAUGE\"\n            description: \"Replication lag behind master in seconds\"\n\n    pg_postmaster:\n      query: \"SELECT pg_postmaster_start_time as start_time_seconds from pg_postmaster_start_time()\"\n      master: true\n      metrics:\n        - start_time_seconds:\n            usage: \"GAUGE\"\n            description: \"Time at which postmaster started\"\n\n    pg_stat_user_tables:\n      query: |\n        SELECT\n          current_database() datname,\n          schemaname,\n          relname,\n          seq_scan,\n          seq_tup_read,\n          idx_scan,\n          idx_tup_fetch,\n          n_tup_ins,\n          n_tup_upd,\n          n_tup_del,\n          n_tup_hot_upd,\n          n_live_tup,\n          n_dead_tup,\n          n_mod_since_analyze,\n          COALESCE(last_vacuum, '1970-01-01Z') as last_vacuum,\n          COALESCE(last_autovacuum, '1970-01-01Z') as last_autovacuum,\n          COALESCE(last_analyze, '1970-01-01Z') as last_analyze,\n          COALESCE(last_autoanalyze, '1970-01-01Z') as last_autoanalyze,\n          vacuum_count,\n          autovacuum_count,\n          analyze_count,\n          autoanalyze_count\n        FROM pg_stat_user_tables\n      metrics:\n        - datname:\n            usage: \"LABEL\"\n            description: \"Name of current database\"\n        - schemaname:\n            usage: \"LABEL\"\n            description: \"Name of the schema that this table is in\"\n        - relname:\n            usage: \"LABEL\"\n            description: \"Name of this table\"\n        - seq_scan:\n            usage: \"COUNTER\"\n            description: \"Number of sequential scans initiated on this table\"\n        - seq_tup_read:\n            usage: \"COUNTER\"\n            description: \"Number of live rows fetched by sequential scans\"\n        - idx_scan:\n            usage: \"COUNTER\"\n            description: \"Number of index scans initiated on this table\"\n        - idx_tup_fetch:\n            usage: \"COUNTER\"\n            description: \"Number of live rows fetched by index scans\"\n        - n_tup_ins:\n            usage: \"COUNTER\"\n            description: \"Number of rows inserted\"\n        - n_tup_upd:\n            usage: \"COUNTER\"\n            description: \"Number of rows updated\"\n        - n_tup_del:\n            usage: \"COUNTER\"\n            description: \"Number of rows deleted\"\n        - n_tup_hot_upd:\n            usage: \"COUNTER\"\n            description: \"Number of rows HOT updated\"\n        - n_live_tup:\n            usage: \"GAUGE\"\n            description: \"Estimated number of live rows\"\n        - n_dead_tup:\n            usage: \"GAUGE\"\n            description: \"Estimated number of dead rows\"\n        - n_mod_since_analyze:\n            usage: \"GAUGE\"\n            description: \"Estimated number of rows modified since this table was last analyzed\"\n        - last_vacuum:\n            usage: \"GAUGE\"\n            description: \"Last time at which this table was manually vacuumed\"\n        - last_autovacuum:\n            usage: \"GAUGE\"\n            description: \"Last time at which this table was vacuumed by the autovacuum daemon\"\n        - last_analyze:\n            usage: \"GAUGE\"\n            description: \"Last time at which this table was manually analyzed\"\n        - last_autoanalyze:\n            usage: \"GAUGE\"\n            description: \"Last time at which this table was analyzed by the autovacuum daemon\"\n        - vacuum_count:\n            usage: \"COUNTER\"\n            description: \"Number of times this table has been manually vacuumed\"\n        - autovacuum_count:\n            usage: \"COUNTER\"\n            description: \"Number of times this table has been vacuumed by the autovacuum daemon\"\n        - analyze_count:\n            usage: \"COUNTER\"\n            description: \"Number of times this table has been manually analyzed\"\n        - autoanalyze_count:\n            usage: \"COUNTER\"\n            description: \"Number of times this table has been analyzed by the autovacuum daemon\"\n\n    temporal_executions:\n      query: |\n        SELECT\n          namespace_id,\n          COUNT(*) as total_executions,\n          COUNT(*) FILTER (WHERE state = 1) as running_executions,\n          COUNT(*) FILTER (WHERE state = 2) as completed_executions,\n          COUNT(*) FILTER (WHERE state = 3) as failed_executions,\n          COUNT(*) FILTER (WHERE state = 4) as cancelled_executions,\n          COUNT(*) FILTER (WHERE state = 5) as terminated_executions\n        FROM executions\n        GROUP BY namespace_id\n      metrics:\n        - namespace_id:\n            usage: \"LABEL\"\n            description: \"Temporal namespace ID\"\n        - total_executions:\n            usage: \"GAUGE\"\n            description: \"Total number of workflow executions\"\n        - running_executions:\n            usage: \"GAUGE\"\n            description: \"Number of running workflow executions\"\n        - completed_executions:\n            usage: \"GAUGE\"\n            description: \"Number of completed workflow executions\"\n        - failed_executions:\n            usage: \"GAUGE\"\n            description: \"Number of failed workflow executions\"\n        - cancelled_executions:\n            usage: \"GAUGE\"\n            description: \"Number of cancelled workflow executions\"\n        - terminated_executions:\n            usage: \"GAUGE\"\n            description: \"Number of terminated workflow executions\"\n</code></pre>"},{"location":"implementation/database-setup/#database-maintenance-scripts","title":"Database Maintenance Scripts","text":""},{"location":"implementation/database-setup/#maintenance-cronjob","title":"Maintenance CronJob","text":"<pre><code># k8s/database/maintenance/maintenance-cronjob.yaml\napiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: postgresql-maintenance\n  namespace: temporal-system\nspec:\n  schedule: \"0 3 * * 0\"  # Weekly on Sunday at 3 AM\n  concurrencyPolicy: Forbid\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          restartPolicy: OnFailure\n          containers:\n          - name: maintenance\n            image: postgres:15.4\n            command:\n            - /bin/bash\n            - -c\n            - |\n              set -euo pipefail\n\n              echo \"Starting database maintenance at $(date)\"\n\n              # Vacuum and analyze all databases\n              for db in temporal temporal_visibility; do\n                echo \"Maintaining database: $db\"\n\n                # Vacuum analyze\n                PGPASSWORD=\"$DB_PASSWORD\" psql -h \"$DB_HOST\" -U \"$DB_USER\" -d \"$db\" -c \"VACUUM ANALYZE;\"\n\n                # Reindex\n                PGPASSWORD=\"$DB_PASSWORD\" psql -h \"$DB_HOST\" -U \"$DB_USER\" -d \"$db\" -c \"REINDEX DATABASE $db;\"\n\n                # Update statistics\n                PGPASSWORD=\"$DB_PASSWORD\" psql -h \"$DB_HOST\" -U \"$DB_USER\" -d \"$db\" -c \"ANALYZE;\"\n              done\n\n              echo \"Database maintenance completed at $(date)\"\n\n            env:\n            - name: DB_HOST\n              value: \"postgresql-primary\"\n            - name: DB_USER\n              value: \"temporal\"\n            - name: DB_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: postgresql-credentials\n                  key: password\n\n            resources:\n              limits:\n                memory: 512Mi\n                cpu: 500m\n              requests:\n                memory: 256Mi\n                cpu: 250m\n</code></pre> <p>This comprehensive database setup guide provides enterprise-grade PostgreSQL deployment with high availability, performance optimization, backup/recovery procedures, and monitoring capabilities specifically tuned for Temporal.io workloads.</p>"},{"location":"implementation/infrastructure-setup/","title":"Infrastructure Setup","text":"<p>This guide provides step-by-step instructions for setting up the infrastructure required for Temporal.io enterprise deployment, including Kubernetes cluster, networking, storage, and foundational services.</p>"},{"location":"implementation/infrastructure-setup/#overview","title":"Overview","text":"<p>The infrastructure setup includes: - Kubernetes cluster provisioning - Network configuration and security groups - Storage provisioning and configuration - Load balancer setup - DNS and certificate management - Monitoring infrastructure</p>"},{"location":"implementation/infrastructure-setup/#prerequisites","title":"Prerequisites","text":""},{"location":"implementation/infrastructure-setup/#required-tools","title":"Required Tools","text":"<pre><code># Install required tools on macOS\nbrew install kubectl\nbrew install helm\nbrew install terraform\nbrew install aws-cli\nbrew install eksctl  # for AWS EKS\nbrew install k9s     # optional but recommended\n\n# Verify installations\nkubectl version --client\nhelm version\nterraform version\naws --version\n</code></pre>"},{"location":"implementation/infrastructure-setup/#required-permissions","title":"Required Permissions","text":""},{"location":"implementation/infrastructure-setup/#aws-iam-permissions","title":"AWS IAM Permissions","text":"<pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"eks:*\",\n                \"ec2:*\",\n                \"iam:*\",\n                \"cloudformation:*\",\n                \"autoscaling:*\",\n                \"elasticloadbalancing:*\",\n                \"route53:*\",\n                \"acm:*\",\n                \"rds:*\",\n                \"elasticache:*\"\n            ],\n            \"Resource\": \"*\"\n        }\n    ]\n}\n</code></pre>"},{"location":"implementation/infrastructure-setup/#gcp-iam-roles","title":"GCP IAM Roles","text":"<pre><code># Required roles for GKE deployment\ngcloud projects add-iam-policy-binding PROJECT_ID \\\n    --member=\"user:YOUR_EMAIL\" \\\n    --role=\"roles/container.admin\"\n\ngcloud projects add-iam-policy-binding PROJECT_ID \\\n    --member=\"user:YOUR_EMAIL\" \\\n    --role=\"roles/compute.admin\"\n\ngcloud projects add-iam-policy-binding PROJECT_ID \\\n    --member=\"user:YOUR_EMAIL\" \\\n    --role=\"roles/iam.serviceAccountAdmin\"\n</code></pre>"},{"location":"implementation/infrastructure-setup/#terraform-infrastructure","title":"Terraform Infrastructure","text":""},{"location":"implementation/infrastructure-setup/#directory-structure","title":"Directory Structure","text":"<pre><code>infrastructure/\n\u251c\u2500\u2500 terraform/\n\u2502   \u251c\u2500\u2500 modules/\n\u2502   \u2502   \u251c\u2500\u2500 eks/\n\u2502   \u2502   \u251c\u2500\u2500 vpc/\n\u2502   \u2502   \u251c\u2500\u2500 rds/\n\u2502   \u2502   \u2514\u2500\u2500 elasticache/\n\u2502   \u2514\u2500\u2500 environments/\n\u2502       \u251c\u2500\u2500 development/\n\u2502       \u251c\u2500\u2500 staging/\n\u2502       \u2514\u2500\u2500 production/\n\u251c\u2500\u2500 scripts/\n\u2514\u2500\u2500 docs/\n</code></pre>"},{"location":"implementation/infrastructure-setup/#vpc-and-networking","title":"VPC and Networking","text":""},{"location":"implementation/infrastructure-setup/#vpc-module","title":"VPC Module","text":"<pre><code># terraform/modules/vpc/main.tf\nresource \"aws_vpc\" \"main\" {\n  cidr_block           = var.vpc_cidr\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  tags = {\n    Name        = \"${var.cluster_name}-vpc\"\n    Environment = var.environment\n    Project     = \"temporal\"\n  }\n}\n\nresource \"aws_internet_gateway\" \"main\" {\n  vpc_id = aws_vpc.main.id\n\n  tags = {\n    Name = \"${var.cluster_name}-igw\"\n  }\n}\n\n# Public subnets\nresource \"aws_subnet\" \"public\" {\n  count = length(var.availability_zones)\n\n  vpc_id                  = aws_vpc.main.id\n  cidr_block              = var.public_subnet_cidrs[count.index]\n  availability_zone       = var.availability_zones[count.index]\n  map_public_ip_on_launch = true\n\n  tags = {\n    Name                     = \"${var.cluster_name}-public-${count.index + 1}\"\n    \"kubernetes.io/role/elb\" = \"1\"\n    Environment              = var.environment\n  }\n}\n\n# Private subnets\nresource \"aws_subnet\" \"private\" {\n  count = length(var.availability_zones)\n\n  vpc_id            = aws_vpc.main.id\n  cidr_block        = var.private_subnet_cidrs[count.index]\n  availability_zone = var.availability_zones[count.index]\n\n  tags = {\n    Name                              = \"${var.cluster_name}-private-${count.index + 1}\"\n    \"kubernetes.io/role/internal-elb\" = \"1\"\n    Environment                       = var.environment\n  }\n}\n\n# NAT Gateway\nresource \"aws_eip\" \"nat\" {\n  count = length(var.availability_zones)\n  vpc   = true\n\n  tags = {\n    Name = \"${var.cluster_name}-nat-eip-${count.index + 1}\"\n  }\n}\n\nresource \"aws_nat_gateway\" \"main\" {\n  count = length(var.availability_zones)\n\n  allocation_id = aws_eip.nat[count.index].id\n  subnet_id     = aws_subnet.public[count.index].id\n\n  tags = {\n    Name = \"${var.cluster_name}-nat-${count.index + 1}\"\n  }\n\n  depends_on = [aws_internet_gateway.main]\n}\n\n# Route tables\nresource \"aws_route_table\" \"public\" {\n  vpc_id = aws_vpc.main.id\n\n  route {\n    cidr_block = \"0.0.0.0/0\"\n    gateway_id = aws_internet_gateway.main.id\n  }\n\n  tags = {\n    Name = \"${var.cluster_name}-public-rt\"\n  }\n}\n\nresource \"aws_route_table\" \"private\" {\n  count  = length(var.availability_zones)\n  vpc_id = aws_vpc.main.id\n\n  route {\n    cidr_block     = \"0.0.0.0/0\"\n    nat_gateway_id = aws_nat_gateway.main[count.index].id\n  }\n\n  tags = {\n    Name = \"${var.cluster_name}-private-rt-${count.index + 1}\"\n  }\n}\n\n# Route table associations\nresource \"aws_route_table_association\" \"public\" {\n  count = length(var.availability_zones)\n\n  subnet_id      = aws_subnet.public[count.index].id\n  route_table_id = aws_route_table.public.id\n}\n\nresource \"aws_route_table_association\" \"private\" {\n  count = length(var.availability_zones)\n\n  subnet_id      = aws_subnet.private[count.index].id\n  route_table_id = aws_route_table.private[count.index].id\n}\n</code></pre>"},{"location":"implementation/infrastructure-setup/#vpc-variables","title":"VPC Variables","text":"<pre><code># terraform/modules/vpc/variables.tf\nvariable \"cluster_name\" {\n  description = \"Name of the EKS cluster\"\n  type        = string\n}\n\nvariable \"environment\" {\n  description = \"Environment name\"\n  type        = string\n}\n\nvariable \"vpc_cidr\" {\n  description = \"CIDR block for VPC\"\n  type        = string\n  default     = \"10.0.0.0/16\"\n}\n\nvariable \"availability_zones\" {\n  description = \"List of availability zones\"\n  type        = list(string)\n}\n\nvariable \"public_subnet_cidrs\" {\n  description = \"CIDR blocks for public subnets\"\n  type        = list(string)\n}\n\nvariable \"private_subnet_cidrs\" {\n  description = \"CIDR blocks for private subnets\"\n  type        = list(string)\n}\n</code></pre>"},{"location":"implementation/infrastructure-setup/#eks-cluster-setup","title":"EKS Cluster Setup","text":""},{"location":"implementation/infrastructure-setup/#eks-module","title":"EKS Module","text":"<pre><code># terraform/modules/eks/main.tf\nresource \"aws_eks_cluster\" \"main\" {\n  name     = var.cluster_name\n  role_arn = aws_iam_role.cluster.arn\n  version  = var.kubernetes_version\n\n  vpc_config {\n    subnet_ids              = concat(var.public_subnet_ids, var.private_subnet_ids)\n    endpoint_private_access = true\n    endpoint_public_access  = true\n    public_access_cidrs     = var.public_access_cidrs\n  }\n\n  encryption_config {\n    provider {\n      key_arn = aws_kms_key.eks.arn\n    }\n    resources = [\"secrets\"]\n  }\n\n  enabled_cluster_log_types = [\"api\", \"audit\", \"authenticator\", \"controllerManager\", \"scheduler\"]\n\n  depends_on = [\n    aws_iam_role_policy_attachment.cluster_AmazonEKSClusterPolicy,\n    aws_cloudwatch_log_group.cluster,\n  ]\n\n  tags = {\n    Environment = var.environment\n    Project     = \"temporal\"\n  }\n}\n\nresource \"aws_cloudwatch_log_group\" \"cluster\" {\n  name              = \"/aws/eks/${var.cluster_name}/cluster\"\n  retention_in_days = 7\n}\n\n# EKS Node Group\nresource \"aws_eks_node_group\" \"main\" {\n  cluster_name    = aws_eks_cluster.main.name\n  node_group_name = \"${var.cluster_name}-nodes\"\n  node_role_arn   = aws_iam_role.node.arn\n  subnet_ids      = var.private_subnet_ids\n\n  capacity_type  = var.capacity_type\n  instance_types = var.instance_types\n\n  scaling_config {\n    desired_size = var.desired_capacity\n    max_size     = var.max_capacity\n    min_size     = var.min_capacity\n  }\n\n  update_config {\n    max_unavailable = 1\n  }\n\n  # Ensure that IAM Role permissions are created before and deleted after EKS Node Group handling.\n  depends_on = [\n    aws_iam_role_policy_attachment.node_AmazonEKSWorkerNodePolicy,\n    aws_iam_role_policy_attachment.node_AmazonEKS_CNI_Policy,\n    aws_iam_role_policy_attachment.node_AmazonEC2ContainerRegistryReadOnly,\n  ]\n\n  tags = {\n    Environment = var.environment\n    Project     = \"temporal\"\n  }\n}\n\n# IAM Role for EKS Cluster\nresource \"aws_iam_role\" \"cluster\" {\n  name = \"${var.cluster_name}-cluster-role\"\n\n  assume_role_policy = jsonencode({\n    Statement = [{\n      Action = \"sts:AssumeRole\"\n      Effect = \"Allow\"\n      Principal = {\n        Service = \"eks.amazonaws.com\"\n      }\n    }]\n    Version = \"2012-10-17\"\n  })\n}\n\nresource \"aws_iam_role_policy_attachment\" \"cluster_AmazonEKSClusterPolicy\" {\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonEKSClusterPolicy\"\n  role       = aws_iam_role.cluster.name\n}\n\n# IAM Role for EKS Node Group\nresource \"aws_iam_role\" \"node\" {\n  name = \"${var.cluster_name}-node-role\"\n\n  assume_role_policy = jsonencode({\n    Statement = [{\n      Action = \"sts:AssumeRole\"\n      Effect = \"Allow\"\n      Principal = {\n        Service = \"ec2.amazonaws.com\"\n      }\n    }]\n    Version = \"2012-10-17\"\n  })\n}\n\nresource \"aws_iam_role_policy_attachment\" \"node_AmazonEKSWorkerNodePolicy\" {\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy\"\n  role       = aws_iam_role.node.name\n}\n\nresource \"aws_iam_role_policy_attachment\" \"node_AmazonEKS_CNI_Policy\" {\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy\"\n  role       = aws_iam_role.node.name\n}\n\nresource \"aws_iam_role_policy_attachment\" \"node_AmazonEC2ContainerRegistryReadOnly\" {\n  policy_arn = \"arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly\"\n  role       = aws_iam_role.node.name\n}\n\n# KMS Key for EKS encryption\nresource \"aws_kms_key\" \"eks\" {\n  description = \"EKS Secret Encryption Key\"\n\n  tags = {\n    Name        = \"${var.cluster_name}-eks-key\"\n    Environment = var.environment\n  }\n}\n\nresource \"aws_kms_alias\" \"eks\" {\n  name          = \"alias/${var.cluster_name}-eks\"\n  target_key_id = aws_kms_key.eks.key_id\n}\n</code></pre>"},{"location":"implementation/infrastructure-setup/#rds-postgresql-setup","title":"RDS PostgreSQL Setup","text":""},{"location":"implementation/infrastructure-setup/#rds-module","title":"RDS Module","text":"<pre><code># terraform/modules/rds/main.tf\nresource \"aws_db_subnet_group\" \"main\" {\n  name       = \"${var.cluster_name}-db-subnet-group\"\n  subnet_ids = var.private_subnet_ids\n\n  tags = {\n    Name        = \"${var.cluster_name}-db-subnet-group\"\n    Environment = var.environment\n  }\n}\n\nresource \"aws_security_group\" \"rds\" {\n  name_prefix = \"${var.cluster_name}-rds-\"\n  vpc_id      = var.vpc_id\n\n  ingress {\n    from_port   = 5432\n    to_port     = 5432\n    protocol    = \"tcp\"\n    cidr_blocks = var.allowed_cidr_blocks\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name        = \"${var.cluster_name}-rds-sg\"\n    Environment = var.environment\n  }\n}\n\nresource \"aws_db_instance\" \"main\" {\n  allocated_storage           = var.allocated_storage\n  max_allocated_storage       = var.max_allocated_storage\n  storage_type                = \"gp3\"\n  storage_encrypted           = true\n  kms_key_id                  = aws_kms_key.rds.arn\n\n  db_name  = var.database_name\n  engine   = \"postgres\"\n  engine_version = var.postgres_version\n  instance_class = var.instance_class\n\n  username = var.username\n  password = var.password\n\n  vpc_security_group_ids = [aws_security_group.rds.id]\n  db_subnet_group_name   = aws_db_subnet_group.main.name\n\n  backup_retention_period = var.backup_retention_period\n  backup_window          = var.backup_window\n  maintenance_window     = var.maintenance_window\n\n  skip_final_snapshot = var.environment != \"production\"\n  deletion_protection = var.environment == \"production\"\n\n  performance_insights_enabled = true\n  monitoring_interval         = 60\n  monitoring_role_arn         = aws_iam_role.rds_monitoring.arn\n\n  tags = {\n    Name        = \"${var.cluster_name}-postgres\"\n    Environment = var.environment\n  }\n}\n\n# RDS Read Replica for production\nresource \"aws_db_instance\" \"replica\" {\n  count = var.environment == \"production\" ? 1 : 0\n\n  identifier             = \"${var.cluster_name}-postgres-replica\"\n  replicate_source_db    = aws_db_instance.main.id\n  instance_class         = var.replica_instance_class\n  publicly_accessible    = false\n  auto_minor_version_upgrade = false\n\n  tags = {\n    Name        = \"${var.cluster_name}-postgres-replica\"\n    Environment = var.environment\n  }\n}\n\n# KMS Key for RDS encryption\nresource \"aws_kms_key\" \"rds\" {\n  description = \"RDS encryption key\"\n\n  tags = {\n    Name        = \"${var.cluster_name}-rds-key\"\n    Environment = var.environment\n  }\n}\n\nresource \"aws_kms_alias\" \"rds\" {\n  name          = \"alias/${var.cluster_name}-rds\"\n  target_key_id = aws_kms_key.rds.key_id\n}\n\n# IAM Role for RDS Enhanced Monitoring\nresource \"aws_iam_role\" \"rds_monitoring\" {\n  name = \"${var.cluster_name}-rds-monitoring-role\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = \"sts:AssumeRole\"\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"monitoring.rds.amazonaws.com\"\n        }\n      }\n    ]\n  })\n}\n\nresource \"aws_iam_role_policy_attachment\" \"rds_monitoring\" {\n  role       = aws_iam_role.rds_monitoring.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonRDSEnhancedMonitoringRole\"\n}\n</code></pre>"},{"location":"implementation/infrastructure-setup/#elasticache-redis-setup","title":"ElastiCache Redis Setup","text":""},{"location":"implementation/infrastructure-setup/#elasticache-module","title":"ElastiCache Module","text":"<pre><code># terraform/modules/elasticache/main.tf\nresource \"aws_elasticache_subnet_group\" \"main\" {\n  name       = \"${var.cluster_name}-cache-subnet\"\n  subnet_ids = var.private_subnet_ids\n}\n\nresource \"aws_security_group\" \"elasticache\" {\n  name_prefix = \"${var.cluster_name}-cache-\"\n  vpc_id      = var.vpc_id\n\n  ingress {\n    from_port   = 6379\n    to_port     = 6379\n    protocol    = \"tcp\"\n    cidr_blocks = var.allowed_cidr_blocks\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name        = \"${var.cluster_name}-cache-sg\"\n    Environment = var.environment\n  }\n}\n\nresource \"aws_elasticache_replication_group\" \"main\" {\n  replication_group_id         = \"${var.cluster_name}-redis\"\n  description                  = \"Redis cluster for ${var.cluster_name}\"\n\n  node_type                    = var.node_type\n  port                         = 6379\n  parameter_group_name         = aws_elasticache_parameter_group.main.name\n  subnet_group_name            = aws_elasticache_subnet_group.main.name\n  security_group_ids           = [aws_security_group.elasticache.id]\n\n  num_cache_clusters           = var.num_cache_clusters\n  at_rest_encryption_enabled   = true\n  transit_encryption_enabled   = true\n  auth_token                   = var.auth_token\n\n  maintenance_window           = var.maintenance_window\n  snapshot_retention_limit     = var.snapshot_retention_limit\n  snapshot_window              = var.snapshot_window\n\n  tags = {\n    Name        = \"${var.cluster_name}-redis\"\n    Environment = var.environment\n  }\n}\n\nresource \"aws_elasticache_parameter_group\" \"main\" {\n  family = \"redis7\"\n  name   = \"${var.cluster_name}-redis-params\"\n\n  parameter {\n    name  = \"maxmemory-policy\"\n    value = \"allkeys-lru\"\n  }\n}\n</code></pre>"},{"location":"implementation/infrastructure-setup/#environment-specific-configurations","title":"Environment-Specific Configurations","text":""},{"location":"implementation/infrastructure-setup/#development-environment","title":"Development Environment","text":"<pre><code># terraform/environments/development/main.tf\nmodule \"vpc\" {\n  source = \"../../modules/vpc\"\n\n  cluster_name             = \"temporal-dev\"\n  environment             = \"development\"\n  vpc_cidr                = \"10.0.0.0/16\"\n  availability_zones      = [\"us-west-2a\", \"us-west-2b\"]\n  public_subnet_cidrs     = [\"10.0.1.0/24\", \"10.0.2.0/24\"]\n  private_subnet_cidrs    = [\"10.0.10.0/24\", \"10.0.20.0/24\"]\n}\n\nmodule \"eks\" {\n  source = \"../../modules/eks\"\n\n  cluster_name         = \"temporal-dev\"\n  environment         = \"development\"\n  kubernetes_version  = \"1.28\"\n  public_subnet_ids   = module.vpc.public_subnet_ids\n  private_subnet_ids  = module.vpc.private_subnet_ids\n\n  instance_types      = [\"t3.medium\"]\n  capacity_type       = \"ON_DEMAND\"\n  desired_capacity    = 2\n  min_capacity        = 1\n  max_capacity        = 4\n\n  public_access_cidrs = [\"0.0.0.0/0\"]\n}\n\nmodule \"rds\" {\n  source = \"../../modules/rds\"\n\n  cluster_name            = \"temporal-dev\"\n  environment            = \"development\"\n  vpc_id                 = module.vpc.vpc_id\n  private_subnet_ids     = module.vpc.private_subnet_ids\n  allowed_cidr_blocks    = [module.vpc.vpc_cidr]\n\n  instance_class         = \"db.t3.micro\"\n  allocated_storage      = 20\n  max_allocated_storage  = 100\n  postgres_version       = \"15.4\"\n\n  database_name          = \"temporal\"\n  username               = \"temporal\"\n  password               = var.db_password\n\n  backup_retention_period = 7\n  backup_window          = \"03:00-04:00\"\n  maintenance_window     = \"sun:04:00-sun:05:00\"\n}\n\nmodule \"elasticache\" {\n  source = \"../../modules/elasticache\"\n\n  cluster_name           = \"temporal-dev\"\n  environment           = \"development\"\n  vpc_id                = module.vpc.vpc_id\n  private_subnet_ids    = module.vpc.private_subnet_ids\n  allowed_cidr_blocks   = [module.vpc.vpc_cidr]\n\n  node_type             = \"cache.t3.micro\"\n  num_cache_clusters    = 1\n  auth_token            = var.redis_auth_token\n\n  maintenance_window         = \"sun:05:00-sun:06:00\"\n  snapshot_retention_limit   = 1\n  snapshot_window           = \"03:00-05:00\"\n}\n</code></pre>"},{"location":"implementation/infrastructure-setup/#production-environment","title":"Production Environment","text":"<pre><code># terraform/environments/production/main.tf\nmodule \"vpc\" {\n  source = \"../../modules/vpc\"\n\n  cluster_name             = \"temporal-prod\"\n  environment             = \"production\"\n  vpc_cidr                = \"10.1.0.0/16\"\n  availability_zones      = [\"us-west-2a\", \"us-west-2b\", \"us-west-2c\"]\n  public_subnet_cidrs     = [\"10.1.1.0/24\", \"10.1.2.0/24\", \"10.1.3.0/24\"]\n  private_subnet_cidrs    = [\"10.1.10.0/24\", \"10.1.20.0/24\", \"10.1.30.0/24\"]\n}\n\nmodule \"eks\" {\n  source = \"../../modules/eks\"\n\n  cluster_name         = \"temporal-prod\"\n  environment         = \"production\"\n  kubernetes_version  = \"1.28\"\n  public_subnet_ids   = module.vpc.public_subnet_ids\n  private_subnet_ids  = module.vpc.private_subnet_ids\n\n  instance_types      = [\"m5.large\", \"m5.xlarge\"]\n  capacity_type       = \"ON_DEMAND\"\n  desired_capacity    = 6\n  min_capacity        = 3\n  max_capacity        = 12\n\n  public_access_cidrs = [\"203.0.113.0/24\"] # Your office IP range\n}\n\nmodule \"rds\" {\n  source = \"../../modules/rds\"\n\n  cluster_name            = \"temporal-prod\"\n  environment            = \"production\"\n  vpc_id                 = module.vpc.vpc_id\n  private_subnet_ids     = module.vpc.private_subnet_ids\n  allowed_cidr_blocks    = [module.vpc.vpc_cidr]\n\n  instance_class         = \"db.r5.xlarge\"\n  replica_instance_class = \"db.r5.large\"\n  allocated_storage      = 100\n  max_allocated_storage  = 1000\n  postgres_version       = \"15.4\"\n\n  database_name          = \"temporal\"\n  username               = \"temporal\"\n  password               = var.db_password\n\n  backup_retention_period = 30\n  backup_window          = \"03:00-04:00\"\n  maintenance_window     = \"sun:04:00-sun:05:00\"\n}\n\nmodule \"elasticache\" {\n  source = \"../../modules/elasticache\"\n\n  cluster_name           = \"temporal-prod\"\n  environment           = \"production\"\n  vpc_id                = module.vpc.vpc_id\n  private_subnet_ids    = module.vpc.private_subnet_ids\n  allowed_cidr_blocks   = [module.vpc.vpc_cidr]\n\n  node_type             = \"cache.r6g.large\"\n  num_cache_clusters    = 3\n  auth_token            = var.redis_auth_token\n\n  maintenance_window         = \"sun:05:00-sun:06:00\"\n  snapshot_retention_limit   = 7\n  snapshot_window           = \"03:00-05:00\"\n}\n</code></pre>"},{"location":"implementation/infrastructure-setup/#deployment-scripts","title":"Deployment Scripts","text":""},{"location":"implementation/infrastructure-setup/#infrastructure-deployment-script","title":"Infrastructure Deployment Script","text":"<pre><code>#!/bin/bash\n# scripts/deploy-infrastructure.sh\n\nset -euo pipefail\n\nENVIRONMENT=${1:-development}\nACTION=${2:-plan}\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m'\n\nlog() {\n    echo -e \"${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}\"\n}\n\nwarn() {\n    echo -e \"${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}\"\n}\n\nerror() {\n    echo -e \"${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}\"\n    exit 1\n}\n\n# Validate environment\nif [[ ! \"$ENVIRONMENT\" =~ ^(development|staging|production)$ ]]; then\n    error \"Invalid environment. Must be one of: development, staging, production\"\nfi\n\n# Validate action\nif [[ ! \"$ACTION\" =~ ^(plan|apply|destroy)$ ]]; then\n    error \"Invalid action. Must be one of: plan, apply, destroy\"\nfi\n\nTERRAFORM_DIR=\"terraform/environments/$ENVIRONMENT\"\n\n# Check if Terraform directory exists\nif [[ ! -d \"$TERRAFORM_DIR\" ]]; then\n    error \"Terraform directory not found: $TERRAFORM_DIR\"\nfi\n\nlog \"Deploying infrastructure for environment: $ENVIRONMENT\"\nlog \"Action: $ACTION\"\n\ncd \"$TERRAFORM_DIR\"\n\n# Initialize Terraform\nlog \"Initializing Terraform...\"\nterraform init\n\n# Validate configuration\nlog \"Validating Terraform configuration...\"\nterraform validate\n\n# Plan or apply\ncase \"$ACTION\" in\n    plan)\n        log \"Creating Terraform plan...\"\n        terraform plan -out=tfplan\n        ;;\n    apply)\n        log \"Applying Terraform configuration...\"\n        if [[ -f \"tfplan\" ]]; then\n            terraform apply tfplan\n        else\n            terraform apply -auto-approve\n        fi\n\n        # Update kubeconfig\n        if [[ \"$ACTION\" == \"apply\" ]]; then\n            log \"Updating kubeconfig...\"\n            CLUSTER_NAME=$(terraform output -raw cluster_name)\n            REGION=$(terraform output -raw region)\n            aws eks update-kubeconfig --region \"$REGION\" --name \"$CLUSTER_NAME\"\n\n            log \"Infrastructure deployment completed successfully!\"\n            log \"Cluster endpoint: $(terraform output -raw cluster_endpoint)\"\n            log \"Database endpoint: $(terraform output -raw database_endpoint)\"\n        fi\n        ;;\n    destroy)\n        warn \"This will destroy all infrastructure in $ENVIRONMENT environment!\"\n        read -p \"Are you sure? Type 'yes' to confirm: \" -r\n        if [[ $REPLY == \"yes\" ]]; then\n            terraform destroy -auto-approve\n            log \"Infrastructure destroyed successfully\"\n        else\n            log \"Destroy cancelled\"\n        fi\n        ;;\nesac\n</code></pre>"},{"location":"implementation/infrastructure-setup/#post-deployment-setup-script","title":"Post-Deployment Setup Script","text":"<pre><code>#!/bin/bash\n# scripts/post-deployment-setup.sh\n\nset -euo pipefail\n\nENVIRONMENT=${1:-development}\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\nerror() {\n    echo -e \"\\033[0;31m[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1\\033[0m\"\n    exit 1\n}\n\nlog \"Running post-deployment setup for environment: $ENVIRONMENT\"\n\n# Verify cluster connectivity\nlog \"Verifying cluster connectivity...\"\nif ! kubectl cluster-info &gt; /dev/null 2&gt;&amp;1; then\n    error \"Cannot connect to Kubernetes cluster\"\nfi\n\n# Install cert-manager\nlog \"Installing cert-manager...\"\nkubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.0/cert-manager.yaml\nkubectl wait --for=condition=available --timeout=300s deployment/cert-manager -n cert-manager\nkubectl wait --for=condition=available --timeout=300s deployment/cert-manager-cainjector -n cert-manager\nkubectl wait --for=condition=available --timeout=300s deployment/cert-manager-webhook -n cert-manager\n\n# Install AWS Load Balancer Controller\nlog \"Installing AWS Load Balancer Controller...\"\nhelm repo add eks https://aws.github.io/eks-charts\nhelm repo update\n\nCLUSTER_NAME=$(kubectl config current-context | cut -d'/' -f2)\nVPC_ID=$(aws eks describe-cluster --name \"$CLUSTER_NAME\" --query \"cluster.resourcesVpcConfig.vpcId\" --output text)\n\nhelm upgrade --install aws-load-balancer-controller eks/aws-load-balancer-controller \\\n    -n kube-system \\\n    --set clusterName=\"$CLUSTER_NAME\" \\\n    --set serviceAccount.create=false \\\n    --set serviceAccount.name=aws-load-balancer-controller \\\n    --set region=us-west-2 \\\n    --set vpcId=\"$VPC_ID\"\n\n# Install external-secrets operator\nlog \"Installing external-secrets operator...\"\nhelm repo add external-secrets https://charts.external-secrets.io\nhelm upgrade --install external-secrets external-secrets/external-secrets \\\n    -n external-secrets-system \\\n    --create-namespace\n\n# Create namespaces\nlog \"Creating namespaces...\"\nkubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: temporal-system\n  labels:\n    istio-injection: enabled\n---\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: temporal-app\n  labels:\n    istio-injection: enabled\n---\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: monitoring\n  labels:\n    istio-injection: enabled\nEOF\n\n# Install Prometheus Operator\nlog \"Installing Prometheus Operator...\"\nhelm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm upgrade --install prometheus-operator prometheus-community/kube-prometheus-stack \\\n    -n monitoring \\\n    --set grafana.adminPassword=admin123 \\\n    --set prometheus.prometheusSpec.retention=30d\n\nlog \"Post-deployment setup completed successfully!\"\nlog \"Next steps:\"\nlog \"1. Configure DNS and certificates\"\nlog \"2. Set up external secrets\"\nlog \"3. Deploy Temporal cluster\"\n</code></pre>"},{"location":"implementation/infrastructure-setup/#validation-and-testing","title":"Validation and Testing","text":""},{"location":"implementation/infrastructure-setup/#infrastructure-validation-script","title":"Infrastructure Validation Script","text":"<pre><code>#!/bin/bash\n# scripts/validate-infrastructure.sh\n\nset -euo pipefail\n\nENVIRONMENT=${1:-development}\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\nerror() {\n    echo -e \"\\033[0;31m[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1\\033[0m\"\n    exit 1\n}\n\nwarn() {\n    echo -e \"\\033[1;33m[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1\\033[0m\"\n}\n\nlog \"Validating infrastructure for environment: $ENVIRONMENT\"\n\n# Check cluster connectivity\nlog \"Checking cluster connectivity...\"\nif kubectl cluster-info &gt; /dev/null 2&gt;&amp;1; then\n    log \"\u2713 Cluster connectivity OK\"\nelse\n    error \"\u2717 Cannot connect to cluster\"\nfi\n\n# Check node status\nlog \"Checking node status...\"\nREADY_NODES=$(kubectl get nodes --no-headers | grep -c \"Ready\")\nTOTAL_NODES=$(kubectl get nodes --no-headers | wc -l)\nif [[ $READY_NODES -eq $TOTAL_NODES ]] &amp;&amp; [[ $TOTAL_NODES -gt 0 ]]; then\n    log \"\u2713 All $TOTAL_NODES nodes are ready\"\nelse\n    warn \"\u2717 Only $READY_NODES out of $TOTAL_NODES nodes are ready\"\nfi\n\n# Check essential services\nlog \"Checking essential services...\"\nSERVICES=(\"kube-dns\" \"aws-load-balancer-controller\" \"cert-manager\")\nfor service in \"${SERVICES[@]}\"; do\n    if kubectl get pods -A | grep -q \"$service.*Running\"; then\n        log \"\u2713 $service is running\"\n    else\n        warn \"\u2717 $service is not running\"\n    fi\ndone\n\n# Check database connectivity\nlog \"Checking database connectivity...\"\nif kubectl run db-test --image=postgres:13 --rm -i --restart=Never -- \\\n    psql -h \"$DB_ENDPOINT\" -U temporal -d temporal -c \"SELECT 1\" &gt; /dev/null 2&gt;&amp;1; then\n    log \"\u2713 Database connectivity OK\"\nelse\n    error \"\u2717 Cannot connect to database\"\nfi\n\n# Check Redis connectivity\nlog \"Checking Redis connectivity...\"\nif kubectl run redis-test --image=redis:7 --rm -i --restart=Never -- \\\n    redis-cli -h \"$REDIS_ENDPOINT\" ping &gt; /dev/null 2&gt;&amp;1; then\n    log \"\u2713 Redis connectivity OK\"\nelse\n    error \"\u2717 Cannot connect to Redis\"\nfi\n\nlog \"Infrastructure validation completed\"\n</code></pre> <p>This infrastructure setup guide provides a comprehensive foundation for deploying Temporal.io in a production-ready environment with proper networking, security, and scalability considerations.</p>"},{"location":"implementation/security-configuration/","title":"Security Configuration","text":"<p>This guide provides comprehensive security configuration for Temporal.io enterprise deployment, covering network security, authentication, authorization, encryption, and compliance requirements.</p>"},{"location":"implementation/security-configuration/#overview","title":"Overview","text":"<p>Security configuration includes: - Network policies and segmentation - TLS/SSL certificate management - Authentication and authorization - Secrets management - RBAC configuration - Audit logging and compliance - Security scanning and vulnerability management</p>"},{"location":"implementation/security-configuration/#network-security","title":"Network Security","text":""},{"location":"implementation/security-configuration/#network-policies","title":"Network Policies","text":""},{"location":"implementation/security-configuration/#default-deny-policy","title":"Default Deny Policy","text":"<pre><code># k8s/security/network-policies/default-deny.yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: default-deny-all\n  namespace: temporal-system\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\n</code></pre>"},{"location":"implementation/security-configuration/#temporal-backend-network-policy","title":"Temporal Backend Network Policy","text":"<pre><code># k8s/security/network-policies/temporal-backend.yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: temporal-backend-policy\n  namespace: temporal-system\nspec:\n  podSelector:\n    matchLabels:\n      app.kubernetes.io/name: temporal\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  # Allow ingress from workers and API services\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-app\n    - podSelector:\n        matchLabels:\n          app.kubernetes.io/component: web\n    ports:\n    - protocol: TCP\n      port: 7233  # Frontend service\n    - protocol: TCP\n      port: 7234  # History service\n    - protocol: TCP\n      port: 7235  # Matching service\n  # Allow ingress from load balancer\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: kube-system\n    ports:\n    - protocol: TCP\n      port: 8080  # Web UI\n  egress:\n  # Allow egress to database\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 5432  # PostgreSQL\n  # Allow egress to Redis\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 6379  # Redis\n  # Allow DNS resolution\n  - to: []\n    ports:\n    - protocol: UDP\n      port: 53\n    - protocol: TCP\n      port: 53\n  # Allow HTTPS for external services\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 443\n</code></pre>"},{"location":"implementation/security-configuration/#application-network-policy","title":"Application Network Policy","text":"<pre><code># k8s/security/network-policies/temporal-app.yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: temporal-app-policy\n  namespace: temporal-app\nspec:\n  podSelector:\n    matchLabels:\n      app.kubernetes.io/part-of: temporal-app\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  # Allow ingress from load balancer\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: kube-system\n    ports:\n    - protocol: TCP\n      port: 8000  # FastAPI\n  egress:\n  # Allow egress to Temporal backend\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-system\n    ports:\n    - protocol: TCP\n      port: 7233\n  # Allow egress to Redis\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 6379\n  # Allow DNS resolution\n  - to: []\n    ports:\n    - protocol: UDP\n      port: 53\n    - protocol: TCP\n      port: 53\n  # Allow HTTPS for external APIs\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 443\n</code></pre>"},{"location":"implementation/security-configuration/#security-groups-aws","title":"Security Groups (AWS)","text":""},{"location":"implementation/security-configuration/#database-security-group","title":"Database Security Group","text":"<pre><code># terraform/modules/security-groups/rds.tf\nresource \"aws_security_group\" \"rds\" {\n  name_prefix = \"${var.cluster_name}-rds-\"\n  vpc_id      = var.vpc_id\n  description = \"Security group for RDS database\"\n\n  # Allow connections from EKS nodes only\n  ingress {\n    description     = \"PostgreSQL from EKS\"\n    from_port       = 5432\n    to_port         = 5432\n    protocol        = \"tcp\"\n    security_groups = [aws_security_group.eks_nodes.id]\n  }\n\n  # Allow connections from bastion host for administration\n  ingress {\n    description     = \"PostgreSQL from bastion\"\n    from_port       = 5432\n    to_port         = 5432\n    protocol        = \"tcp\"\n    security_groups = [aws_security_group.bastion.id]\n  }\n\n  egress {\n    description = \"All outbound traffic\"\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name        = \"${var.cluster_name}-rds-sg\"\n    Environment = var.environment\n  }\n}\n</code></pre>"},{"location":"implementation/security-configuration/#eks-nodes-security-group","title":"EKS Nodes Security Group","text":"<pre><code># terraform/modules/security-groups/eks.tf\nresource \"aws_security_group\" \"eks_nodes\" {\n  name_prefix = \"${var.cluster_name}-eks-nodes-\"\n  vpc_id      = var.vpc_id\n  description = \"Security group for EKS worker nodes\"\n\n  # Allow nodes to communicate with each other\n  ingress {\n    description = \"Node to node communication\"\n    from_port   = 0\n    to_port     = 65535\n    protocol    = \"tcp\"\n    self        = true\n  }\n\n  # Allow pods to communicate with the cluster API Server\n  ingress {\n    description     = \"Cluster API Server\"\n    from_port       = 443\n    to_port         = 443\n    protocol        = \"tcp\"\n    security_groups = [aws_security_group.eks_cluster.id]\n  }\n\n  # Allow NodePort services\n  ingress {\n    description = \"NodePort services\"\n    from_port   = 30000\n    to_port     = 32767\n    protocol    = \"tcp\"\n    cidr_blocks = [var.vpc_cidr]\n  }\n\n  egress {\n    description = \"All outbound traffic\"\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name        = \"${var.cluster_name}-eks-nodes-sg\"\n    Environment = var.environment\n  }\n}\n</code></pre>"},{"location":"implementation/security-configuration/#tlsssl-configuration","title":"TLS/SSL Configuration","text":""},{"location":"implementation/security-configuration/#certificate-manager-setup","title":"Certificate Manager Setup","text":""},{"location":"implementation/security-configuration/#clusterissuer-for-lets-encrypt","title":"ClusterIssuer for Let's Encrypt","text":"<pre><code># k8s/security/certificates/cluster-issuer.yaml\napiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-prod\nspec:\n  acme:\n    server: https://acme-v02.api.letsencrypt.org/directory\n    email: admin@yourcompany.com\n    privateKeySecretRef:\n      name: letsencrypt-prod\n    solvers:\n    - dns01:\n        route53:\n          region: us-west-2\n          accessKeyID: AKIAIOSFODNN7EXAMPLE\n          secretAccessKeySecretRef:\n            name: route53-credentials\n            key: secret-access-key\n---\napiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-staging\nspec:\n  acme:\n    server: https://acme-staging-v02.api.letsencrypt.org/directory\n    email: admin@yourcompany.com\n    privateKeySecretRef:\n      name: letsencrypt-staging\n    solvers:\n    - dns01:\n        route53:\n          region: us-west-2\n          accessKeyID: AKIAIOSFODNN7EXAMPLE\n          secretAccessKeySecretRef:\n            name: route53-credentials\n            key: secret-access-key\n</code></pre>"},{"location":"implementation/security-configuration/#certificate-for-temporal-services","title":"Certificate for Temporal Services","text":"<pre><code># k8s/security/certificates/temporal-cert.yaml\napiVersion: cert-manager.io/v1\nkind: Certificate\nmetadata:\n  name: temporal-tls\n  namespace: temporal-system\nspec:\n  secretName: temporal-tls-secret\n  issuerRef:\n    name: letsencrypt-prod\n    kind: ClusterIssuer\n  commonName: temporal.yourcompany.com\n  dnsNames:\n  - temporal.yourcompany.com\n  - temporal-web.yourcompany.com\n  - temporal-frontend.temporal-system.svc.cluster.local\n  usages:\n  - digital signature\n  - key encipherment\n  - server auth\n  - client auth\n</code></pre>"},{"location":"implementation/security-configuration/#tls-configuration-for-temporal","title":"TLS Configuration for Temporal","text":""},{"location":"implementation/security-configuration/#temporal-tls-configuration","title":"Temporal TLS Configuration","text":"<pre><code># helm/values/security/tls.yaml\nserver:\n  config:\n    tls:\n      frontend:\n        server:\n          certFile: /etc/temporal/certs/tls.crt\n          keyFile: /etc/temporal/certs/tls.key\n          clientCAFile: /etc/temporal/certs/ca.crt\n          requireClientAuth: true\n        client:\n          serverName: temporal-frontend\n          certFile: /etc/temporal/certs/tls.crt\n          keyFile: /etc/temporal/certs/tls.key\n          caFile: /etc/temporal/certs/ca.crt\n      history:\n        server:\n          certFile: /etc/temporal/certs/tls.crt\n          keyFile: /etc/temporal/certs/tls.key\n          clientCAFile: /etc/temporal/certs/ca.crt\n          requireClientAuth: true\n        client:\n          serverName: temporal-history\n          certFile: /etc/temporal/certs/tls.crt\n          keyFile: /etc/temporal/certs/tls.key\n          caFile: /etc/temporal/certs/ca.crt\n      matching:\n        server:\n          certFile: /etc/temporal/certs/tls.crt\n          keyFile: /etc/temporal/certs/tls.key\n          clientCAFile: /etc/temporal/certs/ca.crt\n          requireClientAuth: true\n        client:\n          serverName: temporal-matching\n          certFile: /etc/temporal/certs/tls.crt\n          keyFile: /etc/temporal/certs/tls.key\n          caFile: /etc/temporal/certs/ca.crt\n</code></pre>"},{"location":"implementation/security-configuration/#authentication-and-authorization","title":"Authentication and Authorization","text":""},{"location":"implementation/security-configuration/#oidc-integration","title":"OIDC Integration","text":""},{"location":"implementation/security-configuration/#oidc-configuration-for-temporal-web","title":"OIDC Configuration for Temporal Web","text":"<pre><code># k8s/security/auth/oidc-config.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: temporal-web-auth-config\n  namespace: temporal-system\ndata:\n  config.yaml: |\n    auth:\n      enabled: true\n      providers:\n        - label: \"Company SSO\"\n          type: oidc\n          providerUrl: \"https://auth.yourcompany.com\"\n          clientId: \"temporal-web\"\n          clientSecret: \"${OIDC_CLIENT_SECRET}\"\n          scopes:\n            - openid\n            - profile\n            - email\n          callbackUrl: \"https://temporal.yourcompany.com/auth/callback\"\n          usernameAttribute: \"email\"\n          groupsAttribute: \"groups\"\n      authorizer:\n        roleMapping:\n          admin:\n            - \"temporal-admins\"\n          read:\n            - \"temporal-readers\"\n          write:\n            - \"temporal-writers\"\n</code></pre>"},{"location":"implementation/security-configuration/#external-secret-for-oidc","title":"External Secret for OIDC","text":"<pre><code># k8s/security/auth/oidc-secret.yaml\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: temporal-oidc-secret\n  namespace: temporal-system\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: temporal-oidc-secret\n    creationPolicy: Owner\n  data:\n  - secretKey: client-secret\n    remoteRef:\n      key: temporal/oidc\n      property: client_secret\n</code></pre>"},{"location":"implementation/security-configuration/#jwt-configuration","title":"JWT Configuration","text":""},{"location":"implementation/security-configuration/#jwt-authorizer-configuration","title":"JWT Authorizer Configuration","text":"<pre><code># k8s/security/auth/jwt-config.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: temporal-auth-config\n  namespace: temporal-system\ndata:\n  auth.yaml: |\n    authorization:\n      jwtKeyProvider:\n        keySourceURIs:\n          - \"https://auth.yourcompany.com/.well-known/jwks.json\"\n        refreshInterval: \"1h\"\n      permissionsClaimName: \"permissions\"\n\n    claims:\n      mappers:\n        - name: \"admin\"\n          role: \"admin\"\n          permissions:\n            - \"system:admin\"\n            - \"namespace:admin\"\n            - \"workflow:admin\"\n        - name: \"developer\"\n          role: \"developer\"\n          permissions:\n            - \"namespace:read\"\n            - \"namespace:write\"\n            - \"workflow:read\"\n            - \"workflow:write\"\n        - name: \"readonly\"\n          role: \"readonly\"\n          permissions:\n            - \"namespace:read\"\n            - \"workflow:read\"\n</code></pre>"},{"location":"implementation/security-configuration/#rbac-configuration","title":"RBAC Configuration","text":""},{"location":"implementation/security-configuration/#kubernetes-rbac-for-temporal","title":"Kubernetes RBAC for Temporal","text":"<pre><code># k8s/security/rbac/temporal-rbac.yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: temporal-admin\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"services\", \"endpoints\", \"persistentvolumeclaims\", \"events\", \"configmaps\", \"secrets\"]\n  verbs: [\"*\"]\n- apiGroups: [\"apps\"]\n  resources: [\"deployments\", \"daemonsets\", \"replicasets\", \"statefulsets\"]\n  verbs: [\"*\"]\n- apiGroups: [\"networking.k8s.io\"]\n  resources: [\"networkpolicies\"]\n  verbs: [\"*\"]\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: temporal-operator\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"services\", \"endpoints\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"apps\"]\n  resources: [\"deployments\", \"replicasets\", \"statefulsets\"]\n  verbs: [\"get\", \"list\", \"watch\", \"update\", \"patch\"]\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: temporal-admin-binding\nsubjects:\n- kind: User\n  name: temporal-admin@yourcompany.com\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: ClusterRole\n  name: temporal-admin\n  apiGroup: rbac.authorization.k8s.io\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: temporal-operator-binding\n  namespace: temporal-system\nsubjects:\n- kind: ServiceAccount\n  name: temporal-server\n  namespace: temporal-system\nroleRef:\n  kind: ClusterRole\n  name: temporal-operator\n  apiGroup: rbac.authorization.k8s.io\n</code></pre>"},{"location":"implementation/security-configuration/#secrets-management","title":"Secrets Management","text":""},{"location":"implementation/security-configuration/#hashicorp-vault-integration","title":"HashiCorp Vault Integration","text":""},{"location":"implementation/security-configuration/#vault-secretstore-configuration","title":"Vault SecretStore Configuration","text":"<pre><code># k8s/security/secrets/vault-secretstore.yaml\napiVersion: external-secrets.io/v1beta1\nkind: SecretStore\nmetadata:\n  name: vault-backend\n  namespace: temporal-system\nspec:\n  provider:\n    vault:\n      server: \"https://vault.yourcompany.com\"\n      path: \"secret\"\n      version: \"v2\"\n      auth:\n        kubernetes:\n          mountPath: \"kubernetes\"\n          role: \"temporal-role\"\n          serviceAccountRef:\n            name: \"temporal-external-secrets\"\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: temporal-external-secrets\n  namespace: temporal-system\n  annotations:\n    eks.amazonaws.com/role-arn: arn:aws:iam::ACCOUNT:role/temporal-external-secrets-role\n</code></pre>"},{"location":"implementation/security-configuration/#database-credentials-secret","title":"Database Credentials Secret","text":"<pre><code># k8s/security/secrets/database-secret.yaml\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: temporal-database-secret\n  namespace: temporal-system\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: temporal-database-credentials\n    creationPolicy: Owner\n    template:\n      type: Opaque\n      data:\n        host: \"{{ .host }}\"\n        port: \"{{ .port }}\"\n        database: \"{{ .database }}\"\n        username: \"{{ .username }}\"\n        password: \"{{ .password }}\"\n        connection_string: \"postgres://{{ .username }}:{{ .password }}@{{ .host }}:{{ .port }}/{{ .database }}?sslmode=require\"\n  data:\n  - secretKey: host\n    remoteRef:\n      key: temporal/database\n      property: host\n  - secretKey: port\n    remoteRef:\n      key: temporal/database\n      property: port\n  - secretKey: database\n    remoteRef:\n      key: temporal/database\n      property: database\n  - secretKey: username\n    remoteRef:\n      key: temporal/database\n      property: username\n  - secretKey: password\n    remoteRef:\n      key: temporal/database\n      property: password\n</code></pre>"},{"location":"implementation/security-configuration/#application-secrets","title":"Application Secrets","text":"<pre><code># k8s/security/secrets/app-secrets.yaml\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: temporal-app-secrets\n  namespace: temporal-app\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: temporal-app-secrets\n    creationPolicy: Owner\n  data:\n  - secretKey: jwt-secret\n    remoteRef:\n      key: temporal/app\n      property: jwt_secret\n  - secretKey: encryption-key\n    remoteRef:\n      key: temporal/app\n      property: encryption_key\n  - secretKey: api-key\n    remoteRef:\n      key: temporal/app\n      property: api_key\n</code></pre>"},{"location":"implementation/security-configuration/#encryption-at-rest","title":"Encryption at Rest","text":""},{"location":"implementation/security-configuration/#database-encryption","title":"Database Encryption","text":"<pre><code># terraform/modules/rds/encryption.tf\nresource \"aws_kms_key\" \"rds\" {\n  description             = \"RDS encryption key for ${var.cluster_name}\"\n  deletion_window_in_days = var.environment == \"production\" ? 30 : 7\n  enable_key_rotation     = true\n\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Sid    = \"Enable IAM User Permissions\"\n        Effect = \"Allow\"\n        Principal = {\n          AWS = \"arn:aws:iam::${data.aws_caller_identity.current.account_id}:root\"\n        }\n        Action   = \"kms:*\"\n        Resource = \"*\"\n      },\n      {\n        Sid    = \"Allow RDS Service\"\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"rds.amazonaws.com\"\n        }\n        Action = [\n          \"kms:Decrypt\",\n          \"kms:GenerateDataKey\",\n          \"kms:CreateGrant\"\n        ]\n        Resource = \"*\"\n      }\n    ]\n  })\n\n  tags = {\n    Name        = \"${var.cluster_name}-rds-kms\"\n    Environment = var.environment\n  }\n}\n\nresource \"aws_kms_alias\" \"rds\" {\n  name          = \"alias/${var.cluster_name}-rds\"\n  target_key_id = aws_kms_key.rds.key_id\n}\n</code></pre>"},{"location":"implementation/security-configuration/#kubernetes-secret-encryption","title":"Kubernetes Secret Encryption","text":"<pre><code># k8s/security/encryption/secret-encryption.yaml\napiVersion: apiserver.config.k8s.io/v1\nkind: EncryptionConfiguration\nresources:\n- resources:\n  - secrets\n  providers:\n  - kms:\n      name: aws-kms\n      endpoint: arn:aws:kms:us-west-2:ACCOUNT:key/KEY-ID\n      cachesize: 1000\n      timeout: 3s\n  - identity: {}\n</code></pre>"},{"location":"implementation/security-configuration/#pod-security","title":"Pod Security","text":""},{"location":"implementation/security-configuration/#pod-security-standards","title":"Pod Security Standards","text":"<pre><code># k8s/security/pod-security/pod-security-policy.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: temporal-system\n  labels:\n    pod-security.kubernetes.io/enforce: restricted\n    pod-security.kubernetes.io/audit: restricted\n    pod-security.kubernetes.io/warn: restricted\n---\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: temporal-app\n  labels:\n    pod-security.kubernetes.io/enforce: restricted\n    pod-security.kubernetes.io/audit: restricted\n    pod-security.kubernetes.io/warn: restricted\n</code></pre>"},{"location":"implementation/security-configuration/#security-context-configuration","title":"Security Context Configuration","text":"<pre><code># k8s/security/pod-security/security-context.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: temporal-security-context\n  namespace: temporal-system\ndata:\n  security-context.yaml: |\n    securityContext:\n      runAsNonRoot: true\n      runAsUser: 10001\n      runAsGroup: 10001\n      fsGroup: 10001\n      seccompProfile:\n        type: RuntimeDefault\n    containerSecurityContext:\n      allowPrivilegeEscalation: false\n      readOnlyRootFilesystem: true\n      runAsNonRoot: true\n      runAsUser: 10001\n      runAsGroup: 10001\n      capabilities:\n        drop:\n        - ALL\n      seccompProfile:\n        type: RuntimeDefault\n</code></pre>"},{"location":"implementation/security-configuration/#audit-logging","title":"Audit Logging","text":""},{"location":"implementation/security-configuration/#audit-policy-configuration","title":"Audit Policy Configuration","text":"<pre><code># k8s/security/audit/audit-policy.yaml\napiVersion: audit.k8s.io/v1\nkind: Policy\nrules:\n# Don't log requests for events\n- level: None\n  resources:\n  - group: \"\"\n    resources: [\"events\"]\n\n# Don't log authenticated requests to certain non-resource URL paths\n- level: None\n  userGroups: [\"system:authenticated\"]\n  nonResourceURLs:\n  - \"/api*\" # Wildcard matching.\n  - \"/version\"\n  - \"/healthz\"\n\n# Log the request body of configmap changes in kube-system\n- level: Request\n  resources:\n  - group: \"\"\n    resources: [\"configmaps\"]\n  namespaces: [\"kube-system\"]\n\n# Log configmap and secret changes in all other namespaces at the Metadata level\n- level: Metadata\n  resources:\n  - group: \"\"\n    resources: [\"secrets\", \"configmaps\"]\n\n# Log all other requests at the Metadata level\n- level: Metadata\n  # Long-running requests like watches that fall under this rule will not\n  # generate an audit event in RequestReceived.\n  omitStages:\n  - RequestReceived\n</code></pre>"},{"location":"implementation/security-configuration/#falco-security-monitoring","title":"Falco Security Monitoring","text":"<pre><code># k8s/security/monitoring/falco.yaml\napiVersion: helm.cattle.io/v1\nkind: HelmChart\nmetadata:\n  name: falco\n  namespace: kube-system\nspec:\n  chart: falco\n  repo: https://falcosecurity.github.io/charts\n  targetNamespace: falco\n  valuesContent: |-\n    driver:\n      kind: ebpf\n    falco:\n      rules_file:\n        - /etc/falco/falco_rules.yaml\n        - /etc/falco/falco_rules.local.yaml\n        - /etc/falco/k8s_audit_rules.yaml\n        - /etc/falco/rules.d\n      json_output: true\n      json_include_output_property: true\n      log_stderr: true\n      log_syslog: false\n      priority: debug\n      buffered_outputs: false\n      outputs:\n        rate: 1\n        max_burst: 1000\n      syscall_event_drops:\n        actions:\n          - log\n          - alert\n        rate: 0.03333\n        max_burst: 10\n    customRules:\n      temporal_rules.yaml: |-\n        - rule: Temporal Database Connection\n          desc: Detect connections to Temporal database\n          condition: &gt;\n            spawned_process and\n            proc.name=psql and\n            proc.args contains \"temporal\"\n          output: &gt;\n            Temporal database connection detected\n            (user=%user.name command=%proc.cmdline pid=%proc.pid container=%container.name)\n          priority: INFO\n          tags: [temporal, database]\n\n        - rule: Temporal Secret Access\n          desc: Detect access to Temporal secrets\n          condition: &gt;\n            ka.verb in (get, list) and\n            ka.uri.param[name] contains \"temporal\" and\n            ka.resource.resource=secrets\n          output: &gt;\n            Temporal secret accessed\n            (user=%ka.user.name verb=%ka.verb resource=%ka.target.name)\n          priority: WARNING\n          tags: [temporal, secrets]\n</code></pre>"},{"location":"implementation/security-configuration/#compliance-and-security-scanning","title":"Compliance and Security Scanning","text":""},{"location":"implementation/security-configuration/#vulnerability-scanning-with-trivy","title":"Vulnerability Scanning with Trivy","text":"<pre><code># k8s/security/scanning/trivy-operator.yaml\napiVersion: helm.cattle.io/v1\nkind: HelmChart\nmetadata:\n  name: trivy-operator\n  namespace: kube-system\nspec:\n  chart: trivy-operator\n  repo: https://aquasecurity.github.io/helm-charts/\n  targetNamespace: trivy-system\n  valuesContent: |-\n    operator:\n      scannerReportTTL: \"24h\"\n      vulnerabilityReportsPlugin: \"Trivy\"\n      configAuditReportsPlugin: \"Trivy\"\n\n    trivy:\n      serverURL: \"\"\n      timeout: \"5m0s\"\n      resources:\n        requests:\n          cpu: 100m\n          memory: 100M\n        limits:\n          cpu: 500m\n          memory: 500M\n</code></pre>"},{"location":"implementation/security-configuration/#cis-kubernetes-benchmark","title":"CIS Kubernetes Benchmark","text":"<pre><code>#!/bin/bash\n# scripts/security/run-cis-benchmark.sh\n\nset -euo pipefail\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\nlog \"Running CIS Kubernetes Benchmark...\"\n\n# Install kube-bench\nkubectl apply -f https://raw.githubusercontent.com/aquasecurity/kube-bench/main/job.yaml\n\n# Wait for job completion\nkubectl wait --for=condition=complete job/kube-bench --timeout=300s\n\n# Get results\nkubectl logs job/kube-bench &gt; cis-benchmark-results.txt\n\nlog \"CIS Benchmark completed. Results saved to cis-benchmark-results.txt\"\n\n# Clean up\nkubectl delete job kube-bench\n\n# Parse results for critical findings\nCRITICAL_FINDINGS=$(grep -c \"FAIL\" cis-benchmark-results.txt || true)\nif [[ $CRITICAL_FINDINGS -gt 0 ]]; then\n    log \"WARNING: Found $CRITICAL_FINDINGS critical security findings\"\n    grep \"FAIL\" cis-benchmark-results.txt\n    exit 1\nelse\n    log \"No critical security findings detected\"\nfi\n</code></pre>"},{"location":"implementation/security-configuration/#opa-gatekeeper-policies","title":"OPA Gatekeeper Policies","text":"<pre><code># k8s/security/policies/gatekeeper-constraints.yaml\napiVersion: templates.gatekeeper.sh/v1beta1\nkind: ConstraintTemplate\nmetadata:\n  name: k8srequiredlabels\nspec:\n  crd:\n    spec:\n      names:\n        kind: K8sRequiredLabels\n      validation:\n        type: object\n        properties:\n          labels:\n            type: array\n            items:\n              type: string\n  targets:\n    - target: admission.k8s.gatekeeper.sh\n      rego: |\n        package k8srequiredlabels\n\n        violation[{\"msg\": msg}] {\n          required := input.parameters.labels\n          provided := input.review.object.metadata.labels\n          missing := required[_]\n          not provided[missing]\n          msg := sprintf(\"Missing required label: %v\", [missing])\n        }\n\n---\napiVersion: config.gatekeeper.sh/v1alpha1\nkind: K8sRequiredLabels\nmetadata:\n  name: must-have-temporal-labels\nspec:\n  match:\n    kinds:\n      - apiGroups: [\"apps\"]\n        kinds: [\"Deployment\"]\n    namespaces: [\"temporal-system\", \"temporal-app\"]\n  parameters:\n    labels: [\"app.kubernetes.io/name\", \"app.kubernetes.io/version\", \"environment\"]\n</code></pre>"},{"location":"implementation/security-configuration/#security-automation-scripts","title":"Security Automation Scripts","text":""},{"location":"implementation/security-configuration/#security-configuration-script","title":"Security Configuration Script","text":"<pre><code>#!/bin/bash\n# scripts/security/configure-security.sh\n\nset -euo pipefail\n\nENVIRONMENT=${1:-development}\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\nerror() {\n    echo -e \"\\033[0;31m[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1\\033[0m\"\n    exit 1\n}\n\nlog \"Configuring security for environment: $ENVIRONMENT\"\n\n# Apply network policies\nlog \"Applying network policies...\"\nkubectl apply -f k8s/security/network-policies/\n\n# Configure RBAC\nlog \"Configuring RBAC...\"\nkubectl apply -f k8s/security/rbac/\n\n# Setup certificate management\nlog \"Setting up certificate management...\"\nkubectl apply -f k8s/security/certificates/\n\n# Configure secrets management\nlog \"Configuring secrets management...\"\nkubectl apply -f k8s/security/secrets/\n\n# Apply pod security policies\nlog \"Applying pod security policies...\"\nkubectl apply -f k8s/security/pod-security/\n\n# Setup audit logging\nlog \"Setting up audit logging...\"\nkubectl apply -f k8s/security/audit/\n\n# Install security monitoring\nlog \"Installing security monitoring...\"\nkubectl apply -f k8s/security/monitoring/\n\n# Install OPA Gatekeeper\nlog \"Installing OPA Gatekeeper...\"\nhelm repo add gatekeeper https://open-policy-agent.github.io/gatekeeper/charts\nhelm upgrade --install gatekeeper gatekeeper/gatekeeper \\\n    --namespace gatekeeper-system \\\n    --create-namespace\n\n# Apply Gatekeeper policies\nlog \"Applying Gatekeeper policies...\"\nkubectl apply -f k8s/security/policies/\n\nlog \"Security configuration completed successfully!\"\n</code></pre>"},{"location":"implementation/security-configuration/#security-validation-script","title":"Security Validation Script","text":"<pre><code>#!/bin/bash\n# scripts/security/validate-security.sh\n\nset -euo pipefail\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\nwarn() {\n    echo -e \"\\033[1;33m[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1\\033[0m\"\n}\n\nerror() {\n    echo -e \"\\033[0;31m[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1\\033[0m\"\n}\n\nlog \"Validating security configuration...\"\n\n# Check network policies\nlog \"Checking network policies...\"\nNETWORK_POLICIES=$(kubectl get networkpolicies -A --no-headers | wc -l)\nif [[ $NETWORK_POLICIES -gt 0 ]]; then\n    log \"\u2713 Network policies are configured ($NETWORK_POLICIES policies found)\"\nelse\n    warn \"\u2717 No network policies found\"\nfi\n\n# Check pod security\nlog \"Checking pod security...\"\nPRIVILEGED_PODS=$(kubectl get pods -A -o jsonpath='{.items[?(@.spec.securityContext.privileged==true)].metadata.name}' | wc -w)\nif [[ $PRIVILEGED_PODS -eq 0 ]]; then\n    log \"\u2713 No privileged pods found\"\nelse\n    warn \"\u2717 Found $PRIVILEGED_PODS privileged pods\"\nfi\n\n# Check certificate management\nlog \"Checking certificate management...\"\nif kubectl get clusterissuer letsencrypt-prod &amp;&gt;/dev/null; then\n    log \"\u2713 Certificate management is configured\"\nelse\n    error \"\u2717 Certificate management not configured\"\nfi\n\n# Check secrets encryption\nlog \"Checking secrets encryption...\"\nif kubectl get secret -n kube-system | grep -q encryption-config; then\n    log \"\u2713 Secrets encryption is enabled\"\nelse\n    warn \"\u2717 Secrets encryption not detected\"\nfi\n\n# Check RBAC\nlog \"Checking RBAC...\"\nCLUSTER_ROLES=$(kubectl get clusterroles | grep -c temporal || true)\nif [[ $CLUSTER_ROLES -gt 0 ]]; then\n    log \"\u2713 Temporal RBAC is configured\"\nelse\n    warn \"\u2717 Temporal RBAC not found\"\nfi\n\n# Check audit logging\nlog \"Checking audit logging...\"\nif kubectl get configmap -n kube-system audit-policy &amp;&gt;/dev/null; then\n    log \"\u2713 Audit logging is configured\"\nelse\n    warn \"\u2717 Audit logging not configured\"\nfi\n\nlog \"Security validation completed\"\n</code></pre> <p>This comprehensive security configuration guide provides enterprise-grade security for Temporal.io deployments with defense-in-depth principles, compliance requirements, and automated security monitoring.</p>"},{"location":"implementation/temporal-deployment/","title":"Temporal Deployment","text":"<p>This guide provides comprehensive deployment instructions for Temporal.io server cluster in enterprise environments, covering high availability setup, configuration, scaling, and operational best practices.</p>"},{"location":"implementation/temporal-deployment/#overview","title":"Overview","text":"<p>The Temporal deployment includes: - Temporal server cluster with multiple services - High availability configuration - Auto-scaling and load balancing - Service mesh integration - Monitoring and observability - Configuration management</p>"},{"location":"implementation/temporal-deployment/#architecture-components","title":"Architecture Components","text":""},{"location":"implementation/temporal-deployment/#temporal-services","title":"Temporal Services","text":"<pre><code>graph TB\n    subgraph \"Load Balancer\"\n        LB[Application Load Balancer]\n    end\n\n    subgraph \"Temporal Cluster\"\n        FRONTEND[Frontend Service]\n        HISTORY[History Service]\n        MATCHING[Matching Service]\n        WORKER[Worker Service]\n        WEB[Web UI]\n    end\n\n    subgraph \"Data Layer\"\n        POSTGRES[(PostgreSQL)]\n        REDIS[(Redis)]\n        ES[(Elasticsearch)]\n    end\n\n    subgraph \"External Services\"\n        WORKERS[Application Workers]\n        APIS[API Services]\n    end\n\n    LB --&gt; FRONTEND\n    LB --&gt; WEB\n\n    FRONTEND --&gt; HISTORY\n    FRONTEND --&gt; MATCHING\n    FRONTEND --&gt; WORKER\n\n    HISTORY --&gt; POSTGRES\n    MATCHING --&gt; POSTGRES\n    WORKER --&gt; POSTGRES\n\n    FRONTEND --&gt; REDIS\n    WEB --&gt; FRONTEND\n\n    WORKERS --&gt; FRONTEND\n    APIS --&gt; FRONTEND</code></pre>"},{"location":"implementation/temporal-deployment/#helm-chart-configuration","title":"Helm Chart Configuration","text":""},{"location":"implementation/temporal-deployment/#main-temporal-chart-values","title":"Main Temporal Chart Values","text":"<pre><code># helm/values/temporal/production.yaml\nserver:\n  image:\n    repository: temporalio/server\n    tag: \"1.29.1\"\n    pullPolicy: IfNotPresent\n\n  replicaCount: 3\n\n  config:\n    # Persistence configuration\n    persistence:\n      defaultStore: default\n      visibilityStore: visibility\n      numHistoryShards: 4096\n\n      datastores:\n        default:\n          driver: \"postgres\"\n          host: \"postgresql-primary\"\n          port: 5432\n          database: \"temporal\"\n          user: \"temporal\"\n          password: \"${POSTGRES_PASSWORD}\"\n          maxConns: 50\n          maxIdleConns: 10\n          maxConnLifetime: \"1h\"\n          tls:\n            enabled: true\n            caFile: \"/etc/temporal/certs/ca.crt\"\n            certFile: \"/etc/temporal/certs/tls.crt\"\n            keyFile: \"/etc/temporal/certs/tls.key\"\n            serverName: \"postgresql-primary\"\n\n        visibility:\n          driver: \"postgres\"\n          host: \"postgresql-primary\"\n          port: 5432\n          database: \"temporal_visibility\"\n          user: \"temporal\"\n          password: \"${POSTGRES_PASSWORD}\"\n          maxConns: 10\n          maxIdleConns: 5\n          maxConnLifetime: \"1h\"\n          tls:\n            enabled: true\n            caFile: \"/etc/temporal/certs/ca.crt\"\n            certFile: \"/etc/temporal/certs/tls.crt\"\n            keyFile: \"/etc/temporal/certs/tls.key\"\n            serverName: \"postgresql-primary\"\n\n    # Global configuration\n    global:\n      membership:\n        maxJoinDuration: 30s\n        broadcastAddress: \"\"\n\n      pprof:\n        port: 7936\n\n      metrics:\n        prometheus:\n          timerType: \"histogram\"\n          listenAddress: \"0.0.0.0:9090\"\n\n        statsd: {}\n\n      tls:\n        internode:\n          server:\n            certFile: \"/etc/temporal/certs/tls.crt\"\n            keyFile: \"/etc/temporal/certs/tls.key\"\n            clientCAFile: \"/etc/temporal/certs/ca.crt\"\n            requireClientAuth: true\n          client:\n            serverName: \"temporal\"\n            certFile: \"/etc/temporal/certs/tls.crt\"\n            keyFile: \"/etc/temporal/certs/tls.key\"\n            caFile: \"/etc/temporal/certs/ca.crt\"\n\n    # Service-specific configurations\n    services:\n      frontend:\n        rpc:\n          grpcPort: 7233\n          membershipPort: 6933\n          bindOnLocalHost: false\n\n        metrics:\n          prometheus:\n            listenAddress: \"0.0.0.0:9090\"\n\n        # Rate limiting\n        rps: 1200\n\n        # Authentication\n        authorizer:\n          jwtKeyProvider:\n            keySourceURIs:\n              - \"https://auth.company.com/.well-known/jwks.json\"\n            refreshInterval: \"1h\"\n          permissionsClaimName: \"permissions\"\n\n      history:\n        rpc:\n          grpcPort: 7234\n          membershipPort: 6934\n          bindOnLocalHost: false\n\n        metrics:\n          prometheus:\n            listenAddress: \"0.0.0.0:9090\"\n\n        # History service tuning\n        numHistoryShards: 4096\n        historyCountLimitError: 50000\n        historyCountLimitWarn: 10000\n\n      matching:\n        rpc:\n          grpcPort: 7235\n          membershipPort: 6935\n          bindOnLocalHost: false\n\n        metrics:\n          prometheus:\n            listenAddress: \"0.0.0.0:9090\"\n\n        # Matching service tuning\n        numTasklistWritePartitions: 3\n        numTasklistReadPartitions: 3\n\n      worker:\n        rpc:\n          grpcPort: 7239\n          membershipPort: 6939\n          bindOnLocalHost: false\n\n        metrics:\n          prometheus:\n            listenAddress: \"0.0.0.0:9090\"\n\n  # Resource configuration per service\n  frontend:\n    replicaCount: 3\n    resources:\n      requests:\n        memory: \"512Mi\"\n        cpu: \"250m\"\n      limits:\n        memory: \"1Gi\"\n        cpu: \"500m\"\n\n    service:\n      type: ClusterIP\n      port: 7233\n      annotations:\n        service.beta.kubernetes.io/aws-load-balancer-type: nlb\n        service.beta.kubernetes.io/aws-load-balancer-internal: \"true\"\n\n    autoscaling:\n      enabled: true\n      minReplicas: 3\n      maxReplicas: 10\n      targetCPUUtilizationPercentage: 70\n      targetMemoryUtilizationPercentage: 80\n\n  history:\n    replicaCount: 3\n    resources:\n      requests:\n        memory: \"1Gi\"\n        cpu: \"500m\"\n      limits:\n        memory: \"2Gi\"\n        cpu: \"1000m\"\n\n    autoscaling:\n      enabled: true\n      minReplicas: 3\n      maxReplicas: 10\n      targetCPUUtilizationPercentage: 70\n      targetMemoryUtilizationPercentage: 80\n\n  matching:\n    replicaCount: 3\n    resources:\n      requests:\n        memory: \"512Mi\"\n        cpu: \"250m\"\n      limits:\n        memory: \"1Gi\"\n        cpu: \"500m\"\n\n    autoscaling:\n      enabled: true\n      minReplicas: 3\n      maxReplicas: 8\n      targetCPUUtilizationPercentage: 70\n      targetMemoryUtilizationPercentage: 80\n\n  worker:\n    replicaCount: 2\n    resources:\n      requests:\n        memory: \"512Mi\"\n        cpu: \"250m\"\n      limits:\n        memory: \"1Gi\"\n        cpu: \"500m\"\n\n# Web UI configuration\nweb:\n  enabled: true\n  image:\n    repository: temporalio/web\n    tag: \"2.8.0\"\n    pullPolicy: IfNotPresent\n\n  replicaCount: 2\n\n  config:\n    auth:\n      enabled: true\n      providers:\n        - label: \"Company SSO\"\n          type: \"oidc\"\n          providerUrl: \"https://auth.company.com\"\n          clientId: \"temporal-web\"\n          clientSecret: \"${OIDC_CLIENT_SECRET}\"\n          scopes:\n            - \"openid\"\n            - \"profile\"\n            - \"email\"\n          callbackUrl: \"https://temporal.company.com/auth/callback\"\n\n    routing:\n      default_to_namespace: \"default\"\n      issue_report_link: \"https://github.com/company/temporal-issues\"\n\n    temporal:\n      grpc_endpoint: \"temporal-frontend:7233\"\n      grpc_ca: \"/etc/temporal/certs/ca.crt\"\n      grpc_cert: \"/etc/temporal/certs/tls.crt\"\n      grpc_key: \"/etc/temporal/certs/tls.key\"\n\n  service:\n    type: ClusterIP\n    port: 8080\n    annotations:\n      service.beta.kubernetes.io/aws-load-balancer-type: alb\n      service.beta.kubernetes.io/aws-load-balancer-scheme: internet-facing\n      service.beta.kubernetes.io/aws-load-balancer-ssl-redirect: \"443\"\n\n  ingress:\n    enabled: true\n    className: \"alb\"\n    annotations:\n      alb.ingress.kubernetes.io/scheme: internet-facing\n      alb.ingress.kubernetes.io/target-type: ip\n      alb.ingress.kubernetes.io/certificate-arn: \"arn:aws:acm:us-west-2:ACCOUNT:certificate/CERT-ID\"\n      alb.ingress.kubernetes.io/ssl-redirect: \"443\"\n      alb.ingress.kubernetes.io/listen-ports: '[{\"HTTP\": 80}, {\"HTTPS\": 443}]'\n    hosts:\n      - host: temporal.company.com\n        paths:\n          - path: /\n            pathType: Prefix\n    tls:\n      - hosts:\n          - temporal.company.com\n        secretName: temporal-web-tls\n\n# Elasticsearch for advanced visibility (optional)\nelasticsearch:\n  enabled: true\n  image:\n    repository: elasticsearch\n    tag: \"7.17.0\"\n\n  master:\n    replicaCount: 3\n    resources:\n      requests:\n        memory: \"1Gi\"\n        cpu: \"500m\"\n      limits:\n        memory: \"2Gi\"\n        cpu: \"1000m\"\n\n  data:\n    replicaCount: 3\n    resources:\n      requests:\n        memory: \"2Gi\"\n        cpu: \"1000m\"\n      limits:\n        memory: \"4Gi\"\n        cpu: \"2000m\"\n\n    persistence:\n      storageClass: \"gp3\"\n      size: \"100Gi\"\n\n# Prometheus configuration\nprometheus:\n  enabled: true\n  serviceMonitor:\n    enabled: true\n    interval: \"30s\"\n    namespace: \"monitoring\"\n    additionalLabels:\n      app: temporal\n</code></pre>"},{"location":"implementation/temporal-deployment/#environment-specific-values","title":"Environment-Specific Values","text":""},{"location":"implementation/temporal-deployment/#development-environment","title":"Development Environment","text":"<pre><code># helm/values/temporal/development.yaml\nserver:\n  replicaCount: 1\n\n  frontend:\n    replicaCount: 1\n    resources:\n      requests:\n        memory: \"256Mi\"\n        cpu: \"100m\"\n      limits:\n        memory: \"512Mi\"\n        cpu: \"250m\"\n    autoscaling:\n      enabled: false\n\n  history:\n    replicaCount: 1\n    resources:\n      requests:\n        memory: \"512Mi\"\n        cpu: \"250m\"\n      limits:\n        memory: \"1Gi\"\n        cpu: \"500m\"\n    autoscaling:\n      enabled: false\n\n  matching:\n    replicaCount: 1\n    resources:\n      requests:\n        memory: \"256Mi\"\n        cpu: \"100m\"\n      limits:\n        memory: \"512Mi\"\n        cpu: \"250m\"\n    autoscaling:\n      enabled: false\n\n  worker:\n    replicaCount: 1\n\nweb:\n  replicaCount: 1\n  config:\n    auth:\n      enabled: false\n\nelasticsearch:\n  enabled: false\n\nprometheus:\n  enabled: true\n</code></pre>"},{"location":"implementation/temporal-deployment/#production-environment","title":"Production Environment","text":"<pre><code># helm/values/temporal/production.yaml\nserver:\n  replicaCount: 5\n\n  frontend:\n    replicaCount: 5\n    resources:\n      requests:\n        memory: \"1Gi\"\n        cpu: \"500m\"\n      limits:\n        memory: \"2Gi\"\n        cpu: \"1000m\"\n    autoscaling:\n      enabled: true\n      minReplicas: 5\n      maxReplicas: 20\n\n  history:\n    replicaCount: 5\n    resources:\n      requests:\n        memory: \"2Gi\"\n        cpu: \"1000m\"\n      limits:\n        memory: \"4Gi\"\n        cpu: \"2000m\"\n    autoscaling:\n      enabled: true\n      minReplicas: 5\n      maxReplicas: 15\n\n  matching:\n    replicaCount: 5\n    resources:\n      requests:\n        memory: \"1Gi\"\n        cpu: \"500m\"\n      limits:\n        memory: \"2Gi\"\n        cpu: \"1000m\"\n    autoscaling:\n      enabled: true\n      minReplicas: 5\n      maxReplicas: 12\n\n  worker:\n    replicaCount: 3\n\nweb:\n  replicaCount: 3\n  config:\n    auth:\n      enabled: true\n\nelasticsearch:\n  enabled: true\n  master:\n    replicaCount: 3\n  data:\n    replicaCount: 5\n\nprometheus:\n  enabled: true\n</code></pre>"},{"location":"implementation/temporal-deployment/#secrets-configuration","title":"Secrets Configuration","text":""},{"location":"implementation/temporal-deployment/#database-connection-secrets","title":"Database Connection Secrets","text":"<pre><code># k8s/temporal/secrets/database-connection.yaml\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: temporal-database-connection\n  namespace: temporal-system\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: temporal-database-connection\n    creationPolicy: Owner\n    template:\n      type: Opaque\n      data:\n        POSTGRES_PASSWORD: \"{{ .password }}\"\n        POSTGRES_CONNECTION_STRING: \"postgres://{{ .username }}:{{ .password }}@{{ .host }}:{{ .port }}/{{ .database }}?sslmode=require\"\n        VISIBILITY_CONNECTION_STRING: \"postgres://{{ .username }}:{{ .password }}@{{ .host }}:{{ .port }}/{{ .visibility_database }}?sslmode=require\"\n  data:\n  - secretKey: username\n    remoteRef:\n      key: temporal/database\n      property: username\n  - secretKey: password\n    remoteRef:\n      key: temporal/database\n      property: password\n  - secretKey: host\n    remoteRef:\n      key: temporal/database\n      property: host\n  - secretKey: port\n    remoteRef:\n      key: temporal/database\n      property: port\n  - secretKey: database\n    remoteRef:\n      key: temporal/database\n      property: database\n  - secretKey: visibility_database\n    remoteRef:\n      key: temporal/database\n      property: visibility_database\n</code></pre>"},{"location":"implementation/temporal-deployment/#authentication-secrets","title":"Authentication Secrets","text":"<pre><code># k8s/temporal/secrets/auth-secrets.yaml\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: temporal-auth-secrets\n  namespace: temporal-system\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: temporal-auth-secrets\n    creationPolicy: Owner\n  data:\n  - secretKey: OIDC_CLIENT_SECRET\n    remoteRef:\n      key: temporal/auth\n      property: oidc_client_secret\n  - secretKey: JWT_PRIVATE_KEY\n    remoteRef:\n      key: temporal/auth\n      property: jwt_private_key\n  - secretKey: JWT_PUBLIC_KEY\n    remoteRef:\n      key: temporal/auth\n      property: jwt_public_key\n</code></pre>"},{"location":"implementation/temporal-deployment/#service-configuration","title":"Service Configuration","text":""},{"location":"implementation/temporal-deployment/#service-definitions","title":"Service Definitions","text":"<pre><code># k8s/temporal/services/temporal-services.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: temporal-frontend\n  namespace: temporal-system\n  labels:\n    app.kubernetes.io/name: temporal\n    app.kubernetes.io/component: frontend\nspec:\n  type: ClusterIP\n  ports:\n  - port: 7233\n    targetPort: 7233\n    protocol: TCP\n    name: rpc\n  - port: 9090\n    targetPort: 9090\n    protocol: TCP\n    name: metrics\n  selector:\n    app.kubernetes.io/name: temporal\n    app.kubernetes.io/component: frontend\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: temporal-history\n  namespace: temporal-system\n  labels:\n    app.kubernetes.io/name: temporal\n    app.kubernetes.io/component: history\nspec:\n  type: ClusterIP\n  ports:\n  - port: 7234\n    targetPort: 7234\n    protocol: TCP\n    name: rpc\n  - port: 9090\n    targetPort: 9090\n    protocol: TCP\n    name: metrics\n  selector:\n    app.kubernetes.io/name: temporal\n    app.kubernetes.io/component: history\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: temporal-matching\n  namespace: temporal-system\n  labels:\n    app.kubernetes.io/name: temporal\n    app.kubernetes.io/component: matching\nspec:\n  type: ClusterIP\n  ports:\n  - port: 7235\n    targetPort: 7235\n    protocol: TCP\n    name: rpc\n  - port: 9090\n    targetPort: 9090\n    protocol: TCP\n    name: metrics\n  selector:\n    app.kubernetes.io/name: temporal\n    app.kubernetes.io/component: matching\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: temporal-web\n  namespace: temporal-system\n  labels:\n    app.kubernetes.io/name: temporal\n    app.kubernetes.io/component: web\nspec:\n  type: ClusterIP\n  ports:\n  - port: 8080\n    targetPort: 8080\n    protocol: TCP\n    name: http\n  selector:\n    app.kubernetes.io/name: temporal\n    app.kubernetes.io/component: web\n</code></pre>"},{"location":"implementation/temporal-deployment/#load-balancer-configuration","title":"Load Balancer Configuration","text":"<pre><code># k8s/temporal/services/load-balancer.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: temporal-frontend-external\n  namespace: temporal-system\n  annotations:\n    service.beta.kubernetes.io/aws-load-balancer-type: \"nlb\"\n    service.beta.kubernetes.io/aws-load-balancer-internal: \"true\"\n    service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: \"true\"\n    service.beta.kubernetes.io/aws-load-balancer-backend-protocol: \"tcp\"\n    service.beta.kubernetes.io/aws-load-balancer-healthcheck-protocol: \"tcp\"\n    service.beta.kubernetes.io/aws-load-balancer-healthcheck-interval: \"10\"\n    service.beta.kubernetes.io/aws-load-balancer-healthcheck-timeout: \"6\"\n    service.beta.kubernetes.io/aws-load-balancer-healthy-threshold: \"2\"\n    service.beta.kubernetes.io/aws-load-balancer-unhealthy-threshold: \"2\"\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 7233\n    targetPort: 7233\n    protocol: TCP\n    name: rpc\n  selector:\n    app.kubernetes.io/name: temporal\n    app.kubernetes.io/component: frontend\n</code></pre>"},{"location":"implementation/temporal-deployment/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"implementation/temporal-deployment/#servicemonitor-for-prometheus","title":"ServiceMonitor for Prometheus","text":"<pre><code># k8s/temporal/monitoring/service-monitor.yaml\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: temporal-server\n  namespace: temporal-system\n  labels:\n    app.kubernetes.io/name: temporal\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: temporal\n  endpoints:\n  - port: metrics\n    interval: 30s\n    path: /metrics\n    honorLabels: true\n  namespaceSelector:\n    matchNames:\n    - temporal-system\n</code></pre>"},{"location":"implementation/temporal-deployment/#grafana-dashboard-configmap","title":"Grafana Dashboard ConfigMap","text":"<pre><code># k8s/temporal/monitoring/grafana-dashboard.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: temporal-dashboard\n  namespace: monitoring\n  labels:\n    grafana_dashboard: \"1\"\ndata:\n  temporal-overview.json: |\n    {\n      \"dashboard\": {\n        \"id\": null,\n        \"title\": \"Temporal Overview\",\n        \"tags\": [\"temporal\"],\n        \"style\": \"dark\",\n        \"timezone\": \"browser\",\n        \"panels\": [\n          {\n            \"id\": 1,\n            \"title\": \"Frontend Service Health\",\n            \"type\": \"stat\",\n            \"targets\": [\n              {\n                \"expr\": \"up{job=\\\"temporal-server\\\", service=\\\"temporal-frontend\\\"}\",\n                \"legendFormat\": \"{{instance}}\"\n              }\n            ],\n            \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 0}\n          },\n          {\n            \"id\": 2,\n            \"title\": \"Request Rate\",\n            \"type\": \"graph\",\n            \"targets\": [\n              {\n                \"expr\": \"rate(temporal_request_total[5m])\",\n                \"legendFormat\": \"{{operation}}\"\n              }\n            ],\n            \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 0}\n          },\n          {\n            \"id\": 3,\n            \"title\": \"Request Latency\",\n            \"type\": \"graph\",\n            \"targets\": [\n              {\n                \"expr\": \"histogram_quantile(0.95, rate(temporal_request_latency_bucket[5m]))\",\n                \"legendFormat\": \"95th percentile\"\n              },\n              {\n                \"expr\": \"histogram_quantile(0.50, rate(temporal_request_latency_bucket[5m]))\",\n                \"legendFormat\": \"50th percentile\"\n              }\n            ],\n            \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 0, \"y\": 8}\n          },\n          {\n            \"id\": 4,\n            \"title\": \"Active Workflows\",\n            \"type\": \"graph\",\n            \"targets\": [\n              {\n                \"expr\": \"temporal_workflow_active_count\",\n                \"legendFormat\": \"{{namespace}}\"\n              }\n            ],\n            \"gridPos\": {\"h\": 8, \"w\": 12, \"x\": 12, \"y\": 8}\n          }\n        ],\n        \"time\": {\n          \"from\": \"now-1h\",\n          \"to\": \"now\"\n        },\n        \"refresh\": \"30s\"\n      }\n    }\n</code></pre>"},{"location":"implementation/temporal-deployment/#deployment-automation","title":"Deployment Automation","text":""},{"location":"implementation/temporal-deployment/#deployment-script","title":"Deployment Script","text":"<pre><code>#!/bin/bash\n# scripts/deploy-temporal.sh\n\nset -euo pipefail\n\nENVIRONMENT=${1:-development}\nNAMESPACE=\"temporal-system\"\nHELM_CHART_VERSION=${2:-1.20.0}\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m'\n\nlog() {\n    echo -e \"${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}\"\n}\n\nwarn() {\n    echo -e \"${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}\"\n}\n\nerror() {\n    echo -e \"${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}\"\n    exit 1\n}\n\n# Validate environment\nif [[ ! \"$ENVIRONMENT\" =~ ^(development|staging|production)$ ]]; then\n    error \"Invalid environment. Must be one of: development, staging, production\"\nfi\n\nlog \"Deploying Temporal cluster to $ENVIRONMENT environment\"\n\n# Check prerequisites\nlog \"Checking prerequisites...\"\nif ! command -v kubectl &amp;&gt; /dev/null; then\n    error \"kubectl is required but not installed\"\nfi\n\nif ! command -v helm &amp;&gt; /dev/null; then\n    error \"helm is required but not installed\"\nfi\n\n# Verify cluster connectivity\nif ! kubectl cluster-info &gt; /dev/null 2&gt;&amp;1; then\n    error \"Cannot connect to Kubernetes cluster\"\nfi\n\n# Create namespace if it doesn't exist\nlog \"Ensuring namespace exists...\"\nkubectl create namespace \"$NAMESPACE\" --dry-run=client -o yaml | kubectl apply -f -\n\n# Add Temporal Helm repository\nlog \"Adding Temporal Helm repository...\"\nhelm repo add temporalio https://go.temporal.io/helm-charts\nhelm repo update\n\n# Apply secrets\nlog \"Applying secrets...\"\nkubectl apply -f k8s/temporal/secrets/\n\n# Wait for secrets to be ready\nlog \"Waiting for external secrets to sync...\"\nkubectl wait --for=condition=Ready externalsecret/temporal-database-connection -n \"$NAMESPACE\" --timeout=300s\nkubectl wait --for=condition=Ready externalsecret/temporal-auth-secrets -n \"$NAMESPACE\" --timeout=300s\n\n# Deploy Temporal server\nlog \"Deploying Temporal server...\"\nhelm upgrade --install temporal temporalio/temporal \\\n    --namespace \"$NAMESPACE\" \\\n    --version \"$HELM_CHART_VERSION\" \\\n    --values \"helm/values/temporal/base.yaml\" \\\n    --values \"helm/values/temporal/${ENVIRONMENT}.yaml\" \\\n    --wait --timeout=15m\n\n# Apply additional Kubernetes resources\nlog \"Applying additional resources...\"\nkubectl apply -f k8s/temporal/services/\nkubectl apply -f k8s/temporal/monitoring/\n\n# Wait for services to be ready\nlog \"Waiting for services to be ready...\"\nkubectl wait --for=condition=available deployment/temporal-frontend -n \"$NAMESPACE\" --timeout=600s\nkubectl wait --for=condition=available deployment/temporal-history -n \"$NAMESPACE\" --timeout=600s\nkubectl wait --for=condition=available deployment/temporal-matching -n \"$NAMESPACE\" --timeout=600s\nkubectl wait --for=condition=available deployment/temporal-worker -n \"$NAMESPACE\" --timeout=600s\n\nif helm get values temporal -n \"$NAMESPACE\" | grep -q \"web:.*enabled: true\"; then\n    kubectl wait --for=condition=available deployment/temporal-web -n \"$NAMESPACE\" --timeout=600s\nfi\n\n# Verify deployment\nlog \"Verifying deployment...\"\nFRONTEND_READY=$(kubectl get deployment temporal-frontend -n \"$NAMESPACE\" -o jsonpath='{.status.readyReplicas}')\nHISTORY_READY=$(kubectl get deployment temporal-history -n \"$NAMESPACE\" -o jsonpath='{.status.readyReplicas}')\nMATCHING_READY=$(kubectl get deployment temporal-matching -n \"$NAMESPACE\" -o jsonpath='{.status.readyReplicas}')\n\nlog \"Frontend replicas ready: $FRONTEND_READY\"\nlog \"History replicas ready: $HISTORY_READY\"\nlog \"Matching replicas ready: $MATCHING_READY\"\n\n# Test connectivity\nlog \"Testing connectivity...\"\nkubectl run temporal-test --image=temporalio/admin-tools:latest --rm -i --restart=Never -- \\\n    temporal --address temporal-frontend:7233 workflow list --namespace default || warn \"Connectivity test failed\"\n\nlog \"Temporal deployment completed successfully!\"\nlog \"Access the web UI at: https://temporal.${ENVIRONMENT}.company.com\"\nlog \"gRPC endpoint: temporal-frontend.${NAMESPACE}.svc.cluster.local:7233\"\n</code></pre>"},{"location":"implementation/temporal-deployment/#health-check-script","title":"Health Check Script","text":"<pre><code>#!/bin/bash\n# scripts/health-check-temporal.sh\n\nset -euo pipefail\n\nNAMESPACE=\"temporal-system\"\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\nerror() {\n    echo -e \"\\033[0;31m[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1\\033[0m\"\n}\n\nwarn() {\n    echo -e \"\\033[1;33m[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1\\033[0m\"\n}\n\nlog \"Running Temporal cluster health checks...\"\n\n# Check pod status\nlog \"Checking pod status...\"\nPODS_NOT_READY=$(kubectl get pods -n \"$NAMESPACE\" -o jsonpath='{.items[?(@.status.phase!=\"Running\")].metadata.name}')\nif [[ -n \"$PODS_NOT_READY\" ]]; then\n    warn \"Pods not ready: $PODS_NOT_READY\"\nelse\n    log \"\u2713 All pods are running\"\nfi\n\n# Check service endpoints\nlog \"Checking service endpoints...\"\nSERVICES=(\"temporal-frontend\" \"temporal-history\" \"temporal-matching\" \"temporal-worker\")\nfor service in \"${SERVICES[@]}\"; do\n    ENDPOINTS=$(kubectl get endpoints \"$service\" -n \"$NAMESPACE\" -o jsonpath='{.subsets[*].addresses[*].ip}' | wc -w)\n    if [[ $ENDPOINTS -gt 0 ]]; then\n        log \"\u2713 $service has $ENDPOINTS endpoints\"\n    else\n        error \"\u2717 $service has no endpoints\"\n    fi\ndone\n\n# Check database connectivity\nlog \"Checking database connectivity...\"\nkubectl run db-test --image=postgres:13 --rm -i --restart=Never -- \\\n    pg_isready -h postgresql-primary -p 5432 -U temporal &gt; /dev/null 2&gt;&amp;1\nif [[ $? -eq 0 ]]; then\n    log \"\u2713 Database connectivity OK\"\nelse\n    error \"\u2717 Database connectivity failed\"\nfi\n\n# Check Temporal frontend health\nlog \"Checking Temporal frontend health...\"\nkubectl run temporal-health --image=temporalio/admin-tools:latest --rm -i --restart=Never -- \\\n    temporal --address temporal-frontend:7233 cluster health &gt; /dev/null 2&gt;&amp;1\nif [[ $? -eq 0 ]]; then\n    log \"\u2713 Temporal frontend health OK\"\nelse\n    error \"\u2717 Temporal frontend health check failed\"\nfi\n\n# Check metrics endpoints\nlog \"Checking metrics endpoints...\"\nfor service in \"${SERVICES[@]}\"; do\n    kubectl run metrics-test --image=curlimages/curl:latest --rm -i --restart=Never -- \\\n        curl -f \"http://${service}:9090/metrics\" &gt; /dev/null 2&gt;&amp;1\n    if [[ $? -eq 0 ]]; then\n        log \"\u2713 $service metrics endpoint OK\"\n    else\n        warn \"\u2717 $service metrics endpoint failed\"\n    fi\ndone\n\n# Check web UI (if enabled)\nif kubectl get deployment temporal-web -n \"$NAMESPACE\" &gt; /dev/null 2&gt;&amp;1; then\n    log \"Checking web UI health...\"\n    kubectl run web-test --image=curlimages/curl:latest --rm -i --restart=Never -- \\\n        curl -f \"http://temporal-web:8080/\" &gt; /dev/null 2&gt;&amp;1\n    if [[ $? -eq 0 ]]; then\n        log \"\u2713 Web UI health OK\"\n    else\n        warn \"\u2717 Web UI health check failed\"\n    fi\nfi\n\nlog \"Health check completed\"\n</code></pre>"},{"location":"implementation/temporal-deployment/#rolling-update-script","title":"Rolling Update Script","text":"<pre><code>#!/bin/bash\n# scripts/rolling-update-temporal.sh\n\nset -euo pipefail\n\nNAMESPACE=\"temporal-system\"\nNEW_VERSION=${1:-latest}\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\nwarn() {\n    echo -e \"\\033[1;33m[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1\\033[0m\"\n}\n\nerror() {\n    echo -e \"\\033[0;31m[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1\\033[0m\"\n    exit 1\n}\n\nlog \"Starting rolling update to version: $NEW_VERSION\"\n\n# Backup current deployment\nlog \"Backing up current deployment...\"\nhelm get values temporal -n \"$NAMESPACE\" &gt; \"temporal-backup-$(date +%Y%m%d-%H%M%S).yaml\"\n\n# Update Temporal server\nlog \"Updating Temporal server...\"\nhelm upgrade temporal temporalio/temporal \\\n    --namespace \"$NAMESPACE\" \\\n    --set server.image.tag=\"$NEW_VERSION\" \\\n    --reuse-values \\\n    --wait --timeout=15m\n\n# Monitor rollout\nlog \"Monitoring rollout status...\"\nkubectl rollout status deployment/temporal-frontend -n \"$NAMESPACE\" --timeout=600s\nkubectl rollout status deployment/temporal-history -n \"$NAMESPACE\" --timeout=600s\nkubectl rollout status deployment/temporal-matching -n \"$NAMESPACE\" --timeout=600s\nkubectl rollout status deployment/temporal-worker -n \"$NAMESPACE\" --timeout=600s\n\n# Verify update\nlog \"Verifying update...\"\nCURRENT_VERSION=$(kubectl get deployment temporal-frontend -n \"$NAMESPACE\" -o jsonpath='{.spec.template.spec.containers[0].image}' | cut -d: -f2)\nif [[ \"$CURRENT_VERSION\" == \"$NEW_VERSION\" ]]; then\n    log \"\u2713 Update completed successfully to version: $CURRENT_VERSION\"\nelse\n    error \"\u2717 Update failed. Current version: $CURRENT_VERSION, Expected: $NEW_VERSION\"\nfi\n\n# Run health checks\nlog \"Running post-update health checks...\"\n./scripts/health-check-temporal.sh\n\nlog \"Rolling update completed successfully!\"\n</code></pre> <p>This comprehensive Temporal deployment guide provides enterprise-grade deployment with high availability, monitoring, automation scripts, and operational procedures for production environments.</p>"},{"location":"implementation/upgrade-guide/","title":"Temporal Upgrade Guide","text":"<p>This guide provides detailed instructions for upgrading your Temporal deployment from version 1.27.x to 1.29.1, including prerequisites, step-by-step procedures, rollback strategies, and troubleshooting.</p>"},{"location":"implementation/upgrade-guide/#overview","title":"Overview","text":"<p>Upgrading Temporal requires careful planning and execution to ensure zero downtime and data integrity. This guide covers:</p> <ul> <li>Pre-upgrade checklist and preparation</li> <li>Database schema migrations</li> <li>Server component upgrades</li> <li>Worker and client updates</li> <li>Validation and verification</li> <li>Rollback procedures</li> </ul>"},{"location":"implementation/upgrade-guide/#upgrade-path-127x-1291","title":"Upgrade Path: 1.27.x \u2192 1.29.1","text":""},{"location":"implementation/upgrade-guide/#version-compatibility-matrix","title":"Version Compatibility Matrix","text":"Current Version Target Version Direct Upgrade Notes 1.27.x 1.29.1 \u2705 Yes Requires schema migration 1.26.x 1.29.1 \u2705 Yes Requires schema migration 1.25.x 1.29.1 \u26a0\ufe0f Not recommended Upgrade to 1.27 first &lt;1.25 1.29.1 \u274c No Multi-step upgrade required"},{"location":"implementation/upgrade-guide/#breaking-changes-127-129","title":"Breaking Changes: 1.27 \u2192 1.29","text":""},{"location":"implementation/upgrade-guide/#1-schema-changes-128","title":"1. Schema Changes (1.28+)","text":"<ul> <li>PostgreSQL Schema: v1.16 \u2192 v1.17</li> <li>MySQL Schema: v1.16 \u2192 v1.17</li> <li>Cassandra Schema: v1.11 \u2192 v1.12</li> <li>Visibility Schema: Updates for improved query performance</li> </ul>"},{"location":"implementation/upgrade-guide/#2-docker-image-changes-129","title":"2. Docker Image Changes (1.29+)","text":"<ul> <li>Slimmed images with reduced dependencies</li> <li>Separate admin-tools image required</li> <li>Base image changes may affect custom Dockerfiles</li> </ul>"},{"location":"implementation/upgrade-guide/#3-metrics-changes-129","title":"3. Metrics Changes (1.29)","text":"<ul> <li>Some metrics renamed for consistency</li> <li>Enhanced cardinality control</li> <li>Legacy metrics format deprecated</li> </ul>"},{"location":"implementation/upgrade-guide/#4-configuration-changes","title":"4. Configuration Changes","text":"<ul> <li>New eager workflow start settings (enabled by default)</li> <li>Worker versioning configuration options</li> <li>Enhanced authorization plugin API</li> </ul>"},{"location":"implementation/upgrade-guide/#pre-upgrade-checklist","title":"Pre-Upgrade Checklist","text":""},{"location":"implementation/upgrade-guide/#1-environment-assessment","title":"1. Environment Assessment","text":"<pre><code># Check current Temporal version\nkubectl get deployment temporal-frontend -n temporal-backend -o jsonpath='{.spec.template.spec.containers[0].image}'\n\n# Check database schema version\nkubectl exec -it deployment/temporal-admintools -n temporal-backend -- \\\n  temporal-sql-tool --plugin postgres12 \\\n  --ep postgresql.example.com \\\n  -u temporal \\\n  --db temporal \\\n  show-schema-version\n\n# Check current resource usage\nkubectl top pods -n temporal-backend\nkubectl top nodes\n</code></pre>"},{"location":"implementation/upgrade-guide/#2-backup-strategy","title":"2. Backup Strategy","text":""},{"location":"implementation/upgrade-guide/#database-backup","title":"Database Backup","text":"<pre><code># PostgreSQL backup\nkubectl exec -it postgresql-primary-0 -n temporal-backend -- \\\n  pg_dump -U temporal -Fc temporal &gt; temporal-backup-$(date +%Y%m%d-%H%M%S).dump\n\n# Verify backup\npg_restore --list temporal-backup-*.dump | head -20\n\n# Store backup securely\naws s3 cp temporal-backup-*.dump s3://your-backup-bucket/temporal/$(date +%Y%m%d)/\n</code></pre>"},{"location":"implementation/upgrade-guide/#configuration-backup","title":"Configuration Backup","text":"<pre><code># Backup Helm values\nhelm get values temporal -n temporal-backend &gt; temporal-values-backup-$(date +%Y%m%d).yaml\n\n# Backup Kubernetes resources\nkubectl get all,configmap,secret -n temporal-backend -o yaml &gt; k8s-resources-backup-$(date +%Y%m%d).yaml\n\n# Backup custom configurations\ncp -r /etc/temporal/config /backup/temporal-config-$(date +%Y%m%d)\n</code></pre>"},{"location":"implementation/upgrade-guide/#workflow-state-verification","title":"Workflow State Verification","text":"<pre><code># Export critical workflow states\nkubectl exec -it deployment/temporal-admintools -n temporal-backend -- \\\n  tctl workflow list --query 'ExecutionStatus=\"Running\"' --more --pagesize 1000 \\\n  &gt; running-workflows-$(date +%Y%m%d).txt\n\n# Count running workflows by type\nkubectl exec -it deployment/temporal-admintools -n temporal-backend -- \\\n  tctl workflow list --query 'ExecutionStatus=\"Running\"' | \\\n  jq -r '.WorkflowType' | sort | uniq -c\n</code></pre>"},{"location":"implementation/upgrade-guide/#3-staging-environment-testing","title":"3. Staging Environment Testing","text":"<p>Critical: Always test the upgrade in a staging environment first!</p> <pre><code># Clone production data to staging (PostgreSQL example)\npg_dump -U temporal -h prod-postgres.example.com temporal | \\\n  psql -U temporal -h staging-postgres.example.com temporal\n\n# Apply upgrade in staging\n# (Follow upgrade procedures in staging first)\n\n# Validate staging environment\n./scripts/validate-staging.sh\n</code></pre>"},{"location":"implementation/upgrade-guide/#upgrade-procedures","title":"Upgrade Procedures","text":""},{"location":"implementation/upgrade-guide/#step-1-prepare-the-upgrade","title":"Step 1: Prepare the Upgrade","text":""},{"location":"implementation/upgrade-guide/#11-download-schema-migration-files","title":"1.1. Download Schema Migration Files","text":"<pre><code># Download Temporal schema repository\ngit clone https://github.com/temporalio/temporal.git\ncd temporal/schema\n\n# Checkout the target version\ngit checkout v1.29.1\n\n# Verify schema files\nls -la postgresql/v12/temporal/versioned/v1.17/\nls -la postgresql/v12/visibility/versioned/v1.17/\n</code></pre>"},{"location":"implementation/upgrade-guide/#12-review-migration-scripts","title":"1.2. Review Migration Scripts","text":"<pre><code># Review schema changes\ncat postgresql/v12/temporal/versioned/v1.17/*.sql\ncat postgresql/v12/visibility/versioned/v1.17/*.sql\n\n# Check for breaking changes\ngrep -i \"drop\\|alter\\|rename\" postgresql/v12/temporal/versioned/v1.17/*.sql\n</code></pre>"},{"location":"implementation/upgrade-guide/#13-schedule-maintenance-window","title":"1.3. Schedule Maintenance Window","text":"<p>For production environments: - Recommended window: 2-4 hours - Low-traffic period: Preferred - Communication: Notify stakeholders - Rollback time: Reserve 50% of window for potential rollback</p>"},{"location":"implementation/upgrade-guide/#step-2-database-schema-migration","title":"Step 2: Database Schema Migration","text":""},{"location":"implementation/upgrade-guide/#21-pre-migration-validation","title":"2.1. Pre-Migration Validation","text":"<pre><code># Verify database connectivity\ntemporal-sql-tool --plugin postgres12 \\\n  --ep postgresql.example.com \\\n  -u temporal \\\n  --db temporal \\\n  validate\n\n# Check current schema version\ntemporal-sql-tool --plugin postgres12 \\\n  --ep postgresql.example.com \\\n  -u temporal \\\n  --db temporal \\\n  show-schema-version\n\n# Expected output for 1.27.x:\n# Current database schema version: 1.16\n</code></pre>"},{"location":"implementation/upgrade-guide/#22-dry-run-migration","title":"2.2. Dry-Run Migration","text":"<pre><code># Dry-run schema update (no changes applied)\ntemporal-sql-tool --plugin postgres12 \\\n  --ep postgresql.example.com \\\n  -u temporal \\\n  -p 5432 \\\n  --db temporal \\\n  --tls \\\n  --tls-cert-file /path/to/client.crt \\\n  --tls-key-file /path/to/client.key \\\n  --tls-ca-file /path/to/ca.crt \\\n  update-schema \\\n  -d ./postgresql/v12/temporal/versioned \\\n  --dry-run\n\n# Review the output carefully\n</code></pre>"},{"location":"implementation/upgrade-guide/#23-apply-schema-migration","title":"2.3. Apply Schema Migration","text":"<pre><code># Migrate default store (temporal database)\ntemporal-sql-tool --plugin postgres12 \\\n  --ep postgresql.example.com \\\n  -u temporal \\\n  -p 5432 \\\n  --db temporal \\\n  --tls \\\n  --tls-cert-file /path/to/client.crt \\\n  --tls-key-file /path/to/client.key \\\n  --tls-ca-file /path/to/ca.crt \\\n  update-schema \\\n  -d ./postgresql/v12/temporal/versioned\n\n# Migrate visibility store\ntemporal-sql-tool --plugin postgres12 \\\n  --ep postgresql.example.com \\\n  -u temporal \\\n  -p 5432 \\\n  --db temporal_visibility \\\n  --tls \\\n  --tls-cert-file /path/to/client.crt \\\n  --tls-key-file /path/to/client.key \\\n  --tls-ca-file /path/to/ca.crt \\\n  update-schema \\\n  -d ./postgresql/v12/visibility/versioned\n</code></pre>"},{"location":"implementation/upgrade-guide/#24-verify-schema-migration","title":"2.4. Verify Schema Migration","text":"<pre><code># Verify new schema version\ntemporal-sql-tool --plugin postgres12 \\\n  --ep postgresql.example.com \\\n  -u temporal \\\n  --db temporal \\\n  show-schema-version\n\n# Expected output:\n# Current database schema version: 1.17\n\n# Verify tables and indexes\npsql -U temporal -h postgresql.example.com -d temporal -c \"\\dt\"\npsql -U temporal -h postgresql.example.com -d temporal -c \"\\di\"\n</code></pre>"},{"location":"implementation/upgrade-guide/#step-3-update-helm-values","title":"Step 3: Update Helm Values","text":""},{"location":"implementation/upgrade-guide/#31-create-updated-values-file","title":"3.1. Create Updated Values File","text":"<pre><code># values-1.29.yaml\nserver:\n  image:\n    repository: temporalio/server\n    tag: 1.29.1\n    pullPolicy: IfNotPresent\n\n  replicaCount: 3\n\n  config:\n    # Enable eager workflow start (new default in 1.29)\n    services:\n      frontend:\n        eagerWorkflowStartEnabled: true\n        rateLimit:\n          eagerWorkflowStart:\n            maxPerSecond: 100\n            burstSize: 200\n\n    # Existing persistence configuration\n    persistence:\n      defaultStore: default\n      visibilityStore: visibility\n      numHistoryShards: 4096\n\n      datastores:\n        default:\n          driver: \"postgres12\"\n          host: \"postgresql.example.com\"\n          port: 5432\n          database: \"temporal\"\n          user: \"temporal\"\n          existingSecret: \"temporal-default-store\"\n          maxConns: 50\n          maxIdleConns: 10\n          maxConnLifetime: \"1h\"\n\n        visibility:\n          driver: \"postgres12\"\n          host: \"postgresql.example.com\"\n          port: 5432\n          database: \"temporal_visibility\"\n          user: \"temporal\"\n          existingSecret: \"temporal-visibility-store\"\n          maxConns: 20\n          maxIdleConns: 5\n          maxConnLifetime: \"1h\"\n\n    # Update TLS settings to 1.3\n    global:\n      tls:\n        internode:\n          server:\n            minVersion: \"1.3\"\n            certFile: /etc/temporal/certs/tls.crt\n            keyFile: /etc/temporal/certs/tls.key\n            clientCAFile: /etc/temporal/certs/ca.crt\n          client:\n            minVersion: \"1.3\"\n            certFile: /etc/temporal/certs/tls.crt\n            keyFile: /etc/temporal/certs/tls.key\n            caFile: /etc/temporal/certs/ca.crt\n\nadmintools:\n  image:\n    repository: temporalio/admin-tools\n    tag: 1.29.1-tctl-1.18.2-cli-1.3.0\n    pullPolicy: IfNotPresent\n\nweb:\n  image:\n    repository: temporalio/ui\n    tag: 2.40.0  # Latest UI version\n    pullPolicy: IfNotPresent\n</code></pre>"},{"location":"implementation/upgrade-guide/#32-diff-current-and-new-configuration","title":"3.2. Diff Current and New Configuration","text":"<pre><code># Compare configurations\nhelm get values temporal -n temporal-backend &gt; current-values.yaml\ndiff -u current-values.yaml values-1.29.yaml\n\n# Review differences carefully\n</code></pre>"},{"location":"implementation/upgrade-guide/#step-4-rolling-upgrade-of-temporal-server","title":"Step 4: Rolling Upgrade of Temporal Server","text":""},{"location":"implementation/upgrade-guide/#41-update-admin-tools-first","title":"4.1. Update Admin Tools First","text":"<pre><code># Upgrade admin tools (safe, no impact on running workflows)\nhelm upgrade temporal temporalio/temporal \\\n  -n temporal-backend \\\n  --reuse-values \\\n  --set admintools.image.tag=1.29.1-tctl-1.18.2-cli-1.3.0 \\\n  --wait\n\n# Verify admin tools\nkubectl get pods -n temporal-backend -l app=temporal-admintools\nkubectl logs -n temporal-backend -l app=temporal-admintools --tail=50\n</code></pre>"},{"location":"implementation/upgrade-guide/#42-upgrade-frontend-service","title":"4.2. Upgrade Frontend Service","text":"<pre><code># Frontend handles client connections - upgrade carefully\nhelm upgrade temporal temporalio/temporal \\\n  -n temporal-backend \\\n  --reuse-values \\\n  --set server.image.tag=1.29.1 \\\n  --set server.frontend.replicaCount=3 \\\n  --wait \\\n  --timeout 10m\n\n# Monitor frontend rollout\nkubectl rollout status deployment/temporal-frontend -n temporal-backend\n\n# Verify frontend health\nkubectl exec -it deployment/temporal-admintools -n temporal-backend -- \\\n  tctl cluster health\n</code></pre>"},{"location":"implementation/upgrade-guide/#43-upgrade-history-service","title":"4.3. Upgrade History Service","text":"<pre><code># History service manages workflow state - critical component\nhelm upgrade temporal temporalio/temporal \\\n  -n temporal-backend \\\n  --reuse-values \\\n  --set server.image.tag=1.29.1 \\\n  --wait \\\n  --timeout 15m\n\n# Monitor history rollout (this takes longest)\nkubectl rollout status deployment/temporal-history -n temporal-backend\n\n# Verify no workflow disruptions\nkubectl logs -n temporal-backend -l app=temporal-history --tail=100 | \\\n  grep -i \"error\\|fatal\"\n</code></pre>"},{"location":"implementation/upgrade-guide/#44-upgrade-matching-service","title":"4.4. Upgrade Matching Service","text":"<pre><code># Matching service handles task queues\nhelm upgrade temporal temporalio/temporal \\\n  -n temporal-backend \\\n  --reuse-values \\\n  --set server.image.tag=1.29.1 \\\n  --wait\n\n# Monitor matching rollout\nkubectl rollout status deployment/temporal-matching -n temporal-backend\n</code></pre>"},{"location":"implementation/upgrade-guide/#45-upgrade-worker-service","title":"4.5. Upgrade Worker Service","text":"<pre><code># Internal worker service\nhelm upgrade temporal temporalio/temporal \\\n  -n temporal-backend \\\n  --reuse-values \\\n  --set server.image.tag=1.29.1 \\\n  --wait\n\n# Monitor worker rollout\nkubectl rollout status deployment/temporal-worker -n temporal-backend\n</code></pre>"},{"location":"implementation/upgrade-guide/#46-complete-upgrade-with-full-values","title":"4.6. Complete Upgrade with Full Values","text":"<pre><code># Apply all configuration changes\nhelm upgrade temporal temporalio/temporal \\\n  -n temporal-backend \\\n  -f values-1.29.yaml \\\n  --wait \\\n  --timeout 20m\n\n# Verify all components\nkubectl get pods -n temporal-backend\nkubectl get deployment -n temporal-backend\n</code></pre>"},{"location":"implementation/upgrade-guide/#step-5-validate-upgrade","title":"Step 5: Validate Upgrade","text":""},{"location":"implementation/upgrade-guide/#51-cluster-health-check","title":"5.1. Cluster Health Check","text":"<pre><code># Check cluster health\nkubectl exec -it deployment/temporal-admintools -n temporal-backend -- \\\n  tctl cluster health\n\n# Expected output:\n# SERVING\n\n# Check all services\nkubectl exec -it deployment/temporal-admintools -n temporal-backend -- \\\n  tctl admin cluster describe\n</code></pre>"},{"location":"implementation/upgrade-guide/#52-workflow-validation","title":"5.2. Workflow Validation","text":"<pre><code># Verify running workflows\nkubectl exec -it deployment/temporal-admintools -n temporal-backend -- \\\n  tctl workflow list --query 'ExecutionStatus=\"Running\"'\n\n# Test workflow start (using eager start)\nkubectl exec -it deployment/temporal-admintools -n temporal-backend -- \\\n  tctl workflow start \\\n    --taskqueue test-queue \\\n    --workflow_type TestWorkflow \\\n    --execution_timeout 300 \\\n    --input '\"test-upgrade\"'\n\n# Verify workflow execution\nkubectl exec -it deployment/temporal-admintools -n temporal-backend -- \\\n  tctl workflow show -w &lt;workflow-id&gt;\n</code></pre>"},{"location":"implementation/upgrade-guide/#53-metrics-verification","title":"5.3. Metrics Verification","text":"<pre><code># Check Prometheus metrics\nkubectl port-forward -n temporal-backend svc/temporal-frontend 9090:9090 &amp;\ncurl http://localhost:9090/metrics | grep temporal_\n\n# Verify new metrics are present\ncurl http://localhost:9090/metrics | grep \"temporal_request_latency\"\n</code></pre>"},{"location":"implementation/upgrade-guide/#54-api-testing","title":"5.4. API Testing","text":"<pre><code># test_upgrade.py - Test client connectivity\nfrom temporalio.client import Client\nimport asyncio\n\nasync def test_connection():\n    client = await Client.connect(\"temporal.example.com:7233\")\n\n    # Test namespace access\n    await client.list_workflows(\"WorkflowType='TestWorkflow'\")\n\n    # Test workflow start (validates eager start)\n    handle = await client.start_workflow(\n        TestWorkflow.run,\n        id=f\"test-upgrade-{int(time.time())}\",\n        task_queue=\"test-queue\"\n    )\n\n    result = await handle.result()\n    print(f\"Upgrade validation successful: {result}\")\n\nasyncio.run(test_connection())\n</code></pre>"},{"location":"implementation/upgrade-guide/#step-6-update-workers-and-clients","title":"Step 6: Update Workers and Clients","text":""},{"location":"implementation/upgrade-guide/#61-update-python-sdk-in-workers","title":"6.1. Update Python SDK in Workers","text":"<pre><code># Update requirements.txt or pyproject.toml\n# From: temporalio&gt;=1.7.0\n# To:   temporalio&gt;=1.18.2\n\n# Using uv (recommended)\ncd /path/to/worker\nuv pip install temporalio==1.18.2\n\n# Or using pip\npip install --upgrade temporalio==1.18.2\n\n# Rebuild worker images\ndocker build -t your-registry/temporal-worker:v2.0.0 .\ndocker push your-registry/temporal-worker:v2.0.0\n</code></pre>"},{"location":"implementation/upgrade-guide/#62-deploy-updated-workers","title":"6.2. Deploy Updated Workers","text":"<pre><code># k8s/worker-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: temporal-worker\n  namespace: temporal-product\nspec:\n  replicas: 3\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0  # Zero downtime\n  template:\n    spec:\n      containers:\n      - name: worker\n        image: your-registry/temporal-worker:v2.0.0\n        env:\n        - name: TEMPORAL_HOST\n          value: \"temporal-frontend.temporal-backend:7233\"\n        - name: SDK_VERSION\n          value: \"1.18.2\"\n</code></pre> <pre><code># Deploy updated workers\nkubectl apply -f k8s/worker-deployment.yaml\n\n# Monitor rollout (zero downtime)\nkubectl rollout status deployment/temporal-worker -n temporal-product\n\n# Verify workers are processing tasks\nkubectl logs -n temporal-product -l app=temporal-worker --tail=100\n</code></pre>"},{"location":"implementation/upgrade-guide/#63-update-client-applications","title":"6.3. Update Client Applications","text":"<pre><code># Update client applications gradually\nfrom temporalio.client import Client\n\n# New features available in 1.18.2+\nasync def use_new_features():\n    client = await Client.connect(\n        \"temporal.example.com:7233\",\n        namespace=\"production\"\n    )\n\n    # Use Update-With-Start (GA in 1.28+)\n    handle = await client.start_workflow(\n        OrderWorkflow.run,\n        id=\"order-12345\",\n        task_queue=\"orders\"\n    )\n\n    # Execute update\n    result = await handle.execute_update(\n        OrderWorkflow.update_status,\n        \"processing\"\n    )\n</code></pre>"},{"location":"implementation/upgrade-guide/#step-7-post-upgrade-monitoring","title":"Step 7: Post-Upgrade Monitoring","text":""},{"location":"implementation/upgrade-guide/#71-monitor-for-24-48-hours","title":"7.1. Monitor for 24-48 Hours","text":"<pre><code># Setup monitoring dashboard\ncat &lt;&lt;EOF &gt; prometheus-queries.yaml\nqueries:\n  # Request latency\n  - temporal_request_latency_bucket\n\n  # Error rates\n  - rate(temporal_request_errors_total[5m])\n\n  # Workflow execution rates\n  - rate(temporal_workflow_execution_started[5m])\n\n  # Worker polling\n  - temporal_worker_task_slots_available\n\n  # Database connections\n  - temporal_persistence_requests_total\nEOF\n\n# Alert on anomalies\n</code></pre>"},{"location":"implementation/upgrade-guide/#72-performance-comparison","title":"7.2. Performance Comparison","text":"<pre><code># Compare metrics before/after upgrade\n# - Workflow start latency (should improve with eager start)\n# - Task processing throughput\n# - Database query performance\n# - Resource utilization\n</code></pre>"},{"location":"implementation/upgrade-guide/#rollback-procedures","title":"Rollback Procedures","text":""},{"location":"implementation/upgrade-guide/#when-to-rollback","title":"When to Rollback","text":"<p>Rollback if you encounter: - Persistent cluster health failures - High error rates (&gt;5% increase) - Workflow execution failures - Database connectivity issues - Critical feature regressions</p>"},{"location":"implementation/upgrade-guide/#rollback-steps","title":"Rollback Steps","text":""},{"location":"implementation/upgrade-guide/#1-rollback-temporal-server","title":"1. Rollback Temporal Server","text":"<pre><code># Rollback to previous version\nhelm rollback temporal -n temporal-backend\n\n# Or specify specific revision\nhelm rollback temporal &lt;revision-number&gt; -n temporal-backend\n\n# Verify rollback\nkubectl get pods -n temporal-backend\nkubectl exec -it deployment/temporal-admintools -n temporal-backend -- \\\n  tctl cluster health\n</code></pre>"},{"location":"implementation/upgrade-guide/#2-rollback-database-schema-if-necessary","title":"2. Rollback Database Schema (If Necessary)","text":"<pre><code># Restore database from backup\npg_restore -U temporal -h postgresql.example.com -d temporal \\\n  temporal-backup-YYYYMMDD-HHMMSS.dump\n\n# Verify schema version\ntemporal-sql-tool --plugin postgres12 \\\n  --ep postgresql.example.com \\\n  -u temporal \\\n  --db temporal \\\n  show-schema-version\n</code></pre>"},{"location":"implementation/upgrade-guide/#3-rollback-workers","title":"3. Rollback Workers","text":"<pre><code># Revert to previous worker image\nkubectl set image deployment/temporal-worker \\\n  worker=your-registry/temporal-worker:v1.0.0 \\\n  -n temporal-product\n\nkubectl rollout status deployment/temporal-worker -n temporal-product\n</code></pre>"},{"location":"implementation/upgrade-guide/#troubleshooting-common-issues","title":"Troubleshooting Common Issues","text":""},{"location":"implementation/upgrade-guide/#issue-1-schema-migration-fails","title":"Issue 1: Schema Migration Fails","text":"<p>Symptoms: <pre><code>Error: schema version mismatch\n</code></pre></p> <p>Resolution: <pre><code># Check schema version\ntemporal-sql-tool --plugin postgres12 \\\n  --ep postgresql.example.com \\\n  -u temporal \\\n  --db temporal \\\n  show-schema-version\n\n# Force schema update if stuck\ntemporal-sql-tool --plugin postgres12 \\\n  --ep postgresql.example.com \\\n  -u temporal \\\n  --db temporal \\\n  update-schema \\\n  -d ./postgresql/v12/temporal/versioned \\\n  --version 1.17\n</code></pre></p>"},{"location":"implementation/upgrade-guide/#issue-2-frontend-connection-errors","title":"Issue 2: Frontend Connection Errors","text":"<p>Symptoms: <pre><code>rpc error: code = Unavailable desc = connection error\n</code></pre></p> <p>Resolution: <pre><code># Check frontend pods\nkubectl get pods -n temporal-backend -l app=temporal-frontend\n\n# Check frontend logs\nkubectl logs -n temporal-backend -l app=temporal-frontend --tail=200\n\n# Verify service endpoints\nkubectl get endpoints temporal-frontend -n temporal-backend\n\n# Test connectivity\nkubectl run -it --rm debug --image=busybox --restart=Never -- \\\n  nc -zv temporal-frontend.temporal-backend.svc.cluster.local 7233\n</code></pre></p>"},{"location":"implementation/upgrade-guide/#issue-3-worker-version-mismatch","title":"Issue 3: Worker Version Mismatch","text":"<p>Symptoms: <pre><code>Worker SDK version incompatible with server\n</code></pre></p> <p>Resolution: <pre><code># Update worker SDK\npip install --upgrade temporalio==1.18.2\n\n# Rebuild and redeploy workers\ndocker build -t your-registry/temporal-worker:latest .\nkubectl rollout restart deployment/temporal-worker -n temporal-product\n</code></pre></p>"},{"location":"implementation/upgrade-guide/#issue-4-eager-workflow-start-issues","title":"Issue 4: Eager Workflow Start Issues","text":"<p>Symptoms: <pre><code>Eager workflow start failed, falling back to normal start\n</code></pre></p> <p>Resolution: <pre><code># Adjust rate limits in Helm values\nserver:\n  config:\n    services:\n      frontend:\n        eagerWorkflowStartEnabled: true\n        rateLimit:\n          eagerWorkflowStart:\n            maxPerSecond: 200  # Increase limit\n            burstSize: 400\n</code></pre></p>"},{"location":"implementation/upgrade-guide/#issue-5-high-database-load","title":"Issue 5: High Database Load","text":"<p>Symptoms: - Slow query performance - Connection pool exhaustion</p> <p>Resolution: <pre><code># Adjust connection pool settings\nserver:\n  config:\n    persistence:\n      datastores:\n        default:\n          maxConns: 100  # Increase connections\n          maxIdleConns: 20\n          maxConnLifetime: \"30m\"  # Reduce lifetime\n</code></pre></p>"},{"location":"implementation/upgrade-guide/#best-practices","title":"Best Practices","text":""},{"location":"implementation/upgrade-guide/#1-gradual-rollout","title":"1. Gradual Rollout","text":"<ul> <li>Upgrade staging first</li> <li>Use canary deployments for workers</li> <li>Monitor extensively at each stage</li> </ul>"},{"location":"implementation/upgrade-guide/#2-communication","title":"2. Communication","text":"<ul> <li>Notify stakeholders of maintenance window</li> <li>Prepare rollback communications</li> <li>Document all changes</li> </ul>"},{"location":"implementation/upgrade-guide/#3-automation","title":"3. Automation","text":"<pre><code># Create upgrade automation script\n#!/bin/bash\nset -e\n\n./scripts/backup-database.sh\n./scripts/test-schema-migration.sh\n./scripts/upgrade-temporal.sh\n./scripts/validate-upgrade.sh\n./scripts/monitor-health.sh\n</code></pre>"},{"location":"implementation/upgrade-guide/#4-testing","title":"4. Testing","text":"<ul> <li>Test all critical workflows post-upgrade</li> <li>Validate new features work as expected</li> <li>Performance benchmark comparison</li> </ul>"},{"location":"implementation/upgrade-guide/#additional-resources","title":"Additional Resources","text":"<ul> <li>Temporal Upgrade Documentation</li> <li>Schema Migration Tools</li> <li>What's New in Temporal 1.29</li> <li>Temporal GitHub Releases</li> </ul>"},{"location":"implementation/upgrade-guide/#support","title":"Support","text":"<p>For upgrade assistance: - Temporal Community Forum - Temporal Slack - Professional support: support@temporal.io</p>"},{"location":"reference/api/","title":"API Reference","text":"<p>This comprehensive API reference covers all Temporal.io APIs, including the Frontend Service API, Worker API, Admin API, and client SDKs. The reference includes detailed endpoint documentation, request/response schemas, and practical examples.</p>"},{"location":"reference/api/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Frontend Service API</li> <li>Worker API</li> <li>Admin API</li> <li>Client SDK APIs</li> <li>Authentication &amp; Authorization</li> <li>Error Codes</li> <li>Rate Limiting</li> <li>Versioning</li> </ul>"},{"location":"reference/api/#frontend-service-api","title":"Frontend Service API","text":"<p>The Frontend Service API is the main interface for client interactions with Temporal. All client SDKs communicate through this API.</p>"},{"location":"reference/api/#base-url-and-authentication","title":"Base URL and Authentication","text":"<pre><code>Base URL: https://temporal.company.com:7233\nProtocol: gRPC over HTTP/2\nAuthentication: JWT Bearer Token (optional)\n</code></pre>"},{"location":"reference/api/#workflow-operations","title":"Workflow Operations","text":""},{"location":"reference/api/#startworkflowexecution","title":"StartWorkflowExecution","text":"<p>Starts a new workflow execution.</p> <p>Method: <code>POST /api/v1/namespaces/{namespace}/workflows</code></p> <p>Request Schema: <pre><code>message StartWorkflowExecutionRequest {\n  string namespace = 1;\n  string workflow_id = 2;\n  temporal.api.common.v1.WorkflowType workflow_type = 3;\n  string task_queue = 4;\n  google.protobuf.Any input = 5;\n  google.protobuf.Duration workflow_execution_timeout = 6;\n  google.protobuf.Duration workflow_run_timeout = 7;\n  google.protobuf.Duration workflow_task_timeout = 8;\n  string identity = 9;\n  string request_id = 10;\n  temporal.api.enums.v1.WorkflowIdReusePolicy workflow_id_reuse_policy = 11;\n  temporal.api.common.v1.RetryPolicy retry_policy = 12;\n  string cron_schedule = 13;\n  temporal.api.common.v1.Memo memo = 14;\n  temporal.api.common.v1.SearchAttributes search_attributes = 15;\n  temporal.api.common.v1.Header header = 16;\n}\n</code></pre></p> <p>Response Schema: <pre><code>message StartWorkflowExecutionResponse {\n  string run_id = 1;\n  bool started = 2;\n}\n</code></pre></p> <p>Example Request: <pre><code>{\n  \"namespace\": \"default\",\n  \"workflow_id\": \"order-processing-12345\",\n  \"workflow_type\": {\n    \"name\": \"OrderProcessingWorkflow\"\n  },\n  \"task_queue\": \"order-processing-queue\",\n  \"input\": {\n    \"order_id\": \"12345\",\n    \"customer_id\": \"customer-67890\",\n    \"items\": [\n      {\n        \"product_id\": \"product-001\",\n        \"quantity\": 2,\n        \"price\": 29.99\n      }\n    ]\n  },\n  \"workflow_execution_timeout\": \"86400s\",\n  \"workflow_run_timeout\": \"3600s\",\n  \"workflow_task_timeout\": \"10s\",\n  \"identity\": \"order-service-v1.2.3\",\n  \"workflow_id_reuse_policy\": \"ALLOW_DUPLICATE_FAILED_ONLY\",\n  \"retry_policy\": {\n    \"initial_interval\": \"1s\",\n    \"backoff_coefficient\": 2.0,\n    \"maximum_interval\": \"100s\",\n    \"maximum_attempts\": 3\n  },\n  \"memo\": {\n    \"fields\": {\n      \"environment\": {\n        \"data\": \"production\"\n      },\n      \"version\": {\n        \"data\": \"v1.2.3\"\n      }\n    }\n  },\n  \"search_attributes\": {\n    \"indexed_fields\": {\n      \"OrderId\": {\n        \"data\": \"12345\"\n      },\n      \"CustomerId\": {\n        \"data\": \"customer-67890\"\n      },\n      \"Environment\": {\n        \"data\": \"production\"\n      }\n    }\n  }\n}\n</code></pre></p> <p>Example Response: <pre><code>{\n  \"run_id\": \"01234567-89ab-cdef-0123-456789abcdef\",\n  \"started\": true\n}\n</code></pre></p>"},{"location":"reference/api/#getworkflowexecution","title":"GetWorkflowExecution","text":"<p>Retrieves information about a workflow execution.</p> <p>Method: <code>GET /api/v1/namespaces/{namespace}/workflows/{workflow_id}/runs/{run_id}</code></p> <p>Request Schema: <pre><code>message GetWorkflowExecutionRequest {\n  string namespace = 1;\n  temporal.api.common.v1.WorkflowExecution execution = 2;\n}\n</code></pre></p> <p>Response Schema: <pre><code>message GetWorkflowExecutionResponse {\n  temporal.api.workflowservice.v1.WorkflowExecutionInfo execution_info = 1;\n  repeated temporal.api.history.v1.HistoryEvent workflow_execution_history = 2;\n  bytes next_page_token = 3;\n}\n</code></pre></p>"},{"location":"reference/api/#terminateworkflowexecution","title":"TerminateWorkflowExecution","text":"<p>Terminates a running workflow execution.</p> <p>Method: <code>POST /api/v1/namespaces/{namespace}/workflows/{workflow_id}/runs/{run_id}/terminate</code></p> <p>Request Schema: <pre><code>message TerminateWorkflowExecutionRequest {\n  string namespace = 1;\n  temporal.api.common.v1.WorkflowExecution workflow_execution = 2;\n  string reason = 3;\n  google.protobuf.Any details = 4;\n  string identity = 5;\n}\n</code></pre></p>"},{"location":"reference/api/#signalworkflowexecution","title":"SignalWorkflowExecution","text":"<p>Sends a signal to a running workflow execution.</p> <p>Method: <code>POST /api/v1/namespaces/{namespace}/workflows/{workflow_id}/runs/{run_id}/signal</code></p> <p>Request Schema: <pre><code>message SignalWorkflowExecutionRequest {\n  string namespace = 1;\n  temporal.api.common.v1.WorkflowExecution workflow_execution = 2;\n  string signal_name = 3;\n  google.protobuf.Any input = 4;\n  string identity = 5;\n  string request_id = 6;\n  string control = 7;\n  temporal.api.common.v1.Header header = 8;\n}\n</code></pre></p> <p>Example Request: <pre><code>{\n  \"namespace\": \"default\",\n  \"workflow_execution\": {\n    \"workflow_id\": \"order-processing-12345\",\n    \"run_id\": \"01234567-89ab-cdef-0123-456789abcdef\"\n  },\n  \"signal_name\": \"payment_received\",\n  \"input\": {\n    \"payment_id\": \"payment-98765\",\n    \"amount\": 59.98,\n    \"currency\": \"USD\",\n    \"method\": \"credit_card\"\n  },\n  \"identity\": \"payment-service-v1.1.0\",\n  \"request_id\": \"signal-request-12345\"\n}\n</code></pre></p>"},{"location":"reference/api/#queryworkflow","title":"QueryWorkflow","text":"<p>Queries the current state of a workflow execution.</p> <p>Method: <code>POST /api/v1/namespaces/{namespace}/workflows/{workflow_id}/runs/{run_id}/query</code></p> <p>Request Schema: <pre><code>message QueryWorkflowRequest {\n  string namespace = 1;\n  temporal.api.common.v1.WorkflowExecution execution = 2;\n  temporal.api.query.v1.WorkflowQuery query = 3;\n  temporal.api.enums.v1.QueryRejectCondition query_reject_condition = 4;\n  temporal.api.common.v1.Header header = 5;\n}\n</code></pre></p> <p>Example Request: <pre><code>{\n  \"namespace\": \"default\",\n  \"execution\": {\n    \"workflow_id\": \"order-processing-12345\",\n    \"run_id\": \"01234567-89ab-cdef-0123-456789abcdef\"\n  },\n  \"query\": {\n    \"query_type\": \"get_order_status\",\n    \"query_args\": {}\n  },\n  \"query_reject_condition\": \"NOT_OPEN\"\n}\n</code></pre></p>"},{"location":"reference/api/#activity-operations","title":"Activity Operations","text":""},{"location":"reference/api/#recordactivitytaskheartbeat","title":"RecordActivityTaskHeartbeat","text":"<p>Records a heartbeat for an activity task.</p> <p>Method: <code>POST /api/v1/namespaces/{namespace}/activities/heartbeat</code></p> <p>Request Schema: <pre><code>message RecordActivityTaskHeartbeatRequest {\n  string namespace = 1;\n  bytes task_token = 2;\n  google.protobuf.Any details = 3;\n  string identity = 4;\n}\n</code></pre></p>"},{"location":"reference/api/#respondactivitytaskcompleted","title":"RespondActivityTaskCompleted","text":"<p>Responds to an activity task with completion.</p> <p>Method: <code>POST /api/v1/namespaces/{namespace}/activities/complete</code></p> <p>Request Schema: <pre><code>message RespondActivityTaskCompletedRequest {\n  string namespace = 1;\n  bytes task_token = 2;\n  google.protobuf.Any result = 3;\n  string identity = 4;\n}\n</code></pre></p>"},{"location":"reference/api/#respondactivitytaskfailed","title":"RespondActivityTaskFailed","text":"<p>Responds to an activity task with failure.</p> <p>Method: <code>POST /api/v1/namespaces/{namespace}/activities/fail</code></p> <p>Request Schema: <pre><code>message RespondActivityTaskFailedRequest {\n  string namespace = 1;\n  bytes task_token = 2;\n  temporal.api.failure.v1.Failure failure = 3;\n  string identity = 4;\n  int64 last_heartbeat_time = 5;\n}\n</code></pre></p>"},{"location":"reference/api/#task-queue-operations","title":"Task Queue Operations","text":""},{"location":"reference/api/#pollworkflowtaskqueue","title":"PollWorkflowTaskQueue","text":"<p>Polls for workflow tasks from a task queue.</p> <p>Method: <code>POST /api/v1/namespaces/{namespace}/task-queues/{task_queue}/workflow-tasks/poll</code></p> <p>Request Schema: <pre><code>message PollWorkflowTaskQueueRequest {\n  string namespace = 1;\n  string task_queue = 2;\n  string identity = 3;\n  string binary_checksum = 4;\n  temporal.api.taskqueue.v1.TaskQueueMetadata task_queue_metadata = 5;\n}\n</code></pre></p> <p>Response Schema: <pre><code>message PollWorkflowTaskQueueResponse {\n  bytes task_token = 1;\n  temporal.api.common.v1.WorkflowExecution workflow_execution = 2;\n  temporal.api.common.v1.WorkflowType workflow_type = 3;\n  int64 previous_started_event_id = 4;\n  int64 started_event_id = 5;\n  int64 attempt = 6;\n  int64 backlog_count_hint = 7;\n  google.protobuf.Timestamp scheduled_time = 8;\n  google.protobuf.Timestamp started_time = 9;\n  repeated temporal.api.history.v1.HistoryEvent history = 10;\n  bytes next_page_token = 11;\n  temporal.api.query.v1.WorkflowQuery query = 12;\n  temporal.api.taskqueue.v1.TaskQueue workflow_execution_task_queue = 13;\n  google.protobuf.Duration workflow_task_timeout = 14;\n  repeated temporal.api.sdk.v1.WorkflowTaskCompletedMetadata messages = 15;\n}\n</code></pre></p>"},{"location":"reference/api/#pollactivitytaskqueue","title":"PollActivityTaskQueue","text":"<p>Polls for activity tasks from a task queue.</p> <p>Method: <code>POST /api/v1/namespaces/{namespace}/task-queues/{task_queue}/activity-tasks/poll</code></p> <p>Request Schema: <pre><code>message PollActivityTaskQueueRequest {\n  string namespace = 1;\n  string task_queue = 2;\n  string identity = 3;\n  temporal.api.taskqueue.v1.TaskQueueMetadata task_queue_metadata = 4;\n}\n</code></pre></p>"},{"location":"reference/api/#namespace-operations","title":"Namespace Operations","text":""},{"location":"reference/api/#registernamespace","title":"RegisterNamespace","text":"<p>Registers a new namespace.</p> <p>Method: <code>POST /api/v1/namespaces</code></p> <p>Request Schema: <pre><code>message RegisterNamespaceRequest {\n  string namespace = 1;\n  string description = 2;\n  string owner_email = 3;\n  google.protobuf.Duration workflow_execution_retention_period = 4;\n  map&lt;string, string&gt; data = 5;\n  bool is_global_namespace = 6;\n  repeated temporal.api.replication.v1.ClusterReplicationConfig clusters = 7;\n  string active_cluster_name = 8;\n  temporal.api.namespace.v1.ArchivalConfig history_archival_config = 9;\n  temporal.api.namespace.v1.ArchivalConfig visibility_archival_config = 10;\n}\n</code></pre></p> <p>Example Request: <pre><code>{\n  \"namespace\": \"order-processing\",\n  \"description\": \"Namespace for order processing workflows\",\n  \"owner_email\": \"team-orders@company.com\",\n  \"workflow_execution_retention_period\": \"2592000s\",\n  \"data\": {\n    \"environment\": \"production\",\n    \"team\": \"orders\",\n    \"cost_center\": \"engineering\"\n  },\n  \"is_global_namespace\": false,\n  \"history_archival_config\": {\n    \"state\": \"ENABLED\",\n    \"uri\": \"s3://temporal-archival/order-processing/history\"\n  },\n  \"visibility_archival_config\": {\n    \"state\": \"ENABLED\",\n    \"uri\": \"s3://temporal-archival/order-processing/visibility\"\n  }\n}\n</code></pre></p>"},{"location":"reference/api/#describenamespace","title":"DescribeNamespace","text":"<p>Describes a namespace and its configuration.</p> <p>Method: <code>GET /api/v1/namespaces/{namespace}</code></p> <p>Response Schema: <pre><code>message DescribeNamespaceResponse {\n  temporal.api.namespace.v1.NamespaceInfo namespace_info = 1;\n  temporal.api.namespace.v1.NamespaceConfig config = 2;\n  temporal.api.replication.v1.NamespaceReplicationConfig replication_config = 3;\n  int64 failover_version = 4;\n  bool is_global_namespace = 5;\n}\n</code></pre></p>"},{"location":"reference/api/#listnamespaces","title":"ListNamespaces","text":"<p>Lists all namespaces.</p> <p>Method: <code>GET /api/v1/namespaces</code></p> <p>Query Parameters: - <code>page_size</code>: Maximum number of namespaces to return - <code>next_page_token</code>: Token for pagination</p>"},{"location":"reference/api/#search-and-visibility","title":"Search and Visibility","text":""},{"location":"reference/api/#listworkflowexecutions","title":"ListWorkflowExecutions","text":"<p>Lists workflow executions with optional filtering.</p> <p>Method: <code>GET /api/v1/namespaces/{namespace}/workflows</code></p> <p>Query Parameters: - <code>query</code>: SQL-like query string for filtering - <code>page_size</code>: Maximum number of results to return - <code>next_page_token</code>: Token for pagination</p> <p>Example Query: <pre><code>GET /api/v1/namespaces/default/workflows?query=WorkflowType='OrderProcessingWorkflow' AND ExecutionStatus='Running' AND StartTime &gt; '2023-01-01T00:00:00Z'\n</code></pre></p> <p>Response Schema: <pre><code>message ListWorkflowExecutionsResponse {\n  repeated temporal.api.workflow.v1.WorkflowExecutionInfo executions = 1;\n  bytes next_page_token = 2;\n}\n</code></pre></p>"},{"location":"reference/api/#scanworkflowexecutions","title":"ScanWorkflowExecutions","text":"<p>Scans workflow executions without requiring an index.</p> <p>Method: <code>POST /api/v1/namespaces/{namespace}/workflows/scan</code></p>"},{"location":"reference/api/#countworkflowexecutions","title":"CountWorkflowExecutions","text":"<p>Counts workflow executions matching a query.</p> <p>Method: <code>GET /api/v1/namespaces/{namespace}/workflows/count</code></p> <p>Query Parameters: - <code>query</code>: SQL-like query string for filtering</p>"},{"location":"reference/api/#worker-api","title":"Worker API","text":"<p>The Worker API is used by worker processes to poll for tasks and respond with results.</p>"},{"location":"reference/api/#worker-registration","title":"Worker Registration","text":""},{"location":"reference/api/#registerworker","title":"RegisterWorker","text":"<p>Registers a worker with the Temporal service.</p> <p>Request Schema: <pre><code>message RegisterWorkerRequest {\n  string namespace = 1;\n  string task_queue = 2;\n  string identity = 3;\n  repeated string workflow_types = 4;\n  repeated string activity_types = 5;\n  temporal.api.sdk.v1.WorkerVersionCapabilities version_capabilities = 6;\n}\n</code></pre></p>"},{"location":"reference/api/#task-processing","title":"Task Processing","text":""},{"location":"reference/api/#respondworkflowtaskcompleted","title":"RespondWorkflowTaskCompleted","text":"<p>Responds to a workflow task with completion.</p> <p>Method: <code>POST /api/v1/namespaces/{namespace}/workflow-tasks/complete</code></p> <p>Request Schema: <pre><code>message RespondWorkflowTaskCompletedRequest {\n  string namespace = 1;\n  bytes task_token = 2;\n  repeated temporal.api.command.v1.Command commands = 3;\n  string identity = 4;\n  bool sticky_attributes = 5;\n  bool return_new_workflow_task = 6;\n  bool force_create_new_workflow_task = 7;\n  string binary_checksum = 8;\n  temporal.api.sdk.v1.WorkflowTaskCompletedMetadata sdk_metadata = 9;\n  map&lt;string, temporal.api.common.v1.Payloads&gt; query_results = 10;\n  temporal.api.common.v1.Memo memo_update = 11;\n}\n</code></pre></p>"},{"location":"reference/api/#respondworkflowtaskfailed","title":"RespondWorkflowTaskFailed","text":"<p>Responds to a workflow task with failure.</p> <p>Method: <code>POST /api/v1/namespaces/{namespace}/workflow-tasks/fail</code></p> <p>Request Schema: <pre><code>message RespondWorkflowTaskFailedRequest {\n  string namespace = 1;\n  bytes task_token = 2;\n  temporal.api.enums.v1.WorkflowTaskFailedCause cause = 3;\n  temporal.api.failure.v1.Failure failure = 4;\n  string identity = 5;\n  string binary_checksum = 6;\n}\n</code></pre></p>"},{"location":"reference/api/#admin-api","title":"Admin API","text":"<p>The Admin API provides administrative operations for cluster management.</p>"},{"location":"reference/api/#cluster-operations","title":"Cluster Operations","text":""},{"location":"reference/api/#describecluster","title":"DescribeCluster","text":"<p>Describes the cluster configuration and status.</p> <p>Method: <code>GET /api/v1/cluster</code></p> <p>Response Schema: <pre><code>message DescribeClusterResponse {\n  temporal.api.cluster.v1.ClusterInfo cluster_info = 1;\n  repeated temporal.api.cluster.v1.ClusterMember membership_info = 2;\n}\n</code></pre></p>"},{"location":"reference/api/#listclustermembers","title":"ListClusterMembers","text":"<p>Lists all members of the cluster.</p> <p>Method: <code>GET /api/v1/cluster/members</code></p>"},{"location":"reference/api/#shard-management","title":"Shard Management","text":""},{"location":"reference/api/#describeshard","title":"DescribeShard","text":"<p>Describes a specific shard.</p> <p>Method: <code>GET /api/v1/shards/{shard_id}</code></p>"},{"location":"reference/api/#closeshard","title":"CloseShard","text":"<p>Closes a specific shard.</p> <p>Method: <code>POST /api/v1/shards/{shard_id}/close</code></p>"},{"location":"reference/api/#task-queue-management","title":"Task Queue Management","text":""},{"location":"reference/api/#describetaskqueue","title":"DescribeTaskQueue","text":"<p>Describes a task queue's status and configuration.</p> <p>Method: <code>GET /api/v1/namespaces/{namespace}/task-queues/{task_queue}</code></p> <p>Response Schema: <pre><code>message DescribeTaskQueueResponse {\n  repeated temporal.api.taskqueue.v1.PollerInfo pollers = 1;\n  temporal.api.taskqueue.v1.TaskQueueStatus task_queue_status = 2;\n}\n</code></pre></p>"},{"location":"reference/api/#listtaskqueuepartitions","title":"ListTaskQueuePartitions","text":"<p>Lists partitions for a task queue.</p> <p>Method: <code>GET /api/v1/namespaces/{namespace}/task-queues/{task_queue}/partitions</code></p>"},{"location":"reference/api/#history-management","title":"History Management","text":""},{"location":"reference/api/#getworkflowexecutionhistory","title":"GetWorkflowExecutionHistory","text":"<p>Retrieves the complete history of a workflow execution.</p> <p>Method: <code>GET /api/v1/namespaces/{namespace}/workflows/{workflow_id}/runs/{run_id}/history</code></p> <p>Query Parameters: - <code>maximum_page_size</code>: Maximum number of events per page - <code>next_page_token</code>: Token for pagination - <code>wait_new_event</code>: Whether to wait for new events - <code>history_event_filter_type</code>: Filter for event types</p> <p>Response Schema: <pre><code>message GetWorkflowExecutionHistoryResponse {\n  repeated temporal.api.history.v1.HistoryEvent history = 1;\n  bytes next_page_token = 2;\n  bool archived = 3;\n}\n</code></pre></p>"},{"location":"reference/api/#client-sdk-apis","title":"Client SDK APIs","text":""},{"location":"reference/api/#go-sdk-api","title":"Go SDK API","text":""},{"location":"reference/api/#client-creation","title":"Client Creation","text":"<pre><code>package main\n\nimport (\n    \"go.temporal.io/sdk/client\"\n    \"go.temporal.io/sdk/worker\"\n)\n\n// Create a Temporal client\nfunc createClient() (client.Client, error) {\n    c, err := client.Dial(client.Options{\n        HostPort:  \"temporal.company.com:7233\",\n        Namespace: \"default\",\n        ConnectionOptions: client.ConnectionOptions{\n            TLS: &amp;tls.Config{\n                ServerName: \"temporal.company.com\",\n            },\n        },\n        Credentials: client.NewAPIKeyStaticCredentials(\"your-api-key\"),\n    })\n    return c, err\n}\n</code></pre>"},{"location":"reference/api/#workflow-execution","title":"Workflow Execution","text":"<pre><code>// Start a workflow\nfunc startWorkflow(c client.Client) error {\n    options := client.StartWorkflowOptions{\n        ID:                 \"order-processing-12345\",\n        TaskQueue:          \"order-processing-queue\",\n        WorkflowRunTimeout: time.Hour * 24,\n        WorkflowTaskTimeout: time.Second * 10,\n        RetryPolicy: &amp;temporal.RetryPolicy{\n            InitialInterval:    time.Second,\n            BackoffCoefficient: 2.0,\n            MaximumInterval:    time.Second * 100,\n            MaximumAttempts:    3,\n        },\n        Memo: map[string]interface{}{\n            \"environment\": \"production\",\n            \"version\":     \"v1.2.3\",\n        },\n        SearchAttributes: map[string]interface{}{\n            \"OrderId\":     \"12345\",\n            \"CustomerId\":  \"customer-67890\",\n            \"Environment\": \"production\",\n        },\n    }\n\n    we, err := c.ExecuteWorkflow(context.Background(), options, OrderProcessingWorkflow, OrderInput{\n        OrderID:    \"12345\",\n        CustomerID: \"customer-67890\",\n        Items: []OrderItem{\n            {ProductID: \"product-001\", Quantity: 2, Price: 29.99},\n        },\n    })\n    return err\n}\n\n// Signal a workflow\nfunc signalWorkflow(c client.Client, workflowID, runID string) error {\n    return c.SignalWorkflow(context.Background(), workflowID, runID, \"payment_received\", PaymentInfo{\n        PaymentID: \"payment-98765\",\n        Amount:    59.98,\n        Currency:  \"USD\",\n        Method:    \"credit_card\",\n    })\n}\n\n// Query a workflow\nfunc queryWorkflow(c client.Client, workflowID, runID string) (OrderStatus, error) {\n    var result OrderStatus\n    value, err := c.QueryWorkflow(context.Background(), workflowID, runID, \"get_order_status\")\n    if err != nil {\n        return result, err\n    }\n    err = value.Get(&amp;result)\n    return result, err\n}\n</code></pre>"},{"location":"reference/api/#worker-setup","title":"Worker Setup","text":"<pre><code>// Create and start a worker\nfunc startWorker() error {\n    c, err := createClient()\n    if err != nil {\n        return err\n    }\n    defer c.Close()\n\n    w := worker.New(c, \"order-processing-queue\", worker.Options{\n        MaxConcurrentActivityExecutionSize: 100,\n        MaxConcurrentWorkflowTaskExecutionSize: 100,\n        MaxConcurrentActivityTaskPollers: 10,\n        MaxConcurrentWorkflowTaskPollers: 10,\n    })\n\n    // Register workflows and activities\n    w.RegisterWorkflow(OrderProcessingWorkflow)\n    w.RegisterActivity(ProcessPaymentActivity)\n    w.RegisterActivity(UpdateInventoryActivity)\n    w.RegisterActivity(SendNotificationActivity)\n\n    return w.Run(worker.InterruptCh())\n}\n</code></pre>"},{"location":"reference/api/#java-sdk-api","title":"Java SDK API","text":""},{"location":"reference/api/#client-creation_1","title":"Client Creation","text":"<pre><code>import io.temporal.client.WorkflowClient;\nimport io.temporal.client.WorkflowClientOptions;\nimport io.temporal.serviceclient.WorkflowServiceStubs;\nimport io.temporal.serviceclient.WorkflowServiceStubsOptions;\n\npublic class TemporalClient {\n    public static WorkflowClient createClient() {\n        WorkflowServiceStubsOptions serviceOptions = WorkflowServiceStubsOptions.newBuilder()\n            .setTarget(\"temporal.company.com:7233\")\n            .build();\n\n        WorkflowServiceStubs service = WorkflowServiceStubs.newServiceStubs(serviceOptions);\n\n        WorkflowClientOptions clientOptions = WorkflowClientOptions.newBuilder()\n            .setNamespace(\"default\")\n            .build();\n\n        return WorkflowClient.newInstance(service, clientOptions);\n    }\n}\n</code></pre>"},{"location":"reference/api/#workflow-operations_1","title":"Workflow Operations","text":"<pre><code>import io.temporal.client.WorkflowOptions;\nimport io.temporal.common.RetryOptions;\n\npublic class WorkflowOperations {\n    private final WorkflowClient client;\n\n    public void startWorkflow() {\n        WorkflowOptions options = WorkflowOptions.newBuilder()\n            .setWorkflowId(\"order-processing-12345\")\n            .setTaskQueue(\"order-processing-queue\")\n            .setWorkflowRunTimeout(Duration.ofHours(24))\n            .setWorkflowTaskTimeout(Duration.ofSeconds(10))\n            .setRetryOptions(RetryOptions.newBuilder()\n                .setInitialInterval(Duration.ofSeconds(1))\n                .setBackoffCoefficient(2.0)\n                .setMaximumInterval(Duration.ofSeconds(100))\n                .setMaximumAttempts(3)\n                .build())\n            .setMemo(ImmutableMap.of(\n                \"environment\", \"production\",\n                \"version\", \"v1.2.3\"\n            ))\n            .setSearchAttributes(ImmutableMap.of(\n                \"OrderId\", \"12345\",\n                \"CustomerId\", \"customer-67890\",\n                \"Environment\", \"production\"\n            ))\n            .build();\n\n        OrderProcessingWorkflow workflow = client.newWorkflowStub(OrderProcessingWorkflow.class, options);\n\n        OrderInput input = new OrderInput();\n        input.setOrderId(\"12345\");\n        input.setCustomerId(\"customer-67890\");\n\n        WorkflowExecution execution = WorkflowClient.start(workflow::processOrder, input);\n    }\n\n    public void signalWorkflow(String workflowId) {\n        OrderProcessingWorkflow workflow = client.newWorkflowStub(OrderProcessingWorkflow.class, workflowId);\n\n        PaymentInfo payment = new PaymentInfo();\n        payment.setPaymentId(\"payment-98765\");\n        payment.setAmount(59.98);\n        payment.setCurrency(\"USD\");\n        payment.setMethod(\"credit_card\");\n\n        workflow.paymentReceived(payment);\n    }\n}\n</code></pre>"},{"location":"reference/api/#python-sdk-api","title":"Python SDK API","text":""},{"location":"reference/api/#client-creation_2","title":"Client Creation","text":"<pre><code>import asyncio\nfrom temporalio.client import Client, TLSConfig\nfrom temporalio.worker import Worker\n\nasync def create_client():\n    return await Client.connect(\n        \"temporal.company.com:7233\",\n        namespace=\"default\",\n        tls=TLSConfig(\n            server_root_ca_cert=None,  # Use system CA\n            client_cert=None,\n            client_private_key=None,\n        ),\n        api_key=\"your-api-key\",\n    )\n</code></pre>"},{"location":"reference/api/#workflow-operations_2","title":"Workflow Operations","text":"<pre><code>from temporalio.common import RetryPolicy\nfrom datetime import timedelta\n\nasync def start_workflow():\n    client = await create_client()\n\n    result = await client.execute_workflow(\n        OrderProcessingWorkflow.run,\n        OrderInput(\n            order_id=\"12345\",\n            customer_id=\"customer-67890\",\n            items=[\n                OrderItem(product_id=\"product-001\", quantity=2, price=29.99)\n            ]\n        ),\n        id=\"order-processing-12345\",\n        task_queue=\"order-processing-queue\",\n        execution_timeout=timedelta(hours=24),\n        task_timeout=timedelta(seconds=10),\n        retry_policy=RetryPolicy(\n            initial_interval=timedelta(seconds=1),\n            backoff_coefficient=2.0,\n            maximum_interval=timedelta(seconds=100),\n            maximum_attempts=3,\n        ),\n        memo={\n            \"environment\": \"production\",\n            \"version\": \"v1.2.3\",\n        },\n        search_attributes={\n            \"OrderId\": \"12345\",\n            \"CustomerId\": \"customer-67890\",\n            \"Environment\": \"production\",\n        },\n    )\n\n    return result\n\nasync def signal_workflow():\n    client = await create_client()\n    handle = client.get_workflow_handle(\"order-processing-12345\")\n\n    await handle.signal(\n        OrderProcessingWorkflow.payment_received,\n        PaymentInfo(\n            payment_id=\"payment-98765\",\n            amount=59.98,\n            currency=\"USD\",\n            method=\"credit_card\",\n        )\n    )\n\nasync def query_workflow():\n    client = await create_client()\n    handle = client.get_workflow_handle(\"order-processing-12345\")\n\n    result = await handle.query(OrderProcessingWorkflow.get_order_status)\n    return result\n</code></pre>"},{"location":"reference/api/#typescript-sdk-api","title":"TypeScript SDK API","text":""},{"location":"reference/api/#client-creation_3","title":"Client Creation","text":"<pre><code>import { Connection, Client } from '@temporalio/client';\nimport { Worker } from '@temporalio/worker';\nimport fs from 'fs';\n\nasync function createClient(): Promise&lt;Client&gt; {\n  const connection = await Connection.connect({\n    address: 'temporal.company.com:7233',\n    tls: {\n      serverNameOverride: 'temporal.company.com',\n      serverRootCACertificate: fs.readFileSync('./certs/ca.crt'),\n      clientCertPair: {\n        crt: fs.readFileSync('./certs/client.crt'),\n        key: fs.readFileSync('./certs/client.key'),\n      },\n    },\n    metadata: {\n      'authorization': 'Bearer your-api-key',\n    },\n  });\n\n  return new Client({\n    connection,\n    namespace: 'default',\n  });\n}\n</code></pre>"},{"location":"reference/api/#workflow-operations_3","title":"Workflow Operations","text":"<pre><code>import { WorkflowHandle } from '@temporalio/client';\n\nasync function startWorkflow(): Promise&lt;WorkflowHandle&lt;typeof orderProcessingWorkflow&gt;&gt; {\n  const client = await createClient();\n\n  const handle = await client.workflow.start(orderProcessingWorkflow, {\n    workflowId: 'order-processing-12345',\n    taskQueue: 'order-processing-queue',\n    args: [{\n      orderId: '12345',\n      customerId: 'customer-67890',\n      items: [\n        { productId: 'product-001', quantity: 2, price: 29.99 }\n      ]\n    }],\n    workflowRunTimeout: '24h',\n    workflowTaskTimeout: '10s',\n    retry: {\n      initialInterval: '1s',\n      backoffCoefficient: 2.0,\n      maximumInterval: '100s',\n      maximumAttempts: 3,\n    },\n    memo: {\n      environment: 'production',\n      version: 'v1.2.3',\n    },\n    searchAttributes: {\n      OrderId: ['12345'],\n      CustomerId: ['customer-67890'],\n      Environment: ['production'],\n    },\n  });\n\n  return handle;\n}\n\nasync function signalWorkflow(): Promise&lt;void&gt; {\n  const client = await createClient();\n  const handle = client.workflow.getHandle('order-processing-12345');\n\n  await handle.signal(paymentReceivedSignal, {\n    paymentId: 'payment-98765',\n    amount: 59.98,\n    currency: 'USD',\n    method: 'credit_card',\n  });\n}\n\nasync function queryWorkflow(): Promise&lt;OrderStatus&gt; {\n  const client = await createClient();\n  const handle = client.workflow.getHandle('order-processing-12345');\n\n  const result = await handle.query(getOrderStatusQuery);\n  return result;\n}\n</code></pre>"},{"location":"reference/api/#authentication-authorization","title":"Authentication &amp; Authorization","text":""},{"location":"reference/api/#jwt-authentication","title":"JWT Authentication","text":"<p>Temporal supports JWT-based authentication for securing API access.</p>"},{"location":"reference/api/#jwt-token-format","title":"JWT Token Format","text":"<pre><code>{\n  \"iss\": \"https://auth.company.com\",\n  \"sub\": \"user@company.com\",\n  \"aud\": \"temporal.company.com\",\n  \"exp\": 1640995200,\n  \"iat\": 1640908800,\n  \"permissions\": [\n    \"temporal:workflow:start\",\n    \"temporal:workflow:signal\",\n    \"temporal:workflow:read\"\n  ],\n  \"namespace\": \"default\"\n}\n</code></pre>"},{"location":"reference/api/#api-key-authentication","title":"API Key Authentication","text":"<pre><code># Using Bearer token in Authorization header\ncurl -H \"Authorization: Bearer your-api-key\" \\\n     -H \"Content-Type: application/json\" \\\n     https://temporal.company.com:7233/api/v1/namespaces/default/workflows\n</code></pre>"},{"location":"reference/api/#rbac-permissions","title":"RBAC Permissions","text":""},{"location":"reference/api/#permission-hierarchy","title":"Permission Hierarchy","text":"<pre><code>temporal:*                          # Full access\n\u251c\u2500\u2500 temporal:cluster:*              # Cluster administration\n\u251c\u2500\u2500 temporal:namespace:*            # Namespace management\n\u2502   \u251c\u2500\u2500 temporal:namespace:create\n\u2502   \u251c\u2500\u2500 temporal:namespace:read\n\u2502   \u251c\u2500\u2500 temporal:namespace:update\n\u2502   \u2514\u2500\u2500 temporal:namespace:delete\n\u2514\u2500\u2500 temporal:workflow:*             # Workflow operations\n    \u251c\u2500\u2500 temporal:workflow:start\n    \u251c\u2500\u2500 temporal:workflow:signal\n    \u251c\u2500\u2500 temporal:workflow:query\n    \u251c\u2500\u2500 temporal:workflow:read\n    \u251c\u2500\u2500 temporal:workflow:list\n    \u251c\u2500\u2500 temporal:workflow:terminate\n    \u2514\u2500\u2500 temporal:workflow:cancel\n</code></pre>"},{"location":"reference/api/#error-codes","title":"Error Codes","text":""},{"location":"reference/api/#standard-error-codes","title":"Standard Error Codes","text":"Code Name Description <code>INVALID_ARGUMENT</code> Invalid Argument The request contains invalid parameters <code>ALREADY_EXISTS</code> Already Exists The workflow execution already exists <code>NOT_FOUND</code> Not Found The requested resource was not found <code>PERMISSION_DENIED</code> Permission Denied Insufficient permissions for the operation <code>RESOURCE_EXHAUSTED</code> Resource Exhausted Rate limit exceeded or quota reached <code>FAILED_PRECONDITION</code> Failed Precondition Operation cannot be performed in current state <code>ABORTED</code> Aborted Operation was aborted due to conflict <code>OUT_OF_RANGE</code> Out of Range Parameter value is out of valid range <code>UNIMPLEMENTED</code> Unimplemented Operation is not implemented <code>INTERNAL</code> Internal Error Internal server error <code>UNAVAILABLE</code> Unavailable Service is temporarily unavailable <code>DATA_LOSS</code> Data Loss Unrecoverable data loss or corruption <code>UNAUTHENTICATED</code> Unauthenticated Authentication credentials are missing or invalid"},{"location":"reference/api/#workflow-specific-error-codes","title":"Workflow-Specific Error Codes","text":"Code Name Description <code>WORKFLOW_EXECUTION_ALREADY_STARTED</code> Workflow Already Started Workflow with the same ID is already running <code>WORKFLOW_EXECUTION_NOT_FOUND</code> Workflow Not Found No workflow execution found with the given ID <code>WORKFLOW_EXECUTION_COMPLETED</code> Workflow Completed Operation not allowed on completed workflow <code>WORKFLOW_TASK_TIMEOUT</code> Workflow Task Timeout Workflow task timed out <code>ACTIVITY_TASK_TIMEOUT</code> Activity Task Timeout Activity task timed out <code>NAMESPACE_NOT_FOUND</code> Namespace Not Found The specified namespace does not exist <code>TASK_QUEUE_NOT_FOUND</code> Task Queue Not Found The specified task queue does not exist"},{"location":"reference/api/#error-response-format","title":"Error Response Format","text":"<pre><code>{\n  \"error\": {\n    \"code\": \"INVALID_ARGUMENT\",\n    \"message\": \"Workflow ID cannot be empty\",\n    \"details\": [\n      {\n        \"type\": \"BadRequest\",\n        \"field\": \"workflow_id\",\n        \"description\": \"workflow_id is required and cannot be empty\"\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"reference/api/#rate-limiting","title":"Rate Limiting","text":""},{"location":"reference/api/#rate-limit-headers","title":"Rate Limit Headers","text":"<p>API responses include rate limiting information in headers:</p> <pre><code>X-RateLimit-Limit: 1000\nX-RateLimit-Remaining: 999\nX-RateLimit-Reset: 1640995200\nX-RateLimit-Scope: namespace:default\n</code></pre>"},{"location":"reference/api/#rate-limit-categories","title":"Rate Limit Categories","text":""},{"location":"reference/api/#global-rate-limits","title":"Global Rate Limits","text":"<ul> <li>API Requests: 10,000 requests per minute per cluster</li> <li>Workflow Starts: 1,000 starts per minute per namespace</li> <li>Activity Executions: 10,000 executions per minute per namespace</li> </ul>"},{"location":"reference/api/#per-namespace-rate-limits","title":"Per-Namespace Rate Limits","text":"<ul> <li>Workflow Executions: 100 concurrent executions per namespace</li> <li>Task Queue Operations: 1,000 operations per minute per task queue</li> <li>History Events: 100,000 events per minute per namespace</li> </ul>"},{"location":"reference/api/#per-client-rate-limits","title":"Per-Client Rate Limits","text":"<ul> <li>API Calls: 100 requests per second per client</li> <li>Long Polls: 10 concurrent long polls per client</li> <li>Heartbeats: 1,000 heartbeats per minute per client</li> </ul>"},{"location":"reference/api/#rate-limit-error-response","title":"Rate Limit Error Response","text":"<pre><code>{\n  \"error\": {\n    \"code\": \"RESOURCE_EXHAUSTED\",\n    \"message\": \"Rate limit exceeded for namespace 'default'\",\n    \"details\": [\n      {\n        \"type\": \"RateLimitExceeded\",\n        \"scope\": \"namespace:default\",\n        \"limit\": 1000,\n        \"window\": \"1m\",\n        \"retry_after\": 30\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"reference/api/#versioning","title":"Versioning","text":""},{"location":"reference/api/#api-versioning-strategy","title":"API Versioning Strategy","text":"<p>Temporal uses semantic versioning for API compatibility:</p> <ul> <li>Major Version: Breaking changes (e.g., v1 \u2192 v2)</li> <li>Minor Version: Backward-compatible additions</li> <li>Patch Version: Bug fixes and improvements</li> </ul>"},{"location":"reference/api/#version-headers","title":"Version Headers","text":"<p>Include API version in requests:</p> <pre><code>curl -H \"Temporal-API-Version: v1\" \\\n     -H \"Content-Type: application/json\" \\\n     https://temporal.company.com:7233/api/v1/namespaces\n</code></pre>"},{"location":"reference/api/#supported-api-versions","title":"Supported API Versions","text":"Version Status Support End Date <code>v1</code> Current N/A <code>v1beta1</code> Deprecated 2024-12-31"},{"location":"reference/api/#version-compatibility","title":"Version Compatibility","text":""},{"location":"reference/api/#client-sdk-compatibility-matrix","title":"Client SDK Compatibility Matrix","text":"SDK Version API v1 API v1beta1 Go SDK 1.x \u2705 \u2705 Java SDK 1.x \u2705 \u2705 Python SDK 1.x \u2705 \u2705 TypeScript SDK 1.x \u2705 \u2705 <p>This comprehensive API reference provides detailed information about all Temporal.io APIs, including request/response schemas, authentication methods, error handling, and practical examples across multiple programming languages.</p>"},{"location":"reference/cli-commands/","title":"CLI Commands Reference","text":"<p>This comprehensive reference covers all Temporal CLI commands for managing workflows, activities, namespaces, and clusters. The guide includes detailed command syntax, options, and practical examples.</p>"},{"location":"reference/cli-commands/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Installation</li> <li>Configuration</li> <li>Workflow Commands</li> <li>Activity Commands</li> <li>Namespace Commands</li> <li>Task Queue Commands</li> <li>Cluster Commands</li> <li>Search Commands</li> <li>Administrative Commands</li> <li>Monitoring Commands</li> <li>Environment Variables</li> <li>Output Formats</li> </ul>"},{"location":"reference/cli-commands/#installation","title":"Installation","text":""},{"location":"reference/cli-commands/#install-temporal-cli","title":"Install Temporal CLI","text":""},{"location":"reference/cli-commands/#using-homebrew-macoslinux","title":"Using Homebrew (macOS/Linux)","text":"<pre><code>brew install temporal\n</code></pre>"},{"location":"reference/cli-commands/#using-github-releases","title":"Using GitHub Releases","text":"<pre><code># Download latest release\ncurl -sSf https://temporal.download/cli.sh | sh\n\n# Or specific version\ncurl -sSf https://temporal.download/cli.sh | sh -s -- --version 0.10.0\n</code></pre>"},{"location":"reference/cli-commands/#using-go","title":"Using Go","text":"<pre><code>go install go.temporal.io/cli/temporal@latest\n</code></pre>"},{"location":"reference/cli-commands/#using-docker","title":"Using Docker","text":"<pre><code>docker pull temporalio/cli:latest\nalias temporal=\"docker run --rm -it temporalio/cli:latest\"\n</code></pre>"},{"location":"reference/cli-commands/#verify-installation","title":"Verify Installation","text":"<pre><code>temporal version\n</code></pre>"},{"location":"reference/cli-commands/#configuration","title":"Configuration","text":""},{"location":"reference/cli-commands/#global-configuration","title":"Global Configuration","text":""},{"location":"reference/cli-commands/#initialize-configuration","title":"Initialize Configuration","text":"<pre><code>temporal config set version 1.0.0\ntemporal config set namespace default\ntemporal config set address temporal.company.com:7233\ntemporal config set codec-endpoint http://localhost:8080\n</code></pre>"},{"location":"reference/cli-commands/#view-configuration","title":"View Configuration","text":"<pre><code>temporal config get\ntemporal config get namespace\n</code></pre>"},{"location":"reference/cli-commands/#environment-based-configuration","title":"Environment-based Configuration","text":"<pre><code># Set via environment variables\nexport TEMPORAL_ADDRESS=temporal.company.com:7233\nexport TEMPORAL_NAMESPACE=production\nexport TEMPORAL_TLS_CERT_PATH=/path/to/cert.pem\nexport TEMPORAL_TLS_KEY_PATH=/path/to/key.pem\nexport TEMPORAL_TLS_CA_PATH=/path/to/ca.pem\nexport TEMPORAL_HEADERS_PROVIDER=YOUR_HEADERS_PROVIDER\n</code></pre>"},{"location":"reference/cli-commands/#tls-configuration","title":"TLS Configuration","text":"<pre><code># Configure TLS\ntemporal config set tls.cert-path /etc/temporal/certs/client.crt\ntemporal config set tls.key-path /etc/temporal/certs/client.key\ntemporal config set tls.ca-path /etc/temporal/certs/ca.crt\ntemporal config set tls.server-name temporal.company.com\n</code></pre>"},{"location":"reference/cli-commands/#authentication-configuration","title":"Authentication Configuration","text":"<pre><code># Configure API key authentication\ntemporal config set auth.api-key your-api-key\n\n# Configure OAuth\ntemporal config set auth.oauth.client-id your-client-id\ntemporal config set auth.oauth.client-secret your-client-secret\ntemporal config set auth.oauth.token-url https://auth.company.com/oauth/token\n</code></pre>"},{"location":"reference/cli-commands/#workflow-commands","title":"Workflow Commands","text":""},{"location":"reference/cli-commands/#start-workflow","title":"Start Workflow","text":""},{"location":"reference/cli-commands/#basic-workflow-start","title":"Basic Workflow Start","text":"<pre><code>temporal workflow start \\\n  --workflow-type OrderProcessingWorkflow \\\n  --task-queue order-processing-queue \\\n  --workflow-id order-12345 \\\n  --input '{\"orderId\": \"12345\", \"customerId\": \"customer-67890\"}'\n</code></pre>"},{"location":"reference/cli-commands/#advanced-workflow-start","title":"Advanced Workflow Start","text":"<pre><code>temporal workflow start \\\n  --workflow-type OrderProcessingWorkflow \\\n  --task-queue order-processing-queue \\\n  --workflow-id order-12345 \\\n  --input-file order-input.json \\\n  --workflow-execution-timeout 24h \\\n  --workflow-run-timeout 1h \\\n  --workflow-task-timeout 10s \\\n  --retry-policy '{\n    \"initialInterval\": \"1s\",\n    \"backoffCoefficient\": 2.0,\n    \"maximumInterval\": \"100s\",\n    \"maximumAttempts\": 3\n  }' \\\n  --cron-schedule \"0 12 * * *\" \\\n  --memo '{\"environment\": \"production\", \"version\": \"v1.2.3\"}' \\\n  --search-attribute 'OrderId=\"12345\"' \\\n  --search-attribute 'CustomerId=\"customer-67890\"' \\\n  --search-attribute 'Environment=\"production\"'\n</code></pre>"},{"location":"reference/cli-commands/#start-with-input-file","title":"Start with Input File","text":"<pre><code># Create input file\ncat &gt; order-input.json &lt;&lt; EOF\n{\n  \"orderId\": \"12345\",\n  \"customerId\": \"customer-67890\",\n  \"items\": [\n    {\n      \"productId\": \"product-001\",\n      \"quantity\": 2,\n      \"price\": 29.99\n    }\n  ],\n  \"shippingAddress\": {\n    \"street\": \"123 Main St\",\n    \"city\": \"Anytown\",\n    \"state\": \"CA\",\n    \"zipCode\": \"12345\"\n  }\n}\nEOF\n\ntemporal workflow start \\\n  --workflow-type OrderProcessingWorkflow \\\n  --task-queue order-processing-queue \\\n  --workflow-id order-12345 \\\n  --input-file order-input.json\n</code></pre>"},{"location":"reference/cli-commands/#execute-workflow-start-and-wait","title":"Execute Workflow (Start and Wait)","text":"<pre><code># Execute workflow and wait for completion\ntemporal workflow execute \\\n  --workflow-type OrderProcessingWorkflow \\\n  --task-queue order-processing-queue \\\n  --workflow-id order-12345 \\\n  --input '{\"orderId\": \"12345\"}' \\\n  --workflow-execution-timeout 24h\n</code></pre>"},{"location":"reference/cli-commands/#describe-workflow","title":"Describe Workflow","text":"<pre><code># Describe workflow execution\ntemporal workflow describe \\\n  --workflow-id order-12345\n\n# Describe with specific run ID\ntemporal workflow describe \\\n  --workflow-id order-12345 \\\n  --run-id 01234567-89ab-cdef-0123-456789abcdef\n\n# Raw output format\ntemporal workflow describe \\\n  --workflow-id order-12345 \\\n  --raw\n</code></pre>"},{"location":"reference/cli-commands/#show-workflow-history","title":"Show Workflow History","text":"<pre><code># Show workflow history\ntemporal workflow show \\\n  --workflow-id order-12345\n\n# Show with pagination\ntemporal workflow show \\\n  --workflow-id order-12345 \\\n  --limit 10 \\\n  --no-pager\n\n# Show specific event types\ntemporal workflow show \\\n  --workflow-id order-12345 \\\n  --event-type WorkflowExecutionStarted,ActivityTaskScheduled\n\n# Show in JSON format\ntemporal workflow show \\\n  --workflow-id order-12345 \\\n  --output json\n\n# Show with time range\ntemporal workflow show \\\n  --workflow-id order-12345 \\\n  --start-time \"2023-01-01T00:00:00Z\" \\\n  --end-time \"2023-01-02T00:00:00Z\"\n</code></pre>"},{"location":"reference/cli-commands/#signal-workflow","title":"Signal Workflow","text":"<pre><code># Send signal to workflow\ntemporal workflow signal \\\n  --workflow-id order-12345 \\\n  --name payment_received \\\n  --input '{\"paymentId\": \"payment-98765\", \"amount\": 59.98}'\n\n# Signal with input file\ntemporal workflow signal \\\n  --workflow-id order-12345 \\\n  --name payment_received \\\n  --input-file payment-info.json\n\n# Signal with run ID\ntemporal workflow signal \\\n  --workflow-id order-12345 \\\n  --run-id 01234567-89ab-cdef-0123-456789abcdef \\\n  --name payment_received \\\n  --input '{\"paymentId\": \"payment-98765\"}'\n</code></pre>"},{"location":"reference/cli-commands/#query-workflow","title":"Query Workflow","text":"<pre><code># Query workflow state\ntemporal workflow query \\\n  --workflow-id order-12345 \\\n  --type get_order_status\n\n# Query with arguments\ntemporal workflow query \\\n  --workflow-id order-12345 \\\n  --type get_item_details \\\n  --input '{\"itemId\": \"item-001\"}'\n\n# Query with run ID\ntemporal workflow query \\\n  --workflow-id order-12345 \\\n  --run-id 01234567-89ab-cdef-0123-456789abcdef \\\n  --type get_order_status\n</code></pre>"},{"location":"reference/cli-commands/#terminate-workflow","title":"Terminate Workflow","text":"<pre><code># Terminate workflow\ntemporal workflow terminate \\\n  --workflow-id order-12345 \\\n  --reason \"Order cancelled by customer\"\n\n# Terminate with details\ntemporal workflow terminate \\\n  --workflow-id order-12345 \\\n  --reason \"System maintenance\" \\\n  --details '{\"maintenanceWindow\": \"2023-01-01T02:00:00Z\"}'\n\n# Terminate specific run\ntemporal workflow terminate \\\n  --workflow-id order-12345 \\\n  --run-id 01234567-89ab-cdef-0123-456789abcdef \\\n  --reason \"Duplicate execution\"\n</code></pre>"},{"location":"reference/cli-commands/#cancel-workflow","title":"Cancel Workflow","text":"<pre><code># Cancel workflow\ntemporal workflow cancel \\\n  --workflow-id order-12345 \\\n  --reason \"Customer requested cancellation\"\n\n# Cancel with run ID\ntemporal workflow cancel \\\n  --workflow-id order-12345 \\\n  --run-id 01234567-89ab-cdef-0123-456789abcdef \\\n  --reason \"Payment failed\"\n</code></pre>"},{"location":"reference/cli-commands/#reset-workflow","title":"Reset Workflow","text":"<pre><code># Reset workflow to specific event\ntemporal workflow reset \\\n  --workflow-id order-12345 \\\n  --event-id 25 \\\n  --reason \"Fix data corruption\"\n\n# Reset to last workflow task\ntemporal workflow reset \\\n  --workflow-id order-12345 \\\n  --type LastWorkflowTask \\\n  --reason \"Reprocess with updated logic\"\n\n# Reset to first workflow task\ntemporal workflow reset \\\n  --workflow-id order-12345 \\\n  --type FirstWorkflowTask \\\n  --reason \"Complete restart\"\n\n# Reset with new run ID\ntemporal workflow reset \\\n  --workflow-id order-12345 \\\n  --event-id 25 \\\n  --reason \"Fix data corruption\" \\\n  --reapply-exclude-type ActivityTaskScheduled\n</code></pre>"},{"location":"reference/cli-commands/#list-workflows","title":"List Workflows","text":"<pre><code># List all workflows\ntemporal workflow list\n\n# List with query filter\ntemporal workflow list \\\n  --query \"WorkflowType='OrderProcessingWorkflow' AND ExecutionStatus='Running'\"\n\n# List with pagination\ntemporal workflow list \\\n  --limit 50 \\\n  --earliest-time \"2023-01-01T00:00:00Z\" \\\n  --latest-time \"2023-01-31T23:59:59Z\"\n\n# List archived workflows\ntemporal workflow list \\\n  --archived \\\n  --query \"WorkflowType='OrderProcessingWorkflow'\"\n\n# List with specific fields\ntemporal workflow list \\\n  --fields WorkflowId,WorkflowType,Status,StartTime\n</code></pre>"},{"location":"reference/cli-commands/#count-workflows","title":"Count Workflows","text":"<pre><code># Count all workflows\ntemporal workflow count\n\n# Count with query\ntemporal workflow count \\\n  --query \"WorkflowType='OrderProcessingWorkflow' AND ExecutionStatus='Running'\"\n</code></pre>"},{"location":"reference/cli-commands/#activity-commands","title":"Activity Commands","text":""},{"location":"reference/cli-commands/#show-activity","title":"Show Activity","text":"<pre><code># Show activity details\ntemporal activity show \\\n  --workflow-id order-12345 \\\n  --activity-id process-payment-001\n\n# Show activity history\ntemporal activity show \\\n  --workflow-id order-12345 \\\n  --activity-id process-payment-001 \\\n  --show-history\n</code></pre>"},{"location":"reference/cli-commands/#complete-activity","title":"Complete Activity","text":"<pre><code># Complete activity manually\ntemporal activity complete \\\n  --workflow-id order-12345 \\\n  --activity-id process-payment-001 \\\n  --result '{\"paymentId\": \"payment-98765\", \"status\": \"completed\"}'\n\n# Complete activity from file\ntemporal activity complete \\\n  --workflow-id order-12345 \\\n  --activity-id process-payment-001 \\\n  --result-file payment-result.json\n</code></pre>"},{"location":"reference/cli-commands/#fail-activity","title":"Fail Activity","text":"<pre><code># Fail activity manually\ntemporal activity fail \\\n  --workflow-id order-12345 \\\n  --activity-id process-payment-001 \\\n  --reason \"Payment provider unavailable\" \\\n  --details '{\"errorCode\": \"PROVIDER_DOWN\", \"retryable\": true}'\n</code></pre>"},{"location":"reference/cli-commands/#namespace-commands","title":"Namespace Commands","text":""},{"location":"reference/cli-commands/#register-namespace","title":"Register Namespace","text":"<pre><code># Register new namespace\ntemporal namespace register development\n\n# Register with configuration\ntemporal namespace register production \\\n  --description \"Production environment namespace\" \\\n  --owner-email \"team-platform@company.com\" \\\n  --retention 30d \\\n  --data environment=production \\\n  --data team=platform \\\n  --data cost-center=engineering\n</code></pre>"},{"location":"reference/cli-commands/#describe-namespace","title":"Describe Namespace","text":"<pre><code># Describe namespace\ntemporal namespace describe default\ntemporal namespace describe production\n</code></pre>"},{"location":"reference/cli-commands/#list-namespaces","title":"List Namespaces","text":"<pre><code># List all namespaces\ntemporal namespace list\n\n# List with specific fields\ntemporal namespace list \\\n  --fields Name,Description,OwnerEmail,State\n</code></pre>"},{"location":"reference/cli-commands/#update-namespace","title":"Update Namespace","text":"<pre><code># Update namespace retention\ntemporal namespace update production \\\n  --retention 60d\n\n# Update namespace description\ntemporal namespace update production \\\n  --description \"Updated production environment\"\n\n# Update namespace data\ntemporal namespace update production \\\n  --data cost-center=platform\n</code></pre>"},{"location":"reference/cli-commands/#delete-namespace","title":"Delete Namespace","text":"<pre><code># Delete namespace (if supported)\ntemporal namespace delete development \\\n  --yes\n</code></pre>"},{"location":"reference/cli-commands/#task-queue-commands","title":"Task Queue Commands","text":""},{"location":"reference/cli-commands/#describe-task-queue","title":"Describe Task Queue","text":"<pre><code># Describe task queue\ntemporal task-queue describe order-processing-queue\n\n# Describe with pollers information\ntemporal task-queue describe order-processing-queue \\\n  --include-pollers\n\n# Describe specific task queue type\ntemporal task-queue describe order-processing-queue \\\n  --task-queue-type workflow\n</code></pre>"},{"location":"reference/cli-commands/#list-task-queues","title":"List Task Queues","text":"<pre><code># List task queues in namespace\ntemporal task-queue list\n\n# List with specific namespace\ntemporal task-queue list \\\n  --namespace production\n</code></pre>"},{"location":"reference/cli-commands/#get-task-queue-history","title":"Get Task Queue History","text":"<pre><code># Get task queue build ID history\ntemporal task-queue get-build-id-history order-processing-queue\n\n# Get history with maximum entries\ntemporal task-queue get-build-id-history order-processing-queue \\\n  --max-entries 100\n</code></pre>"},{"location":"reference/cli-commands/#update-task-queue-build-ids","title":"Update Task Queue Build IDs","text":"<pre><code># Add new compatible build ID\ntemporal task-queue update-build-ids add-new-compatible \\\n  --task-queue order-processing-queue \\\n  --build-id v1.2.3 \\\n  --existing-compatible-build-id v1.2.2\n\n# Add new default build ID\ntemporal task-queue update-build-ids add-new-default \\\n  --task-queue order-processing-queue \\\n  --build-id v1.3.0\n</code></pre>"},{"location":"reference/cli-commands/#cluster-commands","title":"Cluster Commands","text":""},{"location":"reference/cli-commands/#describe-cluster","title":"Describe Cluster","text":"<pre><code># Describe cluster\ntemporal cluster describe\n\n# Get cluster information\ntemporal cluster system-info\n</code></pre>"},{"location":"reference/cli-commands/#health-check","title":"Health Check","text":"<pre><code># Check cluster health\ntemporal cluster health\n\n# Check with verbose output\ntemporal cluster health --verbose\n</code></pre>"},{"location":"reference/cli-commands/#get-cluster-members","title":"Get Cluster Members","text":"<pre><code># List cluster members\ntemporal cluster list-members\n\n# List with role filter\ntemporal cluster list-members --role frontend\ntemporal cluster list-members --role history\ntemporal cluster list-members --role matching\ntemporal cluster list-members --role worker\n</code></pre>"},{"location":"reference/cli-commands/#search-commands","title":"Search Commands","text":""},{"location":"reference/cli-commands/#search-workflows","title":"Search Workflows","text":"<pre><code># Search workflows with SQL-like query\ntemporal workflow list \\\n  --query \"WorkflowType = 'OrderProcessingWorkflow'\"\n\n# Complex search query\ntemporal workflow list \\\n  --query \"WorkflowType = 'OrderProcessingWorkflow' \n           AND ExecutionStatus = 'Running' \n           AND StartTime &gt; '2023-01-01T00:00:00Z'\"\n\n# Search with custom search attributes\ntemporal workflow list \\\n  --query \"CustomerId = 'customer-67890' \n           AND OrderStatus = 'pending'\"\n\n# Search archived workflows\ntemporal workflow list \\\n  --archived \\\n  --query \"WorkflowType = 'OrderProcessingWorkflow' \n           AND CloseTime &gt; '2023-01-01T00:00:00Z'\"\n</code></pre>"},{"location":"reference/cli-commands/#search-operators","title":"Search Operators","text":"<pre><code># Equality\ntemporal workflow list --query \"WorkflowType = 'MyWorkflow'\"\n\n# Inequality\ntemporal workflow list --query \"ExecutionDuration &gt; 3600\"\n\n# Range queries\ntemporal workflow list --query \"StartTime BETWEEN '2023-01-01T00:00:00Z' AND '2023-01-31T23:59:59Z'\"\n\n# IN operator\ntemporal workflow list --query \"WorkflowType IN ('WorkflowA', 'WorkflowB')\"\n\n# Text search\ntemporal workflow list --query \"WorkflowId STARTS_WITH 'order-'\"\n\n# Logical operators\ntemporal workflow list --query \"(WorkflowType = 'OrderWorkflow' OR WorkflowType = 'PaymentWorkflow') AND ExecutionStatus = 'Running'\"\n</code></pre>"},{"location":"reference/cli-commands/#administrative-commands","title":"Administrative Commands","text":""},{"location":"reference/cli-commands/#server-commands","title":"Server Commands","text":""},{"location":"reference/cli-commands/#start-development-server","title":"Start Development Server","text":"<pre><code># Start local development server\ntemporal server start-dev\n\n# Start with UI\ntemporal server start-dev --ui-port 8080\n\n# Start with specific database\ntemporal server start-dev \\\n  --db-filename temporal.db \\\n  --port 7233\n\n# Start with namespaces\ntemporal server start-dev \\\n  --namespace development \\\n  --namespace testing\n</code></pre>"},{"location":"reference/cli-commands/#database-migration","title":"Database Migration","text":"<pre><code># Setup database schema\ntemporal sql-tool \\\n  --database temporal \\\n  --plugin postgres \\\n  --endpoint postgres://user:pass@localhost/temporal \\\n  setup-schema\n\n# Update database schema\ntemporal sql-tool \\\n  --database temporal \\\n  --plugin postgres \\\n  --endpoint postgres://user:pass@localhost/temporal \\\n  update-schema \\\n  --schema-dir ./schema/postgresql/v96\n\n# Create initial database\ntemporal sql-tool \\\n  --database temporal \\\n  --plugin postgres \\\n  --endpoint postgres://user:pass@localhost/temporal \\\n  create-database\n</code></pre>"},{"location":"reference/cli-commands/#operator-commands","title":"Operator Commands","text":""},{"location":"reference/cli-commands/#shard-management","title":"Shard Management","text":"<pre><code># Describe shard\ntemporal operator shard describe --shard-id 1\n\n# Close shard\ntemporal operator shard close --shard-id 1 --reason \"Maintenance\"\n\n# List shards\ntemporal operator shard list\n</code></pre>"},{"location":"reference/cli-commands/#search-attribute-management","title":"Search Attribute Management","text":"<pre><code># List search attributes\ntemporal operator search-attribute list\n\n# Add search attribute\ntemporal operator search-attribute create \\\n  --name OrderTotal \\\n  --type Double\n\n# Remove search attribute\ntemporal operator search-attribute remove \\\n  --name OldAttribute \\\n  --yes\n</code></pre>"},{"location":"reference/cli-commands/#cluster-metadata","title":"Cluster Metadata","text":"<pre><code># Get cluster metadata\ntemporal operator cluster describe\n\n# Add cluster to metadata\ntemporal operator cluster add \\\n  --cluster-name production-west \\\n  --cluster-address temporal-west.company.com:7233\n\n# Remove cluster from metadata\ntemporal operator cluster remove \\\n  --cluster-name old-cluster\n</code></pre>"},{"location":"reference/cli-commands/#monitoring-commands","title":"Monitoring Commands","text":""},{"location":"reference/cli-commands/#workflow-monitoring","title":"Workflow Monitoring","text":"<pre><code># Monitor workflow execution in real-time\ntemporal workflow observe \\\n  --workflow-id order-12345\n\n# Monitor with specific events\ntemporal workflow observe \\\n  --workflow-id order-12345 \\\n  --event-type ActivityTaskCompleted,WorkflowExecutionCompleted\n</code></pre>"},{"location":"reference/cli-commands/#task-queue-monitoring","title":"Task Queue Monitoring","text":"<pre><code># Monitor task queue metrics\ntemporal task-queue describe order-processing-queue \\\n  --include-pollers\n\n# Watch task queue continuously\nwatch -n 5 \"temporal task-queue describe order-processing-queue\"\n</code></pre>"},{"location":"reference/cli-commands/#system-monitoring","title":"System Monitoring","text":"<pre><code># Get system information\ntemporal cluster system-info\n\n# Monitor cluster health\nwatch -n 10 \"temporal cluster health\"\n\n# Get namespace metrics\ntemporal namespace describe production\n</code></pre>"},{"location":"reference/cli-commands/#environment-variables","title":"Environment Variables","text":""},{"location":"reference/cli-commands/#core-environment-variables","title":"Core Environment Variables","text":"<pre><code># Server connection\nexport TEMPORAL_ADDRESS=temporal.company.com:7233\nexport TEMPORAL_NAMESPACE=production\n\n# TLS configuration\nexport TEMPORAL_TLS_CERT_PATH=/etc/temporal/certs/client.crt\nexport TEMPORAL_TLS_KEY_PATH=/etc/temporal/certs/client.key\nexport TEMPORAL_TLS_CA_PATH=/etc/temporal/certs/ca.crt\nexport TEMPORAL_TLS_SERVER_NAME=temporal.company.com\nexport TEMPORAL_TLS_DISABLE_HOST_VERIFICATION=false\n\n# Authentication\nexport TEMPORAL_API_KEY=your-api-key\nexport TEMPORAL_OAUTH_CLIENT_ID=your-client-id\nexport TEMPORAL_OAUTH_CLIENT_SECRET=your-client-secret\n\n# CLI behavior\nexport TEMPORAL_CLI_AUTO_CONFIRM=false\nexport TEMPORAL_CLI_OUTPUT_FORMAT=table\nexport TEMPORAL_CLI_PAGER=less\nexport TEMPORAL_CLI_COLOR=auto\n\n# Development\nexport TEMPORAL_DEV_SERVER_DB_FILENAME=temporal.db\nexport TEMPORAL_DEV_SERVER_PORT=7233\nexport TEMPORAL_DEV_SERVER_UI_PORT=8080\n</code></pre>"},{"location":"reference/cli-commands/#advanced-environment-variables","title":"Advanced Environment Variables","text":"<pre><code># Codec configuration\nexport TEMPORAL_CODEC_ENDPOINT=http://localhost:8080\nexport TEMPORAL_CODEC_AUTH=bearer-token\n\n# Headers provider\nexport TEMPORAL_HEADERS_PROVIDER_EXECUTABLE=/path/to/headers-provider\nexport TEMPORAL_HEADERS_PROVIDER_ARGUMENTS=\"arg1 arg2\"\n\n# Logging\nexport TEMPORAL_CLI_LOG_LEVEL=info\nexport TEMPORAL_CLI_LOG_FORMAT=json\n\n# Plugin configuration\nexport TEMPORAL_PLUGIN_DIR=/etc/temporal/plugins\nexport TEMPORAL_PLUGIN_CONFIG_DIR=/etc/temporal/plugin-configs\n</code></pre>"},{"location":"reference/cli-commands/#output-formats","title":"Output Formats","text":""},{"location":"reference/cli-commands/#table-format-default","title":"Table Format (Default)","text":"<pre><code>temporal workflow list\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 WORKFLOW ID      \u2502 WORKFLOW TYPE  \u2502 STATUS   \u2502 START TIME          \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502 order-12345      \u2502 OrderWorkflow  \u2502 Running  \u2502 2023-01-01 10:00:00 \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"reference/cli-commands/#json-format","title":"JSON Format","text":"<pre><code>temporal workflow list --output json\n# [\n#   {\n#     \"workflowId\": \"order-12345\",\n#     \"workflowType\": \"OrderWorkflow\",\n#     \"status\": \"Running\",\n#     \"startTime\": \"2023-01-01T10:00:00Z\"\n#   }\n# ]\n</code></pre>"},{"location":"reference/cli-commands/#yaml-format","title":"YAML Format","text":"<pre><code>temporal workflow describe --workflow-id order-12345 --output yaml\n# workflowExecutionInfo:\n#   workflowId: order-12345\n#   workflowType: OrderWorkflow\n#   status: Running\n#   startTime: \"2023-01-01T10:00:00Z\"\n</code></pre>"},{"location":"reference/cli-commands/#card-format","title":"Card Format","text":"<pre><code>temporal workflow describe --workflow-id order-12345 --output card\n# \u256d\u2500 Workflow Execution \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n# \u2502 Workflow Id    order-12345                               \u2502\n# \u2502 Run Id         01234567-89ab-cdef-0123-456789abcdef      \u2502\n# \u2502 Type           OrderWorkflow                             \u2502\n# \u2502 Namespace      default                                   \u2502\n# \u2502 Task Queue     order-processing-queue                    \u2502\n# \u2502 Status         Running                                   \u2502\n# \u2502 Start Time     2023-01-01 10:00:00 UTC                   \u2502\n# \u2502 Execution Time 2h 30m 45s                                \u2502\n# \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"reference/cli-commands/#raw-format","title":"Raw Format","text":"<pre><code>temporal workflow describe --workflow-id order-12345 --raw\n# Outputs the raw protobuf response\n</code></pre>"},{"location":"reference/cli-commands/#command-categories","title":"Command Categories","text":""},{"location":"reference/cli-commands/#workflow-lifecycle-commands","title":"Workflow Lifecycle Commands","text":"<pre><code># Start workflow\ntemporal workflow start --workflow-type MyWorkflow --task-queue my-queue --workflow-id wf-123\n\n# Execute and wait\ntemporal workflow execute --workflow-type MyWorkflow --task-queue my-queue --workflow-id wf-123\n\n# Signal workflow\ntemporal workflow signal --workflow-id wf-123 --name my-signal --input '{}'\n\n# Query workflow\ntemporal workflow query --workflow-id wf-123 --type my-query\n\n# Cancel workflow\ntemporal workflow cancel --workflow-id wf-123\n\n# Terminate workflow\ntemporal workflow terminate --workflow-id wf-123 --reason \"reason\"\n\n# Reset workflow\ntemporal workflow reset --workflow-id wf-123 --event-id 10\n</code></pre>"},{"location":"reference/cli-commands/#information-commands","title":"Information Commands","text":"<pre><code># Describe workflow\ntemporal workflow describe --workflow-id wf-123\n\n# Show workflow history\ntemporal workflow show --workflow-id wf-123\n\n# List workflows\ntemporal workflow list\n\n# Count workflows\ntemporal workflow count\n</code></pre>"},{"location":"reference/cli-commands/#administrative-commands_1","title":"Administrative Commands","text":"<pre><code># Namespace operations\ntemporal namespace register my-namespace\ntemporal namespace describe my-namespace\ntemporal namespace list\ntemporal namespace update my-namespace --retention 30d\n\n# Task queue operations\ntemporal task-queue describe my-queue\ntemporal task-queue list\n\n# Cluster operations\ntemporal cluster describe\ntemporal cluster health\ntemporal cluster list-members\n</code></pre>"},{"location":"reference/cli-commands/#development-commands","title":"Development Commands","text":"<pre><code># Start development server\ntemporal server start-dev\n\n# Database operations\ntemporal sql-tool setup-schema\ntemporal sql-tool update-schema\n\n# Operator commands\ntemporal operator shard describe --shard-id 1\ntemporal operator search-attribute list\n</code></pre> <p>This comprehensive CLI reference provides detailed information about all Temporal CLI commands, their options, and practical usage examples for various operational scenarios.</p>"},{"location":"reference/configuration/","title":"Configuration Reference","text":"<p>This comprehensive reference guide covers all configuration options for Temporal.io deployments, including server configuration, database settings, security parameters, and operational tuning options.</p>"},{"location":"reference/configuration/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Server Configuration</li> <li>Database Configuration</li> <li>Security Configuration</li> <li>Observability Configuration</li> <li>Performance Tuning</li> <li>Environment Variables</li> <li>Configuration Examples</li> </ul>"},{"location":"reference/configuration/#server-configuration","title":"Server Configuration","text":""},{"location":"reference/configuration/#main-configuration-file","title":"Main Configuration File","text":"<p>The main Temporal server configuration file (<code>config.yaml</code>) defines all core settings:</p> <pre><code># config/server-config.yaml\nlog:\n  stdout: true\n  level: \"info\"\n  format: \"json\"\n\npersistence:\n  defaultStore: default\n  visibilityStore: visibility\n  numHistoryShards: 4\n  datastores:\n    default:\n      sql:\n        pluginName: \"postgres\"\n        databaseName: \"temporal\"\n        connectAddr: \"postgres.temporal.svc.cluster.local:5432\"\n        connectProtocol: \"tcp\"\n        user: \"temporal\"\n        password: \"${TEMPORAL_DB_PASSWORD}\"\n        maxConns: 20\n        maxIdleConns: 20\n        maxConnLifetime: \"1h\"\n        connectAttributes:\n          sslmode: \"require\"\n    visibility:\n      sql:\n        pluginName: \"postgres\"\n        databaseName: \"temporal_visibility\"\n        connectAddr: \"postgres.temporal.svc.cluster.local:5432\"\n        connectProtocol: \"tcp\"\n        user: \"temporal\"\n        password: \"${TEMPORAL_DB_PASSWORD}\"\n        maxConns: 10\n        maxIdleConns: 10\n        maxConnLifetime: \"1h\"\n        connectAttributes:\n          sslmode: \"require\"\n\nglobal:\n  membership:\n    maxJoinDuration: 30s\n    broadcastAddress: \"0.0.0.0\"\n  pprof:\n    port: 7936\n  metrics:\n    prometheus:\n      timerType: \"histogram\"\n      listenAddress: \"0.0.0.0:9090\"\n\nservices:\n  frontend:\n    rpc:\n      grpcPort: 7233\n      membershipPort: 6933\n      bindOnLocalHost: false\n    metrics:\n      prometheus:\n        handlerPath: \"/metrics\"\n        listenAddress: \"0.0.0.0:9090\"\n\n  matching:\n    rpc:\n      grpcPort: 7235\n      membershipPort: 6935\n      bindOnLocalHost: false\n\n  history:\n    rpc:\n      grpcPort: 7234\n      membershipPort: 6934\n      bindOnLocalHost: false\n\n  worker:\n    rpc:\n      grpcPort: 7239\n      membershipPort: 6939\n      bindOnLocalHost: false\n\nclusterMetadata:\n  enableGlobalNamespace: false\n  failoverVersionIncrement: 10\n  masterClusterName: \"active\"\n  currentClusterName: \"active\"\n  clusterInformation:\n    active:\n      enabled: true\n      initialFailoverVersion: 1\n      rpcName: \"frontend\"\n      rpcAddress: \"127.0.0.1:7233\"\n\ndcRedirectionPolicy:\n  policy: \"noop\"\n\narchival:\n  history:\n    state: \"enabled\"\n    enableRead: true\n    provider:\n      filestore:\n        fileMode: \"0666\"\n        dirMode: \"0766\"\n      gstorage:\n        credentialsPath: \"/tmp/gcloud/keyfile.json\"\n        workflowExecutionRetentionPeriod: \"30d\"\n  visibility:\n    state: \"enabled\"\n    enableRead: true\n    provider:\n      filestore:\n        fileMode: \"0666\"\n        dirMode: \"0766\"\n\npublicClient:\n  hostPort: \"temporal-frontend:7233\"\n\ndynamicConfigClient:\n  filepath: \"/etc/temporal/dynamicconfig/production.yaml\"\n  pollInterval: \"10s\"\n</code></pre>"},{"location":"reference/configuration/#service-specific-configuration","title":"Service-Specific Configuration","text":""},{"location":"reference/configuration/#frontend-service-configuration","title":"Frontend Service Configuration","text":"<pre><code># config/frontend-config.yaml\nfrontend:\n  # RPC Configuration\n  rpc:\n    grpcPort: 7233\n    membershipPort: 6933\n    bindOnLocalHost: false\n    bindOnIP: \"0.0.0.0\"\n    disableLoopbackIP: false\n\n  # Rate Limiting\n  rps:\n    maxDomainVisibilityListSize: 100\n    maxDomainVisibilityReadQPS: 400\n    maxDomainVisibilityWriteQPS: 300\n    maxIDLengthLimit: 1000\n\n  # Namespace Configuration\n  namespaceDefaults:\n    retention: \"72h\"\n    emitMetrics: true\n    archival:\n      history:\n        state: \"disabled\"\n      visibility:\n        state: \"disabled\"\n\n  # Security Configuration\n  authorization:\n    jwtKeyProvider:\n      keySourceURIs:\n        - \"file:///etc/temporal/auth/public.key\"\n      refreshInterval: \"1h\"\n    permissionsClaimName: \"permissions\"\n    authorizer: \"default\"\n\n  # History Service Client Configuration\n  historyClient:\n    numberOfShards: 4\n    rpcTimeout: \"30s\"\n    maxRetryPolicy:\n      initialInterval: \"1s\"\n      maximumInterval: \"30s\"\n      expirationInterval: \"5m\"\n      maximumAttempts: 5\n\n  # Search Attributes\n  searchAttributes:\n    forceSearchAttributesCacheRefreshOnRead: false\n    cacheRefreshInterval: \"1m\"\n</code></pre>"},{"location":"reference/configuration/#history-service-configuration","title":"History Service Configuration","text":"<pre><code># config/history-config.yaml\nhistory:\n  # RPC Configuration\n  rpc:\n    grpcPort: 7234\n    membershipPort: 6934\n    bindOnLocalHost: false\n\n  # Persistence Configuration\n  historyMgrNumConns: 50\n  executionMgrNumConns: 50\n\n  # Task Processing\n  taskProcessRPS: 1000\n  taskSchedulerType: \"weighted-round-robin\"\n  taskSchedulerWorkerCount: 200\n  taskSchedulerShardWorkerCount: 0\n  taskSchedulerQueueSize: 10000\n  taskSchedulerDispatcherCount: 1\n\n  # Replication\n  replicationTaskProcessorStartWait: \"5s\"\n  replicationTaskProcessorType: \"task-processor\"\n  replicationTaskProcessorShardWorkerCount: 2\n\n  # Transfer Queue\n  transferTaskWorkerCount: 100\n  transferTaskBatchSize: 100\n  transferProcessorStartDelay: \"5s\"\n  transferProcessorMaxPollRPS: 1000\n  transferProcessorMaxPollInterval: \"1m\"\n  transferProcessorMaxPollIntervalJitterCoefficient: 0.15\n  transferProcessorUpdateAckInterval: \"30s\"\n\n  # Timer Queue\n  timerTaskWorkerCount: 100\n  timerTaskBatchSize: 100\n  timerProcessorStartDelay: \"5s\"\n  timerProcessorMaxPollRPS: 1000\n  timerProcessorMaxPollInterval: \"5m\"\n  timerProcessorMaxPollIntervalJitterCoefficient: 0.15\n  timerProcessorUpdateAckInterval: \"30s\"\n\n  # Visibility Queue\n  visibilityTaskWorkerCount: 100\n  visibilityTaskBatchSize: 100\n  visibilityProcessorStartDelay: \"5s\"\n  visibilityProcessorMaxPollRPS: 1000\n  visibilityProcessorMaxPollInterval: \"1m\"\n  visibilityProcessorMaxPollIntervalJitterCoefficient: 0.15\n  visibilityProcessorUpdateAckInterval: \"30s\"\n\n  # Workflow Execution\n  maxAutoResetPoints: 20\n  defaultWorkflowExecutionTimeout: \"72h\"\n  defaultWorkflowRunTimeout: \"72h\"\n  defaultWorkflowTaskTimeout: \"10s\"\n\n  # Shard Controller\n  shardController:\n    membershipUpdateListener:\n      enabled: true\n      type: \"noop\"\n    shardGracefulCloseTimeout: \"5m\"\n</code></pre>"},{"location":"reference/configuration/#matching-service-configuration","title":"Matching Service Configuration","text":"<pre><code># config/matching-config.yaml\nmatching:\n  # RPC Configuration\n  rpc:\n    grpcPort: 7235\n    membershipPort: 6935\n    bindOnLocalHost: false\n\n  # Task List Configuration\n  numTasklistWritePartitions: 1\n  numTasklistReadPartitions: 1\n  forwarderMaxOutstandingPolls: 1000\n  forwarderMaxOutstandingTasks: 1000\n  forwarderMaxRatePerSecond: 10000\n  forwarderMaxChildrenPerNode: 20\n\n  # Poller Configuration\n  longPollExpirationInterval: \"1m\"\n  maxTasklistIdleTime: \"5m\"\n  outstandingTaskAppendsThreshold: 250\n  maxTaskBatchSize: 1000\n  getTasksBatchSize: 1000\n  updateAckInterval: \"1m\"\n  idleTasklistCheckInterval: \"5m\"\n  maxIdleTasklistAge: \"5m\"\n\n  # Rate Limiting\n  rps: 30000\n  domainUserRPS: 300\n\n  # Load Balancing\n  loadBalancer:\n    mode: \"task\"\n    lookAheadCountPerPartition: 20\n    defaultTaskDispatchRPS: 100000.0\n    defaultTaskDispatchRPSTTL: \"60s\"\n</code></pre>"},{"location":"reference/configuration/#worker-service-configuration","title":"Worker Service Configuration","text":"<pre><code># config/worker-config.yaml\nworker:\n  # RPC Configuration\n  rpc:\n    grpcPort: 7239\n    membershipPort: 6939\n    bindOnLocalHost: false\n\n  # Archival Worker\n  archiver:\n    maxConcurrentActivityExecutionSize: 1000\n    maxConcurrentWorkflowTaskExecutionSize: 1000\n    maxConcurrentActivityTaskPollers: 20\n    maxConcurrentWorkflowTaskPollers: 20\n\n  # Indexer\n  indexer:\n    maxConcurrentActivityExecutionSize: 1000\n    maxConcurrentWorkflowTaskExecutionSize: 1000\n    maxConcurrentActivityTaskPollers: 3\n    maxConcurrentWorkflowTaskPollers: 3\n\n  # Replicator\n  replicator:\n    maxConcurrentActivityExecutionSize: 1000\n    maxConcurrentWorkflowTaskExecutionSize: 1000\n    maxConcurrentActivityTaskPollers: 1\n    maxConcurrentWorkflowTaskPollers: 1\n\n  # Scanner\n  scanner:\n    maxConcurrentActivityExecutionSize: 1000\n    maxConcurrentWorkflowTaskExecutionSize: 1000\n    maxConcurrentActivityTaskPollers: 1\n    maxConcurrentWorkflowTaskPollers: 1\n</code></pre>"},{"location":"reference/configuration/#database-configuration","title":"Database Configuration","text":""},{"location":"reference/configuration/#postgresql-configuration","title":"PostgreSQL Configuration","text":"<pre><code># config/database/postgres-config.yaml\npersistence:\n  defaultStore: default\n  visibilityStore: visibility\n  datastores:\n    default:\n      sql:\n        pluginName: \"postgres\"\n        databaseName: \"temporal\"\n        connectAddr: \"postgres.temporal.svc.cluster.local:5432\"\n        connectProtocol: \"tcp\"\n        user: \"temporal\"\n        password: \"${TEMPORAL_DB_PASSWORD}\"\n\n        # Connection Pool Settings\n        maxConns: 50\n        maxIdleConns: 25\n        maxConnLifetime: \"1h\"\n        maxIdleTime: \"15m\"\n\n        # Connection Attributes\n        connectAttributes:\n          sslmode: \"require\"\n          sslcert: \"/etc/temporal/certs/client.crt\"\n          sslkey: \"/etc/temporal/certs/client.key\"\n          sslrootcert: \"/etc/temporal/certs/ca.crt\"\n          application_name: \"temporal\"\n          search_path: \"temporal\"\n\n        # Advanced Settings\n        taskScanPartitions: 4\n        txIsolationLevel: \"READ_COMMITTED\"\n\n    visibility:\n      sql:\n        pluginName: \"postgres\"\n        databaseName: \"temporal_visibility\"\n        connectAddr: \"postgres.temporal.svc.cluster.local:5432\"\n        connectProtocol: \"tcp\"\n        user: \"temporal\"\n        password: \"${TEMPORAL_DB_PASSWORD}\"\n        maxConns: 20\n        maxIdleConns: 10\n        maxConnLifetime: \"1h\"\n        connectAttributes:\n          sslmode: \"require\"\n          application_name: \"temporal-visibility\"\n</code></pre>"},{"location":"reference/configuration/#elasticsearch-configuration","title":"Elasticsearch Configuration","text":"<pre><code># config/database/elasticsearch-config.yaml\npersistence:\n  visibilityStore: es-visibility\n  datastores:\n    es-visibility:\n      elasticsearch:\n        version: \"v7\"\n        url:\n          scheme: \"https\"\n          host: \"elasticsearch.temporal.svc.cluster.local:9200\"\n        indices:\n          visibility: \"temporal_visibility_v1_dev\"\n        username: \"temporal\"\n        password: \"${ELASTICSEARCH_PASSWORD}\"\n\n        # Connection Settings\n        maxRetryPolicy:\n          initialInterval: \"1s\"\n          maximumInterval: \"16s\"\n          expirationInterval: \"5m\"\n          maximumAttempts: 9\n\n        # TLS Configuration\n        tls:\n          enabled: true\n          caFile: \"/etc/temporal/certs/elasticsearch-ca.crt\"\n          certFile: \"/etc/temporal/certs/elasticsearch-client.crt\"\n          keyFile: \"/etc/temporal/certs/elasticsearch-client.key\"\n          serverName: \"elasticsearch.temporal.svc.cluster.local\"\n\n        # Performance Settings\n        closeIdleConnectionsInterval: \"15s\"\n        enableSniff: false\n        enableHealthcheck: true\n\n        # Bulk Operations\n        bulkProcessor:\n          numWorkers: 1\n          bulkActions: 1000\n          bulkSize: \"2MB\"\n          flushInterval: \"1s\"\n</code></pre>"},{"location":"reference/configuration/#mysql-configuration","title":"MySQL Configuration","text":"<pre><code># config/database/mysql-config.yaml\npersistence:\n  defaultStore: default\n  visibilityStore: visibility\n  datastores:\n    default:\n      sql:\n        pluginName: \"mysql\"\n        databaseName: \"temporal\"\n        connectAddr: \"mysql.temporal.svc.cluster.local:3306\"\n        connectProtocol: \"tcp\"\n        user: \"temporal\"\n        password: \"${TEMPORAL_DB_PASSWORD}\"\n        maxConns: 50\n        maxIdleConns: 25\n        maxConnLifetime: \"1h\"\n        connectAttributes:\n          tls: \"true\"\n          interpolateParams: \"true\"\n          parseTime: \"true\"\n\n    visibility:\n      sql:\n        pluginName: \"mysql\"\n        databaseName: \"temporal_visibility\"\n        connectAddr: \"mysql.temporal.svc.cluster.local:3306\"\n        connectProtocol: \"tcp\"\n        user: \"temporal\"\n        password: \"${TEMPORAL_DB_PASSWORD}\"\n        maxConns: 20\n        maxIdleConns: 10\n        maxConnLifetime: \"1h\"\n        connectAttributes:\n          tls: \"true\"\n          interpolateParams: \"true\"\n          parseTime: \"true\"\n</code></pre>"},{"location":"reference/configuration/#security-configuration","title":"Security Configuration","text":""},{"location":"reference/configuration/#authentication-configuration","title":"Authentication Configuration","text":"<pre><code># config/security/auth-config.yaml\nglobal:\n  authorization:\n    # JWT Configuration\n    jwtKeyProvider:\n      keySourceURIs:\n        - \"file:///etc/temporal/auth/public.key\"\n        - \"https://auth.company.com/.well-known/jwks.json\"\n      refreshInterval: \"1h\"\n    permissionsClaimName: \"permissions\"\n    authorizer: \"default\"\n\n    # Claims Mapping\n    claimsMapper:\n      roleClaimName: \"roles\"\n      permissionClaimName: \"permissions\"\n      namespaceClaimName: \"namespace\"\n\n# TLS Configuration\ntls:\n  # Frontend TLS\n  frontend:\n    server:\n      certFile: \"/etc/temporal/certs/server.crt\"\n      keyFile: \"/etc/temporal/certs/server.key\"\n      clientCaFiles:\n        - \"/etc/temporal/certs/ca.crt\"\n      requireClientAuth: false\n\n  # Inter-node TLS\n  internode:\n    server:\n      certFile: \"/etc/temporal/certs/server.crt\"\n      keyFile: \"/etc/temporal/certs/server.key\"\n      clientCaFiles:\n        - \"/etc/temporal/certs/ca.crt\"\n      requireClientAuth: true\n    client:\n      certFile: \"/etc/temporal/certs/client.crt\"\n      keyFile: \"/etc/temporal/certs/client.key\"\n      serverCaFiles:\n        - \"/etc/temporal/certs/ca.crt\"\n      serverName: \"temporal.company.com\"\n\n  # Database TLS\n  database:\n    server:\n      certFile: \"/etc/temporal/certs/db-server.crt\"\n      keyFile: \"/etc/temporal/certs/db-server.key\"\n      clientCaFiles:\n        - \"/etc/temporal/certs/ca.crt\"\n    client:\n      certFile: \"/etc/temporal/certs/db-client.crt\"\n      keyFile: \"/etc/temporal/certs/db-client.key\"\n      serverCaFiles:\n        - \"/etc/temporal/certs/ca.crt\"\n</code></pre>"},{"location":"reference/configuration/#rbac-configuration","title":"RBAC Configuration","text":"<pre><code># config/security/rbac-config.yaml\nauthorization:\n  rbac:\n    enabled: true\n    policies:\n      # Admin Policies\n      - role: \"admin\"\n        permissions:\n          - \"temporal:workflow:*\"\n          - \"temporal:activity:*\"\n          - \"temporal:namespace:*\"\n          - \"temporal:cluster:*\"\n        resources:\n          - \"*\"\n\n      # Developer Policies\n      - role: \"developer\"\n        permissions:\n          - \"temporal:workflow:start\"\n          - \"temporal:workflow:signal\"\n          - \"temporal:workflow:query\"\n          - \"temporal:workflow:read\"\n          - \"temporal:activity:execute\"\n        resources:\n          - \"namespace:development\"\n          - \"namespace:testing\"\n\n      # Operator Policies\n      - role: \"operator\"\n        permissions:\n          - \"temporal:workflow:read\"\n          - \"temporal:workflow:list\"\n          - \"temporal:workflow:terminate\"\n          - \"temporal:namespace:read\"\n          - \"temporal:cluster:read\"\n        resources:\n          - \"*\"\n\n      # Read-only Policies\n      - role: \"viewer\"\n        permissions:\n          - \"temporal:workflow:read\"\n          - \"temporal:workflow:list\"\n          - \"temporal:namespace:read\"\n        resources:\n          - \"*\"\n\n    # Role Bindings\n    roleBindings:\n      - subject: \"user:admin@company.com\"\n        role: \"admin\"\n      - subject: \"group:temporal-developers\"\n        role: \"developer\"\n      - subject: \"group:temporal-operators\"\n        role: \"operator\"\n      - subject: \"group:temporal-viewers\"\n        role: \"viewer\"\n</code></pre>"},{"location":"reference/configuration/#observability-configuration","title":"Observability Configuration","text":""},{"location":"reference/configuration/#logging-configuration","title":"Logging Configuration","text":"<pre><code># config/observability/logging-config.yaml\nlog:\n  stdout: true\n  level: \"info\"  # debug, info, warn, error\n  format: \"json\"  # json, console\n\n  # File Logging\n  outputFile: \"/var/log/temporal/server.log\"\n  maxSize: \"100MB\"\n  maxAge: \"7d\"\n  maxBackups: 10\n\n  # Structured Logging\n  fields:\n    service: \"temporal\"\n    version: \"${TEMPORAL_VERSION}\"\n    environment: \"${ENVIRONMENT}\"\n    cluster: \"${CLUSTER_NAME}\"\n\n  # Log Sampling\n  sampling:\n    initial: 100\n    thereafter: 100\n</code></pre>"},{"location":"reference/configuration/#metrics-configuration","title":"Metrics Configuration","text":"<pre><code># config/observability/metrics-config.yaml\nglobal:\n  metrics:\n    # Prometheus Configuration\n    prometheus:\n      timerType: \"histogram\"  # histogram, summary\n      listenAddress: \"0.0.0.0:9090\"\n      handlerPath: \"/metrics\"\n\n      # Histogram Buckets\n      defaultHistogramBuckets:\n        - 0.0005\n        - 0.001\n        - 0.0025\n        - 0.005\n        - 0.01\n        - 0.025\n        - 0.05\n        - 0.1\n        - 0.25\n        - 0.5\n        - 1.0\n        - 2.5\n        - 5.0\n        - 10.0\n        - 25.0\n        - 50.0\n        - 100.0\n\n    # StatsD Configuration (alternative)\n    statsd:\n      hostPort: \"statsd.monitoring.svc.cluster.local:8125\"\n      prefix: \"temporal\"\n      flushInterval: \"10s\"\n      flushBytes: 512\n\n    # M3 Configuration (alternative)\n    m3:\n      hostPort: \"m3coordinator.monitoring.svc.cluster.local:7201\"\n      service: \"temporal\"\n      env: \"production\"\n\n  # Service-specific Metrics\n  services:\n    frontend:\n      metrics:\n        prometheus:\n          handlerPath: \"/metrics\"\n          listenAddress: \"0.0.0.0:9090\"\n    history:\n      metrics:\n        prometheus:\n          handlerPath: \"/metrics\"\n          listenAddress: \"0.0.0.0:9091\"\n    matching:\n      metrics:\n        prometheus:\n          handlerPath: \"/metrics\"\n          listenAddress: \"0.0.0.0:9092\"\n    worker:\n      metrics:\n        prometheus:\n          handlerPath: \"/metrics\"\n          listenAddress: \"0.0.0.0:9093\"\n</code></pre>"},{"location":"reference/configuration/#tracing-configuration","title":"Tracing Configuration","text":"<pre><code># config/observability/tracing-config.yaml\nglobal:\n  # OpenTelemetry Configuration\n  opentelemetry:\n    otel:\n      # OTLP Exporter\n      exporter:\n        otlp:\n          endpoint: \"http://jaeger-collector.monitoring.svc.cluster.local:14268/api/traces\"\n          headers:\n            Authorization: \"Bearer ${TRACING_TOKEN}\"\n          compression: \"gzip\"\n          timeout: \"10s\"\n\n      # Trace Sampling\n      traceSampler:\n        type: \"probabilistic\"\n        param: 0.1  # 10% sampling rate\n\n      # Resource Attributes\n      resource:\n        attributes:\n          service.name: \"temporal\"\n          service.version: \"${TEMPORAL_VERSION}\"\n          deployment.environment: \"${ENVIRONMENT}\"\n\n    # Legacy Jaeger Configuration\n    jaeger:\n      agent:\n        hostPort: \"jaeger-agent.monitoring.svc.cluster.local:6831\"\n      collector:\n        endpoint: \"http://jaeger-collector.monitoring.svc.cluster.local:14268/api/traces\"\n      sampler:\n        type: \"probabilistic\"\n        param: 0.1\n      reporter:\n        logSpans: false\n        maxQueueSize: 1000\n        flushInterval: \"1s\"\n</code></pre>"},{"location":"reference/configuration/#performance-tuning","title":"Performance Tuning","text":""},{"location":"reference/configuration/#resource-limits-configuration","title":"Resource Limits Configuration","text":"<pre><code># config/performance/resource-limits.yaml\n# Frontend Service Limits\nfrontend:\n  rpc:\n    # Connection Limits\n    maxConnectionAge: \"5m\"\n    maxConnectionAgeGrace: \"70s\"\n    maxConnectionIdle: \"1m\"\n    keepAliveTime: \"30s\"\n    keepAliveTimeout: \"5s\"\n\n    # Request Limits\n    maxReceiveMessageSize: \"4MB\"\n    maxSendMessageSize: \"4MB\"\n\n  # Rate Limiting\n  rps:\n    # Per-namespace Rate Limits\n    namespaceMaxBurstRPS: 10000\n    namespaceCountLimitError: 10000\n    namespaceCountLimitWarn: 1000\n\n    # Global Rate Limits\n    globalNamespaceVisibilityMaxBurstRPS: 400\n    globalNamespaceVisibilityMaxQPS: 300\n\n# History Service Limits\nhistory:\n  # Task Processing Limits\n  taskProcessRPS: 1000\n  persistenceMaxQPS: 3000\n  persistenceGlobalMaxQPS: 0\n\n  # Workflow Execution Limits\n  workflowExecutionMaxSize: \"50MB\"\n  historyMaxPageSize: 1000\n  defaultTransactionSizeLimit: \"4MB\"\n\n  # Cache Settings\n  historyCache:\n    maxSize: 512\n    ttl: \"1h\"\n  eventsCache:\n    maxSize: 512\n    ttl: \"1h\"\n\n# Matching Service Limits\nmatching:\n  # Task List Limits\n  taskListLoadBalancerHostRPS: 10000\n  taskListLoadBalancerType: \"default\"\n\n  # Polling Limits\n  longPollExpirationInterval: \"1m\"\n  maxTaskDeleteBatchSize: 100\n  getAllTaskMaxPageSize: 1000\n\n# Worker Service Limits\nworker:\n  # Archival Limits\n  archiverMaxConcurrentActivityExecutionSize: 1000\n  archiverMaxConcurrentWorkflowTaskExecutionSize: 1000\n\n  # Indexer Limits\n  indexerMaxConcurrentActivityExecutionSize: 1000\n  indexerMaxConcurrentWorkflowTaskExecutionSize: 1000\n</code></pre>"},{"location":"reference/configuration/#memory-and-cpu-configuration","title":"Memory and CPU Configuration","text":"<pre><code># config/performance/resource-allocation.yaml\nresources:\n  # Frontend Service Resources\n  frontend:\n    limits:\n      memory: \"2Gi\"\n      cpu: \"1000m\"\n    requests:\n      memory: \"1Gi\"\n      cpu: \"500m\"\n    jvm:\n      heapSize: \"1536m\"\n\n  # History Service Resources\n  history:\n    limits:\n      memory: \"4Gi\"\n      cpu: \"2000m\"\n    requests:\n      memory: \"2Gi\"\n      cpu: \"1000m\"\n    jvm:\n      heapSize: \"3072m\"\n\n  # Matching Service Resources\n  matching:\n    limits:\n      memory: \"2Gi\"\n      cpu: \"1000m\"\n    requests:\n      memory: \"1Gi\"\n      cpu: \"500m\"\n    jvm:\n      heapSize: \"1536m\"\n\n  # Worker Service Resources\n  worker:\n    limits:\n      memory: \"2Gi\"\n      cpu: \"1000m\"\n    requests:\n      memory: \"1Gi\"\n      cpu: \"500m\"\n    jvm:\n      heapSize: \"1536m\"\n</code></pre>"},{"location":"reference/configuration/#environment-variables","title":"Environment Variables","text":""},{"location":"reference/configuration/#core-environment-variables","title":"Core Environment Variables","text":"<pre><code># Environment Variables Reference\n\n# Database Configuration\nTEMPORAL_DB_PASSWORD=&lt;database_password&gt;\nTEMPORAL_VISIBILITY_DB_PASSWORD=&lt;visibility_database_password&gt;\nELASTICSEARCH_PASSWORD=&lt;elasticsearch_password&gt;\n\n# Service Configuration\nTEMPORAL_FRONTEND_PORT=7233\nTEMPORAL_HISTORY_PORT=7234\nTEMPORAL_MATCHING_PORT=7235\nTEMPORAL_WORKER_PORT=7239\n\n# Cluster Configuration\nTEMPORAL_CLUSTER_NAME=temporal-cluster\nTEMPORAL_BROADCAST_ADDRESS=0.0.0.0\nNUM_HISTORY_SHARDS=4\n\n# Security Configuration\nTEMPORAL_TLS_ENABLED=true\nTEMPORAL_AUTH_ENABLED=true\nTEMPORAL_JWT_KEY_ID=temporal-jwt-key\n\n# Logging Configuration\nTEMPORAL_LOG_LEVEL=info\nTEMPORAL_LOG_FORMAT=json\n\n# Metrics Configuration\nTEMPORAL_METRICS_PORT=9090\nTEMPORAL_PROMETHEUS_ENABLED=true\n\n# Development/Debug Settings\nTEMPORAL_DEBUG_MODE=false\nTEMPORAL_PROFILE_PORT=7936\nTEMPORAL_SQL_TX_ISOLATION_COMPATIBLE=false\n\n# Advanced Configuration\nTEMPORAL_CONFIG_DIR=/etc/temporal/config\nTEMPORAL_DYNAMIC_CONFIG_FILE_PATH=/etc/temporal/dynamicconfig/production.yaml\nTEMPORAL_PLUGINS_DIR=/etc/temporal/plugins\n\n# Kubernetes Specific\nPOD_NAME=${HOSTNAME}\nPOD_NAMESPACE=temporal\nPOD_IP=${POD_IP}\n</code></pre>"},{"location":"reference/configuration/#service-specific-environment-variables","title":"Service-Specific Environment Variables","text":"<pre><code># Frontend Service Environment Variables\nFRONTEND_GRPC_PORT=7233\nFRONTEND_MEMBERSHIP_PORT=6933\nFRONTEND_HTTP_PORT=7243\nFRONTEND_METRICS_PORT=9090\n\n# History Service Environment Variables\nHISTORY_GRPC_PORT=7234\nHISTORY_MEMBERSHIP_PORT=6934\nHISTORY_METRICS_PORT=9091\n\n# Matching Service Environment Variables\nMATCHING_GRPC_PORT=7235\nMATCHING_MEMBERSHIP_PORT=6935\nMATCHING_METRICS_PORT=9092\n\n# Worker Service Environment Variables\nWORKER_GRPC_PORT=7239\nWORKER_MEMBERSHIP_PORT=6939\nWORKER_METRICS_PORT=9093\n\n# Database Connection Variables\nDB_HOST=postgres.temporal.svc.cluster.local\nDB_PORT=5432\nDB_NAME=temporal\nDB_USER=temporal\nDB_SSL_MODE=require\n\nVISIBILITY_DB_HOST=postgres.temporal.svc.cluster.local\nVISIBILITY_DB_PORT=5432\nVISIBILITY_DB_NAME=temporal_visibility\nVISIBILITY_DB_USER=temporal\n\n# Elasticsearch Variables\nELASTICSEARCH_HOSTS=elasticsearch.temporal.svc.cluster.local:9200\nELASTICSEARCH_SCHEME=https\nELASTICSEARCH_USER=temporal\nELASTICSEARCH_INDEX=temporal_visibility_v1\n\n# Security Variables\nTLS_CERT_FILE=/etc/temporal/certs/server.crt\nTLS_KEY_FILE=/etc/temporal/certs/server.key\nTLS_CA_FILE=/etc/temporal/certs/ca.crt\n</code></pre>"},{"location":"reference/configuration/#configuration-examples","title":"Configuration Examples","text":""},{"location":"reference/configuration/#development-configuration","title":"Development Configuration","text":"<pre><code># config/examples/development.yaml\nlog:\n  stdout: true\n  level: \"debug\"\n  format: \"console\"\n\npersistence:\n  defaultStore: default\n  visibilityStore: visibility\n  numHistoryShards: 4\n  datastores:\n    default:\n      sql:\n        pluginName: \"postgres\"\n        databaseName: \"temporal_dev\"\n        connectAddr: \"localhost:5432\"\n        connectProtocol: \"tcp\"\n        user: \"temporal\"\n        password: \"temporal\"\n        maxConns: 10\n        maxIdleConns: 5\n        connectAttributes:\n          sslmode: \"disable\"\n\nglobal:\n  membership:\n    maxJoinDuration: 30s\n    broadcastAddress: \"127.0.0.1\"\n  pprof:\n    port: 7936\n  metrics:\n    prometheus:\n      timerType: \"histogram\"\n      listenAddress: \"127.0.0.1:9090\"\n\nservices:\n  frontend:\n    rpc:\n      grpcPort: 7233\n      membershipPort: 6933\n      bindOnLocalHost: true\n\nclusterMetadata:\n  enableGlobalNamespace: false\n  failoverVersionIncrement: 10\n  masterClusterName: \"active\"\n  currentClusterName: \"active\"\n  clusterInformation:\n    active:\n      enabled: true\n      initialFailoverVersion: 1\n      rpcName: \"frontend\"\n      rpcAddress: \"127.0.0.1:7233\"\n\ndynamicConfigClient:\n  filepath: \"/etc/temporal/dynamicconfig/development.yaml\"\n  pollInterval: \"10s\"\n</code></pre>"},{"location":"reference/configuration/#production-configuration","title":"Production Configuration","text":"<pre><code># config/examples/production.yaml\nlog:\n  stdout: true\n  level: \"info\"\n  format: \"json\"\n\npersistence:\n  defaultStore: default\n  visibilityStore: es-visibility\n  numHistoryShards: 16\n  datastores:\n    default:\n      sql:\n        pluginName: \"postgres\"\n        databaseName: \"temporal\"\n        connectAddr: \"postgres-primary.temporal.svc.cluster.local:5432\"\n        connectProtocol: \"tcp\"\n        user: \"temporal\"\n        password: \"${TEMPORAL_DB_PASSWORD}\"\n        maxConns: 50\n        maxIdleConns: 25\n        maxConnLifetime: \"1h\"\n        connectAttributes:\n          sslmode: \"require\"\n          application_name: \"temporal\"\n    es-visibility:\n      elasticsearch:\n        version: \"v7\"\n        url:\n          scheme: \"https\"\n          host: \"elasticsearch.temporal.svc.cluster.local:9200\"\n        indices:\n          visibility: \"temporal_visibility_v1_prod\"\n        username: \"temporal\"\n        password: \"${ELASTICSEARCH_PASSWORD}\"\n        tls:\n          enabled: true\n          caFile: \"/etc/temporal/certs/es-ca.crt\"\n\nglobal:\n  membership:\n    maxJoinDuration: 30s\n    broadcastAddress: \"0.0.0.0\"\n  metrics:\n    prometheus:\n      timerType: \"histogram\"\n      listenAddress: \"0.0.0.0:9090\"\n  authorization:\n    jwtKeyProvider:\n      keySourceURIs:\n        - \"https://auth.company.com/.well-known/jwks.json\"\n      refreshInterval: \"1h\"\n    permissionsClaimName: \"permissions\"\n    authorizer: \"default\"\n\ntls:\n  frontend:\n    server:\n      certFile: \"/etc/temporal/certs/server.crt\"\n      keyFile: \"/etc/temporal/certs/server.key\"\n      clientCaFiles:\n        - \"/etc/temporal/certs/ca.crt\"\n  internode:\n    server:\n      certFile: \"/etc/temporal/certs/server.crt\"\n      keyFile: \"/etc/temporal/certs/server.key\"\n      clientCaFiles:\n        - \"/etc/temporal/certs/ca.crt\"\n      requireClientAuth: true\n    client:\n      certFile: \"/etc/temporal/certs/client.crt\"\n      keyFile: \"/etc/temporal/certs/client.key\"\n      serverCaFiles:\n        - \"/etc/temporal/certs/ca.crt\"\n\nservices:\n  frontend:\n    rpc:\n      grpcPort: 7233\n      membershipPort: 6933\n      bindOnLocalHost: false\n    metrics:\n      prometheus:\n        handlerPath: \"/metrics\"\n        listenAddress: \"0.0.0.0:9090\"\n\narchival:\n  history:\n    state: \"enabled\"\n    enableRead: true\n    provider:\n      s3store:\n        region: \"us-west-2\"\n        bucket: \"temporal-archival-prod\"\n        keyPrefix: \"temporal_archival/development\"\n  visibility:\n    state: \"enabled\"\n    enableRead: true\n    provider:\n      s3store:\n        region: \"us-west-2\"\n        bucket: \"temporal-archival-prod\"\n        keyPrefix: \"temporal_visibility_archival/development\"\n\nclusterMetadata:\n  enableGlobalNamespace: true\n  failoverVersionIncrement: 10\n  masterClusterName: \"active\"\n  currentClusterName: \"active\"\n  clusterInformation:\n    active:\n      enabled: true\n      initialFailoverVersion: 1\n      rpcName: \"frontend\"\n      rpcAddress: \"temporal-frontend.temporal.svc.cluster.local:7233\"\n\ndynamicConfigClient:\n  filepath: \"/etc/temporal/dynamicconfig/production.yaml\"\n  pollInterval: \"60s\"\n</code></pre>"},{"location":"reference/configuration/#multi-cluster-configuration","title":"Multi-Cluster Configuration","text":"<pre><code># config/examples/multi-cluster.yaml\nclusterMetadata:\n  enableGlobalNamespace: true\n  failoverVersionIncrement: 10\n  masterClusterName: \"cluster1\"\n  currentClusterName: \"cluster1\"\n  clusterInformation:\n    cluster1:\n      enabled: true\n      initialFailoverVersion: 1\n      rpcName: \"frontend\"\n      rpcAddress: \"temporal-frontend-cluster1.temporal.svc.cluster.local:7233\"\n    cluster2:\n      enabled: true\n      initialFailoverVersion: 2\n      rpcName: \"frontend\"\n      rpcAddress: \"temporal-frontend-cluster2.temporal.svc.cluster.local:7233\"\n\ndcRedirectionPolicy:\n  policy: \"selected-apis-forwarding\"\n  toDC: \"cluster2\"\n\n# Replication Configuration\nreplication:\n  replicationTaskFetcherParallelism: 4\n  replicationTaskFetcherAggregationInterval: \"2s\"\n  replicationTaskFetcherTimerJitterCoefficient: 0.15\n  replicationTaskProcessorErrorRetryMaxAttempts: 10\n  replicationTaskProcessorErrorRetryWait: \"1s\"\n  replicationTaskProcessorStartWait: \"5s\"\n  replicationTaskProcessorHostQPS: 1500\n  replicationTaskProcessorShardQPS: 100\n</code></pre> <p>This configuration reference provides comprehensive coverage of all Temporal.io configuration options, from basic development setups to complex production deployments with advanced security, observability, and performance tuning capabilities.</p>"},{"location":"reference/faq/","title":"Frequently Asked Questions (FAQ)","text":"<p>This comprehensive FAQ covers the most common questions about Temporal.io, including architecture, development, deployment, and operational concerns.</p>"},{"location":"reference/faq/#table-of-contents","title":"Table of Contents","text":"<ul> <li>General Questions</li> <li>Architecture and Concepts</li> <li>Development Questions</li> <li>Deployment and Operations</li> <li>Performance and Scaling</li> <li>Security and Compliance</li> <li>Troubleshooting</li> <li>Integrations</li> <li>Licensing and Support</li> <li>Migration and Adoption</li> </ul>"},{"location":"reference/faq/#general-questions","title":"General Questions","text":""},{"location":"reference/faq/#what-is-temporal","title":"What is Temporal?","text":"<p>Q: What is Temporal and what problems does it solve?</p> <p>A: Temporal is a distributed workflow orchestration platform that helps developers build reliable, scalable applications. It solves several key problems:</p> <ul> <li>Reliability: Automatic retries, timeouts, and failure handling</li> <li>Durability: Workflow state persists across failures and restarts</li> <li>Visibility: Complete observability into workflow execution</li> <li>Scalability: Handles millions of concurrent workflows</li> <li>Developer Experience: Simple programming model with strong consistency guarantees</li> </ul>"},{"location":"reference/faq/#how-does-temporal-work","title":"How does Temporal work?","text":"<p>Q: Can you explain Temporal's core architecture?</p> <p>A: Temporal consists of several key components:</p> <ol> <li>Temporal Server: The core orchestration engine with multiple services</li> <li>Frontend: API gateway for client requests</li> <li>History: Manages workflow state and history</li> <li>Matching: Routes tasks to workers</li> <li> <p>Worker: Internal service tasks</p> </li> <li> <p>Workers: Your application code that executes workflows and activities</p> </li> <li>Database: Stores workflow state and history (PostgreSQL, MySQL, etc.)</li> <li>Client SDKs: Libraries for Go, Java, Python, TypeScript, etc.</li> </ol> <p>Workflows are executed as code but their state is managed by the Temporal server, providing durability and reliability guarantees.</p>"},{"location":"reference/faq/#is-temporal-open-source","title":"Is Temporal open source?","text":"<p>Q: What is Temporal's licensing model?</p> <p>A: Temporal has a dual licensing model:</p> <ul> <li>Temporal Open Source: MIT licensed, free to use with community support</li> <li>Temporal Cloud: Managed service with enterprise features and support</li> <li>Temporal Enterprise: Self-hosted enterprise version with additional features</li> </ul> <p>The core Temporal Server and all client SDKs are open source and free to use.</p>"},{"location":"reference/faq/#when-should-i-use-temporal","title":"When should I use Temporal?","text":"<p>Q: What are good use cases for Temporal?</p> <p>A: Temporal is ideal for:</p> <ul> <li>Long-running workflows: Order processing, user onboarding, data pipelines</li> <li>Microservice orchestration: Coordinating multiple services</li> <li>Batch processing: ETL jobs, data migration, report generation</li> <li>Human-in-the-loop processes: Approval workflows, manual reviews</li> <li>Saga patterns: Distributed transactions with compensation</li> <li>Scheduled tasks: Cron-like jobs with complex logic</li> <li>Event-driven architectures: Processing events reliably</li> </ul>"},{"location":"reference/faq/#how-does-temporal-compare-to-other-solutions","title":"How does Temporal compare to other solutions?","text":"<p>Q: How does Temporal compare to AWS Step Functions, Apache Airflow, or Kubernetes Jobs?</p> <p>A: Here's a comparison:</p> Feature Temporal AWS Step Functions Apache Airflow Kubernetes Jobs Programming Model Code-first JSON/DSL Python DAGs YAML/Scripts Language Support Go, Java, Python, TS Limited Python mainly Any language Local Development Full simulation Limited Docker setup Complex Debugging Standard tools CloudWatch Web UI kubectl logs Testing Unit/integration Integration only DAG validation End-to-end Versioning Built-in Manual Manual Image versioning Cost Model Self-hosted or SaaS Pay-per-execution Self-hosted Infrastructure"},{"location":"reference/faq/#architecture-and-concepts","title":"Architecture and Concepts","text":""},{"location":"reference/faq/#what-are-workflows-and-activities","title":"What are Workflows and Activities?","text":"<p>Q: What's the difference between workflows and activities?</p> <p>A:  - Workflows: Orchestration logic that defines the sequence of operations. Must be deterministic and can only interact with the outside world through activities. - Activities: Individual units of work that can have side effects (API calls, database operations, file I/O). Can be retried independently.</p> <pre><code>// Workflow - orchestration only\nfunc OrderWorkflow(ctx workflow.Context, order Order) error {\n    // Schedule activities\n    var paymentResult PaymentResult\n    err := workflow.ExecuteActivity(ctx, ProcessPayment, order.Payment).Get(ctx, &amp;paymentResult)\n    if err != nil {\n        return err\n    }\n\n    // Continue with next steps...\n    return workflow.ExecuteActivity(ctx, ShipOrder, order.ShippingInfo).Get(ctx, nil)\n}\n\n// Activity - does actual work\nfunc ProcessPayment(ctx context.Context, payment PaymentInfo) (PaymentResult, error) {\n    // Call external payment API\n    return paymentAPI.ProcessPayment(payment)\n}\n</code></pre>"},{"location":"reference/faq/#what-is-determinism-and-why-is-it-important","title":"What is determinism and why is it important?","text":"<p>Q: Why do workflows need to be deterministic?</p> <p>A: Determinism ensures that replaying a workflow's history produces the same result. This is crucial because:</p> <ol> <li>Failure Recovery: Workflows can be resumed from any point</li> <li>Versioning: Old workflows can be replayed with new code</li> <li>Testing: Workflows behave predictably</li> </ol> <p>Deterministic Operations (\u2705 Allowed): - <code>workflow.ExecuteActivity()</code> - <code>workflow.Sleep()</code> - <code>workflow.Now()</code> - <code>workflow.NewRandom()</code></p> <p>Non-deterministic Operations (\u274c Avoid): - <code>time.Now()</code> - <code>rand.Int()</code> - Network calls - File I/O</p>"},{"location":"reference/faq/#how-does-temporal-handle-failures","title":"How does Temporal handle failures?","text":"<p>Q: What happens when a workflow or activity fails?</p> <p>A: Temporal provides comprehensive failure handling:</p> <p>Activity Failures: - Automatic retries with exponential backoff - Configurable retry policies - Heartbeat timeout detection - Circuit breaker patterns</p> <p>Workflow Failures: - Continue-as-new for long-running workflows - Automatic replay on worker restart - Child workflow failure propagation - Compensation patterns (Saga)</p> <p>Infrastructure Failures: - Worker process crashes \u2192 workflows resume on other workers - Database failures \u2192 automatic failover and recovery - Network partitions \u2192 eventual consistency guarantees</p>"},{"location":"reference/faq/#what-are-task-queues","title":"What are Task Queues?","text":"<p>Q: How do Task Queues work in Temporal?</p> <p>A: Task Queues are the mechanism for distributing work between the Temporal server and workers:</p> <ul> <li>Workflow Task Queues: Deliver workflow tasks (orchestration decisions)</li> <li>Activity Task Queues: Deliver activity tasks (actual work)</li> <li>Routing: Workers poll specific task queues for work</li> <li>Load Balancing: Multiple workers can poll the same queue</li> <li>Isolation: Different workflows can use different queues</li> </ul> <pre><code>// Worker polls specific task queues\nw := worker.New(client, \"order-processing\", worker.Options{})\nw.RegisterWorkflow(OrderWorkflow)\nw.RegisterActivity(ProcessPayment)\n\n// Workflow uses the same task queue\noptions := client.StartWorkflowOptions{\n    TaskQueue: \"order-processing\",\n}\n</code></pre>"},{"location":"reference/faq/#development-questions","title":"Development Questions","text":""},{"location":"reference/faq/#how-do-i-get-started-with-temporal","title":"How do I get started with Temporal?","text":"<p>Q: What's the quickest way to start developing with Temporal?</p> <p>A: Follow these steps:</p> <ol> <li> <p>Install Temporal CLI:    <pre><code>brew install temporal  # macOS\n# or download from GitHub releases\n</code></pre></p> </li> <li> <p>Start local server:    <pre><code>temporal server start-dev\n</code></pre></p> </li> <li> <p>Create a simple workflow (Go example):    <pre><code>func HelloWorldWorkflow(ctx workflow.Context, name string) (string, error) {\n    var result string\n    err := workflow.ExecuteActivity(ctx, HelloWorldActivity, name).Get(ctx, &amp;result)\n    return result, err\n}\n\nfunc HelloWorldActivity(ctx context.Context, name string) (string, error) {\n    return \"Hello \" + name, nil\n}\n</code></pre></p> </li> <li> <p>Run a worker and start workflow:    <pre><code>go run worker/main.go  # Start worker\ngo run starter/main.go # Start workflow\n</code></pre></p> </li> </ol>"},{"location":"reference/faq/#how-do-i-test-temporal-workflows","title":"How do I test Temporal workflows?","text":"<p>Q: What's the best way to test workflows and activities?</p> <p>A: Temporal provides excellent testing support:</p> <p>Unit Testing Workflows: <pre><code>func TestOrderWorkflow(t *testing.T) {\n    testSuite := &amp;testsuite.WorkflowTestSuite{}\n    env := testSuite.NewTestWorkflowEnvironment()\n\n    // Mock activity\n    env.OnActivity(ProcessPayment, mock.Anything).Return(PaymentResult{Success: true}, nil)\n\n    // Execute workflow\n    env.ExecuteWorkflow(OrderWorkflow, Order{ID: \"123\"})\n\n    // Assertions\n    require.True(t, env.IsWorkflowCompleted())\n    require.NoError(t, env.GetWorkflowError())\n}\n</code></pre></p> <p>Integration Testing: <pre><code>func TestOrderWorkflowIntegration(t *testing.T) {\n    client := createTestClient()\n\n    // Start workflow\n    workflowRun, err := client.ExecuteWorkflow(context.Background(), options, OrderWorkflow, order)\n    require.NoError(t, err)\n\n    // Wait for completion\n    var result OrderResult\n    err = workflowRun.Get(context.Background(), &amp;result)\n    require.NoError(t, err)\n}\n</code></pre></p>"},{"location":"reference/faq/#how-do-i-handle-versioning","title":"How do I handle versioning?","text":"<p>Q: How do I deploy new versions of workflows without breaking running instances?</p> <p>A: Temporal provides robust versioning support:</p> <p>Version Your Workflow Code: <pre><code>func OrderWorkflow(ctx workflow.Context, order Order) error {\n    version := workflow.GetVersion(ctx, \"add-inventory-check\", workflow.DefaultVersion, 1)\n\n    if version &gt;= 1 {\n        // New logic - check inventory first\n        err := workflow.ExecuteActivity(ctx, CheckInventory, order).Get(ctx, nil)\n        if err != nil {\n            return err\n        }\n    }\n\n    // Existing logic continues...\n    return workflow.ExecuteActivity(ctx, ProcessPayment, order).Get(ctx, nil)\n}\n</code></pre></p> <p>Use Patch for Simple Changes: <pre><code>func MyWorkflow(ctx workflow.Context) error {\n    if workflow.HasLastCompletionResult(ctx) {\n        // Continue from where we left off\n    }\n\n    // Old logic\n    workflow.ExecuteActivity(ctx, OldActivity).Get(ctx, nil)\n\n    // Add new step with patch\n    if workflow.IsReplaying(ctx) == false {\n        workflow.UpsertSearchAttributes(ctx, map[string]interface{}{\n            \"NewAttribute\": \"value\",\n        })\n    }\n\n    return nil\n}\n</code></pre></p>"},{"location":"reference/faq/#how-do-i-handle-long-running-workflows","title":"How do I handle long-running workflows?","text":"<p>Q: What about workflows that run for months or years?</p> <p>A: Temporal handles long-running workflows through several mechanisms:</p> <p>Continue-As-New Pattern: <pre><code>func LongRunningWorkflow(ctx workflow.Context, state WorkflowState) error {\n    // Process batch of work\n    for i := 0; i &lt; 1000 &amp;&amp; state.HasMoreWork(); i++ {\n        err := workflow.ExecuteActivity(ctx, ProcessItem, state.NextItem()).Get(ctx, nil)\n        if err != nil {\n            return err\n        }\n    }\n\n    // Continue with new execution to avoid large history\n    if state.HasMoreWork() {\n        return workflow.NewContinueAsNewError(ctx, LongRunningWorkflow, state)\n    }\n\n    return nil\n}\n</code></pre></p> <p>Cron Workflows: <pre><code>// Start workflow with cron schedule\noptions := client.StartWorkflowOptions{\n    CronSchedule: \"0 12 * * *\", // Daily at noon\n}\n</code></pre></p> <p>Child Workflows for Isolation: <pre><code>func ParentWorkflow(ctx workflow.Context) error {\n    for _, batch := range batches {\n        // Each batch runs in separate child workflow\n        child := workflow.ExecuteChildWorkflow(ctx, ProcessBatch, batch)\n        // Can monitor or wait for completion\n    }\n    return nil\n}\n</code></pre></p>"},{"location":"reference/faq/#how-do-i-handle-errors-and-retries","title":"How do I handle errors and retries?","text":"<p>Q: How do I configure retry policies and handle different types of errors?</p> <p>A: Temporal provides flexible error handling:</p> <p>Configure Retry Policies: <pre><code>retryPolicy := &amp;temporal.RetryPolicy{\n    InitialInterval:        time.Second,\n    BackoffCoefficient:     2.0,\n    MaximumInterval:        time.Minute,\n    MaximumAttempts:        5,\n    NonRetryableErrorTypes: []string{\"InvalidInputError\"},\n}\n\nactivityOptions := workflow.ActivityOptions{\n    TaskQueue:   \"my-queue\",\n    RetryPolicy: retryPolicy,\n}\n</code></pre></p> <p>Handle Different Error Types: <pre><code>func MyActivity(ctx context.Context, input Input) (Output, error) {\n    if input.ID == \"\" {\n        // Non-retryable error\n        return Output{}, temporal.NewNonRetryableApplicationError(\n            \"invalid input\", \"InvalidInputError\", nil)\n    }\n\n    result, err := externalAPI.Call(input)\n    if err != nil {\n        if isTemporaryError(err) {\n            // Retryable error\n            return Output{}, temporal.NewApplicationError(\n                \"service unavailable\", \"ServiceUnavailable\", err)\n        }\n        // Permanent error\n        return Output{}, temporal.NewNonRetryableApplicationError(\n            \"permanent failure\", \"PermanentError\", err)\n    }\n\n    return result, nil\n}\n</code></pre></p>"},{"location":"reference/faq/#deployment-and-operations","title":"Deployment and Operations","text":""},{"location":"reference/faq/#how-do-i-deploy-temporal","title":"How do I deploy Temporal?","text":"<p>Q: What are the deployment options for Temporal?</p> <p>A: Temporal offers several deployment options:</p> <p>1. Temporal Cloud (Recommended for production) <pre><code># Connect to Temporal Cloud\ntemporal config set address my-namespace.tmprl.cloud:7233\ntemporal config set namespace my-namespace.account\n</code></pre></p> <p>2. Self-hosted with Docker Compose <pre><code># docker-compose.yml\nversion: '3.8'\nservices:\n  temporal:\n    image: temporalio/server:latest\n    ports:\n      - \"7233:7233\"\n    environment:\n      - DB=postgresql\n      - DB_PORT=5432\n      - POSTGRES_USER=temporal\n      - POSTGRES_PWD=temporal\n</code></pre></p> <p>3. Kubernetes with Helm <pre><code>helm repo add temporalio https://charts.temporal.io\nhelm install temporal temporalio/temporal\n</code></pre></p> <p>4. Development Server <pre><code>temporal server start-dev --ui-port 8080\n</code></pre></p>"},{"location":"reference/faq/#what-are-the-infrastructure-requirements","title":"What are the infrastructure requirements?","text":"<p>Q: What infrastructure do I need to run Temporal?</p> <p>A: Minimum Requirements: - CPU: 2 cores per service - Memory: 4GB per service - Database: PostgreSQL 10+ or MySQL 8+ - Storage: 100GB+ depending on workflow volume</p> <p>Production Recommendations: - High Availability: 3+ replicas per service - Load Balancing: Frontend service behind load balancer - Database: Managed database service (AWS RDS, Google Cloud SQL) - Monitoring: Prometheus + Grafana - Logging: Structured JSON logs with centralized collection</p> <p>Scaling Guidelines: - Frontend: Scale based on request volume (1 replica per 10k RPS) - History: Scale based on workflow volume (1 replica per 100k active workflows) - Matching: Scale based on task queue load - Database: Monitor query performance and connection limits</p>"},{"location":"reference/faq/#how-do-i-monitor-temporal","title":"How do I monitor Temporal?","text":"<p>Q: What monitoring and observability tools should I use?</p> <p>A: Temporal provides comprehensive observability:</p> <p>Metrics (Prometheus/Grafana) <pre><code># Expose metrics\nglobal:\n  metrics:\n    prometheus:\n      timerType: \"histogram\"\n      listenAddress: \"0.0.0.0:9090\"\n</code></pre></p> <p>Key Metrics to Monitor: - <code>temporal_request_latency</code>: API latency - <code>temporal_workflow_completed_total</code>: Workflow completion rate - <code>temporal_activity_failed_total</code>: Activity failure rate - <code>temporal_persistence_latency</code>: Database latency</p> <p>Logging <pre><code>log:\n  stdout: true\n  level: \"info\"\n  format: \"json\"\n</code></pre></p> <p>Web UI - Built-in UI at <code>http://temporal:8080</code> - Workflow execution history - Task queue status - System health</p> <p>Custom Metrics <pre><code>// Add custom metrics to workflows\nworkflow.GetMetricsScope(ctx).Counter(\"custom_counter\").Inc(1)\nworkflow.GetMetricsScope(ctx).Gauge(\"custom_gauge\").Update(value)\n</code></pre></p>"},{"location":"reference/faq/#how-do-i-backup-and-restore-temporal","title":"How do I backup and restore Temporal?","text":"<p>Q: What's the backup and disaster recovery strategy?</p> <p>A: Database Backup: <pre><code># PostgreSQL backup\npg_dump temporal &gt; temporal_backup.sql\n\n# MySQL backup\nmysqldump temporal &gt; temporal_backup.sql\n</code></pre></p> <p>Backup Strategy: - Frequency: Daily full backups, hourly incremental - Retention: 30 days of backups - Testing: Regular restore testing - Cross-region: Backup to different region/availability zone</p> <p>Disaster Recovery: <pre><code># Restore from backup\npsql temporal &lt; temporal_backup.sql\n\n# Verify cluster health\ntemporal cluster health\n\n# Check workflow integrity\ntemporal workflow list --limit 10\n</code></pre></p> <p>Multi-Region Setup: <pre><code>clusterMetadata:\n  enableGlobalNamespace: true\n  clusterInformation:\n    cluster1:\n      enabled: true\n      rpcAddress: \"temporal-west.company.com:7233\"\n    cluster2:\n      enabled: true\n      rpcAddress: \"temporal-east.company.com:7233\"\n</code></pre></p>"},{"location":"reference/faq/#performance-and-scaling","title":"Performance and Scaling","text":""},{"location":"reference/faq/#how-does-temporal-scale","title":"How does Temporal scale?","text":"<p>Q: How many workflows can Temporal handle?</p> <p>A: Temporal can scale to handle: - Millions of concurrent workflow executions - Thousands of workflow starts per second - Petabytes of workflow history data</p> <p>Scaling Factors: - Database Performance: Primary bottleneck - Worker Capacity: CPU and memory for processing - Network Bandwidth: For high-throughput scenarios</p> <p>Scaling Strategies: <pre><code># Scale services horizontally\nhistory:\n  numShards: 16  # Increase shards for more parallelism\n  replicas: 10   # Multiple replicas per shard\n\nmatching:\n  replicas: 5    # Scale matching service\n\nfrontend:\n  replicas: 3    # Scale API layer\n</code></pre></p>"},{"location":"reference/faq/#how-do-i-optimize-performance","title":"How do I optimize performance?","text":"<p>Q: What are best practices for Temporal performance?</p> <p>A: Workflow Optimization: <pre><code>// Use batch operations\nfunc BatchWorkflow(ctx workflow.Context, items []Item) error {\n    // Process in batches instead of individual activities\n    futures := make([]workflow.Future, 0)\n    for i := 0; i &lt; len(items); i += 100 {\n        batch := items[i:min(i+100, len(items))]\n        future := workflow.ExecuteActivity(ctx, ProcessBatch, batch)\n        futures = append(futures, future)\n    }\n\n    // Wait for all batches\n    for _, future := range futures {\n        err := future.Get(ctx, nil)\n        if err != nil {\n            return err\n        }\n    }\n    return nil\n}\n</code></pre></p> <p>Activity Optimization: <pre><code>// Use appropriate timeouts\nactivityOptions := workflow.ActivityOptions{\n    StartToCloseTimeout: 30 * time.Second,  // Don't set too high\n    HeartbeatTimeout:    10 * time.Second,  // For long activities\n    RetryPolicy: &amp;temporal.RetryPolicy{\n        MaximumAttempts: 3,  // Don't retry forever\n    },\n}\n</code></pre></p> <p>Database Optimization: <pre><code>-- Add indexes for common queries\nCREATE INDEX CONCURRENTLY idx_executions_namespace_workflow_id \nON executions(namespace_id, workflow_id);\n\n-- Tune database settings\n-- shared_buffers = 25% of RAM\n-- max_connections = 200\n-- work_mem = 256MB\n</code></pre></p>"},{"location":"reference/faq/#what-are-the-resource-limits","title":"What are the resource limits?","text":"<p>Q: Are there any limits I should be aware of?</p> <p>A: Workflow Limits: - History Size: 50MB per workflow (use continue-as-new) - Input/Output: 2MB per activity/workflow - Concurrent Activities: 100k per workflow - Workflow Duration: Unlimited (years if needed)</p> <p>Activity Limits: - Execution Time: No hard limit (configure timeouts) - Heartbeat: Required for activities &gt; 10 seconds - Retry Attempts: Configurable (default: unlimited)</p> <p>System Limits: - Namespace: 10k workflows per second start rate - Task Queue: 1M tasks per minute processing rate - Database: Depends on infrastructure (typically 10k+ QPS)</p> <pre><code>// Monitor and handle limits\nfunc LargeWorkflow(ctx workflow.Context) error {\n    // Check history size\n    info := workflow.GetInfo(ctx)\n    if info.HistoryLength &gt; 10000 {\n        // Continue as new to reset history\n        return workflow.NewContinueAsNewError(ctx, LargeWorkflow)\n    }\n\n    // Process normally\n    return nil\n}\n</code></pre>"},{"location":"reference/faq/#security-and-compliance","title":"Security and Compliance","text":""},{"location":"reference/faq/#how-secure-is-temporal","title":"How secure is Temporal?","text":"<p>Q: What security features does Temporal provide?</p> <p>A: Transport Security: - TLS encryption for all communications - mTLS for service-to-service authentication - Certificate rotation support</p> <p>Authentication &amp; Authorization: - JWT token-based authentication - RBAC (Role-Based Access Control) - API key authentication - LDAP/SSO integration (Enterprise)</p> <p>Data Security: - Encryption at rest (database level) - Data converter for payload encryption - PII redaction capabilities - Audit logging</p> <pre><code>// Encrypt sensitive data\ntype EncryptedDataConverter struct {\n    temporal.DataConverter\n    encryptionKey []byte\n}\n\nfunc (edc *EncryptedDataConverter) ToPayload(value interface{}) (*commonpb.Payload, error) {\n    // Encrypt sensitive fields before storing\n    return edc.encrypt(value)\n}\n</code></pre>"},{"location":"reference/faq/#is-temporal-gdprhipaa-compliant","title":"Is Temporal GDPR/HIPAA compliant?","text":"<p>Q: Can I use Temporal for regulated workloads?</p> <p>A: Temporal can be configured for compliance:</p> <p>GDPR Compliance: - Data encryption and access controls - Right to be forgotten (workflow termination) - Data portability (export capabilities) - Audit trails and logging</p> <p>HIPAA Compliance: - Encryption in transit and at rest - Access controls and authentication - Audit logging - Business Associate Agreement (BAA) available</p> <p>Implementation: <pre><code>// GDPR data handling\nfunc HandleDataDeletionRequest(ctx workflow.Context, userID string) error {\n    // Find and terminate user workflows\n    workflows := findUserWorkflows(userID)\n    for _, wf := range workflows {\n        err := workflow.RequestCancelExternalWorkflow(ctx, wf.ID, \"\").Get(ctx, nil)\n        if err != nil {\n            return err\n        }\n    }\n\n    // Schedule data deletion activity\n    return workflow.ExecuteActivity(ctx, DeleteUserData, userID).Get(ctx, nil)\n}\n</code></pre></p>"},{"location":"reference/faq/#how-do-i-encrypt-workflow-data","title":"How do I encrypt workflow data?","text":"<p>Q: How can I encrypt sensitive data in workflows?</p> <p>A: Custom Data Converter: <pre><code>type EncryptedPayloadConverter struct {\n    temporal.DefaultDataConverter\n    options PayloadConverterOptions\n}\n\nfunc (c *EncryptedPayloadConverter) ToPayload(value interface{}) (*commonpb.Payload, error) {\n    // Check if value contains sensitive data\n    if containsSensitiveData(value) {\n        // Encrypt before storing\n        encrypted, err := c.encrypt(value)\n        if err != nil {\n            return nil, err\n        }\n        return &amp;commonpb.Payload{\n            Metadata: map[string][]byte{\n                \"encoding\":   []byte(\"binary/encrypted\"),\n                \"encryption\": []byte(\"aes256\"),\n            },\n            Data: encrypted,\n        }, nil\n    }\n\n    // Use default conversion for non-sensitive data\n    return c.DefaultDataConverter.ToPayload(value)\n}\n</code></pre></p> <p>Usage: <pre><code>// Configure client with encryption\nclient, err := client.Dial(client.Options{\n    DataConverter: NewEncryptedDataConverter(encryptionKey),\n})\n</code></pre></p>"},{"location":"reference/faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"reference/faq/#common-issues-and-solutions","title":"Common Issues and Solutions","text":"<p>Q: My workflows aren't starting. What should I check?</p> <p>A: Troubleshooting checklist:</p> <ol> <li> <p>Check worker registration: <pre><code>temporal task-queue describe my-queue --include-pollers\n</code></pre></p> </li> <li> <p>Verify workflow registration: <pre><code>// Ensure workflow is registered\nw.RegisterWorkflow(MyWorkflow)\n</code></pre></p> </li> <li> <p>Check for errors: <pre><code>temporal workflow describe --workflow-id my-workflow\n</code></pre></p> </li> <li> <p>Validate input: <pre><code>echo '{\"key\": \"value\"}' | jq .  # Validate JSON\n</code></pre></p> </li> </ol> <p>Q: My activities are timing out. How do I fix this?</p> <p>A: Activity timeout solutions:</p> <ol> <li> <p>Increase timeouts: <pre><code>activityOptions := workflow.ActivityOptions{\n    StartToCloseTimeout: 5 * time.Minute,\n    HeartbeatTimeout:    30 * time.Second,\n}\n</code></pre></p> </li> <li> <p>Add heartbeats: <pre><code>func LongActivity(ctx context.Context) error {\n    for i := 0; i &lt; 1000; i++ {\n        // Send heartbeat periodically\n        activity.RecordHeartbeat(ctx, i)\n\n        // Do work\n        processItem(i)\n    }\n    return nil\n}\n</code></pre></p> </li> <li> <p>Check worker capacity: <pre><code># Monitor worker resource usage\nkubectl top pods -l app=my-worker\n</code></pre></p> </li> </ol> <p>Q: How do I debug workflow execution?</p> <p>A: Debugging techniques:</p> <ol> <li> <p>Use local development: <pre><code>temporal server start-dev --ui-port 8080\n</code></pre></p> </li> <li> <p>Add logging: <pre><code>func MyWorkflow(ctx workflow.Context) error {\n    logger := workflow.GetLogger(ctx)\n    logger.Info(\"Starting workflow\", \"workflowID\", workflow.GetInfo(ctx).WorkflowExecution.ID)\n\n    // Your workflow logic\n    return nil\n}\n</code></pre></p> </li> <li> <p>Use the Web UI:</p> </li> <li>Navigate to <code>http://localhost:8080</code></li> <li>View workflow history and events</li> <li> <p>Check activity results and failures</p> </li> <li> <p>Query workflow state: <pre><code>// Add query handler\nworkflow.SetQueryHandler(ctx, \"getStatus\", func() (string, error) {\n    return currentStatus, nil\n})\n</code></pre></p> </li> </ol> <pre><code># Query from CLI\ntemporal workflow query --workflow-id my-workflow --type getStatus\n</code></pre>"},{"location":"reference/faq/#integrations","title":"Integrations","text":""},{"location":"reference/faq/#which-programming-languages-are-supported","title":"Which programming languages are supported?","text":"<p>Q: What SDKs are available for Temporal?</p> <p>A: Official SDKs: - Go: Full-featured, production-ready - Java: Full-featured, production-ready - Python: Full-featured, production-ready - TypeScript/Node.js: Full-featured, production-ready - PHP: Community-maintained - .NET: Community-maintained</p> <p>Language-specific features: <pre><code>// Go - Strong typing and performance\nfunc TypedWorkflow(ctx workflow.Context, input TypedInput) (TypedOutput, error) {\n    var result TypedOutput\n    err := workflow.ExecuteActivity(ctx, TypedActivity, input).Get(ctx, &amp;result)\n    return result, err\n}\n</code></pre></p> <pre><code># Python - Async/await support\n@workflow.defn\nclass MyWorkflow:\n    @workflow.run\n    async def run(self, input: MyInput) -&gt; MyOutput:\n        return await workflow.execute_activity(\n            my_activity, input, \n            start_to_close_timeout=timedelta(seconds=30)\n        )\n</code></pre>"},{"location":"reference/faq/#how-do-i-integrate-with-other-systems","title":"How do I integrate with other systems?","text":"<p>Q: How does Temporal integrate with message queues, databases, and APIs?</p> <p>A: Message Queue Integration: <pre><code>// Kafka integration\nfunc ProcessKafkaMessage(ctx context.Context, message KafkaMessage) error {\n    // Process message in activity\n    return processMessage(message)\n}\n\nfunc KafkaConsumerWorkflow(ctx workflow.Context) error {\n    // Long-running workflow that processes messages\n    for {\n        var message KafkaMessage\n        err := workflow.ExecuteActivity(ctx, ConsumeKafkaMessage).Get(ctx, &amp;message)\n        if err != nil {\n            continue\n        }\n\n        // Process message\n        err = workflow.ExecuteActivity(ctx, ProcessKafkaMessage, message).Get(ctx, nil)\n        if err != nil {\n            // Handle error or retry\n        }\n    }\n}\n</code></pre></p> <p>Database Integration: <pre><code>// Database operations in activities\nfunc UpdateUserActivity(ctx context.Context, userID string, data UserData) error {\n    db := getDatabase()\n    _, err := db.ExecContext(ctx, \"UPDATE users SET data = $1 WHERE id = $2\", data, userID)\n    return err\n}\n\n// Saga pattern for distributed transactions\nfunc SagaWorkflow(ctx workflow.Context, order Order) error {\n    compensations := make([]workflow.Future, 0)\n\n    // Step 1: Reserve inventory\n    err := workflow.ExecuteActivity(ctx, ReserveInventory, order).Get(ctx, nil)\n    if err != nil {\n        return err\n    }\n    compensations = append(compensations, workflow.ExecuteActivity(ctx, ReleaseInventory, order))\n\n    // Step 2: Process payment\n    err = workflow.ExecuteActivity(ctx, ProcessPayment, order).Get(ctx, nil)\n    if err != nil {\n        // Compensate previous steps\n        for _, compensation := range compensations {\n            compensation.Get(ctx, nil)\n        }\n        return err\n    }\n\n    return nil\n}\n</code></pre></p> <p>API Integration: <pre><code>// REST API calls\nfunc CallExternalAPI(ctx context.Context, request APIRequest) (APIResponse, error) {\n    client := &amp;http.Client{Timeout: 30 * time.Second}\n\n    resp, err := client.Post(request.URL, \"application/json\", bytes.NewBuffer(request.Body))\n    if err != nil {\n        return APIResponse{}, err\n    }\n    defer resp.Body.Close()\n\n    var response APIResponse\n    err = json.NewDecoder(resp.Body).Decode(&amp;response)\n    return response, err\n}\n</code></pre></p>"},{"location":"reference/faq/#can-i-use-temporal-with-kubernetes","title":"Can I use Temporal with Kubernetes?","text":"<p>Q: How do I deploy Temporal workers in Kubernetes?</p> <p>A: Worker Deployment: <pre><code># worker-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: temporal-worker\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: temporal-worker\n  template:\n    metadata:\n      labels:\n        app: temporal-worker\n    spec:\n      containers:\n      - name: worker\n        image: my-temporal-worker:latest\n        env:\n        - name: TEMPORAL_ADDRESS\n          value: \"temporal-frontend:7233\"\n        - name: TEMPORAL_NAMESPACE\n          value: \"default\"\n        resources:\n          requests:\n            memory: \"512Mi\"\n            cpu: \"500m\"\n          limits:\n            memory: \"1Gi\"\n            cpu: \"1000m\"\n</code></pre></p> <p>Horizontal Pod Autoscaler: <pre><code># worker-hpa.yaml\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: temporal-worker-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: temporal-worker\n  minReplicas: 3\n  maxReplicas: 10\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n</code></pre></p>"},{"location":"reference/faq/#licensing-and-support","title":"Licensing and Support","text":""},{"location":"reference/faq/#what-support-options-are-available","title":"What support options are available?","text":"<p>Q: How do I get help with Temporal?</p> <p>A: Support Channels:</p> <p>Community Support (Free): - Temporal Community Forum - GitHub Issues - Stack Overflow - Discord Community</p> <p>Professional Support: - Temporal Cloud: Included with managed service - Enterprise Support: 24/7 support with SLA - Professional Services: Implementation assistance</p> <p>Documentation: - Official Documentation - API Reference - Sample Applications</p>"},{"location":"reference/faq/#whats-included-in-temporal-cloud","title":"What's included in Temporal Cloud?","text":"<p>Q: What are the benefits of Temporal Cloud vs self-hosting?</p> <p>A: Temporal Cloud Benefits: - Managed Infrastructure: No server management - Auto-scaling: Handles traffic spikes automatically - High Availability: 99.9% uptime SLA - Security: SOC 2, GDPR compliant - Monitoring: Built-in observability - Support: Included professional support</p> <p>Pricing Model: - Pay-per-workflow execution - No infrastructure costs - Predictable billing - Free tier available</p> <p>Migration: <pre><code># Export from self-hosted\ntemporal workflow list --output json &gt; workflows.json\n\n# Import to Temporal Cloud\ntemporal --address my-namespace.tmprl.cloud:7233 workflow start ...\n</code></pre></p>"},{"location":"reference/faq/#migration-and-adoption","title":"Migration and Adoption","text":""},{"location":"reference/faq/#how-do-i-migrate-from-other-workflow-engines","title":"How do I migrate from other workflow engines?","text":"<p>Q: I'm using AWS Step Functions/Apache Airflow. How do I migrate?</p> <p>A: Migration Strategy:</p> <p>1. Assessment Phase: - Inventory existing workflows - Identify dependencies and integrations - Plan migration order (simple workflows first)</p> <p>2. Incremental Migration: <pre><code>// Wrapper for existing Step Functions\nfunc MigrateStepFunction(ctx workflow.Context, input StepFunctionInput) error {\n    // Option 1: Call existing Step Function during migration\n    if workflow.GetVersion(ctx, \"migration\", workflow.DefaultVersion, 1) == workflow.DefaultVersion {\n        return workflow.ExecuteActivity(ctx, CallStepFunction, input).Get(ctx, nil)\n    }\n\n    // Option 2: Native Temporal implementation\n    return workflow.ExecuteActivity(ctx, NativeImplementation, input).Get(ctx, nil)\n}\n</code></pre></p> <p>3. Data Migration: <pre><code># Export Step Functions execution history\naws stepfunctions list-executions --state-machine-arn arn:aws:...\n\n# Convert to Temporal format and import\ntemporal workflow start --workflow-type MigratedWorkflow --input converted_data.json\n</code></pre></p>"},{"location":"reference/faq/#how-do-i-introduce-temporal-to-my-team","title":"How do I introduce Temporal to my team?","text":"<p>Q: What's the best way to adopt Temporal in an organization?</p> <p>A: Adoption Strategy:</p> <p>1. Start Small: - Choose a simple, non-critical workflow - Build proof of concept - Demonstrate value to stakeholders</p> <p>2. Training and Education: - Hands-on workshops - Code reviews and pair programming - Internal documentation and best practices</p> <p>3. Gradual Rollout: <pre><code>// Feature flag approach\nfunc NewOrderWorkflow(ctx workflow.Context, order Order) error {\n    if useTemporalWorkflow(order) {\n        return TemporalOrderWorkflow(ctx, order)\n    }\n\n    // Fall back to existing system\n    return LegacyOrderWorkflow(ctx, order)\n}\n</code></pre></p> <p>4. Success Metrics: - Reduced development time - Improved reliability (fewer failures) - Better observability - Developer satisfaction</p> <p>5. Common Concerns and Responses:</p> Concern Response \"Another tool to learn\" \"Temporal reduces complexity overall by eliminating custom retry logic, state management, and error handling\" \"Vendor lock-in\" \"Temporal is open source with standard programming languages - easy to migrate if needed\" \"Performance overhead\" \"Temporal typically improves performance by optimizing retries and eliminating polling patterns\" \"Infrastructure complexity\" \"Start with Temporal Cloud to avoid infrastructure management\" <p>This comprehensive FAQ covers the most common questions about Temporal.io across all aspects of development, deployment, and operations.</p>"},{"location":"reference/troubleshooting-guide/","title":"Troubleshooting Guide","text":"<p>This comprehensive troubleshooting guide helps diagnose and resolve common issues with Temporal.io deployments, workflows, activities, and operational problems.</p>"},{"location":"reference/troubleshooting-guide/#table-of-contents","title":"Table of Contents","text":"<ul> <li>General Troubleshooting</li> <li>Connection Issues</li> <li>Workflow Issues</li> <li>Activity Issues</li> <li>Worker Issues</li> <li>Performance Issues</li> <li>Database Issues</li> <li>Security Issues</li> <li>Monitoring and Observability</li> <li>Common Error Messages</li> <li>Debugging Tools</li> <li>Recovery Procedures</li> </ul>"},{"location":"reference/troubleshooting-guide/#general-troubleshooting","title":"General Troubleshooting","text":""},{"location":"reference/troubleshooting-guide/#initial-diagnosis-steps","title":"Initial Diagnosis Steps","text":"<ol> <li> <p>Check Service Health <pre><code># Check cluster health\ntemporal cluster health\n\n# Check individual service status\ncurl -f http://temporal-frontend:7233/health\ncurl -f http://temporal-history:7234/health\ncurl -f http://temporal-matching:7235/health\ncurl -f http://temporal-worker:7239/health\n</code></pre></p> </li> <li> <p>Verify Configuration <pre><code># Check current configuration\ntemporal config get\n\n# Verify connectivity\ntemporal namespace list\n</code></pre></p> </li> <li> <p>Check Logs <pre><code># View service logs\nkubectl logs -n temporal-system deployment/temporal-frontend\nkubectl logs -n temporal-system deployment/temporal-history\nkubectl logs -n temporal-system deployment/temporal-matching\nkubectl logs -n temporal-system deployment/temporal-worker\n</code></pre></p> </li> <li> <p>Verify Database Connectivity <pre><code># Test database connection\ntemporal sql-tool \\\n  --database temporal \\\n  --plugin postgres \\\n  --endpoint postgres://user:pass@localhost/temporal \\\n  show-tables\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting-guide/#environment-verification-checklist","title":"Environment Verification Checklist","text":"<ul> <li> All services are running and healthy</li> <li> Database is accessible and contains expected schema</li> <li> Network connectivity between services</li> <li> TLS certificates are valid (if using TLS)</li> <li> Authentication configuration is correct</li> <li> Environment variables are set properly</li> <li> Resource limits are sufficient</li> </ul>"},{"location":"reference/troubleshooting-guide/#connection-issues","title":"Connection Issues","text":""},{"location":"reference/troubleshooting-guide/#cannot-connect-to-temporal-server","title":"Cannot Connect to Temporal Server","text":"<p>Symptoms: - Client timeout errors - Connection refused messages - DNS resolution failures</p> <p>Diagnosis: <pre><code># Test basic connectivity\ntelnet temporal.company.com 7233\n\n# Check DNS resolution\nnslookup temporal.company.com\n\n# Test with curl\ncurl -v grpc://temporal.company.com:7233\n\n# Check certificate validity (if using TLS)\nopenssl s_client -connect temporal.company.com:7233 -servername temporal.company.com\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Network Connectivity Issues <pre><code># Check firewall rules\nsudo iptables -L\n\n# Test from different network locations\nping temporal.company.com\ntraceroute temporal.company.com\n</code></pre></p> </li> <li> <p>TLS Configuration Problems <pre><code># Verify certificate chain\nopenssl verify -CAfile ca.crt client.crt\n\n# Check certificate expiration\nopenssl x509 -in client.crt -noout -dates\n\n# Test with proper TLS config\ntemporal --tls-cert-path client.crt \\\n        --tls-key-path client.key \\\n        --tls-ca-path ca.crt \\\n        --address temporal.company.com:7233 \\\n        namespace list\n</code></pre></p> </li> <li> <p>Load Balancer Issues <pre><code># Test direct backend connection\ntemporal --address temporal-frontend-1.company.com:7233 namespace list\n\n# Check load balancer health\ncurl -f http://load-balancer/health\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting-guide/#authentication-failures","title":"Authentication Failures","text":"<p>Symptoms: - \"Unauthenticated\" error messages - JWT token validation failures - API key rejection</p> <p>Diagnosis: <pre><code># Test without authentication\ntemporal --address temporal.company.com:7233 cluster health\n\n# Verify JWT token\njwt-cli decode your-jwt-token\n\n# Check API key format\necho \"Authorization: Bearer $API_KEY\" | base64 -d\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>JWT Token Issues <pre><code># Generate new token\njwt-cli encode \\\n  --iss \"https://auth.company.com\" \\\n  --sub \"user@company.com\" \\\n  --aud \"temporal.company.com\" \\\n  --exp $(date -d \"+1 hour\" +%s) \\\n  --secret \"your-secret\"\n\n# Verify token claims\ntemporal --headers \"Authorization=Bearer $JWT_TOKEN\" namespace list\n</code></pre></p> </li> <li> <p>API Key Problems <pre><code># Set API key correctly\nexport TEMPORAL_API_KEY=\"your-api-key\"\ntemporal config set auth.api-key \"$TEMPORAL_API_KEY\"\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting-guide/#workflow-issues","title":"Workflow Issues","text":""},{"location":"reference/troubleshooting-guide/#workflow-not-starting","title":"Workflow Not Starting","text":"<p>Symptoms: - Workflow start command hangs - \"Already exists\" errors - Task queue not found</p> <p>Diagnosis: <pre><code># Check workflow existence\ntemporal workflow describe --workflow-id my-workflow\n\n# Verify task queue\ntemporal task-queue describe my-task-queue\n\n# Check namespace\ntemporal namespace describe my-namespace\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Workflow ID Conflicts <pre><code># Use unique workflow ID\ntemporal workflow start \\\n  --workflow-type MyWorkflow \\\n  --task-queue my-queue \\\n  --workflow-id \"my-workflow-$(date +%s)\" \\\n  --input '{}'\n\n# Or allow duplicate failed executions\ntemporal workflow start \\\n  --workflow-type MyWorkflow \\\n  --task-queue my-queue \\\n  --workflow-id my-workflow \\\n  --workflow-id-reuse-policy AllowDuplicateFailedOnly \\\n  --input '{}'\n</code></pre></p> </li> <li> <p>Task Queue Issues <pre><code># Create/verify task queue by starting a worker\ntemporal worker start \\\n  --task-queue my-queue \\\n  --workflow-type MyWorkflow\n</code></pre></p> </li> <li> <p>Input Validation Problems <pre><code># Validate JSON input\necho '{\"key\": \"value\"}' | jq .\n\n# Use input file for complex data\ntemporal workflow start \\\n  --workflow-type MyWorkflow \\\n  --task-queue my-queue \\\n  --workflow-id my-workflow \\\n  --input-file input.json\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting-guide/#workflow-stuck-or-not-progressing","title":"Workflow Stuck or Not Progressing","text":"<p>Symptoms: - Workflow shows as running but no progress - Activities not being scheduled - No worker polling</p> <p>Diagnosis: <pre><code># Check workflow history\ntemporal workflow show --workflow-id my-workflow\n\n# Check task queue pollers\ntemporal task-queue describe my-queue --include-pollers\n\n# Check for sticky task queue issues\ntemporal workflow describe --workflow-id my-workflow --raw | grep sticky\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>No Workers Polling <pre><code># Start worker for the task queue\ntemporal worker start \\\n  --task-queue my-queue \\\n  --workflow-type MyWorkflow \\\n  --activity-type MyActivity\n</code></pre></p> </li> <li> <p>Sticky Task Queue Problems <pre><code># Reset workflow to clear sticky queue\ntemporal workflow reset \\\n  --workflow-id my-workflow \\\n  --type LastWorkflowTask \\\n  --reason \"Clear sticky queue\"\n</code></pre></p> </li> <li> <p>Workflow Task Timeout <pre><code># Check for workflow task timeouts in history\ntemporal workflow show --workflow-id my-workflow | grep -i timeout\n\n# Increase workflow task timeout\ntemporal workflow start \\\n  --workflow-type MyWorkflow \\\n  --task-queue my-queue \\\n  --workflow-id my-workflow \\\n  --workflow-task-timeout 60s \\\n  --input '{}'\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting-guide/#workflow-failures","title":"Workflow Failures","text":"<p>Symptoms: - Workflow execution failed - Unexpected termination - Panic in workflow code</p> <p>Diagnosis: <pre><code># Check failure details\ntemporal workflow show --workflow-id my-workflow | grep -A 10 -i \"failed\\|error\"\n\n# Get failure reason\ntemporal workflow describe --workflow-id my-workflow | grep -i failure\n\n# Check worker logs\nkubectl logs -l app=my-worker --tail=100\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Handle Application Errors <pre><code>// Go example - proper error handling\nfunc MyWorkflow(ctx workflow.Context, input MyInput) (MyOutput, error) {\n    var result MyOutput\n    err := workflow.ExecuteActivity(ctx, MyActivity, input).Get(ctx, &amp;result)\n    if err != nil {\n        // Handle specific error types\n        if temporal.IsApplicationError(err) {\n            // Log and potentially retry\n            workflow.GetLogger(ctx).Error(\"Application error\", \"error\", err)\n            return MyOutput{}, err\n        }\n        // Handle other error types\n        return MyOutput{}, err\n    }\n    return result, nil\n}\n</code></pre></p> </li> <li> <p>Fix Determinism Issues <pre><code>// Avoid non-deterministic operations\nfunc MyWorkflow(ctx workflow.Context) error {\n    // WRONG: Don't use time.Now() directly\n    // now := time.Now()\n\n    // CORRECT: Use workflow.Now()\n    now := workflow.Now(ctx)\n\n    // WRONG: Don't use random numbers directly\n    // rand := rand.Intn(100)\n\n    // CORRECT: Use workflow.NewRandom()\n    rand := workflow.NewRandom(ctx).Intn(100)\n\n    return nil\n}\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting-guide/#activity-issues","title":"Activity Issues","text":""},{"location":"reference/troubleshooting-guide/#activity-timeouts","title":"Activity Timeouts","text":"<p>Symptoms: - Activity timeout errors - Activities appearing to hang - Heartbeat timeout failures</p> <p>Diagnosis: <pre><code># Check activity details\ntemporal workflow show --workflow-id my-workflow | grep -A 5 -i activity\n\n# Look for timeout-related events\ntemporal workflow show --workflow-id my-workflow | grep -i timeout\n\n# Check activity configuration\ntemporal workflow describe --workflow-id my-workflow --raw | jq '.workflowExecutionInfo.type'\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Configure Appropriate Timeouts <pre><code>// Go example - proper activity options\nao := workflow.ActivityOptions{\n    TaskQueue:               \"my-queue\",\n    ScheduleToCloseTimeout:  time.Hour,     // Total time allowed\n    ScheduleToStartTimeout:  time.Minute,   // Time to start execution\n    StartToCloseTimeout:     30 * time.Minute, // Execution time\n    HeartbeatTimeout:        time.Minute,   // Heartbeat interval\n    RetryPolicy: &amp;temporal.RetryPolicy{\n        InitialInterval:    time.Second,\n        BackoffCoefficient: 2.0,\n        MaximumInterval:    time.Minute,\n        MaximumAttempts:    3,\n    },\n}\nctx = workflow.WithActivityOptions(ctx, ao)\n</code></pre></p> </li> <li> <p>Implement Activity Heartbeats <pre><code>// Go example - activity with heartbeat\nfunc MyLongRunningActivity(ctx context.Context, input MyInput) (MyOutput, error) {\n    for i := 0; i &lt; 100; i++ {\n        // Do some work\n        processItem(input.Items[i])\n\n        // Send heartbeat every iteration\n        activity.RecordHeartbeat(ctx, i)\n\n        // Check for cancellation\n        if ctx.Err() != nil {\n            return MyOutput{}, ctx.Err()\n        }\n    }\n    return MyOutput{}, nil\n}\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting-guide/#activity-retries-and-failures","title":"Activity Retries and Failures","text":"<p>Symptoms: - Activities failing repeatedly - Exhausted retry attempts - Non-retryable errors</p> <p>Diagnosis: <pre><code># Check activity retry history\ntemporal workflow show --workflow-id my-workflow --event-type ActivityTaskFailed,ActivityTaskCompleted\n\n# Check error details\ntemporal workflow show --workflow-id my-workflow | grep -A 20 \"ActivityTaskFailed\"\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Configure Retry Policies <pre><code>// Go example - retry policy configuration\nretryPolicy := &amp;temporal.RetryPolicy{\n    InitialInterval:        time.Second,\n    BackoffCoefficient:     2.0,\n    MaximumInterval:        time.Minute,\n    MaximumAttempts:        5,\n    NonRetryableErrorTypes: []string{\"InvalidArgumentError\"},\n}\n\nao := workflow.ActivityOptions{\n    TaskQueue:   \"my-queue\",\n    RetryPolicy: retryPolicy,\n}\n</code></pre></p> </li> <li> <p>Handle Errors Appropriately <pre><code>// Go example - error classification\nfunc MyActivity(ctx context.Context, input MyInput) (MyOutput, error) {\n    if input.ID == \"\" {\n        // Non-retryable error\n        return MyOutput{}, temporal.NewNonRetryableApplicationError(\n            \"invalid input\", \"InvalidArgumentError\", nil)\n    }\n\n    result, err := externalService.Call(input)\n    if err != nil {\n        if isTransientError(err) {\n            // Retryable error\n            return MyOutput{}, temporal.NewApplicationError(\n                \"service unavailable\", \"ServiceUnavailable\", err)\n        }\n        // Non-retryable error\n        return MyOutput{}, temporal.NewNonRetryableApplicationError(\n            \"permanent failure\", \"PermanentFailure\", err)\n    }\n\n    return result, nil\n}\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting-guide/#worker-issues","title":"Worker Issues","text":""},{"location":"reference/troubleshooting-guide/#worker-not-polling","title":"Worker Not Polling","text":"<p>Symptoms: - No tasks being processed - Task queue shows no pollers - Worker appears to be running but idle</p> <p>Diagnosis: <pre><code># Check worker registration\ntemporal task-queue describe my-queue --include-pollers\n\n# Check worker logs\nkubectl logs -l app=my-worker\n\n# Verify worker configuration\nps aux | grep temporal-worker\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Verify Worker Configuration <pre><code>// Go example - proper worker setup\nc, err := client.Dial(client.Options{\n    HostPort:  \"temporal.company.com:7233\",\n    Namespace: \"my-namespace\",\n})\nif err != nil {\n    log.Fatal(\"Unable to create client\", err)\n}\ndefer c.Close()\n\nw := worker.New(c, \"my-queue\", worker.Options{\n    MaxConcurrentActivityExecutionSize: 100,\n    MaxConcurrentWorkflowTaskExecutionSize: 100,\n})\n\n// Register workflows and activities\nw.RegisterWorkflow(MyWorkflow)\nw.RegisterActivity(MyActivity)\n\nerr = w.Run(worker.InterruptCh())\nif err != nil {\n    log.Fatal(\"Unable to start worker\", err)\n}\n</code></pre></p> </li> <li> <p>Check Network Connectivity <pre><code># Test connection from worker host\ntelnet temporal.company.com 7233\n\n# Check DNS resolution\nnslookup temporal.company.com\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting-guide/#worker-performance-issues","title":"Worker Performance Issues","text":"<p>Symptoms: - High CPU or memory usage - Slow task processing - Worker crashes or restarts</p> <p>Diagnosis: <pre><code># Check resource usage\ntop -p $(pgrep temporal-worker)\nps aux | grep temporal-worker\n\n# Check memory usage\ncat /proc/$(pgrep temporal-worker)/status | grep -i mem\n\n# Check goroutine count (Go workers)\ncurl http://localhost:8080/debug/pprof/goroutine?debug=1\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Tune Worker Configuration <pre><code>// Go example - optimized worker options\nw := worker.New(c, \"my-queue\", worker.Options{\n    MaxConcurrentActivityExecutionSize:     100,  // Adjust based on activity type\n    MaxConcurrentWorkflowTaskExecutionSize: 100,  // Usually lower than activities\n    MaxConcurrentActivityTaskPollers:       10,   // Number of pollers\n    MaxConcurrentWorkflowTaskPollers:       10,   // Number of pollers\n})\n</code></pre></p> </li> <li> <p>Monitor and Profile <pre><code>// Enable pprof endpoint\nimport _ \"net/http/pprof\"\n\nfunc init() {\n    go func() {\n        log.Println(http.ListenAndServe(\"localhost:6060\", nil))\n    }()\n}\n</code></pre></p> </li> <li> <p>Implement Resource Management <pre><code>// Go example - activity resource management\nfunc MyActivity(ctx context.Context, input MyInput) (MyOutput, error) {\n    // Limit memory usage\n    runtime.GC()\n\n    // Use context for cancellation\n    select {\n    case &lt;-ctx.Done():\n        return MyOutput{}, ctx.Err()\n    default:\n        // Process normally\n    }\n\n    return processInput(input), nil\n}\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting-guide/#performance-issues","title":"Performance Issues","text":""},{"location":"reference/troubleshooting-guide/#high-latency","title":"High Latency","text":"<p>Symptoms: - Slow workflow execution - High response times - Delayed task processing</p> <p>Diagnosis: <pre><code># Check service metrics\ncurl http://temporal-frontend:9090/metrics | grep temporal_request_latency\n\n# Monitor database performance\nEXPLAIN ANALYZE SELECT * FROM executions WHERE namespace_id = 'my-namespace';\n\n# Check network latency\nping temporal.company.com\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Database Optimization <pre><code>-- Add database indexes\nCREATE INDEX CONCURRENTLY idx_executions_namespace_workflow_id \nON executions(namespace_id, workflow_id);\n\n-- Analyze query plans\nEXPLAIN (ANALYZE, BUFFERS) \nSELECT * FROM executions \nWHERE namespace_id = 'my-namespace' \nAND workflow_id = 'my-workflow';\n</code></pre></p> </li> <li> <p>Configure Connection Pools <pre><code># Database configuration\npersistence:\n  defaultStore: default\n  datastores:\n    default:\n      sql:\n        maxConns: 50           # Increase connection pool\n        maxIdleConns: 25       # Keep idle connections\n        maxConnLifetime: \"1h\"  # Connection lifetime\n</code></pre></p> </li> <li> <p>Tune Service Configuration <pre><code># History service tuning\nhistory:\n  taskProcessRPS: 2000          # Increase task processing rate\n  persistenceMaxQPS: 5000       # Increase persistence QPS\n\n# Frontend service tuning  \nfrontend:\n  rps: 10000                    # Increase rate limits\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting-guide/#high-resource-usage","title":"High Resource Usage","text":"<p>Symptoms: - High CPU or memory usage - OOM kills - Disk space issues</p> <p>Diagnosis: <pre><code># Monitor resource usage\nkubectl top pods -n temporal-system\n\n# Check memory usage\nkubectl describe pod temporal-history-xxx -n temporal-system\n\n# Monitor disk usage\ndf -h\ndu -sh /var/lib/temporal/*\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Resource Limit Configuration <pre><code># Kubernetes resource limits\nresources:\n  limits:\n    memory: \"4Gi\"\n    cpu: \"2000m\"\n  requests:\n    memory: \"2Gi\"\n    cpu: \"1000m\"\n</code></pre></p> </li> <li> <p>Memory Management <pre><code># JVM heap size configuration\nenv:\n  - name: JVM_HEAP_SIZE\n    value: \"3g\"\n  - name: GC_OPTS\n    value: \"-XX:+UseG1GC -XX:MaxGCPauseMillis=200\"\n</code></pre></p> </li> <li> <p>Data Retention Policies <pre><code># Configure retention periods\nnamespaceDefaults:\n  retention: \"7d\"              # Reduce retention period\n\narchival:\n  history:\n    state: \"enabled\"           # Enable archival\n    enableRead: true\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting-guide/#database-issues","title":"Database Issues","text":""},{"location":"reference/troubleshooting-guide/#connection-pool-exhaustion","title":"Connection Pool Exhaustion","text":"<p>Symptoms: - \"Too many connections\" errors - Connection timeouts - Database unavailable errors</p> <p>Diagnosis: <pre><code>-- Check active connections\nSELECT count(*) FROM pg_stat_activity WHERE state = 'active';\n\n-- Check connection limits\nSHOW max_connections;\n\n-- Monitor connection usage\nSELECT datname, count(*) FROM pg_stat_activity GROUP BY datname;\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Tune Connection Pool Settings <pre><code>persistence:\n  datastores:\n    default:\n      sql:\n        maxConns: 20           # Reduce if too high\n        maxIdleConns: 10       # Maintain idle connections\n        maxConnLifetime: \"1h\"  # Recycle connections\n</code></pre></p> </li> <li> <p>Database Configuration <pre><code># postgresql.conf\nmax_connections = 200\nshared_buffers = 256MB\neffective_cache_size = 1GB\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting-guide/#slow-queries","title":"Slow Queries","text":"<p>Symptoms: - Database performance issues - Query timeouts - High database load</p> <p>Diagnosis: <pre><code>-- Enable query logging\nSET log_statement = 'all';\nSET log_min_duration_statement = 1000;  -- Log queries &gt; 1s\n\n-- Check slow queries\nSELECT query, mean_time, calls, total_time \nFROM pg_stat_statements \nORDER BY mean_time DESC \nLIMIT 10;\n\n-- Check table sizes\nSELECT schemaname, tablename, pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) \nFROM pg_tables \nWHERE schemaname = 'temporal';\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Add Database Indexes <pre><code>-- Common indexes for Temporal\nCREATE INDEX CONCURRENTLY idx_executions_namespace_workflow_id \nON executions(namespace_id, workflow_id);\n\nCREATE INDEX CONCURRENTLY idx_executions_state \nON executions(namespace_id, state);\n\nCREATE INDEX CONCURRENTLY idx_history_events_workflow_id \nON history_events(namespace_id, workflow_id, run_id);\n</code></pre></p> </li> <li> <p>Database Maintenance <pre><code>-- Update statistics\nANALYZE;\n\n-- Vacuum tables\nVACUUM ANALYZE executions;\nVACUUM ANALYZE history_events;\n\n-- Reindex if needed\nREINDEX TABLE executions;\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting-guide/#security-issues","title":"Security Issues","text":""},{"location":"reference/troubleshooting-guide/#tls-certificate-problems","title":"TLS Certificate Problems","text":"<p>Symptoms: - Certificate verification failures - Expired certificate errors - Certificate chain issues</p> <p>Diagnosis: <pre><code># Check certificate validity\nopenssl x509 -in client.crt -noout -dates\n\n# Verify certificate chain\nopenssl verify -CAfile ca.crt client.crt\n\n# Test TLS connection\nopenssl s_client -connect temporal.company.com:7233 -cert client.crt -key client.key\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Certificate Renewal <pre><code># Generate new certificate\nopenssl req -new -key client.key -out client.csr\n\n# Sign with CA\nopenssl x509 -req -in client.csr -CA ca.crt -CAkey ca.key -out client.crt -days 365\n\n# Update configuration\ntemporal config set tls.cert-path /path/to/new/client.crt\n</code></pre></p> </li> <li> <p>Certificate Chain Issues <pre><code># Create proper certificate chain\ncat client.crt intermediate.crt &gt; client-chain.crt\n\n# Use chain certificate\ntemporal config set tls.cert-path /path/to/client-chain.crt\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting-guide/#authentication-issues","title":"Authentication Issues","text":"<p>Symptoms: - Authentication failures - Permission denied errors - Token validation failures</p> <p>Diagnosis: <pre><code># Test without authentication\ntemporal --address temporal.company.com:7233 --disable-tls cluster health\n\n# Validate JWT token\njwt-cli decode $JWT_TOKEN\n\n# Check RBAC configuration\ntemporal operator cluster describe\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Fix JWT Configuration <pre><code># Ensure JWT is properly formatted\nexport JWT_TOKEN=$(jwt-cli encode \\\n  --iss \"https://auth.company.com\" \\\n  --sub \"user@company.com\" \\\n  --aud \"temporal.company.com\" \\\n  --exp $(date -d \"+1 hour\" +%s) \\\n  --secret \"your-secret\")\n\ntemporal --headers \"Authorization=Bearer $JWT_TOKEN\" namespace list\n</code></pre></p> </li> <li> <p>Configure RBAC Properly <pre><code>authorization:\n  rbac:\n    enabled: true\n    policies:\n      - role: \"developer\"\n        permissions:\n          - \"temporal:workflow:start\"\n          - \"temporal:workflow:read\"\n        resources:\n          - \"namespace:development\"\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting-guide/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"reference/troubleshooting-guide/#missing-metrics","title":"Missing Metrics","text":"<p>Symptoms: - No metrics being exported - Missing dashboards data - Prometheus scraping failures</p> <p>Diagnosis: <pre><code># Check metrics endpoint\ncurl http://temporal-frontend:9090/metrics\n\n# Test Prometheus scraping\ncurl http://prometheus:9090/api/v1/query?query=temporal_request_latency\n\n# Check service configuration\nkubectl describe configmap temporal-config -n temporal-system\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Enable Metrics Export <pre><code>global:\n  metrics:\n    prometheus:\n      timerType: \"histogram\"\n      listenAddress: \"0.0.0.0:9090\"\n</code></pre></p> </li> <li> <p>Configure Prometheus Scraping <pre><code># prometheus.yml\nscrape_configs:\n  - job_name: 'temporal'\n    static_configs:\n      - targets: ['temporal-frontend:9090']\n    metrics_path: /metrics\n    scrape_interval: 30s\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting-guide/#log-analysis-issues","title":"Log Analysis Issues","text":"<p>Symptoms: - Missing log entries - Log parsing failures - Insufficient log details</p> <p>Solutions:</p> <ol> <li> <p>Configure Structured Logging <pre><code>log:\n  stdout: true\n  level: \"info\"\n  format: \"json\"\n</code></pre></p> </li> <li> <p>Log Aggregation Setup <pre><code># Fluentd configuration\n&lt;source&gt;\n  @type tail\n  path /var/log/temporal/*.log\n  pos_file /var/log/fluentd/temporal.log.pos\n  tag temporal.*\n  format json\n&lt;/source&gt;\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting-guide/#common-error-messages","title":"Common Error Messages","text":""},{"location":"reference/troubleshooting-guide/#workflow-execution-already-started","title":"\"Workflow execution already started\"","text":"<p>Error: <code>WorkflowExecutionAlreadyStartedError</code></p> <p>Cause: Attempting to start a workflow with an existing workflow ID</p> <p>Solution: <pre><code># Use unique workflow ID\ntemporal workflow start \\\n  --workflow-id \"unique-id-$(date +%s)\" \\\n  --workflow-type MyWorkflow \\\n  --task-queue my-queue\n\n# Or allow duplicate failed executions\ntemporal workflow start \\\n  --workflow-id my-workflow \\\n  --workflow-id-reuse-policy AllowDuplicateFailedOnly \\\n  --workflow-type MyWorkflow \\\n  --task-queue my-queue\n</code></pre></p>"},{"location":"reference/troubleshooting-guide/#task-queue-not-found","title":"\"Task queue not found\"","text":"<p>Error: <code>BadRequestError: Task queue not found</code></p> <p>Cause: No workers polling the specified task queue</p> <p>Solution: <pre><code># Start a worker for the task queue\ntemporal worker start \\\n  --task-queue my-queue \\\n  --workflow-type MyWorkflow \\\n  --activity-type MyActivity\n</code></pre></p>"},{"location":"reference/troubleshooting-guide/#deadline-exceeded","title":"\"Deadline exceeded\"","text":"<p>Error: <code>DeadlineExceeded: context deadline exceeded</code></p> <p>Cause: Operation timeout, network issues, or server overload</p> <p>Solution: <pre><code># Increase timeout\ntemporal --timeout 60s workflow describe --workflow-id my-workflow\n\n# Check network connectivity\ntelnet temporal.company.com 7233\n\n# Check server health\ntemporal cluster health\n</code></pre></p>"},{"location":"reference/troubleshooting-guide/#permission-denied","title":"\"Permission denied\"","text":"<p>Error: <code>PermissionDenied: access denied</code></p> <p>Cause: Insufficient permissions or authentication issues</p> <p>Solution: <pre><code># Check authentication\ntemporal --headers \"Authorization=Bearer $JWT_TOKEN\" namespace list\n\n# Verify permissions\ntemporal operator cluster describe | grep -i auth\n</code></pre></p>"},{"location":"reference/troubleshooting-guide/#debugging-tools","title":"Debugging Tools","text":""},{"location":"reference/troubleshooting-guide/#enable-debug-logging","title":"Enable Debug Logging","text":"<pre><code># Enable debug logging for CLI\nexport TEMPORAL_CLI_LOG_LEVEL=debug\ntemporal workflow describe --workflow-id my-workflow\n\n# Enable debug logging for services\nkubectl set env deployment/temporal-frontend LOG_LEVEL=debug -n temporal-system\n</code></pre>"},{"location":"reference/troubleshooting-guide/#use-development-tools","title":"Use Development Tools","text":"<pre><code># Start development server with debug\ntemporal server start-dev --log-level debug --ui-port 8080\n\n# Enable pprof for Go workers\ngo tool pprof http://worker:6060/debug/pprof/profile\n</code></pre>"},{"location":"reference/troubleshooting-guide/#network-debugging","title":"Network Debugging","text":"<pre><code># Capture network traffic\ntcpdump -i any -w temporal.pcap port 7233\n\n# Analyze with wireshark\nwireshark temporal.pcap\n\n# Test gRPC connectivity\ngrpcurl -plaintext temporal.company.com:7233 list\n</code></pre>"},{"location":"reference/troubleshooting-guide/#recovery-procedures","title":"Recovery Procedures","text":""},{"location":"reference/troubleshooting-guide/#workflow-recovery","title":"Workflow Recovery","text":"<pre><code># Reset workflow to specific event\ntemporal workflow reset \\\n  --workflow-id stuck-workflow \\\n  --event-id 42 \\\n  --reason \"Recovery from corrupted state\"\n\n# Reset to last workflow task\ntemporal workflow reset \\\n  --workflow-id stuck-workflow \\\n  --type LastWorkflowTask \\\n  --reason \"Retry with fixed worker\"\n</code></pre>"},{"location":"reference/troubleshooting-guide/#database-recovery","title":"Database Recovery","text":"<pre><code>-- Backup before recovery\npg_dump temporal &gt; temporal_backup.sql\n\n-- Repair corrupted data\nUPDATE executions SET state = 1 WHERE state IS NULL;\n\n-- Rebuild indexes\nREINDEX DATABASE temporal;\n</code></pre>"},{"location":"reference/troubleshooting-guide/#service-recovery","title":"Service Recovery","text":"<pre><code># Restart specific service\nkubectl rollout restart deployment/temporal-history -n temporal-system\n\n# Drain and restart nodes\nkubectl drain node-name --ignore-daemonsets\nkubectl uncordon node-name\n\n# Scale services\nkubectl scale deployment/temporal-frontend --replicas=3 -n temporal-system\n</code></pre> <p>This comprehensive troubleshooting guide provides systematic approaches to diagnosing and resolving common Temporal.io issues, from connection problems to complex workflow recovery scenarios.</p>"},{"location":"reference/whats-new/","title":"What's New in Temporal.io","text":"<p>This document highlights the latest features and improvements in Temporal.io from versions 1.26 through 1.29.</p>"},{"location":"reference/whats-new/#temporal-server-129x-october-2025","title":"Temporal Server 1.29.x (October 2025)","text":""},{"location":"reference/whats-new/#key-features","title":"\ud83d\ude80 Key Features","text":""},{"location":"reference/whats-new/#eager-workflow-start-ga-default-enabled","title":"Eager Workflow Start (GA - Default Enabled)","text":"<p>Eager workflow start is now generally available and enabled by default. This feature significantly reduces the latency of starting workflows by executing the first workflow task immediately on the same worker that started the workflow.</p> <p>Benefits: - Reduced workflow start latency by up to 50% - Lower load on the history service - Improved overall system throughput</p> <p>Configuration: <pre><code>server:\n  config:\n    services:\n      frontend:\n        eagerWorkflowStartEnabled: true  # Default in 1.29+\n</code></pre></p>"},{"location":"reference/whats-new/#task-queue-fairness-pre-release","title":"Task Queue Fairness (Pre-release)","text":"<p>Priority-based task distribution within task queues to ensure fair resource allocation across different workflow types.</p> <p>Use Case: Prevent high-volume workflows from starving low-volume critical workflows.</p> <pre><code># Example: Setting workflow priority\nfrom temporalio import workflow\n\n@workflow.defn\nclass CriticalWorkflow:\n    @workflow.run\n    async def run(self) -&gt; str:\n        # This workflow gets higher priority\n        return \"critical task\"\n\n# Start with priority\nawait client.start_workflow(\n    CriticalWorkflow.run,\n    id=\"critical-wf-001\",\n    task_queue=\"critical-queue\",\n    task_queue_priority=10  # Higher number = higher priority\n)\n</code></pre>"},{"location":"reference/whats-new/#breaking-changes","title":"\u26a0\ufe0f Breaking Changes","text":""},{"location":"reference/whats-new/#slimmed-docker-images","title":"Slimmed Docker Images","text":"<p>Starting with 1.29.x, official Docker images are significantly smaller: - Removed unnecessary dependencies - Multi-stage builds for optimized size - Security improvements with minimal attack surface</p> <p>Migration: Update your Kubernetes manifests if they rely on tools that were previously bundled.</p>"},{"location":"reference/whats-new/#improvements","title":"\ud83d\udd27 Improvements","text":"<ul> <li>Activity and Workflow Metrics Changes: Enhanced metrics with better cardinality control</li> <li>Priority and Workflow Versioning Fixes: Resolved issues in priority handling and versioning features</li> <li>Workflow Retry Bug Fixes: Improved reliability in workflow retry scenarios</li> </ul>"},{"location":"reference/whats-new/#temporal-server-128x-june-2025","title":"Temporal Server 1.28.x (June 2025)","text":""},{"location":"reference/whats-new/#major-features","title":"\ud83c\udfaf Major Features","text":""},{"location":"reference/whats-new/#update-with-start-ga","title":"Update-With-Start (GA)","text":"<p>Update-With-Start is now generally available, allowing you to update a workflow at the same time you start it.</p> <p>Use Case: Ensure workflows are created with the latest state without race conditions.</p> <pre><code>from temporalio.client import Client, WorkflowUpdateStage\n\n# Start workflow with update\nhandle = await client.start_workflow(\n    MyWorkflow.run,\n    id=\"workflow-123\",\n    task_queue=\"my-queue\",\n    start_signal=\"initialize\",\n    start_signal_args=[\"initial_data\"]\n)\n\n# Or update existing, start if not exists\ntry:\n    result = await client.get_workflow_handle(\"workflow-123\").execute_update(\n        \"updateMethod\",\n        args=[\"new_data\"],\n        wait_for_stage=WorkflowUpdateStage.ACCEPTED,\n        start_workflow=True,  # Start if doesn't exist\n        start_workflow_operation=StartWorkflowOperation(\n            MyWorkflow.run,\n            task_queue=\"my-queue\"\n        )\n    )\nexcept WorkflowAlreadyStartedError:\n    # Workflow already exists\n    pass\n</code></pre>"},{"location":"reference/whats-new/#versioning-safe-deploy-public-preview","title":"Versioning / Safe-Deploy (Public Preview)","text":"<p>Worker deployment versioning enables safe rollout of workflow code changes without disrupting running workflows.</p> <p>Key Capabilities: - Pin running workflows to specific worker versions - Gradual rollout of new workflow code - Automatic routing based on worker build IDs</p> <pre><code>from temporalio.worker import Worker\n\n# Register worker with build ID\nworker = Worker(\n    client,\n    task_queue=\"my-queue\",\n    workflows=[MyWorkflow],\n    activities=[my_activity],\n    build_id=\"v2.1.0\",  # Version identifier\n    use_worker_versioning=True\n)\n</code></pre>"},{"location":"reference/whats-new/#simple-priority-for-task-queues-pre-release","title":"Simple Priority for Task Queues (Pre-release)","text":"<p>Assign priorities to task queues for better resource management.</p> <pre><code>server:\n  config:\n    services:\n      matching:\n        taskQueuePriorityEnabled: true\n</code></pre>"},{"location":"reference/whats-new/#schema-changes","title":"\ud83d\udcca Schema Changes","text":"<ul> <li>MySQL Schema v1.17</li> <li>PostgreSQL Schema v1.17</li> <li>Cassandra Schema v1.12</li> </ul> <p>Migration Required: Run schema upgrade tools before deploying 1.28.x.</p> <pre><code># PostgreSQL upgrade\ntemporal-sql-tool --plugin postgres12 \\\n  --ep postgresql.example.com \\\n  -u temporal \\\n  -p 5432 \\\n  --db temporal update-schema \\\n  -d /path/to/temporal/schema/postgresql/v12\n</code></pre>"},{"location":"reference/whats-new/#temporal-server-127x-february-2025","title":"Temporal Server 1.27.x (February 2025)","text":""},{"location":"reference/whats-new/#nexus-ga","title":"\ud83c\udf10 Nexus (GA)","text":"<p>Nexus is now generally available, providing cross-namespace and cross-cluster workflow orchestration.</p> <p>Use Cases: - Microservices orchestration across teams - Multi-tenant workflow coordination - Cross-cluster workflow dependencies</p> <pre><code>from temporalio import workflow\nfrom temporalio.workflow import nexus_operation\n\n@workflow.defn\nclass ParentWorkflow:\n    @workflow.run\n    async def run(self) -&gt; str:\n        # Call operation in different namespace/cluster\n        result = await nexus_operation(\n            \"remote-service\",\n            \"processData\",\n            args=[\"data\"],\n            nexus_endpoint=\"https://remote-cluster.temporal.io\"\n        )\n        return result\n</code></pre>"},{"location":"reference/whats-new/#safe-deploys","title":"\ud83d\ude80 Safe Deploys","text":"<p>Enhanced worker versioning capabilities: - Build ID-based workflow routing - Automatic reachability checking - Gradual traffic shifting</p>"},{"location":"reference/whats-new/#visibility-schema-changes","title":"\ud83d\uddc4\ufe0f Visibility Schema Changes","text":"<p>Updates to visibility schema for improved search performance and new query capabilities.</p>"},{"location":"reference/whats-new/#temporal-server-126x-december-2024","title":"Temporal Server 1.26.x (December 2024)","text":""},{"location":"reference/whats-new/#workflow-update-ga","title":"\u2705 Workflow Update (GA)","text":"<p>Workflow Update API is now generally available, allowing external systems to synchronously update running workflows.</p> <p>Benefits: - Synchronous workflow mutations - Type-safe update handlers - Guaranteed execution ordering</p> <pre><code>from temporalio import workflow\n\n@workflow.defn\nclass OrderWorkflow:\n    def __init__(self) -&gt; None:\n        self._status = \"pending\"\n\n    @workflow.run\n    async def run(self, order_id: str) -&gt; str:\n        # Workflow logic\n        await workflow.wait_condition(lambda: self._status == \"completed\")\n        return \"done\"\n\n    @workflow.update\n    def update_status(self, new_status: str) -&gt; str:\n        \"\"\"Update handler - called synchronously from client\"\"\"\n        old_status = self._status\n        self._status = new_status\n        return f\"Updated from {old_status} to {new_status}\"\n\n# Client code\nhandle = await client.get_workflow_handle(\"order-123\")\nresult = await handle.execute_update(\n    OrderWorkflow.update_status,\n    \"processing\"\n)\nprint(result)  # \"Updated from pending to processing\"\n</code></pre>"},{"location":"reference/whats-new/#update-with-start-public-preview","title":"\ud83d\udd04 Update-With-Start (Public Preview)","text":"<p>Early preview of the update-with-start feature (GA in 1.28).</p>"},{"location":"reference/whats-new/#migration-guide","title":"Migration Guide","text":""},{"location":"reference/whats-new/#upgrading-to-129x","title":"Upgrading to 1.29.x","text":"<ol> <li> <p>Update Docker Images: <pre><code>server:\n  image:\n    repository: temporalio/server\n    tag: 1.29.1\n</code></pre></p> </li> <li> <p>Review Metrics Changes: Check your monitoring dashboards for renamed or removed metrics.</p> </li> <li> <p>Test Eager Workflow Start: Verify your workflows work correctly with eager start (enabled by default).</p> </li> <li> <p>Update SDKs:</p> </li> <li>Python SDK: 1.18.2+</li> <li>Go SDK: Latest compatible version</li> <li>Java SDK: Latest compatible version</li> </ol>"},{"location":"reference/whats-new/#upgrading-from-120x-to-129x","title":"Upgrading from 1.20.x to 1.29.x","text":"<ol> <li> <p>Database Schema Upgrades: <pre><code># Run all intermediate schema migrations\n# From 1.20 -&gt; 1.26 -&gt; 1.28 -&gt; 1.29\ntemporal-sql-tool --plugin postgres12 update-schema\n</code></pre></p> </li> <li> <p>Review Breaking Changes:</p> </li> <li>Docker image changes in 1.29</li> <li>Metrics changes across versions</li> <li> <p>API deprecations</p> </li> <li> <p>Test in Staging:</p> </li> <li>Deploy to non-production environment first</li> <li>Verify existing workflows continue properly</li> <li> <p>Test new features incrementally</p> </li> <li> <p>Rolling Upgrade Strategy: <pre><code># 1. Upgrade database schema\ntemporal-sql-tool update-schema\n\n# 2. Upgrade server components one by one\nkubectl rollout restart deployment/temporal-frontend -n temporal-backend\nkubectl rollout status deployment/temporal-frontend -n temporal-backend\n\nkubectl rollout restart deployment/temporal-history -n temporal-backend\nkubectl rollout status deployment/temporal-history -n temporal-backend\n\n# 3. Update workers after server is stable\nkubectl rollout restart deployment/temporal-workers -n temporal-product\n</code></pre></p> </li> </ol>"},{"location":"reference/whats-new/#deprecated-features","title":"Deprecated Features","text":""},{"location":"reference/whats-new/#version-128","title":"Version 1.28+","text":"<ul> <li>Legacy metrics format: Migrate to new metrics format</li> <li>Old authorization plugin API: Use new authorizer interface</li> </ul>"},{"location":"reference/whats-new/#version-129","title":"Version 1.29+","text":"<ul> <li>Bundled tools in Docker images: Use separate tool images</li> </ul>"},{"location":"reference/whats-new/#performance-improvements","title":"Performance Improvements","text":""},{"location":"reference/whats-new/#129x","title":"1.29.x","text":"<ul> <li>50% reduction in workflow start latency (eager start)</li> <li>30% improvement in task queue throughput</li> <li>Reduced memory footprint in history service</li> </ul>"},{"location":"reference/whats-new/#128x","title":"1.28.x","text":"<ul> <li>Improved query performance with schema changes</li> <li>Better connection pooling for database operations</li> <li>Optimized workflow search with enhanced visibility</li> </ul>"},{"location":"reference/whats-new/#127x","title":"1.27.x","text":"<ul> <li>Cross-cluster operations with Nexus (minimal overhead)</li> <li>Worker versioning with efficient routing</li> </ul>"},{"location":"reference/whats-new/#resources","title":"Resources","text":"<ul> <li>Official Release Notes</li> <li>Upgrade Guide</li> <li>Schema Migration Tools</li> <li>Breaking Changes Policy</li> </ul>"},{"location":"reference/whats-new/#next-steps","title":"Next Steps","text":"<ol> <li>Review the complete implementation guide</li> <li>Update your Helm configurations</li> <li>Test new features in development environment</li> <li>Plan your upgrade strategy</li> </ol>"},{"location":"security/auth/","title":"Authentication &amp; Authorization","text":"<p>This guide provides comprehensive authentication and authorization strategies for Temporal.io deployments, ensuring secure access control across all components including server, workers, and client applications.</p>"},{"location":"security/auth/#overview","title":"Overview","text":"<p>Temporal.io security involves multiple layers: - Authentication: Verifying identity of users and services - Authorization: Controlling access to resources and operations - mTLS: Mutual TLS for service-to-service communication - RBAC: Role-based access control for fine-grained permissions - Integration: OIDC, LDAP, and custom authentication providers</p>"},{"location":"security/auth/#architecture","title":"Architecture","text":"<pre><code>graph TB\n    subgraph \"External Authentication\"\n        OIDC[OIDC Provider]\n        LDAP[LDAP/AD]\n        CUSTOM[Custom Auth]\n    end\n\n    subgraph \"Temporal Cluster\"\n        FRONTEND[Frontend Service]\n        HISTORY[History Service]\n        MATCHING[Matching Service]\n        WORKER[Worker Service]\n\n        subgraph \"Authorization\"\n            AUTHZ[Authorizer Plugin]\n            RBAC[RBAC Rules]\n            CLAIMS[Claims Mapper]\n        end\n    end\n\n    subgraph \"Clients &amp; Workers\"\n        SDK[SDK Client]\n        CLI[Temporal CLI]\n        UI[Web UI]\n        WORKERS[Application Workers]\n    end\n\n    subgraph \"Certificate Authority\"\n        CA[Root CA]\n        INTER[Intermediate CA]\n        CERTS[Client Certificates]\n    end\n\n    OIDC --&gt; FRONTEND\n    LDAP --&gt; FRONTEND\n    CUSTOM --&gt; FRONTEND\n\n    FRONTEND --&gt; AUTHZ\n    AUTHZ --&gt; RBAC\n    AUTHZ --&gt; CLAIMS\n\n    SDK --&gt; FRONTEND\n    CLI --&gt; FRONTEND\n    UI --&gt; FRONTEND\n    WORKERS --&gt; FRONTEND\n\n    CA --&gt; INTER\n    INTER --&gt; CERTS\n    CERTS --&gt; SDK\n    CERTS --&gt; WORKERS</code></pre>"},{"location":"security/auth/#authentication-methods","title":"Authentication Methods","text":""},{"location":"security/auth/#1-api-key-authentication","title":"1. API Key Authentication","text":""},{"location":"security/auth/#server-configuration","title":"Server Configuration","text":"<pre><code># config/auth-config.yaml\nauth:\n  enabled: true\n  authorizer: \"api-key\"\n  token_key_id: \"temporal-api-key\"\n\nglobal:\n  authorization:\n    jwtKeyProvider:\n      keySourceURIs:\n        - \"https://auth.company.com/.well-known/jwks.json\"\n    permissionsClaimName: \"permissions\"\n    authorizer: \"api-key\"\n</code></pre>"},{"location":"security/auth/#api-key-management","title":"API Key Management","text":"<pre><code>// auth/api-key-manager.go\npackage auth\n\nimport (\n    \"context\"\n    \"crypto/rand\"\n    \"encoding/base64\"\n    \"fmt\"\n    \"time\"\n\n    \"github.com/golang-jwt/jwt/v4\"\n)\n\ntype APIKeyManager struct {\n    signingKey []byte\n    issuer     string\n    audience   string\n}\n\ntype APIKeyClaims struct {\n    UserID      string   `json:\"user_id\"`\n    Permissions []string `json:\"permissions\"`\n    Namespaces  []string `json:\"namespaces\"`\n    jwt.RegisteredClaims\n}\n\nfunc NewAPIKeyManager(signingKey []byte, issuer, audience string) *APIKeyManager {\n    return &amp;APIKeyManager{\n        signingKey: signingKey,\n        issuer:     issuer,\n        audience:   audience,\n    }\n}\n\nfunc (m *APIKeyManager) GenerateAPIKey(userID string, permissions, namespaces []string, expiry time.Duration) (string, error) {\n    now := time.Now()\n    claims := APIKeyClaims{\n        UserID:      userID,\n        Permissions: permissions,\n        Namespaces:  namespaces,\n        RegisteredClaims: jwt.RegisteredClaims{\n            Issuer:    m.issuer,\n            Audience:  jwt.ClaimStrings{m.audience},\n            Subject:   userID,\n            IssuedAt:  jwt.NewNumericDate(now),\n            ExpiresAt: jwt.NewNumericDate(now.Add(expiry)),\n            NotBefore: jwt.NewNumericDate(now),\n            ID:        generateJTI(),\n        },\n    }\n\n    token := jwt.NewWithClaims(jwt.SigningMethodHS256, claims)\n    return token.SignedString(m.signingKey)\n}\n\nfunc (m *APIKeyManager) ValidateAPIKey(tokenString string) (*APIKeyClaims, error) {\n    token, err := jwt.ParseWithClaims(tokenString, &amp;APIKeyClaims{}, func(token *jwt.Token) (interface{}, error) {\n        if _, ok := token.Method.(*jwt.SigningMethodHMAC); !ok {\n            return nil, fmt.Errorf(\"unexpected signing method: %v\", token.Header[\"alg\"])\n        }\n        return m.signingKey, nil\n    })\n\n    if err != nil {\n        return nil, err\n    }\n\n    if claims, ok := token.Claims.(*APIKeyClaims); ok &amp;&amp; token.Valid {\n        return claims, nil\n    }\n\n    return nil, fmt.Errorf(\"invalid token\")\n}\n\nfunc generateJTI() string {\n    bytes := make([]byte, 16)\n    rand.Read(bytes)\n    return base64.URLEncoding.EncodeToString(bytes)\n}\n</code></pre>"},{"location":"security/auth/#client-usage","title":"Client Usage","text":"<pre><code>// client/auth-client.go\npackage client\n\nimport (\n    \"context\"\n    \"crypto/tls\"\n\n    \"go.temporal.io/sdk/client\"\n)\n\nfunc NewAuthenticatedClient(hostPort, namespace, apiKey string) (client.Client, error) {\n    return client.Dial(client.Options{\n        HostPort:  hostPort,\n        Namespace: namespace,\n        ConnectionOptions: client.ConnectionOptions{\n            TLS: &amp;tls.Config{\n                ServerName: \"temporal.company.com\",\n            },\n        },\n        Credentials: client.NewAPIKeyStaticCredentials(apiKey),\n    })\n}\n</code></pre>"},{"location":"security/auth/#2-oidc-authentication","title":"2. OIDC Authentication","text":""},{"location":"security/auth/#oidc-configuration","title":"OIDC Configuration","text":"<pre><code># config/oidc-config.yaml\nauth:\n  enabled: true\n  authorizer: \"oidc\"\n\nglobal:\n  authorization:\n    jwtKeyProvider:\n      keySourceURIs:\n        - \"https://auth.company.com/.well-known/jwks.json\"\n      refreshInterval: \"1h\"\n    permissionsClaimName: \"permissions\"\n    authorizer: \"oidc\"\n\noidc:\n  issuer_url: \"https://auth.company.com\"\n  client_id: \"temporal-cluster\"\n  client_secret: \"${OIDC_CLIENT_SECRET}\"\n  scopes:\n    - \"openid\"\n    - \"profile\"\n    - \"email\"\n    - \"temporal:read\"\n    - \"temporal:write\"\n  redirect_urls:\n    - \"https://temporal.company.com/auth/callback\"\n  claims_mapping:\n    user_id: \"sub\"\n    email: \"email\"\n    groups: \"groups\"\n    permissions: \"temporal_permissions\"\n</code></pre>"},{"location":"security/auth/#oidc-integration","title":"OIDC Integration","text":"<pre><code>// auth/oidc-provider.go\npackage auth\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"fmt\"\n    \"net/http\"\n\n    \"github.com/coreos/go-oidc/v3/oidc\"\n    \"golang.org/x/oauth2\"\n)\n\ntype OIDCProvider struct {\n    provider     *oidc.Provider\n    oauth2Config oauth2.Config\n    verifier     *oidc.IDTokenVerifier\n}\n\ntype OIDCConfig struct {\n    IssuerURL    string   `json:\"issuer_url\"`\n    ClientID     string   `json:\"client_id\"`\n    ClientSecret string   `json:\"client_secret\"`\n    RedirectURL  string   `json:\"redirect_url\"`\n    Scopes       []string `json:\"scopes\"`\n}\n\nfunc NewOIDCProvider(ctx context.Context, config OIDCConfig) (*OIDCProvider, error) {\n    provider, err := oidc.NewProvider(ctx, config.IssuerURL)\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to create OIDC provider: %w\", err)\n    }\n\n    oauth2Config := oauth2.Config{\n        ClientID:     config.ClientID,\n        ClientSecret: config.ClientSecret,\n        RedirectURL:  config.RedirectURL,\n        Endpoint:     provider.Endpoint(),\n        Scopes:       config.Scopes,\n    }\n\n    verifier := provider.Verifier(&amp;oidc.Config{\n        ClientID: config.ClientID,\n    })\n\n    return &amp;OIDCProvider{\n        provider:     provider,\n        oauth2Config: oauth2Config,\n        verifier:     verifier,\n    }, nil\n}\n\nfunc (p *OIDCProvider) GetAuthURL(state string) string {\n    return p.oauth2Config.AuthCodeURL(state, oauth2.AccessTypeOffline)\n}\n\nfunc (p *OIDCProvider) ExchangeCode(ctx context.Context, code string) (*oidc.IDToken, error) {\n    token, err := p.oauth2Config.Exchange(ctx, code)\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to exchange code: %w\", err)\n    }\n\n    rawIDToken, ok := token.Extra(\"id_token\").(string)\n    if !ok {\n        return nil, fmt.Errorf(\"no id_token in response\")\n    }\n\n    idToken, err := p.verifier.Verify(ctx, rawIDToken)\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to verify ID token: %w\", err)\n    }\n\n    return idToken, nil\n}\n\ntype UserClaims struct {\n    Sub         string   `json:\"sub\"`\n    Email       string   `json:\"email\"`\n    Groups      []string `json:\"groups\"`\n    Permissions []string `json:\"temporal_permissions\"`\n}\n\nfunc (p *OIDCProvider) ParseClaims(idToken *oidc.IDToken) (*UserClaims, error) {\n    var claims UserClaims\n    if err := idToken.Claims(&amp;claims); err != nil {\n        return nil, fmt.Errorf(\"failed to parse claims: %w\", err)\n    }\n    return &amp;claims, nil\n}\n</code></pre>"},{"location":"security/auth/#3-mtls-authentication","title":"3. mTLS Authentication","text":""},{"location":"security/auth/#certificate-generation","title":"Certificate Generation","text":"<pre><code>#!/bin/bash\n# scripts/generate-certs.sh\n\nset -euo pipefail\n\nCERT_DIR=\"certs\"\nCA_KEY=\"$CERT_DIR/ca-key.pem\"\nCA_CERT=\"$CERT_DIR/ca-cert.pem\"\nDAYS_VALID=3650\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\nerror() {\n    echo -e \"\\033[0;31m[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1\\033[0m\"\n    exit 1\n}\n\n# Create certificate directory\nmkdir -p \"$CERT_DIR\"\n\n# Generate CA private key\nif [[ ! -f \"$CA_KEY\" ]]; then\n    log \"Generating CA private key...\"\n    openssl genrsa -out \"$CA_KEY\" 4096\n    chmod 600 \"$CA_KEY\"\nfi\n\n# Generate CA certificate\nif [[ ! -f \"$CA_CERT\" ]]; then\n    log \"Generating CA certificate...\"\n    openssl req -new -x509 -key \"$CA_KEY\" -sha256 -subj \"/C=US/ST=CA/O=Company/CN=Temporal CA\" -days $DAYS_VALID -out \"$CA_CERT\"\nfi\n\n# Function to generate client/server certificates\ngenerate_cert() {\n    local name=\"$1\"\n    local common_name=\"$2\"\n    local san=\"${3:-}\"\n\n    local key_file=\"$CERT_DIR/${name}-key.pem\"\n    local csr_file=\"$CERT_DIR/${name}-csr.pem\"\n    local cert_file=\"$CERT_DIR/${name}-cert.pem\"\n\n    # Generate private key\n    log \"Generating private key for $name...\"\n    openssl genrsa -out \"$key_file\" 2048\n    chmod 600 \"$key_file\"\n\n    # Create certificate signing request\n    log \"Creating CSR for $name...\"\n    if [[ -n \"$san\" ]]; then\n        # Create config file for SAN\n        local config_file=\"$CERT_DIR/${name}.conf\"\n        cat &gt; \"$config_file\" &lt;&lt; EOF\n[req]\ndistinguished_name = req_distinguished_name\nreq_extensions = v3_req\nprompt = no\n\n[req_distinguished_name]\nC = US\nST = CA\nO = Company\nCN = $common_name\n\n[v3_req]\nkeyUsage = keyEncipherment, dataEncipherment\nextendedKeyUsage = serverAuth, clientAuth\nsubjectAltName = @alt_names\n\n[alt_names]\nDNS.1 = $common_name\n$san\nEOF\n        openssl req -new -key \"$key_file\" -out \"$csr_file\" -config \"$config_file\"\n\n        # Sign certificate with CA\n        log \"Signing certificate for $name...\"\n        openssl x509 -req -in \"$csr_file\" -CA \"$CA_CERT\" -CAkey \"$CA_KEY\" -CAcreateserial -out \"$cert_file\" -days $DAYS_VALID -extensions v3_req -extfile \"$config_file\"\n\n        # Clean up\n        rm \"$config_file\" \"$csr_file\"\n    else\n        openssl req -new -key \"$key_file\" -out \"$csr_file\" -subj \"/C=US/ST=CA/O=Company/CN=$common_name\"\n\n        # Sign certificate with CA\n        log \"Signing certificate for $name...\"\n        openssl x509 -req -in \"$csr_file\" -CA \"$CA_CERT\" -CAkey \"$CA_KEY\" -CAcreateserial -out \"$cert_file\" -days $DAYS_VALID\n\n        # Clean up\n        rm \"$csr_file\"\n    fi\n\n    log \"\u2713 Generated certificate for $name: $cert_file\"\n}\n\n# Generate server certificate\ngenerate_cert \"server\" \"temporal.company.com\" \"DNS.2 = temporal-frontend\nDNS.3 = temporal-frontend.temporal.svc.cluster.local\nDNS.4 = localhost\nIP.1 = 127.0.0.1\"\n\n# Generate client certificates\ngenerate_cert \"client\" \"temporal-client\"\ngenerate_cert \"worker\" \"temporal-worker\"\ngenerate_cert \"admin\" \"temporal-admin\"\n\nlog \"\u2713 All certificates generated successfully!\"\nlog \"CA Certificate: $CA_CERT\"\nlog \"Use these certificates for mTLS authentication with Temporal\"\n</code></pre>"},{"location":"security/auth/#mtls-configuration","title":"mTLS Configuration","text":"<pre><code># config/mtls-config.yaml\ntls:\n  # Server TLS configuration\n  frontend:\n    server:\n      certFile: \"/etc/temporal/certs/server-cert.pem\"\n      keyFile: \"/etc/temporal/certs/server-key.pem\"\n      clientCaFiles:\n        - \"/etc/temporal/certs/ca-cert.pem\"\n      requireClientAuth: true\n\n  # Internal service communication\n  internode:\n    server:\n      certFile: \"/etc/temporal/certs/server-cert.pem\"\n      keyFile: \"/etc/temporal/certs/server-key.pem\"\n      clientCaFiles:\n        - \"/etc/temporal/certs/ca-cert.pem\"\n      requireClientAuth: true\n    client:\n      certFile: \"/etc/temporal/certs/client-cert.pem\"\n      keyFile: \"/etc/temporal/certs/client-key.pem\"\n      serverCaFiles:\n        - \"/etc/temporal/certs/ca-cert.pem\"\n      serverName: \"temporal.company.com\"\n\n# Database TLS\npersistence:\n  default:\n    sql:\n      tls:\n        enabled: true\n        caFile: \"/etc/temporal/certs/ca-cert.pem\"\n        certFile: \"/etc/temporal/certs/client-cert.pem\"\n        keyFile: \"/etc/temporal/certs/client-key.pem\"\n        serverName: \"postgres.company.com\"\n</code></pre>"},{"location":"security/auth/#authorization-framework","title":"Authorization Framework","text":""},{"location":"security/auth/#1-custom-authorizer-plugin","title":"1. Custom Authorizer Plugin","text":""},{"location":"security/auth/#plugin-interface","title":"Plugin Interface","text":"<pre><code>// auth/authorizer.go\npackage auth\n\nimport (\n    \"context\"\n\n    \"go.temporal.io/server/common/authorization\"\n)\n\ntype TemporalAuthorizer struct {\n    rbacProvider RBACProvider\n    logger       log.Logger\n}\n\nfunc NewTemporalAuthorizer(rbacProvider RBACProvider, logger log.Logger) authorization.Authorizer {\n    return &amp;TemporalAuthorizer{\n        rbacProvider: rbacProvider,\n        logger:       logger,\n    }\n}\n\nfunc (a *TemporalAuthorizer) Authorize(ctx context.Context, claims *authorization.Claims, target *authorization.CallTarget) (authorization.Result, error) {\n    // Extract user information from claims\n    userID := claims.Subject\n    if userID == \"\" {\n        return authorization.Result{Decision: authorization.DecisionDeny}, nil\n    }\n\n    // Get user permissions\n    permissions, err := a.rbacProvider.GetUserPermissions(ctx, userID)\n    if err != nil {\n        a.logger.Error(\"Failed to get user permissions\", tag.Error(err), tag.WorkflowID(userID))\n        return authorization.Result{Decision: authorization.DecisionDeny}, err\n    }\n\n    // Check if user has required permission for the target\n    required := getRequiredPermission(target)\n    if !hasPermission(permissions, required) {\n        a.logger.Warn(\"User denied access\", \n            tag.WorkflowID(userID), \n            tag.Value(\"required\", required),\n            tag.Value(\"target\", target.APIName))\n        return authorization.Result{Decision: authorization.DecisionDeny}, nil\n    }\n\n    return authorization.Result{Decision: authorization.DecisionAllow}, nil\n}\n\nfunc getRequiredPermission(target *authorization.CallTarget) string {\n    switch target.APIName {\n    case \"StartWorkflowExecution\":\n        return \"temporal:workflow:start\"\n    case \"TerminateWorkflowExecution\":\n        return \"temporal:workflow:terminate\"\n    case \"DescribeWorkflowExecution\":\n        return \"temporal:workflow:read\"\n    case \"ListWorkflowExecutions\":\n        return \"temporal:workflow:list\"\n    case \"GetWorkflowExecutionHistory\":\n        return \"temporal:workflow:history\"\n    case \"SignalWorkflowExecution\":\n        return \"temporal:workflow:signal\"\n    case \"QueryWorkflow\":\n        return \"temporal:workflow:query\"\n    case \"CreateSchedule\":\n        return \"temporal:schedule:create\"\n    case \"UpdateSchedule\":\n        return \"temporal:schedule:update\"\n    case \"DeleteSchedule\":\n        return \"temporal:schedule:delete\"\n    case \"DescribeNamespace\":\n        return \"temporal:namespace:read\"\n    case \"ListNamespaces\":\n        return \"temporal:namespace:list\"\n    default:\n        return \"temporal:unknown\"\n    }\n}\n\nfunc hasPermission(userPermissions []string, required string) bool {\n    for _, perm := range userPermissions {\n        if perm == required || perm == \"temporal:admin\" {\n            return true\n        }\n        // Check wildcard permissions\n        if matchesWildcard(perm, required) {\n            return true\n        }\n    }\n    return false\n}\n\nfunc matchesWildcard(pattern, permission string) bool {\n    // Simple wildcard matching for permissions like \"temporal:workflow:*\"\n    if !strings.HasSuffix(pattern, \"*\") {\n        return false\n    }\n    prefix := strings.TrimSuffix(pattern, \"*\")\n    return strings.HasPrefix(permission, prefix)\n}\n</code></pre>"},{"location":"security/auth/#2-rbac-provider","title":"2. RBAC Provider","text":""},{"location":"security/auth/#role-based-access-control","title":"Role-Based Access Control","text":"<pre><code>// auth/rbac.go\npackage auth\n\nimport (\n    \"context\"\n    \"encoding/json\"\n    \"fmt\"\n    \"time\"\n\n    \"go.temporal.io/server/common/log\"\n    \"go.temporal.io/server/common/log/tag\"\n)\n\ntype RBACProvider interface {\n    GetUserPermissions(ctx context.Context, userID string) ([]string, error)\n    GetUserRoles(ctx context.Context, userID string) ([]string, error)\n    GetRolePermissions(ctx context.Context, role string) ([]string, error)\n    ValidateUserAccess(ctx context.Context, userID, namespace, action string) (bool, error)\n}\n\ntype Role struct {\n    Name        string   `json:\"name\"`\n    Description string   `json:\"description\"`\n    Permissions []string `json:\"permissions\"`\n    Namespaces  []string `json:\"namespaces\"`\n}\n\ntype User struct {\n    ID         string   `json:\"id\"`\n    Email      string   `json:\"email\"`\n    Roles      []string `json:\"roles\"`\n    Namespaces []string `json:\"namespaces\"`\n    Active     bool     `json:\"active\"`\n    CreatedAt  time.Time `json:\"created_at\"`\n    UpdatedAt  time.Time `json:\"updated_at\"`\n}\n\ntype CachedRBACProvider struct {\n    storage StorageProvider\n    cache   CacheProvider\n    logger  log.Logger\n}\n\nfunc NewCachedRBACProvider(storage StorageProvider, cache CacheProvider, logger log.Logger) RBACProvider {\n    return &amp;CachedRBACProvider{\n        storage: storage,\n        cache:   cache,\n        logger:  logger,\n    }\n}\n\nfunc (p *CachedRBACProvider) GetUserPermissions(ctx context.Context, userID string) ([]string, error) {\n    // Check cache first\n    cacheKey := fmt.Sprintf(\"user_permissions:%s\", userID)\n    if cached, err := p.cache.Get(ctx, cacheKey); err == nil {\n        var permissions []string\n        if err := json.Unmarshal(cached, &amp;permissions); err == nil {\n            return permissions, nil\n        }\n    }\n\n    // Get user roles\n    roles, err := p.GetUserRoles(ctx, userID)\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to get user roles: %w\", err)\n    }\n\n    // Aggregate permissions from all roles\n    permissionSet := make(map[string]bool)\n    for _, role := range roles {\n        rolePerms, err := p.GetRolePermissions(ctx, role)\n        if err != nil {\n            p.logger.Warn(\"Failed to get role permissions\", \n                tag.Value(\"role\", role), \n                tag.Error(err))\n            continue\n        }\n\n        for _, perm := range rolePerms {\n            permissionSet[perm] = true\n        }\n    }\n\n    // Convert set to slice\n    permissions := make([]string, 0, len(permissionSet))\n    for perm := range permissionSet {\n        permissions = append(permissions, perm)\n    }\n\n    // Cache the result\n    if data, err := json.Marshal(permissions); err == nil {\n        p.cache.Set(ctx, cacheKey, data, 5*time.Minute)\n    }\n\n    return permissions, nil\n}\n\nfunc (p *CachedRBACProvider) GetUserRoles(ctx context.Context, userID string) ([]string, error) {\n    user, err := p.storage.GetUser(ctx, userID)\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to get user: %w\", err)\n    }\n\n    if !user.Active {\n        return nil, fmt.Errorf(\"user account is inactive\")\n    }\n\n    return user.Roles, nil\n}\n\nfunc (p *CachedRBACProvider) GetRolePermissions(ctx context.Context, roleName string) ([]string, error) {\n    // Check cache first\n    cacheKey := fmt.Sprintf(\"role_permissions:%s\", roleName)\n    if cached, err := p.cache.Get(ctx, cacheKey); err == nil {\n        var permissions []string\n        if err := json.Unmarshal(cached, &amp;permissions); err == nil {\n            return permissions, nil\n        }\n    }\n\n    role, err := p.storage.GetRole(ctx, roleName)\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to get role: %w\", err)\n    }\n\n    // Cache the result\n    if data, err := json.Marshal(role.Permissions); err == nil {\n        p.cache.Set(ctx, cacheKey, data, 10*time.Minute)\n    }\n\n    return role.Permissions, nil\n}\n\nfunc (p *CachedRBACProvider) ValidateUserAccess(ctx context.Context, userID, namespace, action string) (bool, error) {\n    permissions, err := p.GetUserPermissions(ctx, userID)\n    if err != nil {\n        return false, err\n    }\n\n    // Check if user has admin permission\n    for _, perm := range permissions {\n        if perm == \"temporal:admin\" {\n            return true, nil\n        }\n    }\n\n    // Check namespace-specific permissions\n    requiredPerm := fmt.Sprintf(\"temporal:%s:%s\", namespace, action)\n    wildcardPerm := fmt.Sprintf(\"temporal:%s:*\", namespace)\n    globalPerm := fmt.Sprintf(\"temporal:*:%s\", action)\n\n    for _, perm := range permissions {\n        if perm == requiredPerm || perm == wildcardPerm || perm == globalPerm {\n            return true, nil\n        }\n    }\n\n    return false, nil\n}\n</code></pre>"},{"location":"security/auth/#3-default-roles-configuration","title":"3. Default Roles Configuration","text":""},{"location":"security/auth/#predefined-roles","title":"Predefined Roles","text":"<pre><code># config/rbac-roles.yaml\nroles:\n  - name: \"temporal-admin\"\n    description: \"Full administrative access to Temporal cluster\"\n    permissions:\n      - \"temporal:admin\"\n    namespaces:\n      - \"*\"\n\n  - name: \"temporal-developer\"\n    description: \"Developer access for workflow development and testing\"\n    permissions:\n      - \"temporal:workflow:start\"\n      - \"temporal:workflow:terminate\"\n      - \"temporal:workflow:read\"\n      - \"temporal:workflow:list\"\n      - \"temporal:workflow:history\"\n      - \"temporal:workflow:signal\"\n      - \"temporal:workflow:query\"\n      - \"temporal:activity:*\"\n      - \"temporal:schedule:read\"\n      - \"temporal:schedule:list\"\n      - \"temporal:namespace:read\"\n    namespaces:\n      - \"development\"\n      - \"testing\"\n\n  - name: \"temporal-operator\"\n    description: \"Operations team access for monitoring and maintenance\"\n    permissions:\n      - \"temporal:workflow:read\"\n      - \"temporal:workflow:list\"\n      - \"temporal:workflow:history\"\n      - \"temporal:workflow:terminate\"\n      - \"temporal:activity:read\"\n      - \"temporal:activity:list\"\n      - \"temporal:schedule:*\"\n      - \"temporal:namespace:read\"\n      - \"temporal:namespace:list\"\n      - \"temporal:cluster:read\"\n    namespaces:\n      - \"*\"\n\n  - name: \"temporal-viewer\"\n    description: \"Read-only access for monitoring and observability\"\n    permissions:\n      - \"temporal:workflow:read\"\n      - \"temporal:workflow:list\"\n      - \"temporal:workflow:history\"\n      - \"temporal:activity:read\"\n      - \"temporal:activity:list\"\n      - \"temporal:schedule:read\"\n      - \"temporal:schedule:list\"\n      - \"temporal:namespace:read\"\n      - \"temporal:namespace:list\"\n    namespaces:\n      - \"*\"\n\n  - name: \"temporal-service\"\n    description: \"Service account access for automated systems\"\n    permissions:\n      - \"temporal:workflow:start\"\n      - \"temporal:workflow:signal\"\n      - \"temporal:workflow:query\"\n      - \"temporal:activity:*\"\n    namespaces:\n      - \"production\"\n      - \"staging\"\n\nusers:\n  - id: \"admin@company.com\"\n    email: \"admin@company.com\"\n    roles:\n      - \"temporal-admin\"\n    namespaces:\n      - \"*\"\n    active: true\n\n  - id: \"developer@company.com\"\n    email: \"developer@company.com\"\n    roles:\n      - \"temporal-developer\"\n    namespaces:\n      - \"development\"\n      - \"testing\"\n    active: true\n\n  - id: \"ops@company.com\"\n    email: \"ops@company.com\"\n    roles:\n      - \"temporal-operator\"\n    namespaces:\n      - \"*\"\n    active: true\n</code></pre>"},{"location":"security/auth/#kubernetes-integration","title":"Kubernetes Integration","text":""},{"location":"security/auth/#1-service-account-configuration","title":"1. Service Account Configuration","text":"<pre><code># k8s/rbac.yaml\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: temporal-server\n  namespace: temporal\n  annotations:\n    eks.amazonaws.com/role-arn: arn:aws:iam::ACCOUNT:role/temporal-server-role\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: temporal-server\nrules:\n- apiGroups: [\"\"]\n  resources: [\"secrets\", \"configmaps\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"\"]\n  resources: [\"pods\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: temporal-server\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: temporal-server\nsubjects:\n- kind: ServiceAccount\n  name: temporal-server\n  namespace: temporal\n</code></pre>"},{"location":"security/auth/#2-secret-management-integration","title":"2. Secret Management Integration","text":"<pre><code># k8s/external-secrets.yaml\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: temporal-auth-secrets\n  namespace: temporal\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: temporal-auth-secrets\n    creationPolicy: Owner\n  data:\n  - secretKey: jwt-signing-key\n    remoteRef:\n      key: temporal/auth\n      property: jwt_signing_key\n  - secretKey: oidc-client-secret\n    remoteRef:\n      key: temporal/auth\n      property: oidc_client_secret\n  - secretKey: api-key-secret\n    remoteRef:\n      key: temporal/auth\n      property: api_key_secret\n</code></pre> <p>This comprehensive authentication and authorization guide provides enterprise-grade security patterns for Temporal.io deployments with support for multiple authentication methods, fine-grained authorization, and secure integration with modern identity providers.</p>"},{"location":"security/best-practices/","title":"Security Best Practices","text":"<p>This guide provides comprehensive security best practices for Temporal.io deployments, covering defense-in-depth strategies, operational security, compliance requirements, and incident response procedures for enterprise environments.</p>"},{"location":"security/best-practices/#overview","title":"Overview","text":"<p>Security best practices for Temporal.io encompass: - Defense in Depth: Multi-layered security controls - Principle of Least Privilege: Minimal access rights - Zero Trust Architecture: Never trust, always verify - Security by Design: Built-in security from the start - Continuous Monitoring: Real-time threat detection - Compliance: Meeting regulatory requirements</p>"},{"location":"security/best-practices/#security-architecture-framework","title":"Security Architecture Framework","text":"<pre><code>graph TB\n    subgraph \"Security Layers\"\n        PERIMETER[Perimeter Security]\n        NETWORK[Network Security]\n        COMPUTE[Compute Security]\n        APPLICATION[Application Security]\n        DATA[Data Security]\n        IDENTITY[Identity Security]\n    end\n\n    subgraph \"Perimeter Security\"\n        WAF[Web Application Firewall]\n        DDOS[DDoS Protection]\n        CDN[Content Delivery Network]\n    end\n\n    subgraph \"Network Security\"\n        NETPOL[Network Policies]\n        MICROSEG[Micro-segmentation]\n        VPN[VPN Gateway]\n        FIREWALL[Next-Gen Firewall]\n    end\n\n    subgraph \"Compute Security\"\n        RBAC[RBAC Controls]\n        PSP[Pod Security Policies]\n        RUNTIME[Runtime Security]\n        VULN[Vulnerability Scanning]\n    end\n\n    subgraph \"Application Security\"\n        AUTHN[Authentication]\n        AUTHZ[Authorization]\n        TLS[TLS Encryption]\n        SECRETS[Secrets Management]\n    end\n\n    subgraph \"Data Security\"\n        ENCRYPTION[Data Encryption]\n        BACKUP[Secure Backups]\n        DLP[Data Loss Prevention]\n        AUDIT[Audit Logging]\n    end\n\n    subgraph \"Identity Security\"\n        MFA[Multi-Factor Auth]\n        SSO[Single Sign-On]\n        PAM[Privileged Access]\n        LIFECYCLE[Identity Lifecycle]\n    end\n\n    PERIMETER --&gt; NETWORK\n    NETWORK --&gt; COMPUTE\n    COMPUTE --&gt; APPLICATION\n    APPLICATION --&gt; DATA\n    DATA --&gt; IDENTITY</code></pre>"},{"location":"security/best-practices/#infrastructure-security","title":"Infrastructure Security","text":""},{"location":"security/best-practices/#1-kubernetes-security-hardening","title":"1. Kubernetes Security Hardening","text":""},{"location":"security/best-practices/#cluster-security-configuration","title":"Cluster Security Configuration","text":"<pre><code># k8s/security/cluster-security.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: cluster-security-config\n  namespace: kube-system\ndata:\n  kube-apiserver-config.yaml: |\n    # API Server Security Settings\n    audit-log-maxage: 30\n    audit-log-maxbackup: 3\n    audit-log-maxsize: 100\n    audit-log-path: /var/log/audit.log\n    audit-policy-file: /etc/kubernetes/audit-policy.yaml\n    enable-admission-plugins: &gt;\n      NamespaceLifecycle,\n      LimitRanger,\n      ServiceAccount,\n      TaintNodesByCondition,\n      Priority,\n      DefaultTolerationSeconds,\n      DefaultStorageClass,\n      StorageObjectInUseProtection,\n      PersistentVolumeClaimResize,\n      RuntimeClass,\n      CertificateApproval,\n      CertificateSigning,\n      CertificateSubjectRestriction,\n      DefaultIngressClass,\n      MutatingAdmissionWebhook,\n      ValidatingAdmissionWebhook,\n      ResourceQuota,\n      PodSecurityPolicy,\n      NodeRestriction\n    authorization-mode: Node,RBAC\n    anonymous-auth: false\n    insecure-port: 0\n    secure-port: 6443\n    tls-cipher-suites: &gt;\n      TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,\n      TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,\n      TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,\n      TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,\n      TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,\n      TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305\n    tls-min-version: VersionTLS12\n</code></pre>"},{"location":"security/best-practices/#pod-security-standards","title":"Pod Security Standards","text":"<pre><code># k8s/security/pod-security-standards.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: temporal\n  labels:\n    pod-security.kubernetes.io/enforce: restricted\n    pod-security.kubernetes.io/audit: restricted\n    pod-security.kubernetes.io/warn: restricted\n\n---\napiVersion: policy/v1beta1\nkind: PodSecurityPolicy\nmetadata:\n  name: temporal-restricted\nspec:\n  privileged: false\n  allowPrivilegeEscalation: false\n  requiredDropCapabilities:\n    - ALL\n  volumes:\n    - 'configMap'\n    - 'emptyDir'\n    - 'projected'\n    - 'secret'\n    - 'downwardAPI'\n    - 'persistentVolumeClaim'\n  hostNetwork: false\n  hostIPC: false\n  hostPID: false\n  runAsUser:\n    rule: 'MustRunAsNonRoot'\n  runAsGroup:\n    rule: 'MustRunAs'\n    ranges:\n      - min: 1\n        max: 65535\n  seLinux:\n    rule: 'RunAsAny'\n  supplementalGroups:\n    rule: 'MustRunAs'\n    ranges:\n      - min: 1\n        max: 65535\n  fsGroup:\n    rule: 'MustRunAs'\n    ranges:\n      - min: 1\n        max: 65535\n  readOnlyRootFilesystem: true\n</code></pre>"},{"location":"security/best-practices/#security-context-enforcement","title":"Security Context Enforcement","text":"<pre><code># k8s/security/security-context.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: temporal-frontend\n  namespace: temporal\nspec:\n  template:\n    spec:\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 1000\n        runAsGroup: 1000\n        fsGroup: 1000\n        seccompProfile:\n          type: RuntimeDefault\n      containers:\n      - name: temporal\n        securityContext:\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          runAsUser: 1000\n          runAsGroup: 1000\n          capabilities:\n            drop:\n            - ALL\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        - name: var-cache\n          mountPath: /var/cache\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: var-cache\n        emptyDir: {}\n</code></pre>"},{"location":"security/best-practices/#2-container-security","title":"2. Container Security","text":""},{"location":"security/best-practices/#base-image-security","title":"Base Image Security","text":"<pre><code># security/Dockerfile.temporal-secure\n# Use minimal, distroless base image\nFROM gcr.io/distroless/java:11\n\n# Add security labels\nLABEL security.vendor=\"Company Name\" \\\n      security.scanned=\"true\" \\\n      security.scan-date=\"2024-01-15\" \\\n      security.vulnerabilities=\"none\"\n\n# Copy application with minimal permissions\nCOPY --chown=1000:1000 temporal-server.jar /app/\n\n# Use non-root user\nUSER 1000:1000\n\n# Set read-only root filesystem\nVOLUME [\"/tmp\", \"/var/cache\"]\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\n  CMD [\"java\", \"-cp\", \"/app/temporal-server.jar\", \"io.temporal.server.HealthCheck\"]\n\nENTRYPOINT [\"java\", \"-jar\", \"/app/temporal-server.jar\"]\n</code></pre>"},{"location":"security/best-practices/#container-scanning-pipeline","title":"Container Scanning Pipeline","text":"<pre><code># .github/workflows/container-security.yaml\nname: Container Security Scan\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n\njobs:\n  security-scan:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v4\n\n    - name: Build container image\n      run: docker build -t temporal-security-test .\n\n    - name: Run Trivy vulnerability scanner\n      uses: aquasecurity/trivy-action@master\n      with:\n        image-ref: 'temporal-security-test'\n        format: 'sarif'\n        output: 'trivy-results.sarif'\n        severity: 'CRITICAL,HIGH'\n        exit-code: '1'\n\n    - name: Upload Trivy scan results\n      uses: github/codeql-action/upload-sarif@v2\n      with:\n        sarif_file: 'trivy-results.sarif'\n\n    - name: Run Snyk container scan\n      uses: snyk/actions/docker@master\n      env:\n        SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}\n      with:\n        image: temporal-security-test\n        args: --severity-threshold=high\n\n    - name: Run Docker Bench Security\n      run: |\n        docker run --rm --net host --pid host --userns host --cap-add audit_control \\\n          -e DOCKER_CONTENT_TRUST=$DOCKER_CONTENT_TRUST \\\n          -v /etc:/etc:ro \\\n          -v /usr/bin/containerd:/usr/bin/containerd:ro \\\n          -v /usr/bin/runc:/usr/bin/runc:ro \\\n          -v /usr/lib/systemd:/usr/lib/systemd:ro \\\n          -v /var/lib:/var/lib:ro \\\n          -v /var/run/docker.sock:/var/run/docker.sock:ro \\\n          --label docker_bench_security \\\n          docker/docker-bench-security\n</code></pre>"},{"location":"security/best-practices/#application-security","title":"Application Security","text":""},{"location":"security/best-practices/#1-secure-development-practices","title":"1. Secure Development Practices","text":""},{"location":"security/best-practices/#code-security-analysis","title":"Code Security Analysis","text":"<pre><code># .github/workflows/code-security.yaml\nname: Code Security Analysis\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n\njobs:\n  security-analysis:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v4\n\n    - name: Run CodeQL Analysis\n      uses: github/codeql-action/init@v2\n      with:\n        languages: go, java, javascript\n\n    - name: Autobuild\n      uses: github/codeql-action/autobuild@v2\n\n    - name: Perform CodeQL Analysis\n      uses: github/codeql-action/analyze@v2\n\n    - name: Run Semgrep security scan\n      uses: returntocorp/semgrep-action@v1\n      with:\n        config: &gt;-\n          p/security-audit\n          p/secrets\n          p/owasp-top-ten\n\n    - name: Run SonarCloud Scan\n      uses: SonarSource/sonarcloud-github-action@master\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}\n\n    - name: Run Gosec Security Scanner\n      uses: securecodewarrior/github-action-gosec@master\n      with:\n        args: '-fmt sarif -out gosec-results.sarif ./...'\n\n    - name: Upload Gosec results\n      uses: github/codeql-action/upload-sarif@v2\n      with:\n        sarif_file: 'gosec-results.sarif'\n</code></pre>"},{"location":"security/best-practices/#dependency-security","title":"Dependency Security","text":"<pre><code># .github/workflows/dependency-security.yaml\nname: Dependency Security Check\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n  schedule:\n    - cron: '0 6 * * *'  # Daily at 6 AM\n\njobs:\n  dependency-check:\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v4\n\n    - name: Run OWASP Dependency Check\n      uses: dependency-check/Dependency-Check_Action@main\n      with:\n        project: 'temporal-io'\n        path: '.'\n        format: 'ALL'\n        args: &gt;\n          --enableRetired\n          --enableExperimental\n          --failOnCVSS 7\n\n    - name: Run Snyk dependency scan\n      uses: snyk/actions/node@master\n      env:\n        SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}\n      with:\n        args: --severity-threshold=high\n\n    - name: Run npm audit\n      run: |\n        npm audit --audit-level high\n        npm audit fix --force\n\n    - name: Run Go vulnerability check\n      run: |\n        go install golang.org/x/vuln/cmd/govulncheck@latest\n        govulncheck ./...\n</code></pre>"},{"location":"security/best-practices/#2-secure-configuration-management","title":"2. Secure Configuration Management","text":""},{"location":"security/best-practices/#application-security-configuration","title":"Application Security Configuration","text":"<pre><code># config/security-config.yaml\nsecurity:\n  # Authentication configuration\n  authentication:\n    enabled: true\n    method: \"jwt\"\n    jwt:\n      algorithm: \"RS256\"\n      key_rotation_interval: \"24h\"\n      max_token_age: \"1h\"\n      issuer: \"temporal.company.com\"\n      audience: \"temporal-cluster\"\n\n    mTLS:\n      enabled: true\n      require_client_cert: true\n      verify_client_cert: true\n      ca_file: \"/etc/temporal/certs/ca.crt\"\n      cert_file: \"/etc/temporal/certs/server.crt\"\n      key_file: \"/etc/temporal/certs/server.key\"\n\n  # Authorization configuration\n  authorization:\n    enabled: true\n    default_policy: \"deny\"\n    rbac:\n      enabled: true\n      policy_file: \"/etc/temporal/rbac/policy.yaml\"\n      role_mapping_file: \"/etc/temporal/rbac/roles.yaml\"\n\n  # Encryption configuration\n  encryption:\n    # Data encryption at rest\n    at_rest:\n      enabled: true\n      algorithm: \"AES-256-GCM\"\n      key_rotation_interval: \"90d\"\n      key_provider: \"vault\"\n  encryption:\n    # Data encryption in transit\n    in_transit:\n      enabled: true\n      min_tls_version: \"1.3\"  # Updated to TLS 1.3 for Temporal 1.29+\n      cipher_suites:\n        - \"TLS_AES_256_GCM_SHA384\"  # TLS 1.3 cipher suites\n        - \"TLS_AES_128_GCM_SHA256\"\n        - \"TLS_CHACHA20_POLY1305_SHA256\"\n        # TLS 1.2 fallback (if needed)\n        - \"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\"\n        - \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\"\n\n  # Audit configuration\n  audit:\n    enabled: true\n    level: \"info\"\n    log_format: \"json\"\n    log_file: \"/var/log/temporal/audit.log\"\n    max_file_size: \"100MB\"\n    max_files: 10\n    fields:\n      - \"timestamp\"\n      - \"user_id\"\n      - \"action\"\n      - \"resource\"\n      - \"result\"\n      - \"ip_address\"\n      - \"user_agent\"\n\n  # Rate limiting\n  rate_limiting:\n    enabled: true\n    global_limit: \"1000/min\"\n    per_user_limit: \"100/min\"\n    per_ip_limit: \"500/min\"\n\n  # Security headers\n  headers:\n    enabled: true\n    hsts:\n      enabled: true\n      max_age: \"31536000\"\n      include_subdomains: true\n      preload: true\n    csp:\n      enabled: true\n      policy: \"default-src 'self'; script-src 'self' 'unsafe-inline'; style-src 'self' 'unsafe-inline'\"\n    frame_options: \"DENY\"\n    content_type_options: \"nosniff\"\n    xss_protection: \"1; mode=block\"\n</code></pre>"},{"location":"security/best-practices/#3-input-validation-and-sanitization","title":"3. Input Validation and Sanitization","text":""},{"location":"security/best-practices/#workflow-input-validation","title":"Workflow Input Validation","text":"<pre><code>// security/validation.go\npackage security\n\nimport (\n    \"fmt\"\n    \"regexp\"\n    \"strings\"\n    \"time\"\n\n    \"github.com/go-playground/validator/v10\"\n    \"github.com/microcosm-cc/bluemonday\"\n)\n\n// InputValidator provides comprehensive input validation\ntype InputValidator struct {\n    validator *validator.Validate\n    sanitizer *bluemonday.Policy\n}\n\n// NewInputValidator creates a new input validator\nfunc NewInputValidator() *InputValidator {\n    v := validator.New()\n\n    // Custom validation rules\n    v.RegisterValidation(\"workflow_id\", validateWorkflowID)\n    v.RegisterValidation(\"task_queue\", validateTaskQueue)\n    v.RegisterValidation(\"namespace\", validateNamespace)\n\n    // HTML sanitizer\n    p := bluemonday.StrictPolicy()\n\n    return &amp;InputValidator{\n        validator: v,\n        sanitizer: p,\n    }\n}\n\n// WorkflowInput represents validated workflow input\ntype WorkflowInput struct {\n    WorkflowID   string            `validate:\"required,workflow_id,max=255\"`\n    TaskQueue    string            `validate:\"required,task_queue,max=100\"`\n    Namespace    string            `validate:\"required,namespace,max=100\"`\n    Input        map[string]interface{} `validate:\"required\"`\n    Timeout      time.Duration     `validate:\"min=1s,max=24h\"`\n    RetryPolicy  *RetryPolicy      `validate:\"omitempty\"`\n}\n\ntype RetryPolicy struct {\n    MaxAttempts     int           `validate:\"min=1,max=100\"`\n    InitialInterval time.Duration `validate:\"min=1s,max=1h\"`\n    MaxInterval     time.Duration `validate:\"min=1s,max=24h\"`\n    BackoffFactor   float64       `validate:\"min=1.0,max=10.0\"`\n}\n\n// ValidateWorkflowInput validates workflow input parameters\nfunc (v *InputValidator) ValidateWorkflowInput(input *WorkflowInput) error {\n    if err := v.validator.Struct(input); err != nil {\n        return fmt.Errorf(\"validation failed: %w\", err)\n    }\n\n    // Sanitize string inputs\n    input.WorkflowID = v.sanitizer.Sanitize(input.WorkflowID)\n    input.TaskQueue = v.sanitizer.Sanitize(input.TaskQueue)\n    input.Namespace = v.sanitizer.Sanitize(input.Namespace)\n\n    // Validate input data size\n    if err := v.validateDataSize(input.Input); err != nil {\n        return fmt.Errorf(\"input data validation failed: %w\", err)\n    }\n\n    return nil\n}\n\n// Custom validation functions\nfunc validateWorkflowID(fl validator.FieldLevel) bool {\n    workflowID := fl.Field().String()\n\n    // Workflow ID pattern: alphanumeric, hyphens, underscores\n    pattern := `^[a-zA-Z0-9_-]+$`\n    matched, _ := regexp.MatchString(pattern, workflowID)\n\n    return matched &amp;&amp; !containsMaliciousPatterns(workflowID)\n}\n\nfunc validateTaskQueue(fl validator.FieldLevel) bool {\n    taskQueue := fl.Field().String()\n\n    // Task queue pattern: alphanumeric, hyphens, dots\n    pattern := `^[a-zA-Z0-9._-]+$`\n    matched, _ := regexp.MatchString(pattern, taskQueue)\n\n    return matched &amp;&amp; !containsMaliciousPatterns(taskQueue)\n}\n\nfunc validateNamespace(fl validator.FieldLevel) bool {\n    namespace := fl.Field().String()\n\n    // Namespace pattern: lowercase alphanumeric, hyphens\n    pattern := `^[a-z0-9-]+$`\n    matched, _ := regexp.MatchString(pattern, namespace)\n\n    return matched &amp;&amp; !containsMaliciousPatterns(namespace)\n}\n\nfunc containsMaliciousPatterns(input string) bool {\n    maliciousPatterns := []string{\n        \"&lt;script\", \"&lt;/script&gt;\", \"javascript:\", \"vbscript:\",\n        \"onload=\", \"onerror=\", \"onclick=\", \"onmouseover=\",\n        \"eval(\", \"exec(\", \"system(\", \"shell_exec(\",\n        \"../\", \"..\\\\\", \"/etc/passwd\", \"/proc/\",\n        \"DROP TABLE\", \"DELETE FROM\", \"INSERT INTO\", \"UPDATE SET\",\n        \"UNION SELECT\", \"OR 1=1\", \"AND 1=1\",\n    }\n\n    lowerInput := strings.ToLower(input)\n    for _, pattern := range maliciousPatterns {\n        if strings.Contains(lowerInput, strings.ToLower(pattern)) {\n            return true\n        }\n    }\n\n    return false\n}\n\nfunc (v *InputValidator) validateDataSize(data interface{}) error {\n    // Convert to JSON and check size\n    jsonData, err := json.Marshal(data)\n    if err != nil {\n        return fmt.Errorf(\"failed to marshal data: %w\", err)\n    }\n\n    const maxSize = 2 * 1024 * 1024 // 2MB limit\n    if len(jsonData) &gt; maxSize {\n        return fmt.Errorf(\"input data exceeds maximum size of %d bytes\", maxSize)\n    }\n\n    return nil\n}\n</code></pre>"},{"location":"security/best-practices/#data-protection","title":"Data Protection","text":""},{"location":"security/best-practices/#1-encryption-standards","title":"1. Encryption Standards","text":""},{"location":"security/best-practices/#data-encryption-configuration","title":"Data Encryption Configuration","text":"<pre><code># config/encryption-config.yaml\nencryption:\n  # Database encryption\n  database:\n    enabled: true\n    provider: \"vault\"\n    key_derivation: \"PBKDF2\"\n    algorithm: \"AES-256-GCM\"\n    key_rotation: \"quarterly\"\n\n    # Column-level encryption for sensitive data\n    column_encryption:\n      enabled: true\n      columns:\n        - \"workflow_execution.input\"\n        - \"workflow_execution.result\"\n        - \"activity_task.input\"\n        - \"activity_task.result\"\n        - \"history_event.event_data\"\n\n  # Payload encryption\n  payload:\n    enabled: true\n    codec: \"aes-gcm-256\"\n    key_management: \"vault\"\n    compression: \"gzip\"\n\n    # Encryption metadata\n    metadata:\n      algorithm_header: \"x-temporal-encryption-algorithm\"\n      key_id_header: \"x-temporal-key-id\"\n      compression_header: \"x-temporal-compression\"\n\n  # Search attribute encryption\n  search_attributes:\n    enabled: true\n    encrypted_attributes:\n      - \"customer_id\"\n      - \"payment_method\"\n      - \"personal_data\"\n\n    # Deterministic encryption for searchable fields\n    deterministic_encryption:\n      enabled: true\n      algorithm: \"AES-SIV\"\n\n  # Key management\n  key_management:\n    provider: \"vault\"\n    auto_rotation: true\n    rotation_interval: \"90d\"\n    min_key_versions: 3\n\n    vault:\n      address: \"https://vault.company.com\"\n      path: \"temporal/encryption\"\n      role: \"temporal-encryption\"\n</code></pre>"},{"location":"security/best-practices/#payload-encryption-implementation","title":"Payload Encryption Implementation","text":"<pre><code>// security/encryption.go\npackage security\n\nimport (\n    \"crypto/aes\"\n    \"crypto/cipher\"\n    \"crypto/rand\"\n    \"encoding/base64\"\n    \"fmt\"\n    \"io\"\n\n    \"go.temporal.io/sdk/converter\"\n)\n\n// EncryptionCodec implements payload encryption\ntype EncryptionCodec struct {\n    keyManager KeyManager\n    fallback   converter.PayloadCodec\n}\n\ntype KeyManager interface {\n    GetCurrentKey() ([]byte, string, error)\n    GetKey(keyID string) ([]byte, error)\n    RotateKey() error\n}\n\n// NewEncryptionCodec creates a new encryption codec\nfunc NewEncryptionCodec(keyManager KeyManager) *EncryptionCodec {\n    return &amp;EncryptionCodec{\n        keyManager: keyManager,\n        fallback:   converter.NewJSONPayloadCodec(),\n    }\n}\n\n// Encode encrypts payloads\nfunc (e *EncryptionCodec) Encode(payloads []*commonpb.Payload) ([]*commonpb.Payload, error) {\n    if len(payloads) == 0 {\n        return payloads, nil\n    }\n\n    // Get current encryption key\n    key, keyID, err := e.keyManager.GetCurrentKey()\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to get encryption key: %w\", err)\n    }\n\n    encryptedPayloads := make([]*commonpb.Payload, len(payloads))\n    for i, payload := range payloads {\n        encrypted, err := e.encryptPayload(payload, key, keyID)\n        if err != nil {\n            return nil, fmt.Errorf(\"failed to encrypt payload %d: %w\", i, err)\n        }\n        encryptedPayloads[i] = encrypted\n    }\n\n    return encryptedPayloads, nil\n}\n\n// Decode decrypts payloads\nfunc (e *EncryptionCodec) Decode(payloads []*commonpb.Payload) ([]*commonpb.Payload, error) {\n    if len(payloads) == 0 {\n        return payloads, nil\n    }\n\n    decryptedPayloads := make([]*commonpb.Payload, len(payloads))\n    for i, payload := range payloads {\n        if e.isEncrypted(payload) {\n            decrypted, err := e.decryptPayload(payload)\n            if err != nil {\n                return nil, fmt.Errorf(\"failed to decrypt payload %d: %w\", i, err)\n            }\n            decryptedPayloads[i] = decrypted\n        } else {\n            decryptedPayloads[i] = payload\n        }\n    }\n\n    return decryptedPayloads, nil\n}\n\nfunc (e *EncryptionCodec) encryptPayload(payload *commonpb.Payload, key []byte, keyID string) (*commonpb.Payload, error) {\n    // Serialize payload\n    data, err := payload.Marshal()\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to marshal payload: %w\", err)\n    }\n\n    // Create AES-GCM cipher\n    block, err := aes.NewCipher(key)\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to create cipher: %w\", err)\n    }\n\n    gcm, err := cipher.NewGCM(block)\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to create GCM: %w\", err)\n    }\n\n    // Generate nonce\n    nonce := make([]byte, gcm.NonceSize())\n    if _, err := io.ReadFull(rand.Reader, nonce); err != nil {\n        return nil, fmt.Errorf(\"failed to generate nonce: %w\", err)\n    }\n\n    // Encrypt data\n    ciphertext := gcm.Seal(nonce, nonce, data, nil)\n\n    // Create encrypted payload\n    encryptedPayload := &amp;commonpb.Payload{\n        Metadata: map[string][]byte{\n            \"encryption\":  []byte(\"aes-gcm-256\"),\n            \"key-id\":      []byte(keyID),\n            \"encoding\":    []byte(\"binary/encrypted\"),\n        },\n        Data: ciphertext,\n    }\n\n    return encryptedPayload, nil\n}\n\nfunc (e *EncryptionCodec) decryptPayload(payload *commonpb.Payload) (*commonpb.Payload, error) {\n    // Extract key ID\n    keyIDBytes, exists := payload.Metadata[\"key-id\"]\n    if !exists {\n        return nil, fmt.Errorf(\"missing key-id in encrypted payload\")\n    }\n\n    keyID := string(keyIDBytes)\n    key, err := e.keyManager.GetKey(keyID)\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to get decryption key: %w\", err)\n    }\n\n    // Create AES-GCM cipher\n    block, err := aes.NewCipher(key)\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to create cipher: %w\", err)\n    }\n\n    gcm, err := cipher.NewGCM(block)\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to create GCM: %w\", err)\n    }\n\n    // Extract nonce and ciphertext\n    ciphertext := payload.Data\n    if len(ciphertext) &lt; gcm.NonceSize() {\n        return nil, fmt.Errorf(\"ciphertext too short\")\n    }\n\n    nonce := ciphertext[:gcm.NonceSize()]\n    ciphertext = ciphertext[gcm.NonceSize():]\n\n    // Decrypt data\n    plaintext, err := gcm.Open(nil, nonce, ciphertext, nil)\n    if err != nil {\n        return nil, fmt.Errorf(\"failed to decrypt payload: %w\", err)\n    }\n\n    // Unmarshal original payload\n    originalPayload := &amp;commonpb.Payload{}\n    if err := originalPayload.Unmarshal(plaintext); err != nil {\n        return nil, fmt.Errorf(\"failed to unmarshal decrypted payload: %w\", err)\n    }\n\n    return originalPayload, nil\n}\n\nfunc (e *EncryptionCodec) isEncrypted(payload *commonpb.Payload) bool {\n    encryption, exists := payload.Metadata[\"encryption\"]\n    return exists &amp;&amp; string(encryption) == \"aes-gcm-256\"\n}\n</code></pre>"},{"location":"security/best-practices/#2-data-loss-prevention","title":"2. Data Loss Prevention","text":""},{"location":"security/best-practices/#dlp-configuration","title":"DLP Configuration","text":"<pre><code># k8s/security/dlp-config.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: dlp-config\n  namespace: temporal\ndata:\n  dlp-rules.yaml: |\n    data_loss_prevention:\n      enabled: true\n      rules:\n        - name: \"Credit Card Detection\"\n          pattern: '\\b(?:\\d{4}[-\\s]?){3}\\d{4}\\b'\n          action: \"mask\"\n          severity: \"high\"\n          description: \"Detects credit card numbers\"\n\n        - name: \"SSN Detection\"\n          pattern: '\\b\\d{3}-\\d{2}-\\d{4}\\b'\n          action: \"block\"\n          severity: \"critical\"\n          description: \"Detects Social Security Numbers\"\n\n        - name: \"Email Detection\"\n          pattern: '\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n          action: \"mask\"\n          severity: \"medium\"\n          description: \"Detects email addresses\"\n\n        - name: \"Phone Number Detection\"\n          pattern: '\\b\\d{3}-\\d{3}-\\d{4}\\b'\n          action: \"mask\"\n          severity: \"medium\"\n          description: \"Detects phone numbers\"\n\n      masking:\n        credit_card: \"****-****-****-XXXX\"\n        ssn: \"***-**-XXXX\"\n        email: \"****@****.***\"\n        phone: \"***-***-XXXX\"\n\n      audit:\n        enabled: true\n        log_violations: true\n        alert_on_block: true\n</code></pre>"},{"location":"security/best-practices/#monitoring-and-incident-response","title":"Monitoring and Incident Response","text":""},{"location":"security/best-practices/#1-security-monitoring","title":"1. Security Monitoring","text":""},{"location":"security/best-practices/#security-event-detection","title":"Security Event Detection","text":"<pre><code># k8s/monitoring/security-alerts.yaml\napiVersion: monitoring.coreos.com/v1\nkind: PrometheusRule\nmetadata:\n  name: temporal-security-alerts\n  namespace: temporal-monitoring\nspec:\n  groups:\n  - name: security-events\n    rules:\n    - alert: SuspiciousWorkflowActivity\n      expr: rate(temporal_workflow_executions_total{status=\"failed\"}[5m]) &gt; 10\n      for: 2m\n      labels:\n        severity: warning\n        category: security\n      annotations:\n        summary: \"High rate of failed workflow executions\"\n        description: \"{{ $value }} failed workflow executions per second\"\n\n    - alert: UnauthorizedAPIAccess\n      expr: rate(temporal_api_requests_total{status=\"403\"}[5m]) &gt; 5\n      for: 1m\n      labels:\n        severity: critical\n        category: security\n      annotations:\n        summary: \"High rate of unauthorized API access attempts\"\n        description: \"{{ $value }} unauthorized requests per second\"\n\n    - alert: AnomalousUserBehavior\n      expr: rate(temporal_user_actions_total[5m]) &gt; 100\n      for: 5m\n      labels:\n        severity: warning\n        category: security\n      annotations:\n        summary: \"Anomalous user behavior detected\"\n        description: \"User {{ $labels.user }} performing {{ $value }} actions per second\"\n\n    - alert: PotentialDataExfiltration\n      expr: rate(temporal_payload_size_bytes[5m]) &gt; 100000000  # 100MB/s\n      for: 2m\n      labels:\n        severity: critical\n        category: security\n      annotations:\n        summary: \"Large data transfer detected\"\n        description: \"{{ $value }} bytes per second data transfer\"\n\n    - alert: SecurityPolicyViolation\n      expr: increase(temporal_policy_violations_total[5m]) &gt; 0\n      for: 0m\n      labels:\n        severity: critical\n        category: security\n      annotations:\n        summary: \"Security policy violation detected\"\n        description: \"{{ $value }} policy violations in the last 5 minutes\"\n</code></pre>"},{"location":"security/best-practices/#siem-integration","title":"SIEM Integration","text":"<pre><code># k8s/monitoring/siem-integration.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: siem-config\n  namespace: temporal-monitoring\ndata:\n  fluent-bit.conf: |\n    [SERVICE]\n        Flush         1\n        Log_Level     info\n        Daemon        off\n        Parsers_File  parsers.conf\n\n    [INPUT]\n        Name              tail\n        Path              /var/log/temporal/*.log\n        Parser            json\n        Tag               temporal.security\n        Refresh_Interval  5\n\n    [FILTER]\n        Name    modify\n        Match   temporal.security\n        Add     source temporal\n        Add     environment production\n        Add     facility security\n\n    [OUTPUT]\n        Name        forward\n        Match       temporal.security\n        Host        siem.company.com\n        Port        24224\n        tls         on\n        tls.verify  on\n        tls.ca_file /etc/ssl/certs/ca-certificates.crt\n</code></pre>"},{"location":"security/best-practices/#2-incident-response","title":"2. Incident Response","text":""},{"location":"security/best-practices/#security-incident-playbook","title":"Security Incident Playbook","text":"<pre><code># docs/security/incident-response-playbook.yaml\nincident_response:\n  severity_levels:\n    critical:\n      description: \"Immediate threat to system security or data\"\n      response_time: \"15 minutes\"\n      escalation: \"CISO, Security Team, On-call Engineer\"\n\n    high:\n      description: \"Significant security concern requiring urgent attention\"\n      response_time: \"1 hour\"\n      escalation: \"Security Team, Engineering Manager\"\n\n    medium:\n      description: \"Security issue requiring investigation\"\n      response_time: \"4 hours\"\n      escalation: \"Security Team\"\n\n    low:\n      description: \"Minor security concern or potential issue\"\n      response_time: \"24 hours\"\n      escalation: \"Security Team\"\n\n  response_procedures:\n    data_breach:\n      immediate_actions:\n        - \"Isolate affected systems\"\n        - \"Preserve evidence\"\n        - \"Assess scope of breach\"\n        - \"Notify stakeholders\"\n\n      investigation_steps:\n        - \"Collect and analyze logs\"\n        - \"Identify attack vector\"\n        - \"Determine data accessed\"\n        - \"Document timeline\"\n\n      containment:\n        - \"Patch vulnerabilities\"\n        - \"Update access controls\"\n        - \"Implement additional monitoring\"\n        - \"Review security policies\"\n\n    unauthorized_access:\n      immediate_actions:\n        - \"Disable compromised accounts\"\n        - \"Change relevant passwords\"\n        - \"Review access logs\"\n        - \"Check for privilege escalation\"\n\n      investigation_steps:\n        - \"Analyze authentication logs\"\n        - \"Review network traffic\"\n        - \"Check for lateral movement\"\n        - \"Identify affected resources\"\n\n      remediation:\n        - \"Implement MFA\"\n        - \"Review access policies\"\n        - \"Update monitoring rules\"\n        - \"Conduct security training\"\n</code></pre>"},{"location":"security/best-practices/#automated-response-actions","title":"Automated Response Actions","text":"<pre><code>#!/bin/bash\n# scripts/security-incident-response.sh\n\nset -euo pipefail\n\nINCIDENT_TYPE=\"$1\"\nSEVERITY=\"$2\"\nAFFECTED_RESOURCE=\"$3\"\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\nerror() {\n    echo -e \"\\033[0;31m[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1\\033[0m\"\n    exit 1\n}\n\n# Function to isolate compromised pod\nisolate_pod() {\n    local pod_name=\"$1\"\n    local namespace=\"$2\"\n\n    log \"Isolating pod $pod_name in namespace $namespace\"\n\n    # Apply network policy to isolate pod\n    cat &lt;&lt; EOF | kubectl apply -f -\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: isolate-${pod_name}\n  namespace: ${namespace}\nspec:\n  podSelector:\n    matchLabels:\n      name: ${pod_name}\n  policyTypes:\n  - Ingress\n  - Egress\nEOF\n\n    log \"Pod $pod_name isolated\"\n}\n\n# Function to disable user account\ndisable_user() {\n    local user_id=\"$1\"\n\n    log \"Disabling user account: $user_id\"\n\n    # Remove user from all roles\n    kubectl patch configmap temporal-rbac-config -n temporal \\\n        --type='json' \\\n        -p=\"[{\\\"op\\\": \\\"remove\\\", \\\"path\\\": \\\"/data/users/${user_id}\\\"}]\"\n\n    # Revoke active sessions\n    kubectl exec -n temporal deployment/temporal-frontend -- \\\n        temporal operator cluster upsert-search-attributes \\\n        --name \"user_${user_id}_disabled\" \\\n        --type \"Bool\" \\\n        --value \"true\"\n\n    log \"User $user_id disabled\"\n}\n\n# Function to collect forensic data\ncollect_forensics() {\n    local resource=\"$1\"\n    local output_dir=\"/tmp/forensics/$(date +%Y%m%d_%H%M%S)\"\n\n    mkdir -p \"$output_dir\"\n\n    log \"Collecting forensic data for $resource\"\n\n    # Collect pod logs\n    if kubectl get pod \"$resource\" -n temporal &amp;&gt;/dev/null; then\n        kubectl logs \"$resource\" -n temporal --previous &gt; \"$output_dir/pod-logs.txt\"\n        kubectl describe pod \"$resource\" -n temporal &gt; \"$output_dir/pod-description.txt\"\n    fi\n\n    # Collect audit logs\n    kubectl get events -n temporal --sort-by='.lastTimestamp' &gt; \"$output_dir/events.txt\"\n\n    # Collect network policies\n    kubectl get networkpolicies -n temporal -o yaml &gt; \"$output_dir/network-policies.yaml\"\n\n    # Create forensic package\n    tar -czf \"/tmp/forensics-${resource}-$(date +%Y%m%d_%H%M%S).tar.gz\" -C \"$output_dir\" .\n\n    log \"Forensic data collected: $output_dir\"\n}\n\n# Function to send security alert\nsend_alert() {\n    local incident_type=\"$1\"\n    local severity=\"$2\"\n    local details=\"$3\"\n\n    # Send to security team via webhook\n    curl -X POST \"${SECURITY_WEBHOOK_URL}\" \\\n        -H \"Content-Type: application/json\" \\\n        -d \"{\n            \\\"incident_type\\\": \\\"$incident_type\\\",\n            \\\"severity\\\": \\\"$severity\\\",\n            \\\"timestamp\\\": \\\"$(date -u +%Y-%m-%dT%H:%M:%SZ)\\\",\n            \\\"details\\\": \\\"$details\\\",\n            \\\"cluster\\\": \\\"${CLUSTER_NAME:-unknown}\\\"\n        }\"\n\n    log \"Security alert sent\"\n}\n\nmain() {\n    log \"Security incident response triggered\"\n    log \"Type: $INCIDENT_TYPE, Severity: $SEVERITY, Resource: $AFFECTED_RESOURCE\"\n\n    case \"$INCIDENT_TYPE\" in\n        \"unauthorized_access\")\n            disable_user \"$AFFECTED_RESOURCE\"\n            collect_forensics \"$AFFECTED_RESOURCE\"\n            ;;\n        \"compromised_pod\")\n            isolate_pod \"$AFFECTED_RESOURCE\" \"temporal\"\n            collect_forensics \"$AFFECTED_RESOURCE\"\n            ;;\n        \"data_exfiltration\")\n            # Implement network restrictions\n            kubectl apply -f /etc/security/emergency-network-policies.yaml\n            collect_forensics \"$AFFECTED_RESOURCE\"\n            ;;\n        *)\n            log \"Unknown incident type: $INCIDENT_TYPE\"\n            ;;\n    esac\n\n    # Send alert for critical and high severity incidents\n    if [[ \"$SEVERITY\" == \"critical\" || \"$SEVERITY\" == \"high\" ]]; then\n        send_alert \"$INCIDENT_TYPE\" \"$SEVERITY\" \"Automated response executed for $AFFECTED_RESOURCE\"\n    fi\n\n    log \"Incident response completed\"\n}\n\nmain \"$@\"\n</code></pre>"},{"location":"security/best-practices/#compliance-and-auditing","title":"Compliance and Auditing","text":""},{"location":"security/best-practices/#1-compliance-framework-integration","title":"1. Compliance Framework Integration","text":""},{"location":"security/best-practices/#soc-2-compliance-configuration","title":"SOC 2 Compliance Configuration","text":"<pre><code># config/compliance/soc2-config.yaml\nsoc2_compliance:\n  availability:\n    monitoring:\n      uptime_target: \"99.9%\"\n      alerting: \"enabled\"\n      escalation: \"automatic\"\n\n    backup:\n      frequency: \"daily\"\n      retention: \"90 days\"\n      testing: \"monthly\"\n      encryption: \"AES-256\"\n\n  security:\n    access_control:\n      mfa_required: true\n      password_policy: \"complex\"\n      session_timeout: \"30 minutes\"\n      privileged_access_monitoring: true\n\n    vulnerability_management:\n      scanning_frequency: \"weekly\"\n      patch_timeframe: \"30 days\"\n      critical_patch_timeframe: \"7 days\"\n\n    incident_response:\n      documented_procedures: true\n      response_timeframes: \"defined\"\n      testing_frequency: \"quarterly\"\n\n  processing_integrity:\n    data_validation:\n      input_validation: \"comprehensive\"\n      processing_controls: \"automated\"\n      error_handling: \"documented\"\n\n    change_management:\n      approval_process: \"required\"\n      testing_requirements: \"mandatory\"\n      rollback_procedures: \"documented\"\n\n  confidentiality:\n    data_classification:\n      scheme: \"public, internal, confidential, restricted\"\n      handling_procedures: \"documented\"\n      access_controls: \"role-based\"\n\n    encryption:\n      data_at_rest: \"AES-256\"\n      data_in_transit: \"TLS 1.2+\"\n      key_management: \"centralized\"\n\n  privacy:\n    data_minimization: true\n    consent_management: \"implemented\"\n    data_retention: \"policy-defined\"\n    data_subject_rights: \"supported\"\n</code></pre>"},{"location":"security/best-practices/#gdpr-compliance-implementation","title":"GDPR Compliance Implementation","text":"<pre><code>// compliance/gdpr.go\npackage compliance\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"time\"\n\n    \"go.temporal.io/sdk/workflow\"\n)\n\n// GDPRCompliance handles GDPR compliance requirements\ntype GDPRCompliance struct {\n    dataProcessor DataProcessor\n    auditLogger   AuditLogger\n}\n\n// DataSubjectRequest represents a GDPR data subject request\ntype DataSubjectRequest struct {\n    RequestID     string    `json:\"request_id\"`\n    RequestType   string    `json:\"request_type\"` // access, portability, erasure, rectification\n    SubjectID     string    `json:\"subject_id\"`\n    RequestDate   time.Time `json:\"request_date\"`\n    VerificationStatus string `json:\"verification_status\"`\n    ProcessingDeadline time.Time `json:\"processing_deadline\"`\n}\n\n// ProcessDataSubjectRequest workflow\nfunc (g *GDPRCompliance) ProcessDataSubjectRequest(ctx workflow.Context, request DataSubjectRequest) error {\n    logger := workflow.GetLogger(ctx)\n    logger.Info(\"Processing GDPR data subject request\", \"request_id\", request.RequestID, \"type\", request.RequestType)\n\n    // Verify identity\n    verificationResult := &amp;workflow.Future{}\n    err := workflow.ExecuteActivity(ctx, g.VerifySubjectIdentity, request.SubjectID).Get(ctx, verificationResult)\n    if err != nil {\n        return fmt.Errorf(\"identity verification failed: %w\", err)\n    }\n\n    // Process request based on type\n    switch request.RequestType {\n    case \"access\":\n        return g.processAccessRequest(ctx, request)\n    case \"portability\":\n        return g.processPortabilityRequest(ctx, request)\n    case \"erasure\":\n        return g.processErasureRequest(ctx, request)\n    case \"rectification\":\n        return g.processRectificationRequest(ctx, request)\n    default:\n        return fmt.Errorf(\"unsupported request type: %s\", request.RequestType)\n    }\n}\n\nfunc (g *GDPRCompliance) processErasureRequest(ctx workflow.Context, request DataSubjectRequest) error {\n    // Right to be forgotten implementation\n    logger := workflow.GetLogger(ctx)\n\n    // Find all data for subject\n    var dataLocations []string\n    err := workflow.ExecuteActivity(ctx, g.FindPersonalData, request.SubjectID).Get(ctx, &amp;dataLocations)\n    if err != nil {\n        return fmt.Errorf(\"failed to find personal data: %w\", err)\n    }\n\n    // Check for legal basis to retain data\n    var retentionRequirements []string\n    err = workflow.ExecuteActivity(ctx, g.CheckRetentionRequirements, request.SubjectID).Get(ctx, &amp;retentionRequirements)\n    if err != nil {\n        return fmt.Errorf(\"failed to check retention requirements: %w\", err)\n    }\n\n    // Erase data where no legal basis exists\n    for _, location := range dataLocations {\n        if !g.hasRetentionRequirement(location, retentionRequirements) {\n            err = workflow.ExecuteActivity(ctx, g.ErasePersonalData, location, request.SubjectID).Get(ctx, nil)\n            if err != nil {\n                logger.Error(\"Failed to erase data\", \"location\", location, \"error\", err)\n                // Continue with other locations\n            }\n        }\n    }\n\n    // Generate completion report\n    report := g.generateErasureReport(request.SubjectID, dataLocations, retentionRequirements)\n    err = workflow.ExecuteActivity(ctx, g.SendCompletionReport, request.RequestID, report).Get(ctx, nil)\n    if err != nil {\n        return fmt.Errorf(\"failed to send completion report: %w\", err)\n    }\n\n    return nil\n}\n\n// Audit logging for compliance\nfunc (g *GDPRCompliance) LogComplianceEvent(event ComplianceEvent) {\n    g.auditLogger.Log(AuditEntry{\n        Timestamp:   time.Now(),\n        EventType:   \"gdpr_compliance\",\n        Action:      event.Action,\n        Subject:     event.Subject,\n        Object:      event.Object,\n        Result:      event.Result,\n        Details:     event.Details,\n        Compliance:  \"GDPR\",\n        Retention:   \"7 years\",\n    })\n}\n</code></pre>"},{"location":"security/best-practices/#temporal-129-security-best-practices","title":"Temporal 1.29+ Security Best Practices","text":""},{"location":"security/best-practices/#updated-for-latest-features-october-2025","title":"Updated for Latest Features (October 2025)","text":""},{"location":"security/best-practices/#1-eager-workflow-start-security-considerations","title":"1. Eager Workflow Start Security Considerations","text":"<p>With eager workflow start enabled by default in Temporal 1.29+, consider these security implications:</p> <pre><code># Security configuration for eager workflow start\nserver:\n  config:\n    services:\n      frontend:\n        eagerWorkflowStartEnabled: true\n        # Rate limiting for eager starts to prevent abuse\n        rateLimit:\n          eagerWorkflowStart:\n            maxPerSecond: 100\n            burstSize: 200\n</code></pre> <p>Best Practices: - Monitor worker resource usage closely as eager starts increase worker load - Implement strict authentication on workflow start requests - Use task queue rate limiting to prevent DoS attacks - Validate workflow inputs before eager execution</p> <pre><code># Python SDK: Validate before eager start\nfrom temporalio.client import Client\nfrom temporalio import workflow\n\n@workflow.defn\nclass SecureWorkflow:\n    @workflow.run\n    async def run(self, user_input: dict) -&gt; str:\n        # Input validation is critical with eager start\n        if not self.validate_input(user_input):\n            raise ValueError(\"Invalid input detected\")\n        return \"processed\"\n\n    def validate_input(self, data: dict) -&gt; bool:\n        # Implement strict validation\n        if not isinstance(data, dict):\n            return False\n        # Check for malicious patterns\n        return all(self.is_safe_value(v) for v in data.values())\n</code></pre>"},{"location":"security/best-practices/#2-worker-versioning-security","title":"2. Worker Versioning Security","text":"<p>With Worker Versioning (Safe Deploy) in public preview:</p> <pre><code># Secure worker versioning configuration\nworker:\n  versioning:\n    enabled: true\n    buildIDValidation:\n      enabled: true\n      allowedPattern: \"^v\\\\d+\\\\.\\\\d+\\\\.\\\\d+$\"  # Semantic versioning only\n\n    # Security: Prevent unauthorized version registration\n    authorizationPolicy:\n      requireAuthentication: true\n      allowedRoles:\n        - \"deployment-manager\"\n        - \"ci-cd-system\"\n</code></pre> <p>Best Practices: - Restrict who can register new worker versions - Validate build IDs to prevent version spoofing - Audit all version registration events - Use immutable container images with digest-based references</p> <pre><code># Secure worker registration with build ID\nfrom temporalio.worker import Worker\nimport hashlib\nimport os\n\n# Generate verifiable build ID\ndef generate_secure_build_id() -&gt; str:\n    git_commit = os.getenv(\"GIT_COMMIT\", \"unknown\")\n    build_time = os.getenv(\"BUILD_TIMESTAMP\", \"unknown\")\n\n    # Create tamper-resistant build ID\n    build_data = f\"{git_commit}:{build_time}\"\n    build_hash = hashlib.sha256(build_data.encode()).hexdigest()[:8]\n\n    return f\"v{VERSION}-{build_hash}\"\n\nworker = Worker(\n    client,\n    task_queue=\"secure-queue\",\n    workflows=[SecureWorkflow],\n    build_id=generate_secure_build_id(),\n    use_worker_versioning=True\n)\n</code></pre>"},{"location":"security/best-practices/#3-slimmed-docker-images-security","title":"3. Slimmed Docker Images Security","text":"<p>Temporal 1.29+ uses slimmed Docker images. Update your security scanning:</p> <pre><code># Updated Dockerfile for slim images\nFROM temporalio/server:1.29.1 AS temporal-server\n\n# Security: Use distroless or minimal base\nFROM gcr.io/distroless/static-debian11:nonroot\n\n# Copy only necessary binaries\nCOPY --from=temporal-server /usr/local/bin/temporal-server /usr/local/bin/\nCOPY --from=temporal-server /etc/temporal/config /etc/temporal/config\n\n# Security context\nUSER nonroot:nonroot\nWORKDIR /app\n\nENTRYPOINT [\"/usr/local/bin/temporal-server\"]\n</code></pre> <p>Security Scanning for Slim Images: <pre><code># Scan with Trivy\ntrivy image --severity HIGH,CRITICAL temporalio/server:1.29.1\n\n# Scan with Grype\ngrype temporalio/server:1.29.1 --fail-on high\n\n# Generate SBOM\nsyft temporalio/server:1.29.1 -o spdx-json &gt; sbom.json\n</code></pre></p>"},{"location":"security/best-practices/#4-update-with-start-security","title":"4. Update-With-Start Security","text":"<p>With Update-With-Start GA in 1.28+:</p> <pre><code>from temporalio import workflow\nfrom temporalio.client import Client\n\n@workflow.defn\nclass SecureOrderWorkflow:\n    @workflow.run\n    async def run(self, order_id: str) -&gt; str:\n        return f\"Processing order {order_id}\"\n\n    @workflow.update\n    async def update_order(self, new_data: dict) -&gt; str:\n        # Security: Validate update permissions\n        if not self.has_update_permission():\n            raise PermissionError(\"Unauthorized update attempt\")\n\n        # Security: Validate update data\n        if not self.validate_update_data(new_data):\n            raise ValueError(\"Invalid update data\")\n\n        # Process update\n        self._order_data.update(new_data)\n        return \"Updated\"\n</code></pre> <p>Best Practices: - Implement authorization checks in update handlers - Validate all update inputs - Log all update attempts for audit - Use idempotency tokens to prevent replay attacks</p>"},{"location":"security/best-practices/#5-nexus-cross-cluster-security","title":"5. Nexus Cross-Cluster Security","text":"<p>For Nexus (GA in 1.27+) cross-cluster operations:</p> <pre><code># Secure Nexus configuration\nnexus:\n  endpoints:\n    - name: remote-cluster\n      url: https://remote.temporal.io:7233\n\n      # mTLS authentication\n      tls:\n        enabled: true\n        clientCertFile: /etc/temporal/nexus/client.crt\n        clientKeyFile: /etc/temporal/nexus/client.key\n        serverCAFile: /etc/temporal/nexus/ca.crt\n        serverName: remote.temporal.io\n\n      # Additional security\n      authentication:\n        type: \"jwt\"\n        jwt:\n          issuer: \"local-cluster\"\n          audience: \"remote-cluster\"\n          keyFile: /etc/temporal/nexus/jwt-private.key\n\n      # Rate limiting\n      rateLimit:\n        maxCallsPerSecond: 10\n        burstSize: 20\n\n      # Timeout protection\n      timeout:\n        callTimeout: 30s\n        maxRetries: 3\n</code></pre>"},{"location":"security/best-practices/#6-enhanced-metrics-security","title":"6. Enhanced Metrics Security","text":"<p>With updated metrics in 1.29:</p> <pre><code># Secure Prometheus configuration\nprometheus:\n  # Authentication for metrics endpoint\n  basicAuth:\n    enabled: true\n    username: metrics-reader\n    passwordSecretRef:\n      name: prometheus-auth\n      key: password\n\n  # Metrics endpoint security\n  tls:\n    enabled: true\n    certFile: /etc/prometheus/tls.crt\n    keyFile: /etc/prometheus/tls.key\n\n  # Limit metrics cardinality to prevent DoS\n  scrapeConfigs:\n    - job_name: 'temporal'\n      metrics_path: '/metrics'\n      metric_relabel_configs:\n        - source_labels: [__name__]\n          regex: 'temporal_.*'\n          action: keep\n        # Drop high-cardinality metrics\n        - source_labels: [workflow_id]\n          action: labeldrop\n</code></pre>"},{"location":"security/best-practices/#security-checklist-for-temporal-129","title":"Security Checklist for Temporal 1.29+","text":"<ul> <li> Update to TLS 1.3 for all connections</li> <li> Enable eager workflow start with rate limiting</li> <li> Implement worker versioning with authorization</li> <li> Update container image scanning for slim images</li> <li> Add validation for Update-With-Start operations</li> <li> Configure mTLS for Nexus cross-cluster calls</li> <li> Review and update metrics security configuration</li> <li> Test security controls in staging environment</li> <li> Update incident response procedures</li> <li> Train team on new security features</li> </ul>"},{"location":"security/best-practices/#migration-security-considerations","title":"Migration Security Considerations","text":"<p>When upgrading from older versions:</p> <ol> <li> <p>Schema Migration Security: <pre><code># Backup before migration\ntemporal-sql-tool --plugin postgres12 \\\n  --ep postgresql.example.com \\\n  -u temporal_admin \\\n  --db temporal \\\n  backup --output-file temporal-backup-$(date +%Y%m%d).sql\n\n# Test migration in isolated environment first\ntemporal-sql-tool --plugin postgres12 update-schema --dry-run\n\n# Apply with verification\ntemporal-sql-tool --plugin postgres12 update-schema --verify\n</code></pre></p> </li> <li> <p>Rolling Upgrade Security:</p> </li> <li>Keep old and new versions compatible during transition</li> <li>Monitor for security anomalies during upgrade</li> <li>Have rollback plan with security context preserved</li> <li>Verify all security policies after upgrade</li> </ol>"},{"location":"security/best-practices/#resources","title":"Resources","text":"<ul> <li>Temporal 1.29 Security Release Notes</li> <li>What's New in Temporal.io</li> <li>Configuration Reference</li> <li>Official Security Documentation</li> </ul> <p>This comprehensive security best practices guide provides enterprise-grade security controls, monitoring, and compliance frameworks for Temporal.io deployments, ensuring robust protection against threats while meeting regulatory requirements. Updated for Temporal 1.29+ with latest features and recommendations.</p>"},{"location":"security/network-policies/","title":"Network Policies","text":"<p>This guide provides comprehensive network security policies for Temporal.io deployments, implementing zero-trust networking principles with granular traffic control between services, external systems, and client applications.</p>"},{"location":"security/network-policies/#overview","title":"Overview","text":"<p>Network policies in Temporal.io deployments control: - Inter-Service Communication: Between Temporal components - Client Access: From SDK clients and workers to Temporal services - Database Access: Connectivity to PostgreSQL and Elasticsearch - External Services: Integration with monitoring, logging, and other systems - Ingress Traffic: External access through load balancers and ingress controllers</p>"},{"location":"security/network-policies/#architecture","title":"Architecture","text":"<pre><code>graph TB\n    subgraph \"External Zone\"\n        INTERNET[Internet]\n        LB[Load Balancer]\n        CLIENTS[SDK Clients]\n    end\n\n    subgraph \"DMZ Zone\"\n        INGRESS[Ingress Controller]\n        WAF[Web Application Firewall]\n    end\n\n    subgraph \"Application Zone\"\n        FRONTEND[Frontend Service]\n        HISTORY[History Service]\n        MATCHING[Matching Service]\n        WORKER_SVC[Worker Service]\n\n        subgraph \"Worker Pods\"\n            WORKER1[Worker Pod 1]\n            WORKER2[Worker Pod 2]\n            WORKER3[Worker Pod 3]\n        end\n    end\n\n    subgraph \"Data Zone\"\n        POSTGRES[(PostgreSQL)]\n        ELASTICSEARCH[(Elasticsearch)]\n        REDIS[(Redis)]\n    end\n\n    subgraph \"Management Zone\"\n        PROMETHEUS[Prometheus]\n        GRAFANA[Grafana]\n        JAEGER[Jaeger]\n    end\n\n    INTERNET --&gt; LB\n    LB --&gt; WAF\n    WAF --&gt; INGRESS\n    INGRESS --&gt; FRONTEND\n    CLIENTS --&gt; LB\n\n    FRONTEND --&gt; HISTORY\n    FRONTEND --&gt; MATCHING\n    FRONTEND --&gt; WORKER_SVC\n\n    HISTORY --&gt; POSTGRES\n    HISTORY --&gt; ELASTICSEARCH\n    MATCHING --&gt; POSTGRES\n    WORKER_SVC --&gt; POSTGRES\n\n    WORKER1 --&gt; FRONTEND\n    WORKER2 --&gt; FRONTEND\n    WORKER3 --&gt; FRONTEND\n\n    PROMETHEUS --&gt; FRONTEND\n    PROMETHEUS --&gt; HISTORY\n    PROMETHEUS --&gt; MATCHING\n    PROMETHEUS --&gt; WORKER_SVC\n\n    GRAFANA --&gt; PROMETHEUS\n    JAEGER --&gt; ELASTICSEARCH</code></pre>"},{"location":"security/network-policies/#zero-trust-network-policies","title":"Zero-Trust Network Policies","text":""},{"location":"security/network-policies/#1-default-deny-policy","title":"1. Default Deny Policy","text":""},{"location":"security/network-policies/#global-default-deny","title":"Global Default Deny","text":"<pre><code># k8s/network-policies/00-default-deny.yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: default-deny-all\n  namespace: temporal\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\n\n---\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: default-deny-all\n  namespace: temporal-monitoring\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\n\n---\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: default-deny-all\n  namespace: temporal-workers\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\n</code></pre>"},{"location":"security/network-policies/#2-dns-resolution-policy","title":"2. DNS Resolution Policy","text":""},{"location":"security/network-policies/#allow-dns-for-all-pods","title":"Allow DNS for All Pods","text":"<pre><code># k8s/network-policies/01-allow-dns.yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-dns-access\n  namespace: temporal\nspec:\n  podSelector: {}\n  policyTypes:\n  - Egress\n  egress:\n  - to: []\n    ports:\n    - protocol: UDP\n      port: 53\n    - protocol: TCP\n      port: 53\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: kube-system\n    ports:\n    - protocol: UDP\n      port: 53\n    - protocol: TCP\n      port: 53\n\n---\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-dns-access\n  namespace: temporal-monitoring\nspec:\n  podSelector: {}\n  policyTypes:\n  - Egress\n  egress:\n  - to: []\n    ports:\n    - protocol: UDP\n      port: 53\n    - protocol: TCP\n      port: 53\n\n---\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-dns-access\n  namespace: temporal-workers\nspec:\n  podSelector: {}\n  policyTypes:\n  - Egress\n  egress:\n  - to: []\n    ports:\n    - protocol: UDP\n      port: 53\n    - protocol: TCP\n      port: 53\n</code></pre>"},{"location":"security/network-policies/#temporal-service-policies","title":"Temporal Service Policies","text":""},{"location":"security/network-policies/#1-frontend-service-policy","title":"1. Frontend Service Policy","text":""},{"location":"security/network-policies/#frontend-network-policy","title":"Frontend Network Policy","text":"<pre><code># k8s/network-policies/temporal-frontend.yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: temporal-frontend-policy\n  namespace: temporal\nspec:\n  podSelector:\n    matchLabels:\n      app: temporal-frontend\n  policyTypes:\n  - Ingress\n  - Egress\n\n  ingress:\n  # Allow ingress controller access\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: ingress-nginx\n    ports:\n    - protocol: TCP\n      port: 7233\n\n  # Allow load balancer access\n  - from: []\n    ports:\n    - protocol: TCP\n      port: 7233\n\n  # Allow worker access\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-workers\n    ports:\n    - protocol: TCP\n      port: 7233\n\n  # Allow SDK client access\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-clients\n    ports:\n    - protocol: TCP\n      port: 7233\n\n  # Allow monitoring access\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-monitoring\n    - podSelector:\n        matchLabels:\n          app: prometheus\n    ports:\n    - protocol: TCP\n      port: 9090  # Metrics port\n\n  # Allow internal service communication\n  - from:\n    - podSelector:\n        matchLabels:\n          app: temporal-history\n    - podSelector:\n        matchLabels:\n          app: temporal-matching\n    - podSelector:\n        matchLabels:\n          app: temporal-worker\n    ports:\n    - protocol: TCP\n      port: 7233\n    - protocol: TCP\n      port: 7234  # Membership port\n\n  egress:\n  # Allow communication to history service\n  - to:\n    - podSelector:\n        matchLabels:\n          app: temporal-history\n    ports:\n    - protocol: TCP\n      port: 7234\n    - protocol: TCP\n      port: 7235\n\n  # Allow communication to matching service\n  - to:\n    - podSelector:\n        matchLabels:\n          app: temporal-matching\n    ports:\n    - protocol: TCP\n      port: 7235\n\n  # Allow communication to worker service\n  - to:\n    - podSelector:\n        matchLabels:\n          app: temporal-worker\n    ports:\n    - protocol: TCP\n      port: 7239\n\n  # Allow database access\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 5432  # PostgreSQL\n\n  # Allow external service access (specify as needed)\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 443   # HTTPS\n    - protocol: TCP\n      port: 80    # HTTP\n</code></pre>"},{"location":"security/network-policies/#2-history-service-policy","title":"2. History Service Policy","text":""},{"location":"security/network-policies/#history-network-policy","title":"History Network Policy","text":"<pre><code># k8s/network-policies/temporal-history.yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: temporal-history-policy\n  namespace: temporal\nspec:\n  podSelector:\n    matchLabels:\n      app: temporal-history\n  policyTypes:\n  - Ingress\n  - Egress\n\n  ingress:\n  # Allow frontend service access\n  - from:\n    - podSelector:\n        matchLabels:\n          app: temporal-frontend\n    ports:\n    - protocol: TCP\n      port: 7234\n    - protocol: TCP\n      port: 7235\n\n  # Allow matching service access\n  - from:\n    - podSelector:\n        matchLabels:\n          app: temporal-matching\n    ports:\n    - protocol: TCP\n      port: 7235\n\n  # Allow worker service access\n  - from:\n    - podSelector:\n        matchLabels:\n          app: temporal-worker\n    ports:\n    - protocol: TCP\n      port: 7235\n\n  # Allow monitoring access\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-monitoring\n    - podSelector:\n        matchLabels:\n          app: prometheus\n    ports:\n    - protocol: TCP\n      port: 9090  # Metrics port\n\n  # Allow other history instances (clustering)\n  - from:\n    - podSelector:\n        matchLabels:\n          app: temporal-history\n    ports:\n    - protocol: TCP\n      port: 7234\n    - protocol: TCP\n      port: 7235\n\n  egress:\n  # Allow database access\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 5432  # PostgreSQL\n\n  # Allow Elasticsearch access\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 9200  # Elasticsearch\n    - protocol: TCP\n      port: 9300  # Elasticsearch transport\n\n  # Allow communication to other history instances\n  - to:\n    - podSelector:\n        matchLabels:\n          app: temporal-history\n    ports:\n    - protocol: TCP\n      port: 7234\n    - protocol: TCP\n      port: 7235\n\n  # Allow communication to frontend for membership\n  - to:\n    - podSelector:\n        matchLabels:\n          app: temporal-frontend\n    ports:\n    - protocol: TCP\n      port: 7234\n</code></pre>"},{"location":"security/network-policies/#3-matching-service-policy","title":"3. Matching Service Policy","text":""},{"location":"security/network-policies/#matching-network-policy","title":"Matching Network Policy","text":"<pre><code># k8s/network-policies/temporal-matching.yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: temporal-matching-policy\n  namespace: temporal\nspec:\n  podSelector:\n    matchLabels:\n      app: temporal-matching\n  policyTypes:\n  - Ingress\n  - Egress\n\n  ingress:\n  # Allow frontend service access\n  - from:\n    - podSelector:\n        matchLabels:\n          app: temporal-frontend\n    ports:\n    - protocol: TCP\n      port: 7235\n\n  # Allow history service access\n  - from:\n    - podSelector:\n        matchLabels:\n          app: temporal-history\n    ports:\n    - protocol: TCP\n      port: 7235\n\n  # Allow worker service access\n  - from:\n    - podSelector:\n        matchLabels:\n          app: temporal-worker\n    ports:\n    - protocol: TCP\n      port: 7235\n\n  # Allow monitoring access\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-monitoring\n    - podSelector:\n        matchLabels:\n          app: prometheus\n    ports:\n    - protocol: TCP\n      port: 9090  # Metrics port\n\n  # Allow other matching instances (clustering)\n  - from:\n    - podSelector:\n        matchLabels:\n          app: temporal-matching\n    ports:\n    - protocol: TCP\n      port: 7235\n\n  egress:\n  # Allow database access\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 5432  # PostgreSQL\n\n  # Allow communication to history service\n  - to:\n    - podSelector:\n        matchLabels:\n          app: temporal-history\n    ports:\n    - protocol: TCP\n      port: 7235\n\n  # Allow communication to other matching instances\n  - to:\n    - podSelector:\n        matchLabels:\n          app: temporal-matching\n    ports:\n    - protocol: TCP\n      port: 7235\n\n  # Allow communication to frontend for membership\n  - to:\n    - podSelector:\n        matchLabels:\n          app: temporal-frontend\n    ports:\n    - protocol: TCP\n      port: 7234\n</code></pre>"},{"location":"security/network-policies/#4-worker-service-policy","title":"4. Worker Service Policy","text":""},{"location":"security/network-policies/#worker-network-policy","title":"Worker Network Policy","text":"<pre><code># k8s/network-policies/temporal-worker.yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: temporal-worker-policy\n  namespace: temporal\nspec:\n  podSelector:\n    matchLabels:\n      app: temporal-worker\n  policyTypes:\n  - Ingress\n  - Egress\n\n  ingress:\n  # Allow frontend service access\n  - from:\n    - podSelector:\n        matchLabels:\n          app: temporal-frontend\n    ports:\n    - protocol: TCP\n      port: 7239\n\n  # Allow monitoring access\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-monitoring\n    - podSelector:\n        matchLabels:\n          app: prometheus\n    ports:\n    - protocol: TCP\n      port: 9090  # Metrics port\n\n  egress:\n  # Allow communication to frontend service\n  - to:\n    - podSelector:\n        matchLabels:\n          app: temporal-frontend\n    ports:\n    - protocol: TCP\n      port: 7233\n\n  # Allow communication to history service\n  - to:\n    - podSelector:\n        matchLabels:\n          app: temporal-history\n    ports:\n    - protocol: TCP\n      port: 7235\n\n  # Allow communication to matching service\n  - to:\n    - podSelector:\n        matchLabels:\n          app: temporal-matching\n    ports:\n    - protocol: TCP\n      port: 7235\n\n  # Allow database access\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 5432  # PostgreSQL\n</code></pre>"},{"location":"security/network-policies/#application-worker-policies","title":"Application Worker Policies","text":""},{"location":"security/network-policies/#1-worker-namespace-policy","title":"1. Worker Namespace Policy","text":""},{"location":"security/network-policies/#worker-access-policy","title":"Worker Access Policy","text":"<pre><code># k8s/network-policies/application-workers.yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: temporal-application-workers-policy\n  namespace: temporal-workers\nspec:\n  podSelector:\n    matchLabels:\n      component: temporal-worker\n  policyTypes:\n  - Ingress\n  - Egress\n\n  ingress:\n  # Allow monitoring access\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-monitoring\n    - podSelector:\n        matchLabels:\n          app: prometheus\n    ports:\n    - protocol: TCP\n      port: 9090  # Metrics port\n\n  # Allow health check access\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: kube-system\n    ports:\n    - protocol: TCP\n      port: 8080  # Health check port\n\n  egress:\n  # Allow access to Temporal frontend\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal\n      podSelector:\n        matchLabels:\n          app: temporal-frontend\n    ports:\n    - protocol: TCP\n      port: 7233\n\n  # Allow access to external APIs (adjust as needed)\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 443   # HTTPS\n    - protocol: TCP\n      port: 80    # HTTP\n\n  # Allow database access if workers need direct DB access\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 5432  # PostgreSQL\n    - protocol: TCP\n      port: 3306  # MySQL\n    - protocol: TCP\n      port: 27017 # MongoDB\n\n  # Allow Redis access for caching\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 6379  # Redis\n</code></pre>"},{"location":"security/network-policies/#2-specific-worker-application-policy","title":"2. Specific Worker Application Policy","text":""},{"location":"security/network-policies/#payment-worker-policy-example","title":"Payment Worker Policy Example","text":"<pre><code># k8s/network-policies/payment-worker.yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: payment-worker-policy\n  namespace: temporal-workers\nspec:\n  podSelector:\n    matchLabels:\n      app: payment-worker\n  policyTypes:\n  - Ingress\n  - Egress\n\n  ingress:\n  # Allow monitoring access\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-monitoring\n    ports:\n    - protocol: TCP\n      port: 9090\n\n  egress:\n  # Allow access to Temporal\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal\n    ports:\n    - protocol: TCP\n      port: 7233\n\n  # Allow access to payment APIs\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 443\n    # Restrict to specific domains if possible\n\n  # Allow database access\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: databases\n      podSelector:\n        matchLabels:\n          app: payments-db\n    ports:\n    - protocol: TCP\n      port: 5432\n</code></pre>"},{"location":"security/network-policies/#database-access-policies","title":"Database Access Policies","text":""},{"location":"security/network-policies/#1-postgresql-policy","title":"1. PostgreSQL Policy","text":""},{"location":"security/network-policies/#database-network-policy","title":"Database Network Policy","text":"<pre><code># k8s/network-policies/postgresql.yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: postgresql-policy\n  namespace: databases\nspec:\n  podSelector:\n    matchLabels:\n      app: postgresql\n  policyTypes:\n  - Ingress\n  - Egress\n\n  ingress:\n  # Allow Temporal services access\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal\n    ports:\n    - protocol: TCP\n      port: 5432\n\n  # Allow backup services access\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: backup-system\n    ports:\n    - protocol: TCP\n      port: 5432\n\n  # Allow monitoring access\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-monitoring\n      podSelector:\n        matchLabels:\n          app: postgres-exporter\n    ports:\n    - protocol: TCP\n      port: 5432\n\n  # Allow admin access from specific namespace\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: database-admin\n    ports:\n    - protocol: TCP\n      port: 5432\n\n  egress:\n  # Allow external backup destinations\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 443   # S3/Cloud storage\n\n  # Allow replication to read replicas\n  - to:\n    - podSelector:\n        matchLabels:\n          app: postgresql-replica\n    ports:\n    - protocol: TCP\n      port: 5432\n</code></pre>"},{"location":"security/network-policies/#2-elasticsearch-policy","title":"2. Elasticsearch Policy","text":""},{"location":"security/network-policies/#elasticsearch-network-policy","title":"Elasticsearch Network Policy","text":"<pre><code># k8s/network-policies/elasticsearch.yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: elasticsearch-policy\n  namespace: databases\nspec:\n  podSelector:\n    matchLabels:\n      app: elasticsearch\n  policyTypes:\n  - Ingress\n  - Egress\n\n  ingress:\n  # Allow Temporal history service access\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal\n      podSelector:\n        matchLabels:\n          app: temporal-history\n    ports:\n    - protocol: TCP\n      port: 9200\n\n  # Allow Jaeger access for tracing\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-monitoring\n      podSelector:\n        matchLabels:\n          app: jaeger\n    ports:\n    - protocol: TCP\n      port: 9200\n\n  # Allow Kibana access\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-monitoring\n      podSelector:\n        matchLabels:\n          app: kibana\n    ports:\n    - protocol: TCP\n      port: 9200\n\n  # Allow monitoring access\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-monitoring\n      podSelector:\n        matchLabels:\n          app: elasticsearch-exporter\n    ports:\n    - protocol: TCP\n      port: 9200\n\n  # Allow cluster communication\n  - from:\n    - podSelector:\n        matchLabels:\n          app: elasticsearch\n    ports:\n    - protocol: TCP\n      port: 9300   # Transport port\n    - protocol: TCP\n      port: 9200   # HTTP port\n\n  egress:\n  # Allow cluster communication\n  - to:\n    - podSelector:\n        matchLabels:\n          app: elasticsearch\n    ports:\n    - protocol: TCP\n      port: 9300\n    - protocol: TCP\n      port: 9200\n\n  # Allow external snapshot repositories\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 443   # S3/Cloud storage\n</code></pre>"},{"location":"security/network-policies/#monitoring-and-observability-policies","title":"Monitoring and Observability Policies","text":""},{"location":"security/network-policies/#1-prometheus-policy","title":"1. Prometheus Policy","text":""},{"location":"security/network-policies/#prometheus-network-policy","title":"Prometheus Network Policy","text":"<pre><code># k8s/network-policies/prometheus.yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: prometheus-policy\n  namespace: temporal-monitoring\nspec:\n  podSelector:\n    matchLabels:\n      app: prometheus\n  policyTypes:\n  - Ingress\n  - Egress\n\n  ingress:\n  # Allow Grafana access\n  - from:\n    - podSelector:\n        matchLabels:\n          app: grafana\n    ports:\n    - protocol: TCP\n      port: 9090\n\n  # Allow AlertManager access\n  - from:\n    - podSelector:\n        matchLabels:\n          app: alertmanager\n    ports:\n    - protocol: TCP\n      port: 9090\n\n  # Allow admin access\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: admin-tools\n    ports:\n    - protocol: TCP\n      port: 9090\n\n  egress:\n  # Allow scraping Temporal services\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal\n    ports:\n    - protocol: TCP\n      port: 9090   # Metrics port\n\n  # Allow scraping worker services\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-workers\n    ports:\n    - protocol: TCP\n      port: 9090   # Metrics port\n\n  # Allow scraping database exporters\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: databases\n    ports:\n    - protocol: TCP\n      port: 9187   # PostgreSQL exporter\n    - protocol: TCP\n      port: 9114   # Elasticsearch exporter\n\n  # Allow external alert destinations\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 443    # Webhook endpoints\n    - protocol: TCP\n      port: 587    # SMTP\n</code></pre>"},{"location":"security/network-policies/#2-grafana-policy","title":"2. Grafana Policy","text":""},{"location":"security/network-policies/#grafana-network-policy","title":"Grafana Network Policy","text":"<pre><code># k8s/network-policies/grafana.yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: grafana-policy\n  namespace: temporal-monitoring\nspec:\n  podSelector:\n    matchLabels:\n      app: grafana\n  policyTypes:\n  - Ingress\n  - Egress\n\n  ingress:\n  # Allow ingress controller access\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: ingress-nginx\n    ports:\n    - protocol: TCP\n      port: 3000\n\n  # Allow load balancer access\n  - from: []\n    ports:\n    - protocol: TCP\n      port: 3000\n\n  egress:\n  # Allow access to Prometheus\n  - to:\n    - podSelector:\n        matchLabels:\n          app: prometheus\n    ports:\n    - protocol: TCP\n      port: 9090\n\n  # Allow access to Jaeger for tracing\n  - to:\n    - podSelector:\n        matchLabels:\n          app: jaeger-query\n    ports:\n    - protocol: TCP\n      port: 16686\n\n  # Allow external plugin downloads and updates\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 443    # HTTPS\n</code></pre>"},{"location":"security/network-policies/#ingress-and-external-access-policies","title":"Ingress and External Access Policies","text":""},{"location":"security/network-policies/#1-ingress-controller-policy","title":"1. Ingress Controller Policy","text":""},{"location":"security/network-policies/#ingress-network-policy","title":"Ingress Network Policy","text":"<pre><code># k8s/network-policies/ingress-controller.yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: ingress-controller-policy\n  namespace: ingress-nginx\nspec:\n  podSelector:\n    matchLabels:\n      app.kubernetes.io/name: ingress-nginx\n  policyTypes:\n  - Ingress\n  - Egress\n\n  ingress:\n  # Allow external traffic\n  - from: []\n    ports:\n    - protocol: TCP\n      port: 80\n    - protocol: TCP\n      port: 443\n\n  egress:\n  # Allow access to Temporal frontend\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal\n      podSelector:\n        matchLabels:\n          app: temporal-frontend\n    ports:\n    - protocol: TCP\n      port: 7233\n\n  # Allow access to Grafana\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-monitoring\n      podSelector:\n        matchLabels:\n          app: grafana\n    ports:\n    - protocol: TCP\n      port: 3000\n\n  # Allow access to Jaeger UI\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-monitoring\n      podSelector:\n        matchLabels:\n          app: jaeger-query\n    ports:\n    - protocol: TCP\n      port: 16686\n</code></pre>"},{"location":"security/network-policies/#environment-specific-policies","title":"Environment-Specific Policies","text":""},{"location":"security/network-policies/#1-development-environment","title":"1. Development Environment","text":""},{"location":"security/network-policies/#development-relaxed-policy","title":"Development Relaxed Policy","text":"<pre><code># k8s/network-policies/dev-environment.yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: dev-relaxed-policy\n  namespace: temporal-dev\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\n\n  ingress:\n  # Allow all internal cluster traffic\n  - from:\n    - namespaceSelector: {}\n\n  egress:\n  # Allow all egress for development\n  - to: []\n</code></pre>"},{"location":"security/network-policies/#2-production-environment","title":"2. Production Environment","text":""},{"location":"security/network-policies/#production-strict-policy","title":"Production Strict Policy","text":"<pre><code># k8s/network-policies/prod-environment.yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: prod-strict-policy\n  namespace: temporal-production\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress\n  - Egress\n\n  ingress:\n  # Only allow specific namespaces\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          environment: production\n\n  # Allow monitoring\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: temporal-monitoring\n\n  egress:\n  # Restrict egress to specific destinations\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          environment: production\n\n  # Allow external HTTPS only\n  - to: []\n    ports:\n    - protocol: TCP\n      port: 443\n</code></pre>"},{"location":"security/network-policies/#policy-validation-and-testing","title":"Policy Validation and Testing","text":""},{"location":"security/network-policies/#1-network-policy-testing-script","title":"1. Network Policy Testing Script","text":""},{"location":"security/network-policies/#policy-validation","title":"Policy Validation","text":"<pre><code>#!/bin/bash\n# scripts/test-network-policies.sh\n\nset -euo pipefail\n\nNAMESPACE=\"temporal\"\nTEST_NAMESPACE=\"network-policy-test\"\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\nerror() {\n    echo -e \"\\033[0;31m[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1\\033[0m\"\n    exit 1\n}\n\n# Function to test connectivity\ntest_connectivity() {\n    local source_pod=\"$1\"\n    local target_host=\"$2\"\n    local target_port=\"$3\"\n    local expected_result=\"$4\"  # \"allow\" or \"deny\"\n\n    log \"Testing connectivity from $source_pod to $target_host:$target_port (expecting $expected_result)\"\n\n    if kubectl exec -n \"$TEST_NAMESPACE\" \"$source_pod\" -- timeout 5 nc -zv \"$target_host\" \"$target_port\" &amp;&gt;/dev/null; then\n        result=\"allow\"\n    else\n        result=\"deny\"\n    fi\n\n    if [[ \"$result\" == \"$expected_result\" ]]; then\n        log \"\u2713 Test passed: $source_pod -&gt; $target_host:$target_port ($result)\"\n    else\n        error \"\u2717 Test failed: $source_pod -&gt; $target_host:$target_port (expected $expected_result, got $result)\"\n    fi\n}\n\n# Create test namespace\nkubectl create namespace \"$TEST_NAMESPACE\" --dry-run=client -o yaml | kubectl apply -f -\n\n# Label test namespace\nkubectl label namespace \"$TEST_NAMESPACE\" name=\"$TEST_NAMESPACE\" --overwrite\n\n# Deploy test pods\ncat &lt;&lt; EOF | kubectl apply -f -\napiVersion: v1\nkind: Pod\nmetadata:\n  name: test-client\n  namespace: $TEST_NAMESPACE\n  labels:\n    app: test-client\nspec:\n  containers:\n  - name: netshoot\n    image: nicolaka/netshoot\n    command: [\"/bin/bash\"]\n    args: [\"-c\", \"while true; do sleep 30; done;\"]\n\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: test-worker\n  namespace: $TEST_NAMESPACE\n  labels:\n    app: test-worker\n    component: temporal-worker\nspec:\n  containers:\n  - name: netshoot\n    image: nicolaka/netshoot\n    command: [\"/bin/bash\"]\n    args: [\"-c\", \"while true; do sleep 30; done;\"]\nEOF\n\n# Wait for pods to be ready\nkubectl wait pod test-client -n \"$TEST_NAMESPACE\" --for=condition=Ready --timeout=60s\nkubectl wait pod test-worker -n \"$TEST_NAMESPACE\" --for=condition=Ready --timeout=60s\n\n# Test cases\nlog \"Running network policy tests...\"\n\n# Test 1: Client should be able to access frontend\ntest_connectivity \"test-client\" \"temporal-frontend.${NAMESPACE}.svc.cluster.local\" \"7233\" \"allow\"\n\n# Test 2: Client should not be able to access history directly\ntest_connectivity \"test-client\" \"temporal-history.${NAMESPACE}.svc.cluster.local\" \"7235\" \"deny\"\n\n# Test 3: Worker should be able to access frontend\ntest_connectivity \"test-worker\" \"temporal-frontend.${NAMESPACE}.svc.cluster.local\" \"7233\" \"allow\"\n\n# Test 4: Test DNS resolution\ntest_connectivity \"test-client\" \"8.8.8.8\" \"53\" \"allow\"\n\n# Test 5: Test database access restrictions\ntest_connectivity \"test-client\" \"postgresql.databases.svc.cluster.local\" \"5432\" \"deny\"\n\nlog \"\u2713 All network policy tests completed\"\n\n# Cleanup\nkubectl delete namespace \"$TEST_NAMESPACE\"\n</code></pre>"},{"location":"security/network-policies/#2-policy-monitoring","title":"2. Policy Monitoring","text":""},{"location":"security/network-policies/#network-policy-violations-monitor","title":"Network Policy Violations Monitor","text":"<pre><code># k8s/monitoring/network-policy-monitor.yaml\napiVersion: monitoring.coreos.com/v1\nkind: PrometheusRule\nmetadata:\n  name: network-policy-violations\n  namespace: temporal-monitoring\nspec:\n  groups:\n  - name: network-policy\n    rules:\n    - alert: NetworkPolicyViolation\n      expr: increase(networkpolicy_dropped_packets_total[5m]) &gt; 10\n      for: 2m\n      labels:\n        severity: warning\n      annotations:\n        summary: \"High number of dropped packets due to network policies\"\n        description: \"Network policy {{ $labels.policy }} has dropped {{ $value }} packets in the last 5 minutes\"\n\n    - alert: UnexpectedNetworkTraffic\n      expr: increase(networkpolicy_allowed_packets_total{destination_port!~\"7233|7234|7235|7239|5432|9200|53\"}[5m]) &gt; 0\n      for: 1m\n      labels:\n        severity: critical\n      annotations:\n        summary: \"Unexpected network traffic detected\"\n        description: \"Traffic to unexpected port {{ $labels.destination_port }} detected from {{ $labels.source }}\"\n</code></pre> <p>This comprehensive network policies guide provides zero-trust networking for Temporal.io deployments with granular traffic control, security boundaries, and monitoring capabilities.</p>"},{"location":"security/secrets/","title":"Secrets Management","text":"<p>This guide provides comprehensive secrets management strategies for Temporal.io deployments, ensuring secure storage, access, and rotation of sensitive information including database credentials, API keys, certificates, and encryption keys.</p>"},{"location":"security/secrets/#overview","title":"Overview","text":"<p>Secrets management in Temporal.io encompasses: - Database Credentials: PostgreSQL and Elasticsearch authentication - TLS Certificates: Server and client certificates for secure communication - API Keys: Authentication tokens and service credentials - Encryption Keys: Data encryption and JWT signing keys - External Service Credentials: Third-party service authentication</p>"},{"location":"security/secrets/#architecture","title":"Architecture","text":"<pre><code>graph TB\n    subgraph \"External Secret Stores\"\n        VAULT[HashiCorp Vault]\n        AWS_SM[AWS Secrets Manager]\n        AZURE_KV[Azure Key Vault]\n        GCP_SM[GCP Secret Manager]\n    end\n\n    subgraph \"Kubernetes Secret Management\"\n        ESO[External Secrets Operator]\n        SEALED_SECRETS[Sealed Secrets]\n        K8S_SECRETS[Kubernetes Secrets]\n    end\n\n    subgraph \"Temporal Cluster\"\n        FRONTEND[Frontend Service]\n        HISTORY[History Service]\n        MATCHING[Matching Service]\n        WORKER[Worker Service]\n    end\n\n    subgraph \"Data Stores\"\n        POSTGRES[(PostgreSQL)]\n        ELASTICSEARCH[(Elasticsearch)]\n    end\n\n    subgraph \"Certificate Management\"\n        CERT_MANAGER[Cert Manager]\n        CA_CERTS[CA Certificates]\n        TLS_CERTS[TLS Certificates]\n    end\n\n    VAULT --&gt; ESO\n    AWS_SM --&gt; ESO\n    AZURE_KV --&gt; ESO\n    GCP_SM --&gt; ESO\n\n    ESO --&gt; K8S_SECRETS\n    SEALED_SECRETS --&gt; K8S_SECRETS\n    CERT_MANAGER --&gt; K8S_SECRETS\n\n    K8S_SECRETS --&gt; FRONTEND\n    K8S_SECRETS --&gt; HISTORY\n    K8S_SECRETS --&gt; MATCHING\n    K8S_SECRETS --&gt; WORKER\n\n    FRONTEND --&gt; POSTGRES\n    HISTORY --&gt; POSTGRES\n    HISTORY --&gt; ELASTICSEARCH\n\n    CA_CERTS --&gt; TLS_CERTS\n    TLS_CERTS --&gt; FRONTEND\n    TLS_CERTS --&gt; HISTORY\n    TLS_CERTS --&gt; MATCHING\n    TLS_CERTS --&gt; WORKER</code></pre>"},{"location":"security/secrets/#external-secrets-operator-integration","title":"External Secrets Operator Integration","text":""},{"location":"security/secrets/#1-installation-and-configuration","title":"1. Installation and Configuration","text":""},{"location":"security/secrets/#external-secrets-operator-setup","title":"External Secrets Operator Setup","text":"<pre><code>#!/bin/bash\n# scripts/install-external-secrets.sh\n\nset -euo pipefail\n\nNAMESPACE=\"external-secrets-system\"\nVERSION=\"v0.9.11\"\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\nerror() {\n    echo -e \"\\033[0;31m[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1\\033[0m\"\n    exit 1\n}\n\nlog \"Installing External Secrets Operator...\"\n\n# Create namespace\nkubectl create namespace \"$NAMESPACE\" --dry-run=client -o yaml | kubectl apply -f -\n\n# Install using Helm\nhelm repo add external-secrets https://charts.external-secrets.io\nhelm repo update\n\nhelm install external-secrets external-secrets/external-secrets \\\n    --namespace \"$NAMESPACE\" \\\n    --version \"$VERSION\" \\\n    --set installCRDs=true \\\n    --set webhook.port=9443 \\\n    --set certController.create=true\n\n# Wait for deployment\nkubectl wait deployment external-secrets -n \"$NAMESPACE\" --for=condition=Available --timeout=300s\nkubectl wait deployment external-secrets-webhook -n \"$NAMESPACE\" --for=condition=Available --timeout=300s\nkubectl wait deployment external-secrets-cert-controller -n \"$NAMESPACE\" --for=condition=Available --timeout=300s\n\nlog \"\u2713 External Secrets Operator installed successfully\"\n</code></pre>"},{"location":"security/secrets/#2-hashicorp-vault-integration","title":"2. HashiCorp Vault Integration","text":""},{"location":"security/secrets/#vault-secret-store-configuration","title":"Vault Secret Store Configuration","text":"<pre><code># k8s/external-secrets/vault-secret-store.yaml\napiVersion: external-secrets.io/v1beta1\nkind: SecretStore\nmetadata:\n  name: vault-backend\n  namespace: temporal\nspec:\n  provider:\n    vault:\n      server: \"https://vault.company.com\"\n      path: \"secret\"\n      version: \"v2\"\n      auth:\n        kubernetes:\n          mountPath: \"kubernetes\"\n          role: \"temporal-secrets-reader\"\n          serviceAccountRef:\n            name: \"temporal-vault-auth\"\n\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: temporal-vault-auth\n  namespace: temporal\n  annotations:\n    vault.hashicorp.com/role: \"temporal-secrets-reader\"\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: temporal-vault-auth\nrules:\n- apiGroups: [\"\"]\n  resources: [\"serviceaccounts/token\"]\n  verbs: [\"create\"]\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: temporal-vault-auth\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: temporal-vault-auth\nsubjects:\n- kind: ServiceAccount\n  name: temporal-vault-auth\n  namespace: temporal\n</code></pre>"},{"location":"security/secrets/#vault-policy-configuration","title":"Vault Policy Configuration","text":"<pre><code># vault/policies/temporal-secrets.hcl\npath \"secret/data/temporal/*\" {\n  capabilities = [\"read\"]\n}\n\npath \"secret/metadata/temporal/*\" {\n  capabilities = [\"list\", \"read\"]\n}\n\npath \"pki/issue/temporal\" {\n  capabilities = [\"create\", \"update\"]\n}\n\npath \"database/creds/temporal-readonly\" {\n  capabilities = [\"read\"]\n}\n\npath \"database/creds/temporal-readwrite\" {\n  capabilities = [\"read\"]\n}\n</code></pre>"},{"location":"security/secrets/#vault-kubernetes-auth-setup","title":"Vault Kubernetes Auth Setup","text":"<pre><code>#!/bin/bash\n# scripts/setup-vault-auth.sh\n\nset -euo pipefail\n\nVAULT_ADDR=\"https://vault.company.com\"\nKUBERNETES_HOST=\"https://kubernetes.default.svc.cluster.local\"\nVAULT_SA_NAME=\"temporal-vault-auth\"\nNAMESPACE=\"temporal\"\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\n# Get service account token\nSA_JWT_TOKEN=$(kubectl get secret $(kubectl get sa $VAULT_SA_NAME -n $NAMESPACE -o jsonpath='{.secrets[0].name}') -n $NAMESPACE -o jsonpath='{.data.token}' | base64 --decode)\nSA_CA_CRT=$(kubectl get secret $(kubectl get sa $VAULT_SA_NAME -n $NAMESPACE -o jsonpath='{.secrets[0].name}') -n $NAMESPACE -o jsonpath='{.data.ca\\.crt}' | base64 --decode)\n\n# Configure Vault Kubernetes auth\nvault auth enable kubernetes\n\nvault write auth/kubernetes/config \\\n    token_reviewer_jwt=\"$SA_JWT_TOKEN\" \\\n    kubernetes_host=\"$KUBERNETES_HOST\" \\\n    kubernetes_ca_cert=\"$SA_CA_CRT\"\n\n# Create role for temporal\nvault write auth/kubernetes/role/temporal-secrets-reader \\\n    bound_service_account_names=\"$VAULT_SA_NAME\" \\\n    bound_service_account_namespaces=\"$NAMESPACE\" \\\n    policies=\"temporal-secrets\" \\\n    ttl=24h\n\nlog \"\u2713 Vault Kubernetes authentication configured\"\n</code></pre>"},{"location":"security/secrets/#3-aws-secrets-manager-integration","title":"3. AWS Secrets Manager Integration","text":""},{"location":"security/secrets/#aws-secret-store-configuration","title":"AWS Secret Store Configuration","text":"<pre><code># k8s/external-secrets/aws-secret-store.yaml\napiVersion: external-secrets.io/v1beta1\nkind: SecretStore\nmetadata:\n  name: aws-secrets-manager\n  namespace: temporal\nspec:\n  provider:\n    aws:\n      service: SecretsManager\n      region: us-west-2\n      auth:\n        serviceAccount:\n          name: temporal-aws-secrets\n\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: temporal-aws-secrets\n  namespace: temporal\n  annotations:\n    eks.amazonaws.com/role-arn: arn:aws:iam::ACCOUNT_ID:role/temporal-secrets-manager-role\n\n---\napiVersion: external-secrets.io/v1beta1\nkind: ClusterSecretStore\nmetadata:\n  name: aws-parameter-store\nspec:\n  provider:\n    aws:\n      service: ParameterStore\n      region: us-west-2\n      auth:\n        serviceAccount:\n          name: temporal-aws-secrets\n</code></pre>"},{"location":"security/secrets/#iam-role-configuration","title":"IAM Role Configuration","text":"<pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"secretsmanager:GetSecretValue\",\n        \"secretsmanager:DescribeSecret\"\n      ],\n      \"Resource\": [\n        \"arn:aws:secretsmanager:us-west-2:ACCOUNT_ID:secret:temporal/*\"\n      ]\n    },\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"ssm:GetParameter\",\n        \"ssm:GetParameters\",\n        \"ssm:GetParametersByPath\"\n      ],\n      \"Resource\": [\n        \"arn:aws:ssm:us-west-2:ACCOUNT_ID:parameter/temporal/*\"\n      ]\n    }\n  ]\n}\n</code></pre>"},{"location":"security/secrets/#database-secrets-management","title":"Database Secrets Management","text":""},{"location":"security/secrets/#1-postgresql-credentials","title":"1. PostgreSQL Credentials","text":""},{"location":"security/secrets/#database-secret-configuration","title":"Database Secret Configuration","text":"<pre><code># k8s/external-secrets/database-secrets.yaml\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: temporal-postgres-credentials\n  namespace: temporal\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: temporal-postgres-credentials\n    creationPolicy: Owner\n    template:\n      type: Opaque\n      data:\n        username: \"{{ .username }}\"\n        password: \"{{ .password }}\"\n        host: \"{{ .host }}\"\n        port: \"{{ .port }}\"\n        database: \"{{ .database }}\"\n        connection-string: \"postgres://{{ .username }}:{{ .password }}@{{ .host }}:{{ .port }}/{{ .database }}?sslmode=require\"\n        visibility-connection-string: \"postgres://{{ .username }}:{{ .password }}@{{ .host }}:{{ .port }}/{{ .visibility_database }}?sslmode=require\"\n  data:\n  - secretKey: username\n    remoteRef:\n      key: temporal/database\n      property: username\n  - secretKey: password\n    remoteRef:\n      key: temporal/database\n      property: password\n  - secretKey: host\n    remoteRef:\n      key: temporal/database\n      property: host\n  - secretKey: port\n    remoteRef:\n      key: temporal/database\n      property: port\n  - secretKey: database\n    remoteRef:\n      key: temporal/database\n      property: database\n  - secretKey: visibility_database\n    remoteRef:\n      key: temporal/database\n      property: visibility_database\n\n---\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: temporal-postgres-admin-credentials\n  namespace: temporal\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: temporal-postgres-admin-credentials\n    creationPolicy: Owner\n  data:\n  - secretKey: username\n    remoteRef:\n      key: temporal/database-admin\n      property: username\n  - secretKey: password\n    remoteRef:\n      key: temporal/database-admin\n      property: password\n</code></pre>"},{"location":"security/secrets/#2-dynamic-database-credentials-with-vault","title":"2. Dynamic Database Credentials with Vault","text":""},{"location":"security/secrets/#vault-database-engine-configuration","title":"Vault Database Engine Configuration","text":"<pre><code>#!/bin/bash\n# scripts/setup-vault-database.sh\n\nset -euo pipefail\n\nVAULT_ADDR=\"https://vault.company.com\"\nDB_HOST=\"postgres.company.com\"\nDB_PORT=\"5432\"\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\n# Enable database secrets engine\nvault secrets enable database\n\n# Configure PostgreSQL connection\nvault write database/config/temporal-postgres \\\n    plugin_name=postgresql-database-plugin \\\n    connection_url=\"postgresql://{{username}}:{{password}}@${DB_HOST}:${DB_PORT}/postgres?sslmode=require\" \\\n    allowed_roles=\"temporal-readonly,temporal-readwrite\" \\\n    username=\"vault-admin\" \\\n    password=\"$POSTGRES_VAULT_PASSWORD\"\n\n# Create readonly role\nvault write database/roles/temporal-readonly \\\n    db_name=temporal-postgres \\\n    creation_statements=\"CREATE ROLE \\\"{{name}}\\\" WITH LOGIN PASSWORD '{{password}}' VALID UNTIL '{{expiration}}'; \\\n        GRANT SELECT ON ALL TABLES IN SCHEMA public TO \\\"{{name}}\\\";\" \\\n    default_ttl=\"1h\" \\\n    max_ttl=\"24h\"\n\n# Create readwrite role\nvault write database/roles/temporal-readwrite \\\n    db_name=temporal-postgres \\\n    creation_statements=\"CREATE ROLE \\\"{{name}}\\\" WITH LOGIN PASSWORD '{{password}}' VALID UNTIL '{{expiration}}'; \\\n        GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO \\\"{{name}}\\\";\" \\\n    default_ttl=\"1h\" \\\n    max_ttl=\"24h\"\n\nlog \"\u2713 Vault database engine configured for PostgreSQL\"\n</code></pre>"},{"location":"security/secrets/#dynamic-database-secret","title":"Dynamic Database Secret","text":"<pre><code># k8s/external-secrets/dynamic-database-secret.yaml\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: temporal-dynamic-db-credentials\n  namespace: temporal\nspec:\n  refreshInterval: 30m\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: temporal-dynamic-db-credentials\n    creationPolicy: Owner\n    template:\n      type: Opaque\n      data:\n        username: \"{{ .username }}\"\n        password: \"{{ .password }}\"\n        connection-string: \"postgres://{{ .username }}:{{ .password }}@postgres.company.com:5432/temporal?sslmode=require\"\n  data:\n  - secretKey: username\n    remoteRef:\n      key: database/creds/temporal-readwrite\n      property: username\n  - secretKey: password\n    remoteRef:\n      key: database/creds/temporal-readwrite\n      property: password\n</code></pre>"},{"location":"security/secrets/#tls-certificate-secrets","title":"TLS Certificate Secrets","text":""},{"location":"security/secrets/#1-certificate-secret-management","title":"1. Certificate Secret Management","text":""},{"location":"security/secrets/#tls-certificate-secrets_1","title":"TLS Certificate Secrets","text":"<pre><code># k8s/external-secrets/tls-certificates.yaml\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: temporal-server-tls-certs\n  namespace: temporal\nspec:\n  refreshInterval: 6h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: temporal-server-tls\n    creationPolicy: Owner\n    template:\n      type: kubernetes.io/tls\n      data:\n        tls.crt: \"{{ .server_cert }}\"\n        tls.key: \"{{ .server_key }}\"\n        ca.crt: \"{{ .ca_cert }}\"\n  data:\n  - secretKey: server_cert\n    remoteRef:\n      key: temporal/tls/server\n      property: certificate\n  - secretKey: server_key\n    remoteRef:\n      key: temporal/tls/server\n      property: private_key\n  - secretKey: ca_cert\n    remoteRef:\n      key: temporal/tls/ca\n      property: certificate\n\n---\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: temporal-client-tls-certs\n  namespace: temporal\nspec:\n  refreshInterval: 6h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: temporal-client-tls\n    creationPolicy: Owner\n    template:\n      type: kubernetes.io/tls\n  data:\n  - secretKey: tls.crt\n    remoteRef:\n      key: temporal/tls/client\n      property: certificate\n  - secretKey: tls.key\n    remoteRef:\n      key: temporal/tls/client\n      property: private_key\n  - secretKey: ca.crt\n    remoteRef:\n      key: temporal/tls/ca\n      property: certificate\n</code></pre>"},{"location":"security/secrets/#2-automated-certificate-generation-with-vault-pki","title":"2. Automated Certificate Generation with Vault PKI","text":""},{"location":"security/secrets/#vault-pki-setup","title":"Vault PKI Setup","text":"<pre><code>#!/bin/bash\n# scripts/setup-vault-pki.sh\n\nset -euo pipefail\n\nVAULT_ADDR=\"https://vault.company.com\"\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\n# Enable PKI secrets engine\nvault secrets enable -path=pki pki\n\n# Tune the TTL\nvault secrets tune -max-lease-ttl=87600h pki\n\n# Generate root certificate\nvault write -field=certificate pki/root/generate/internal \\\n    common_name=\"Company Root CA\" \\\n    ttl=87600h &gt; ca_cert.pem\n\n# Configure URLs\nvault write pki/config/urls \\\n    issuing_certificates=\"$VAULT_ADDR/v1/pki/ca\" \\\n    crl_distribution_points=\"$VAULT_ADDR/v1/pki/crl\"\n\n# Enable intermediate PKI\nvault secrets enable -path=pki_int pki\nvault secrets tune -max-lease-ttl=43800h pki_int\n\n# Generate intermediate CSR\nvault write -format=json pki_int/intermediate/generate/internal \\\n    common_name=\"Company Intermediate CA\" \\\n    | jq -r '.data.csr' &gt; pki_intermediate.csr\n\n# Sign intermediate certificate\nvault write -format=json pki/root/sign-intermediate \\\n    csr=@pki_intermediate.csr \\\n    format=pem_bundle ttl=\"43800h\" \\\n    | jq -r '.data.certificate' &gt; intermediate.cert.pem\n\n# Import signed certificate\nvault write pki_int/intermediate/set-signed certificate=@intermediate.cert.pem\n\n# Create role for temporal certificates\nvault write pki_int/roles/temporal \\\n    allowed_domains=\"company.com,temporal.company.com\" \\\n    allow_subdomains=true \\\n    max_ttl=\"720h\"\n\nlog \"\u2713 Vault PKI configured successfully\"\n</code></pre>"},{"location":"security/secrets/#dynamic-certificate-generation","title":"Dynamic Certificate Generation","text":"<pre><code># k8s/external-secrets/dynamic-certificates.yaml\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: temporal-dynamic-server-cert\n  namespace: temporal\nspec:\n  refreshInterval: 24h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: temporal-dynamic-server-tls\n    creationPolicy: Owner\n    template:\n      type: kubernetes.io/tls\n      data:\n        tls.crt: \"{{ .certificate }}\"\n        tls.key: \"{{ .private_key }}\"\n        ca.crt: \"{{ .issuing_ca }}\"\n  data:\n  - secretKey: certificate\n    remoteRef:\n      key: pki_int/issue/temporal\n      property: certificate\n  - secretKey: private_key\n    remoteRef:\n      key: pki_int/issue/temporal\n      property: private_key\n  - secretKey: issuing_ca\n    remoteRef:\n      key: pki_int/issue/temporal\n      property: issuing_ca\n</code></pre>"},{"location":"security/secrets/#api-keys-and-jwt-secrets","title":"API Keys and JWT Secrets","text":""},{"location":"security/secrets/#1-jwt-signing-keys","title":"1. JWT Signing Keys","text":""},{"location":"security/secrets/#jwt-secret-configuration","title":"JWT Secret Configuration","text":"<pre><code># k8s/external-secrets/jwt-secrets.yaml\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: temporal-jwt-secrets\n  namespace: temporal\nspec:\n  refreshInterval: 24h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: temporal-jwt-secrets\n    creationPolicy: Owner\n    template:\n      type: Opaque\n      data:\n        jwt-signing-key: \"{{ .signing_key }}\"\n        jwt-public-key: \"{{ .public_key }}\"\n        jwt-key-id: \"{{ .key_id }}\"\n  data:\n  - secretKey: signing_key\n    remoteRef:\n      key: temporal/jwt\n      property: signing_key\n  - secretKey: public_key\n    remoteRef:\n      key: temporal/jwt\n      property: public_key\n  - secretKey: key_id\n    remoteRef:\n      key: temporal/jwt\n      property: key_id\n\n---\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: temporal-api-keys\n  namespace: temporal\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: temporal-api-keys\n    creationPolicy: Owner\n  data:\n  - secretKey: admin-api-key\n    remoteRef:\n      key: temporal/api-keys\n      property: admin_key\n  - secretKey: worker-api-key\n    remoteRef:\n      key: temporal/api-keys\n      property: worker_key\n  - secretKey: monitoring-api-key\n    remoteRef:\n      key: temporal/api-keys\n      property: monitoring_key\n</code></pre>"},{"location":"security/secrets/#2-external-service-credentials","title":"2. External Service Credentials","text":""},{"location":"security/secrets/#third-party-service-secrets","title":"Third-Party Service Secrets","text":"<pre><code># k8s/external-secrets/external-services.yaml\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: temporal-external-services\n  namespace: temporal\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: vault-backend\n    kind: SecretStore\n  target:\n    name: temporal-external-services\n    creationPolicy: Owner\n  data:\n  - secretKey: elasticsearch-username\n    remoteRef:\n      key: temporal/elasticsearch\n      property: username\n  - secretKey: elasticsearch-password\n    remoteRef:\n      key: temporal/elasticsearch\n      property: password\n  - secretKey: redis-password\n    remoteRef:\n      key: temporal/redis\n      property: password\n  - secretKey: smtp-username\n    remoteRef:\n      key: temporal/smtp\n      property: username\n  - secretKey: smtp-password\n    remoteRef:\n      key: temporal/smtp\n      property: password\n  - secretKey: webhook-signing-secret\n    remoteRef:\n      key: temporal/webhooks\n      property: signing_secret\n</code></pre>"},{"location":"security/secrets/#sealed-secrets-alternative","title":"Sealed Secrets Alternative","text":""},{"location":"security/secrets/#1-sealed-secrets-setup","title":"1. Sealed Secrets Setup","text":""},{"location":"security/secrets/#sealed-secrets-installation","title":"Sealed Secrets Installation","text":"<pre><code>#!/bin/bash\n# scripts/install-sealed-secrets.sh\n\nset -euo pipefail\n\nNAMESPACE=\"kube-system\"\nVERSION=\"v0.24.0\"\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\nlog \"Installing Sealed Secrets controller...\"\n\n# Install controller\nkubectl apply -f \"https://github.com/bitnami-labs/sealed-secrets/releases/download/${VERSION}/controller.yaml\"\n\n# Wait for deployment\nkubectl wait deployment sealed-secrets-controller -n \"$NAMESPACE\" --for=condition=Available --timeout=300s\n\n# Install kubeseal CLI\nif ! command -v kubeseal &amp;&gt; /dev/null; then\n    log \"Installing kubeseal CLI...\"\n    wget \"https://github.com/bitnami-labs/sealed-secrets/releases/download/${VERSION}/kubeseal-0.24.0-linux-amd64.tar.gz\"\n    tar xfz kubeseal-0.24.0-linux-amd64.tar.gz\n    sudo install -m 755 kubeseal /usr/local/bin/kubeseal\n    rm kubeseal kubeseal-0.24.0-linux-amd64.tar.gz\nfi\n\nlog \"\u2713 Sealed Secrets installed successfully\"\n</code></pre>"},{"location":"security/secrets/#creating-sealed-secrets","title":"Creating Sealed Secrets","text":"<pre><code>#!/bin/bash\n# scripts/create-sealed-secret.sh\n\nset -euo pipefail\n\nSECRET_NAME=\"$1\"\nNAMESPACE=\"$2\"\nKEY=\"$3\"\nVALUE=\"$4\"\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\n# Create secret and seal it\nkubectl create secret generic \"$SECRET_NAME\" \\\n    --from-literal=\"$KEY=$VALUE\" \\\n    --dry-run=client -o yaml | \\\n    kubeseal -o yaml --namespace \"$NAMESPACE\" &gt; \"sealed-${SECRET_NAME}.yaml\"\n\nlog \"\u2713 Sealed secret created: sealed-${SECRET_NAME}.yaml\"\n</code></pre>"},{"location":"security/secrets/#2-sealed-secret-examples","title":"2. Sealed Secret Examples","text":""},{"location":"security/secrets/#database-credentials-sealed-secret","title":"Database Credentials Sealed Secret","text":"<pre><code># k8s/sealed-secrets/database-credentials.yaml\napiVersion: bitnami.com/v1alpha1\nkind: SealedSecret\nmetadata:\n  name: temporal-postgres-credentials\n  namespace: temporal\nspec:\n  encryptedData:\n    username: AgBy...  # Encrypted username\n    password: AgCj...  # Encrypted password\n    host: AgAz...      # Encrypted host\n    port: AgBw...      # Encrypted port\n    database: AgDf...  # Encrypted database name\n  template:\n    metadata:\n      name: temporal-postgres-credentials\n      namespace: temporal\n    type: Opaque\n</code></pre>"},{"location":"security/secrets/#secrets-rotation-automation","title":"Secrets Rotation Automation","text":""},{"location":"security/secrets/#1-automated-rotation-script","title":"1. Automated Rotation Script","text":""},{"location":"security/secrets/#secret-rotation-workflow","title":"Secret Rotation Workflow","text":"<pre><code>#!/bin/bash\n# scripts/rotate-secrets.sh\n\nset -euo pipefail\n\nNAMESPACE=\"temporal\"\nVAULT_ADDR=\"https://vault.company.com\"\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\nerror() {\n    echo -e \"\\033[0;31m[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1\\033[0m\"\n    exit 1\n}\n\n# Function to rotate database password\nrotate_database_password() {\n    local secret_name=\"$1\"\n\n    log \"Rotating database password for secret: $secret_name\"\n\n    # Generate new password\n    local new_password=$(openssl rand -base64 32)\n\n    # Update password in Vault\n    vault kv patch secret/temporal/database password=\"$new_password\"\n\n    # Force refresh of ExternalSecret\n    kubectl annotate externalsecret \"$secret_name\" -n \"$NAMESPACE\" \\\n        force-sync=\"$(date +%s)\" --overwrite\n\n    # Wait for secret to be updated\n    kubectl wait externalsecret \"$secret_name\" -n \"$NAMESPACE\" \\\n        --for=condition=Ready --timeout=60s\n\n    log \"\u2713 Database password rotated successfully\"\n}\n\n# Function to rotate JWT signing key\nrotate_jwt_key() {\n    local secret_name=\"$1\"\n\n    log \"Rotating JWT signing key for secret: $secret_name\"\n\n    # Generate new RSA key pair\n    local private_key=$(openssl genrsa 2048)\n    local public_key=$(echo \"$private_key\" | openssl rsa -pubout)\n    local key_id=$(openssl rand -hex 8)\n\n    # Update keys in Vault\n    vault kv patch secret/temporal/jwt \\\n        signing_key=\"$private_key\" \\\n        public_key=\"$public_key\" \\\n        key_id=\"$key_id\"\n\n    # Force refresh of ExternalSecret\n    kubectl annotate externalsecret \"$secret_name\" -n \"$NAMESPACE\" \\\n        force-sync=\"$(date +%s)\" --overwrite\n\n    log \"\u2713 JWT signing key rotated successfully\"\n}\n\n# Function to restart deployments after secret rotation\nrestart_deployments() {\n    local deployments=(\"temporal-frontend\" \"temporal-history\" \"temporal-matching\" \"temporal-worker\")\n\n    for deployment in \"${deployments[@]}\"; do\n        log \"Restarting deployment: $deployment\"\n        kubectl rollout restart deployment \"$deployment\" -n \"$NAMESPACE\"\n    done\n\n    # Wait for rollouts to complete\n    for deployment in \"${deployments[@]}\"; do\n        kubectl rollout status deployment \"$deployment\" -n \"$NAMESPACE\" --timeout=300s\n    done\n\n    log \"\u2713 All deployments restarted successfully\"\n}\n\nmain() {\n    log \"Starting secrets rotation process...\"\n\n    # Check if we need to rotate based on age or policy\n    secrets_to_rotate=(\n        \"temporal-postgres-credentials\"\n        \"temporal-jwt-secrets\"\n    )\n\n    for secret in \"${secrets_to_rotate[@]}\"; do\n        case \"$secret\" in\n            \"temporal-postgres-credentials\")\n                rotate_database_password \"$secret\"\n                ;;\n            \"temporal-jwt-secrets\")\n                rotate_jwt_key \"$secret\"\n                ;;\n        esac\n    done\n\n    # Restart deployments to pick up new secrets\n    restart_deployments\n\n    log \"\u2713 Secrets rotation completed successfully\"\n}\n\nmain \"$@\"\n</code></pre>"},{"location":"security/secrets/#2-secrets-monitoring-and-alerting","title":"2. Secrets Monitoring and Alerting","text":""},{"location":"security/secrets/#secret-expiry-monitoring","title":"Secret Expiry Monitoring","text":"<pre><code># k8s/monitoring/secrets-monitor.yaml\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: external-secrets-metrics\n  namespace: external-secrets-system\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: external-secrets\n  endpoints:\n  - port: metrics\n    interval: 30s\n    path: /metrics\n\n---\napiVersion: monitoring.coreos.com/v1\nkind: PrometheusRule\nmetadata:\n  name: secrets-alerts\n  namespace: temporal\nspec:\n  groups:\n  - name: secrets-rotation\n    rules:\n    - alert: ExternalSecretSyncFailed\n      expr: external_secrets_sync_calls_error &gt; 0\n      for: 5m\n      labels:\n        severity: warning\n      annotations:\n        summary: \"External secret sync failed\"\n        description: \"External secret {{ $labels.name }} in namespace {{ $labels.namespace }} failed to sync\"\n\n    - alert: SecretRotationOverdue\n      expr: (time() - external_secrets_sync_calls_success_timestamp) &gt; 86400 * 7\n      for: 1h\n      labels:\n        severity: warning\n      annotations:\n        summary: \"Secret rotation overdue\"\n        description: \"Secret {{ $labels.name }} in namespace {{ $labels.namespace }} has not been rotated in over 7 days\"\n\n    - alert: DatabaseCredentialsExpiringSoon\n      expr: |\n        (\n          external_secrets_sync_calls_success_timestamp{name=\"temporal-postgres-credentials\"}\n          + 86400 * 30  # 30 days\n        ) - time() &lt; 86400 * 7  # 7 days warning\n      for: 1h\n      labels:\n        severity: critical\n      annotations:\n        summary: \"Database credentials expiring soon\"\n        description: \"Database credentials will expire within 7 days and need rotation\"\n</code></pre>"},{"location":"security/secrets/#security-best-practices","title":"Security Best Practices","text":""},{"location":"security/secrets/#1-secret-access-control","title":"1. Secret Access Control","text":""},{"location":"security/secrets/#rbac-for-secrets","title":"RBAC for Secrets","text":"<pre><code># k8s/rbac/secrets-rbac.yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  namespace: temporal\n  name: temporal-secrets-reader\nrules:\n- apiGroups: [\"\"]\n  resources: [\"secrets\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"external-secrets.io\"]\n  resources: [\"externalsecrets\", \"secretstores\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  namespace: temporal\n  name: temporal-secrets-admin\nrules:\n- apiGroups: [\"\"]\n  resources: [\"secrets\"]\n  verbs: [\"*\"]\n- apiGroups: [\"external-secrets.io\"]\n  resources: [\"externalsecrets\", \"secretstores\"]\n  verbs: [\"*\"]\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: temporal-service-secrets\n  namespace: temporal\nsubjects:\n- kind: ServiceAccount\n  name: temporal-server\n  namespace: temporal\nroleRef:\n  kind: Role\n  name: temporal-secrets-reader\n  apiGroup: rbac.authorization.k8s.io\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: temporal-admin-secrets\n  namespace: temporal\nsubjects:\n- kind: Group\n  name: temporal-admins\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: temporal-secrets-admin\n  apiGroup: rbac.authorization.k8s.io\n</code></pre>"},{"location":"security/secrets/#2-secrets-encryption-at-rest","title":"2. Secrets Encryption at Rest","text":""},{"location":"security/secrets/#encryptionconfiguration","title":"EncryptionConfiguration","text":"<pre><code># k8s/encryption/secrets-encryption.yaml\napiVersion: apiserver.config.k8s.io/v1\nkind: EncryptionConfiguration\nresources:\n- resources:\n  - secrets\n  providers:\n  - aescbc:\n      keys:\n      - name: key1\n        secret: &lt;base64-encoded-secret&gt;\n  - identity: {}\n</code></pre>"},{"location":"security/secrets/#3-secrets-auditing","title":"3. Secrets Auditing","text":""},{"location":"security/secrets/#audit-policy-for-secrets","title":"Audit Policy for Secrets","text":"<pre><code># k8s/audit/secrets-audit-policy.yaml\napiVersion: audit.k8s.io/v1\nkind: Policy\nrules:\n- level: RequestResponse\n  resources:\n  - group: \"\"\n    resources: [\"secrets\"]\n  verbs: [\"create\", \"update\", \"patch\", \"delete\"]\n\n- level: Request\n  resources:\n  - group: \"\"\n    resources: [\"secrets\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n\n- level: RequestResponse\n  resources:\n  - group: \"external-secrets.io\"\n    resources: [\"externalsecrets\", \"secretstores\"]\n  verbs: [\"create\", \"update\", \"patch\", \"delete\"]\n</code></pre> <p>This comprehensive secrets management guide provides enterprise-grade security for Temporal.io deployments with multiple secret store integrations, automated rotation, and comprehensive monitoring capabilities.</p>"},{"location":"security/tls/","title":"TLS Configuration","text":"<p>This guide provides comprehensive TLS configuration strategies for Temporal.io deployments, ensuring encrypted communication across all components including server-to-server, client-to-server, and database connections.</p>"},{"location":"security/tls/#overview","title":"Overview","text":"<p>TLS security in Temporal.io encompasses: - Server TLS: Securing external client connections - mTLS: Mutual TLS for service-to-service communication - Database TLS: Encrypted database connections - Certificate Management: Automated certificate lifecycle - Certificate Rotation: Secure certificate renewal processes</p>"},{"location":"security/tls/#architecture","title":"Architecture","text":"<pre><code>graph TB\n    subgraph \"Certificate Authority\"\n        ROOT_CA[Root CA]\n        INTER_CA[Intermediate CA]\n        CERT_MANAGER[Cert Manager]\n    end\n\n    subgraph \"External Load Balancer\"\n        ALB[Application Load Balancer]\n        TLS_TERM[TLS Termination]\n    end\n\n    subgraph \"Temporal Cluster\"\n        FRONTEND[Frontend Service]\n        HISTORY[History Service]\n        MATCHING[Matching Service]\n        WORKER[Worker Service]\n    end\n\n    subgraph \"Data Persistence\"\n        POSTGRES[(PostgreSQL)]\n        ELASTICSEARCH[(Elasticsearch)]\n    end\n\n    subgraph \"Clients\"\n        SDK_CLIENT[SDK Client]\n        CLI_CLIENT[CLI Client]\n        WEB_UI[Web UI]\n        APP_WORKERS[Application Workers]\n    end\n\n    ROOT_CA --&gt; INTER_CA\n    INTER_CA --&gt; CERT_MANAGER\n    CERT_MANAGER --&gt; ALB\n    CERT_MANAGER --&gt; FRONTEND\n    CERT_MANAGER --&gt; HISTORY\n    CERT_MANAGER --&gt; MATCHING\n    CERT_MANAGER --&gt; WORKER\n    CERT_MANAGER --&gt; POSTGRES\n    CERT_MANAGER --&gt; ELASTICSEARCH\n\n    SDK_CLIENT --&gt;|TLS| ALB\n    CLI_CLIENT --&gt;|TLS| ALB\n    WEB_UI --&gt;|TLS| ALB\n    APP_WORKERS --&gt;|mTLS| ALB\n\n    ALB --&gt;|mTLS| FRONTEND\n    FRONTEND --&gt;|mTLS| HISTORY\n    FRONTEND --&gt;|mTLS| MATCHING\n    FRONTEND --&gt;|mTLS| WORKER\n\n    FRONTEND --&gt;|TLS| POSTGRES\n    HISTORY --&gt;|TLS| POSTGRES\n    HISTORY --&gt;|TLS| ELASTICSEARCH</code></pre>"},{"location":"security/tls/#certificate-management","title":"Certificate Management","text":""},{"location":"security/tls/#1-certificate-authority-setup","title":"1. Certificate Authority Setup","text":""},{"location":"security/tls/#root-ca-configuration","title":"Root CA Configuration","text":"<pre><code>#!/bin/bash\n# scripts/setup-ca.sh\n\nset -euo pipefail\n\nCA_DIR=\"ca\"\nROOT_CA_KEY=\"$CA_DIR/root-ca-key.pem\"\nROOT_CA_CERT=\"$CA_DIR/root-ca-cert.pem\"\nINTER_CA_KEY=\"$CA_DIR/intermediate-ca-key.pem\"\nINTER_CA_CERT=\"$CA_DIR/intermediate-ca-cert.pem\"\nINTER_CA_CSR=\"$CA_DIR/intermediate-ca-csr.pem\"\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\nerror() {\n    echo -e \"\\033[0;31m[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1\\033[0m\"\n    exit 1\n}\n\n# Create CA directory\nmkdir -p \"$CA_DIR\"\nchmod 700 \"$CA_DIR\"\n\n# Generate Root CA private key\nif [[ ! -f \"$ROOT_CA_KEY\" ]]; then\n    log \"Generating Root CA private key...\"\n    openssl genrsa -aes256 -out \"$ROOT_CA_KEY\" 4096\n    chmod 600 \"$ROOT_CA_KEY\"\nfi\n\n# Generate Root CA certificate\nif [[ ! -f \"$ROOT_CA_CERT\" ]]; then\n    log \"Generating Root CA certificate...\"\n    cat &gt; \"$CA_DIR/root-ca.conf\" &lt;&lt; EOF\n[req]\ndistinguished_name = req_distinguished_name\nx509_extensions = v3_ca\nprompt = no\n\n[req_distinguished_name]\nC = US\nST = California\nL = San Francisco\nO = Company Name\nOU = IT Department\nCN = Company Root CA\n\n[v3_ca]\nbasicConstraints = critical,CA:TRUE\nkeyUsage = critical,keyCertSign,cRLSign\nsubjectKeyIdentifier = hash\nauthorityKeyIdentifier = keyid:always,issuer:always\nEOF\n\n    openssl req -new -x509 -key \"$ROOT_CA_KEY\" -sha256 -days 3650 \\\n        -out \"$ROOT_CA_CERT\" -config \"$CA_DIR/root-ca.conf\"\n\n    rm \"$CA_DIR/root-ca.conf\"\nfi\n\n# Generate Intermediate CA private key\nif [[ ! -f \"$INTER_CA_KEY\" ]]; then\n    log \"Generating Intermediate CA private key...\"\n    openssl genrsa -aes256 -out \"$INTER_CA_KEY\" 4096\n    chmod 600 \"$INTER_CA_KEY\"\nfi\n\n# Generate Intermediate CA certificate\nif [[ ! -f \"$INTER_CA_CERT\" ]]; then\n    log \"Generating Intermediate CA certificate...\"\n    cat &gt; \"$CA_DIR/intermediate-ca.conf\" &lt;&lt; EOF\n[req]\ndistinguished_name = req_distinguished_name\nreq_extensions = v3_intermediate_ca\nprompt = no\n\n[req_distinguished_name]\nC = US\nST = California\nL = San Francisco\nO = Company Name\nOU = IT Department\nCN = Company Intermediate CA\n\n[v3_intermediate_ca]\nbasicConstraints = critical,CA:TRUE,pathlen:0\nkeyUsage = critical,keyCertSign,cRLSign\nsubjectKeyIdentifier = hash\nauthorityKeyIdentifier = keyid:always,issuer:always\nEOF\n\n    # Create CSR for intermediate CA\n    openssl req -new -key \"$INTER_CA_KEY\" -out \"$INTER_CA_CSR\" \\\n        -config \"$CA_DIR/intermediate-ca.conf\"\n\n    # Sign intermediate CA with root CA\n    openssl x509 -req -in \"$INTER_CA_CSR\" -CA \"$ROOT_CA_CERT\" \\\n        -CAkey \"$ROOT_CA_KEY\" -CAcreateserial -out \"$INTER_CA_CERT\" \\\n        -days 1825 -extensions v3_intermediate_ca \\\n        -extfile \"$CA_DIR/intermediate-ca.conf\"\n\n    # Create certificate chain\n    cat \"$INTER_CA_CERT\" \"$ROOT_CA_CERT\" &gt; \"$CA_DIR/ca-chain.pem\"\n\n    # Clean up\n    rm \"$CA_DIR/intermediate-ca.conf\" \"$INTER_CA_CSR\"\nfi\n\nlog \"\u2713 Certificate Authority setup completed\"\nlog \"Root CA: $ROOT_CA_CERT\"\nlog \"Intermediate CA: $INTER_CA_CERT\"\nlog \"CA Chain: $CA_DIR/ca-chain.pem\"\n</code></pre>"},{"location":"security/tls/#cert-manager-integration","title":"Cert-Manager Integration","text":"<pre><code># k8s/cert-manager/cluster-issuer.yaml\napiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: temporal-ca-issuer\nspec:\n  ca:\n    secretName: temporal-ca-key-pair\n\n---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: temporal-ca-key-pair\n  namespace: cert-manager\ntype: Opaque\ndata:\n  tls.crt: LS0tLS1CRUdJTi... # Base64 encoded intermediate CA cert\n  tls.key: LS0tLS1CRUdJTi... # Base64 encoded intermediate CA key\n\n---\napiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-production\nspec:\n  acme:\n    server: https://acme-v02.api.letsencrypt.org/directory\n    email: admin@company.com\n    privateKeySecretRef:\n      name: letsencrypt-production\n    solvers:\n    - http01:\n        ingress:\n          class: alb\n    - dns01:\n        route53:\n          region: us-west-2\n          accessKeyID: AKIAIOSFODNN7EXAMPLE\n          secretAccessKeySecretRef:\n            name: route53-credentials\n            key: secret-access-key\n</code></pre>"},{"location":"security/tls/#2-server-tls-configuration","title":"2. Server TLS Configuration","text":""},{"location":"security/tls/#frontend-service-tls","title":"Frontend Service TLS","text":"<pre><code># config/frontend-tls.yaml\ntls:\n  frontend:\n    server:\n      certFile: \"/etc/temporal/certs/server.crt\"\n      keyFile: \"/etc/temporal/certs/server.key\"\n      clientCaFiles:\n        - \"/etc/temporal/certs/ca-chain.pem\"\n      requireClientAuth: false  # For external clients\n      cipherSuites:\n        - \"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\"\n        - \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\"\n        - \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\"\n        - \"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\"\n      minVersion: \"1.2\"\n      maxVersion: \"1.3\"\n\n  # Alternative configuration for client certificate authentication\n  frontend_mtls:\n    server:\n      certFile: \"/etc/temporal/certs/server.crt\"\n      keyFile: \"/etc/temporal/certs/server.key\"\n      clientCaFiles:\n        - \"/etc/temporal/certs/ca-chain.pem\"\n      requireClientAuth: true   # For mTLS clients\n      clientCertPolicy: \"RequireAndVerifyClientCert\"\n</code></pre>"},{"location":"security/tls/#certificate-request-template","title":"Certificate Request Template","text":"<pre><code># k8s/certificates/server-cert.yaml\napiVersion: cert-manager.io/v1\nkind: Certificate\nmetadata:\n  name: temporal-server-cert\n  namespace: temporal\nspec:\n  secretName: temporal-server-tls\n  issuerRef:\n    name: temporal-ca-issuer\n    kind: ClusterIssuer\n  commonName: temporal.company.com\n  dnsNames:\n  - temporal.company.com\n  - temporal-frontend\n  - temporal-frontend.temporal.svc.cluster.local\n  - temporal-history\n  - temporal-history.temporal.svc.cluster.local\n  - temporal-matching\n  - temporal-matching.temporal.svc.cluster.local\n  - temporal-worker\n  - temporal-worker.temporal.svc.cluster.local\n  ipAddresses:\n  - 127.0.0.1\n  usages:\n  - digital signature\n  - key encipherment\n  - server auth\n  duration: 8760h  # 1 year\n  renewBefore: 720h  # 30 days\n</code></pre>"},{"location":"security/tls/#3-mutual-tls-mtls-configuration","title":"3. Mutual TLS (mTLS) Configuration","text":""},{"location":"security/tls/#inter-service-communication","title":"Inter-Service Communication","text":"<pre><code># config/internode-mtls.yaml\ntls:\n  internode:\n    server:\n      certFile: \"/etc/temporal/certs/internode.crt\"\n      keyFile: \"/etc/temporal/certs/internode.key\"\n      clientCaFiles:\n        - \"/etc/temporal/certs/ca-chain.pem\"\n      requireClientAuth: true\n      clientCertPolicy: \"RequireAndVerifyClientCert\"\n    client:\n      certFile: \"/etc/temporal/certs/internode.crt\"\n      keyFile: \"/etc/temporal/certs/internode.key\"\n      serverCaFiles:\n        - \"/etc/temporal/certs/ca-chain.pem\"\n      serverName: \"temporal.company.com\"\n      insecureSkipVerify: false\n</code></pre>"},{"location":"security/tls/#client-certificate-configuration","title":"Client Certificate Configuration","text":"<pre><code># k8s/certificates/client-cert.yaml\napiVersion: cert-manager.io/v1\nkind: Certificate\nmetadata:\n  name: temporal-client-cert\n  namespace: temporal\nspec:\n  secretName: temporal-client-tls\n  issuerRef:\n    name: temporal-ca-issuer\n    kind: ClusterIssuer\n  commonName: temporal-client\n  usages:\n  - digital signature\n  - key encipherment\n  - client auth\n  duration: 2160h  # 90 days\n  renewBefore: 168h  # 7 days\n\n---\napiVersion: cert-manager.io/v1\nkind: Certificate\nmetadata:\n  name: temporal-worker-cert\n  namespace: temporal\nspec:\n  secretName: temporal-worker-tls\n  issuerRef:\n    name: temporal-ca-issuer\n    kind: ClusterIssuer\n  commonName: temporal-worker\n  usages:\n  - digital signature\n  - key encipherment\n  - client auth\n  duration: 2160h  # 90 days\n  renewBefore: 168h  # 7 days\n</code></pre>"},{"location":"security/tls/#database-tls-configuration","title":"Database TLS Configuration","text":""},{"location":"security/tls/#1-postgresql-tls-setup","title":"1. PostgreSQL TLS Setup","text":""},{"location":"security/tls/#database-tls-configuration_1","title":"Database TLS Configuration","text":"<pre><code># config/database-tls.yaml\npersistence:\n  default:\n    sql:\n      driver: \"postgres\"\n      datasourceName: \"postgres://temporal:${POSTGRES_PASSWORD}@postgres.company.com:5432/temporal?sslmode=require\"\n      tls:\n        enabled: true\n        caFile: \"/etc/temporal/certs/postgres-ca.crt\"\n        certFile: \"/etc/temporal/certs/postgres-client.crt\"\n        keyFile: \"/etc/temporal/certs/postgres-client.key\"\n        serverName: \"postgres.company.com\"\n        insecureSkipVerify: false\n\n  visibility:\n    sql:\n      driver: \"postgres\"\n      datasourceName: \"postgres://temporal:${POSTGRES_PASSWORD}@postgres.company.com:5432/temporal_visibility?sslmode=require\"\n      tls:\n        enabled: true\n        caFile: \"/etc/temporal/certs/postgres-ca.crt\"\n        certFile: \"/etc/temporal/certs/postgres-client.crt\"\n        keyFile: \"/etc/temporal/certs/postgres-client.key\"\n        serverName: \"postgres.company.com\"\n</code></pre>"},{"location":"security/tls/#postgresql-server-configuration","title":"PostgreSQL Server Configuration","text":"<pre><code># postgresql.conf\nssl = on\nssl_ca_file = '/etc/postgresql/certs/ca-chain.pem'\nssl_cert_file = '/etc/postgresql/certs/server.crt'\nssl_key_file = '/etc/postgresql/certs/server.key'\nssl_ciphers = 'ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384'\nssl_prefer_server_ciphers = on\nssl_protocols = 'TLSv1.2,TLSv1.3'\n\n# Client certificate authentication\nssl_client_ca_file = '/etc/postgresql/certs/ca-chain.pem'\n</code></pre>"},{"location":"security/tls/#2-elasticsearch-tls-setup","title":"2. Elasticsearch TLS Setup","text":""},{"location":"security/tls/#elasticsearch-tls-configuration","title":"Elasticsearch TLS Configuration","text":"<pre><code># config/elasticsearch-tls.yaml\ncluster:\n  metadata:\n    elasticsearch:\n      version: \"v7\"\n      url:\n        scheme: \"https\"\n        host: \"elasticsearch.company.com:9200\"\n      username: \"temporal\"\n      password: \"${ELASTICSEARCH_PASSWORD}\"\n      closeIdleConnectionsInterval: 15s\n      tls:\n        enabled: true\n        caFile: \"/etc/temporal/certs/elasticsearch-ca.crt\"\n        certFile: \"/etc/temporal/certs/elasticsearch-client.crt\"\n        keyFile: \"/etc/temporal/certs/elasticsearch-client.key\"\n        serverName: \"elasticsearch.company.com\"\n        insecureSkipVerify: false\n</code></pre>"},{"location":"security/tls/#kubernetes-tls-integration","title":"Kubernetes TLS Integration","text":""},{"location":"security/tls/#1-tls-secret-management","title":"1. TLS Secret Management","text":"<pre><code># k8s/tls-secrets.yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: temporal-server-tls\n  namespace: temporal\ntype: kubernetes.io/tls\ndata:\n  tls.crt: LS0tLS1CRUdJTi... # Server certificate\n  tls.key: LS0tLS1CRUdJTi... # Server private key\n  ca.crt: LS0tLS1CRUdJTi...  # CA chain\n\n---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: temporal-client-tls\n  namespace: temporal\ntype: kubernetes.io/tls\ndata:\n  tls.crt: LS0tLS1CRUdJTi... # Client certificate\n  tls.key: LS0tLS1CRUdJTi... # Client private key\n  ca.crt: LS0tLS1CRUdJTi...  # CA chain\n\n---\napiVersion: v1\nkind: Secret\nmetadata:\n  name: temporal-database-tls\n  namespace: temporal\ntype: Opaque\ndata:\n  ca.crt: LS0tLS1CRUdJTi...     # Database CA\n  client.crt: LS0tLS1CRUdJTi... # Database client cert\n  client.key: LS0tLS1CRUdJTi... # Database client key\n</code></pre>"},{"location":"security/tls/#2-deployment-configuration","title":"2. Deployment Configuration","text":"<pre><code># k8s/temporal-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: temporal-frontend\n  namespace: temporal\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: temporal-frontend\n  template:\n    metadata:\n      labels:\n        app: temporal-frontend\n    spec:\n      serviceAccountName: temporal-server\n      containers:\n      - name: temporal\n        image: temporalio/auto-setup:1.22.0\n        ports:\n        - containerPort: 7233\n          name: rpc\n        - containerPort: 7234\n          name: membership\n        volumeMounts:\n        - name: server-certs\n          mountPath: /etc/temporal/certs\n          readOnly: true\n        - name: config\n          mountPath: /etc/temporal/config\n        env:\n        - name: SERVICES\n          value: \"frontend\"\n        - name: TLS_CONFIG_FILE\n          value: \"/etc/temporal/config/tls.yaml\"\n        resources:\n          requests:\n            memory: 1Gi\n            cpu: 500m\n          limits:\n            memory: 2Gi\n            cpu: 1000m\n      volumes:\n      - name: server-certs\n        secret:\n          secretName: temporal-server-tls\n      - name: config\n        configMap:\n          name: temporal-config\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: temporal-frontend\n  namespace: temporal\n  annotations:\n    service.beta.kubernetes.io/aws-load-balancer-ssl-cert: arn:aws:acm:us-west-2:ACCOUNT:certificate/CERT-ID\n    service.beta.kubernetes.io/aws-load-balancer-backend-protocol: ssl\n    service.beta.kubernetes.io/aws-load-balancer-ssl-ports: \"443\"\nspec:\n  type: LoadBalancer\n  ports:\n  - port: 443\n    targetPort: 7233\n    protocol: TCP\n    name: rpc-tls\n  selector:\n    app: temporal-frontend\n</code></pre>"},{"location":"security/tls/#3-ingress-tls-configuration","title":"3. Ingress TLS Configuration","text":"<pre><code># k8s/ingress.yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: temporal-ingress\n  namespace: temporal\n  annotations:\n    kubernetes.io/ingress.class: alb\n    alb.ingress.kubernetes.io/scheme: internet-facing\n    alb.ingress.kubernetes.io/target-type: ip\n    alb.ingress.kubernetes.io/listen-ports: '[{\"HTTP\": 80}, {\"HTTPS\": 443}]'\n    alb.ingress.kubernetes.io/ssl-redirect: \"443\"\n    alb.ingress.kubernetes.io/certificate-arn: arn:aws:acm:us-west-2:ACCOUNT:certificate/CERT-ID\n    alb.ingress.kubernetes.io/backend-protocol: HTTPS\n    alb.ingress.kubernetes.io/backend-protocol-version: GRPC\n    cert-manager.io/cluster-issuer: temporal-ca-issuer\nspec:\n  tls:\n  - hosts:\n    - temporal.company.com\n    secretName: temporal-ingress-tls\n  rules:\n  - host: temporal.company.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: temporal-frontend\n            port:\n              number: 443\n</code></pre>"},{"location":"security/tls/#client-sdk-tls-configuration","title":"Client SDK TLS Configuration","text":""},{"location":"security/tls/#1-go-sdk-configuration","title":"1. Go SDK Configuration","text":"<pre><code>// client/tls-client.go\npackage client\n\nimport (\n    \"crypto/tls\"\n    \"crypto/x509\"\n    \"fmt\"\n    \"io/ioutil\"\n\n    \"go.temporal.io/sdk/client\"\n)\n\ntype TLSConfig struct {\n    ServerName   string\n    CertFile     string\n    KeyFile      string\n    CaFile       string\n    InsecureSkip bool\n}\n\nfunc NewTLSClient(hostPort, namespace string, tlsConfig TLSConfig) (client.Client, error) {\n    var tlsConf *tls.Config\n\n    if tlsConfig.CertFile != \"\" &amp;&amp; tlsConfig.KeyFile != \"\" {\n        // Client certificate authentication\n        cert, err := tls.LoadX509KeyPair(tlsConfig.CertFile, tlsConfig.KeyFile)\n        if err != nil {\n            return nil, fmt.Errorf(\"failed to load client certificates: %w\", err)\n        }\n\n        tlsConf = &amp;tls.Config{\n            Certificates: []tls.Certificate{cert},\n            ServerName:   tlsConfig.ServerName,\n        }\n    } else {\n        // Server verification only\n        tlsConf = &amp;tls.Config{\n            ServerName: tlsConfig.ServerName,\n        }\n    }\n\n    // Load CA certificates\n    if tlsConfig.CaFile != \"\" {\n        caCert, err := ioutil.ReadFile(tlsConfig.CaFile)\n        if err != nil {\n            return nil, fmt.Errorf(\"failed to read CA file: %w\", err)\n        }\n\n        caCertPool := x509.NewCertPool()\n        if !caCertPool.AppendCertsFromPEM(caCert) {\n            return nil, fmt.Errorf(\"failed to parse CA certificate\")\n        }\n\n        tlsConf.RootCAs = caCertPool\n    }\n\n    tlsConf.InsecureSkipVerify = tlsConfig.InsecureSkip\n\n    return client.Dial(client.Options{\n        HostPort:  hostPort,\n        Namespace: namespace,\n        ConnectionOptions: client.ConnectionOptions{\n            TLS: tlsConf,\n        },\n    })\n}\n\n// Example usage\nfunc ExampleTLSClient() (client.Client, error) {\n    return NewTLSClient(\"temporal.company.com:443\", \"default\", TLSConfig{\n        ServerName: \"temporal.company.com\",\n        CertFile:   \"/etc/temporal/certs/client.crt\",\n        KeyFile:    \"/etc/temporal/certs/client.key\",\n        CaFile:     \"/etc/temporal/certs/ca-chain.pem\",\n    })\n}\n</code></pre>"},{"location":"security/tls/#2-java-sdk-configuration","title":"2. Java SDK Configuration","text":"<pre><code>// TLSClientFactory.java\npackage com.company.temporal.client;\n\nimport io.temporal.client.WorkflowClient;\nimport io.temporal.client.WorkflowClientOptions;\nimport io.temporal.serviceclient.WorkflowServiceStubs;\nimport io.temporal.serviceclient.WorkflowServiceStubsOptions;\n\nimport javax.net.ssl.KeyManagerFactory;\nimport javax.net.ssl.SSLContext;\nimport javax.net.ssl.TrustManagerFactory;\nimport java.io.FileInputStream;\nimport java.security.KeyStore;\n\npublic class TLSClientFactory {\n\n    public static WorkflowClient createTLSClient(String hostPort, String namespace, TLSConfiguration config) \n            throws Exception {\n\n        SSLContext sslContext = createSSLContext(config);\n\n        WorkflowServiceStubsOptions serviceOptions = WorkflowServiceStubsOptions.newBuilder()\n                .setTarget(hostPort)\n                .setSslContext(sslContext)\n                .build();\n\n        WorkflowServiceStubs service = WorkflowServiceStubs.newServiceStubs(serviceOptions);\n\n        WorkflowClientOptions clientOptions = WorkflowClientOptions.newBuilder()\n                .setNamespace(namespace)\n                .build();\n\n        return WorkflowClient.newInstance(service, clientOptions);\n    }\n\n    private static SSLContext createSSLContext(TLSConfiguration config) throws Exception {\n        SSLContext sslContext = SSLContext.getInstance(\"TLS\");\n\n        // Load truststore (CA certificates)\n        KeyStore trustStore = KeyStore.getInstance(\"JKS\");\n        trustStore.load(new FileInputStream(config.getTrustStorePath()), \n                       config.getTrustStorePassword().toCharArray());\n\n        TrustManagerFactory trustManagerFactory = TrustManagerFactory.getInstance(\n                TrustManagerFactory.getDefaultAlgorithm());\n        trustManagerFactory.init(trustStore);\n\n        // Load keystore (client certificates) if available\n        KeyManagerFactory keyManagerFactory = null;\n        if (config.getKeyStorePath() != null) {\n            KeyStore keyStore = KeyStore.getInstance(\"JKS\");\n            keyStore.load(new FileInputStream(config.getKeyStorePath()), \n                         config.getKeyStorePassword().toCharArray());\n\n            keyManagerFactory = KeyManagerFactory.getInstance(\n                    KeyManagerFactory.getDefaultAlgorithm());\n            keyManagerFactory.init(keyStore, config.getKeyStorePassword().toCharArray());\n        }\n\n        sslContext.init(\n                keyManagerFactory != null ? keyManagerFactory.getKeyManagers() : null,\n                trustManagerFactory.getTrustManagers(),\n                null\n        );\n\n        return sslContext;\n    }\n}\n\nclass TLSConfiguration {\n    private String trustStorePath;\n    private String trustStorePassword;\n    private String keyStorePath;\n    private String keyStorePassword;\n\n    // Getters and setters\n    public String getTrustStorePath() { return trustStorePath; }\n    public void setTrustStorePath(String trustStorePath) { this.trustStorePath = trustStorePath; }\n\n    public String getTrustStorePassword() { return trustStorePassword; }\n    public void setTrustStorePassword(String trustStorePassword) { this.trustStorePassword = trustStorePassword; }\n\n    public String getKeyStorePath() { return keyStorePath; }\n    public void setKeyStorePath(String keyStorePath) { this.keyStorePath = keyStorePath; }\n\n    public String getKeyStorePassword() { return keyStorePassword; }\n    public void setKeyStorePassword(String keyStorePassword) { this.keyStorePassword = keyStorePassword; }\n}\n</code></pre>"},{"location":"security/tls/#certificate-rotation","title":"Certificate Rotation","text":""},{"location":"security/tls/#1-automated-certificate-rotation","title":"1. Automated Certificate Rotation","text":"<pre><code>#!/bin/bash\n# scripts/rotate-certificates.sh\n\nset -euo pipefail\n\nNAMESPACE=\"temporal\"\nCERT_MANAGER_NAMESPACE=\"cert-manager\"\n\nlog() {\n    echo -e \"\\033[0;32m[$(date +'%Y-%m-%d %H:%M:%S')] $1\\033[0m\"\n}\n\nerror() {\n    echo -e \"\\033[0;31m[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1\\033[0m\"\n    exit 1\n}\n\n# Function to trigger certificate renewal\nrenew_certificate() {\n    local cert_name=\"$1\"\n    local namespace=\"$2\"\n\n    log \"Renewing certificate: $cert_name in namespace: $namespace\"\n\n    # Annotate certificate to trigger renewal\n    kubectl annotate certificate \"$cert_name\" -n \"$namespace\" \\\n        cert-manager.io/issue-temporary-certificate=\"$(date +%s)\" --overwrite\n\n    # Wait for renewal to complete\n    kubectl wait certificate \"$cert_name\" -n \"$namespace\" \\\n        --for=condition=Ready --timeout=300s\n\n    log \"\u2713 Certificate $cert_name renewed successfully\"\n}\n\n# Function to restart deployments after certificate renewal\nrestart_deployment() {\n    local deployment=\"$1\"\n    local namespace=\"$2\"\n\n    log \"Restarting deployment: $deployment\"\n\n    kubectl rollout restart deployment \"$deployment\" -n \"$namespace\"\n    kubectl rollout status deployment \"$deployment\" -n \"$namespace\" --timeout=300s\n\n    log \"\u2713 Deployment $deployment restarted successfully\"\n}\n\n# Check certificate expiration\ncheck_certificate_expiration() {\n    local cert_name=\"$1\"\n    local namespace=\"$2\"\n\n    local cert_info=$(kubectl get certificate \"$cert_name\" -n \"$namespace\" -o json)\n    local not_after=$(echo \"$cert_info\" | jq -r '.status.notAfter')\n\n    if [[ \"$not_after\" != \"null\" ]]; then\n        local expiry_date=$(date -d \"$not_after\" +%s)\n        local current_date=$(date +%s)\n        local days_until_expiry=$(( (expiry_date - current_date) / 86400 ))\n\n        log \"Certificate $cert_name expires in $days_until_expiry days\"\n\n        # Renew if expires within 30 days\n        if [[ $days_until_expiry -lt 30 ]]; then\n            log \"Certificate $cert_name is due for renewal\"\n            return 0\n        fi\n    fi\n\n    return 1\n}\n\nmain() {\n    log \"Starting certificate rotation process...\"\n\n    # List of certificates to check and potentially renew\n    certificates=(\n        \"temporal-server-cert:$NAMESPACE\"\n        \"temporal-client-cert:$NAMESPACE\"\n        \"temporal-worker-cert:$NAMESPACE\"\n        \"temporal-database-cert:$NAMESPACE\"\n    )\n\n    # Check and renew certificates\n    for cert_entry in \"${certificates[@]}\"; do\n        IFS=':' read -r cert_name cert_namespace &lt;&lt;&lt; \"$cert_entry\"\n\n        if check_certificate_expiration \"$cert_name\" \"$cert_namespace\"; then\n            renew_certificate \"$cert_name\" \"$cert_namespace\"\n\n            # Restart relevant deployments\n            case \"$cert_name\" in\n                \"temporal-server-cert\")\n                    restart_deployment \"temporal-frontend\" \"$NAMESPACE\"\n                    restart_deployment \"temporal-history\" \"$NAMESPACE\"\n                    restart_deployment \"temporal-matching\" \"$NAMESPACE\"\n                    restart_deployment \"temporal-worker\" \"$NAMESPACE\"\n                    ;;\n                \"temporal-client-cert\")\n                    # Restart client applications\n                    restart_deployment \"temporal-worker\" \"$NAMESPACE\"\n                    ;;\n                \"temporal-worker-cert\")\n                    restart_deployment \"temporal-worker\" \"$NAMESPACE\"\n                    ;;\n                \"temporal-database-cert\")\n                    # Restart all services that connect to database\n                    restart_deployment \"temporal-frontend\" \"$NAMESPACE\"\n                    restart_deployment \"temporal-history\" \"$NAMESPACE\"\n                    ;;\n            esac\n        fi\n    done\n\n    log \"\u2713 Certificate rotation process completed\"\n}\n\nmain \"$@\"\n</code></pre>"},{"location":"security/tls/#2-certificate-monitoring","title":"2. Certificate Monitoring","text":"<pre><code># k8s/monitoring/certificate-monitor.yaml\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: cert-manager-metrics\n  namespace: cert-manager\nspec:\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: cert-manager\n  endpoints:\n  - port: http-metrics\n    interval: 30s\n    path: /metrics\n\n---\napiVersion: monitoring.coreos.com/v1\nkind: PrometheusRule\nmetadata:\n  name: certificate-expiry-alerts\n  namespace: cert-manager\nspec:\n  groups:\n  - name: certificate-expiry\n    rules:\n    - alert: CertificateExpiringSoon\n      expr: certmanager_certificate_expiration_timestamp_seconds - time() &lt; 7 * 24 * 3600\n      for: 1h\n      labels:\n        severity: warning\n      annotations:\n        summary: \"Certificate {{ $labels.name }} in namespace {{ $labels.namespace }} is expiring soon\"\n        description: \"Certificate {{ $labels.name }} in namespace {{ $labels.namespace }} will expire in less than 7 days\"\n\n    - alert: CertificateExpired\n      expr: certmanager_certificate_expiration_timestamp_seconds - time() &lt;= 0\n      for: 0m\n      labels:\n        severity: critical\n      annotations:\n        summary: \"Certificate {{ $labels.name }} in namespace {{ $labels.namespace }} has expired\"\n        description: \"Certificate {{ $labels.name }} in namespace {{ $labels.namespace }} has expired and needs immediate attention\"\n</code></pre> <p>This comprehensive TLS configuration guide provides enterprise-grade encryption and certificate management for Temporal.io deployments, ensuring secure communication across all components with automated certificate lifecycle management.</p>"}]}